---
emoji: 😁
title: Regression 회귀
date: '2022-04-18 23:00:00'
author: 하성민
tags: blog gatsby theme 개츠비 테마
categories: beginner
---

# <span style='background-color: #aaf5b1'>선형회귀</span>

## 목차
1. 분류와 회귀
2. 로지스틱 회귀 (Logistic Regression)
3. SoftMax / Cross Entrophy

오늘날 회귀분석이란 단순히 평균으로 수렴하는 현상을 넘어서서, 두 개 이상의 변수 사이의 함수관계를 추구하는 통계적 방법을 의미하게 됩니다.

선형 회귀분석(linear regression) 두 변수 사이의 관계를 직선 형태로 가정하고 분석 

선형 회귀분석을 해볼만하겠다 싶은 기본가정 내에 들어오면 분석을 해보면 된다.

* 선형성
* 독립성 (다중 회귀분석 시) (독립변수 x들 간에 상관관계가가 없는 성질)
* 등분산성 (분산이 일정한지)
* 정규성 (잔차가 정규분포를 띄는지)

#### 분류와 회귀가 다른 점

분류 : 해당 데이터의 class Y 를 추론 (a일지 b일지) 추론
회귀 : 해당 데이터 y의 정확한 값(2.45, 17.2874 등) 을 추론

---

회귀분석은 

독립변수 x 로 종속변수 y 의 상관관계를 모델링한다.

독립변수 x 가 하나면 단순회귀분석  
여러개면 다중회귀분석 이라고 한다.

---

y = bx + c

b : 회귀계수
c : 오차(파라미터)

머신러닝에선 기호를 조금 다르게 가져간다.  

H = Wx + b  

H = 가정  
W = 가중치  
b = bias  

대부분 W 와 b 는 고차원의 matrix 이다

---

잔차 : Residuals 회귀모델을 이용해 추정한 값과 실제 데이터의 차이

최소제곱법 : '잔차를 다 제곱해서 합한거' 를 젤 작게 하는 거(손실함수)

결정계수 (R-squared, R2 score) 0~1 값, 1일 수록 모델이 좋은거


---

## Logistic regression

: 데이터가 범주에 속할 확률을 0~1의 값으로 예측하고,  
확률에 따라 가장 가능성있는 class 로 분류하는 분류 지도 학습 모델  

선형회귀와 달리 y값이 0~1로만 나온다

이진 분류 문제를 풀 때 많이 사용한다.

Odds = 사건이 발생할 확률을 발생하지 않을 확률로 나눈 값

Log-Odds = Odds 에 log 취한 값인데 이걸 선형회귀분석의 종속변수처럼 구하면 된다.

이걸로 회귀계수(b) 를 구할 수 있다.

<img src="./1.PNG"></img>

결국 logistic 회귀는 시그모이드 함수였던 것이다~

로지스틱 회귀는 결국 Log-Odds 값을 sigmoid에 넣어서
0~1 사이의 값을 구하는 모델인 것이다.

여기서 우리가 threshold (기준값)을 설정해주면, 그 기준값 기준으로
0 또는 1로 바로 출력해준다.

---

## 진짜 짱중요 softmax / cross entrophy 

이게 이진분류에 쓰이는 logistic 함수는  

다중분류에도 쓰일 수 있는데

그러면 시그모이드 말고 **softmax 함수** 를 사용해야 한다.


함수식을 자세히 보면 이는 각 범주의 확률 값이 0에서 1 사이의 값이고, 또 하나의 큰 특징은 모든 범주에 해당하는 softmax의 값을 전부 더했을 때 그 합이 1이 된다는 것입니다. 또한 softmax 함수는 큰 log-odds와 작은 log-odds의 차이를 극대화시켜줍니다. 그렇기 때문에 마지막에 softmax 함수에 모든 범주의 log-odds를 통과시키면 해당 데이터가 어떤 범주로 분류되는지 확실히 알 수 있게 되는데, 가장 큰 값을 1, 그 외 나머지 값들을 0으로 인코딩하는 one-hot encoding을 통해 표현하게 됩니다.

---

cross Entrophy 함수는

위  softmax 함수의 손실 함수로 쓰인다.

선형회귀에서는 오차제곱법이 손실함수로 쓰였던 것 처럼

크로스 엔트로피는 로지스틱 회귀가 추론한 확률분포(q)와 실제 확률분포(p) 간의 종합적인 차이를 계산한다.  

이 차이가 적을수록 cross Entrophy는 작아진다.

---

정리

||선형회귀|로지스틱회귀|다중로지스틱회귀|
|---|---|---|---|
|풀고자하는문제|독립변수x와 종속변수 y|종속변수가 2개(이진분류)|종속변수가 여러개|
|사용되는 함수|최소제곱법|시그모이드, logOdds|크로스엔트로피, 소프트맥스|
|손실함수|최소제곱법|크로스엔트로피|크로스엔트로피|크로스엔트로피


```python

```
