{
    "componentChunkName": "component---src-templates-blog-template-js",
    "path": "/DML_AI1/",
    "result": {"data":{"cur":{"id":"178ea2b3-2dfd-599d-86ad-b2669c612f60","html":"<h1 id=\"span-stylebackground-color-fff4f5인공지능-기초-️-사진-분류-프로그램-맛보기span\" style=\"position:relative;\"><a href=\"#span-stylebackground-color-fff4f5%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-%EA%B8%B0%EC%B4%88-%EF%B8%8F-%EC%82%AC%EC%A7%84-%EB%B6%84%EB%A5%98-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%A8-%EB%A7%9B%EB%B3%B4%EA%B8%B0span\" aria-label=\"span stylebackground color fff4f5인공지능 기초 ️ 사진 분류 프로그램 맛보기span permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><span style='background-color: #fff4f5'>인공지능 기초 🚶‍♂️: 사진 분류 프로그램 맛보기</span></h1>\n<h2 id=\"강아지--고양이-분류-프로그램-제작-\" style=\"position:relative;\"><a href=\"#%EA%B0%95%EC%95%84%EC%A7%80--%EA%B3%A0%EC%96%91%EC%9D%B4-%EB%B6%84%EB%A5%98-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%A8-%EC%A0%9C%EC%9E%91-\" aria-label=\"강아지  고양이 분류 프로그램 제작  permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>강아지 &#x26; 고양이 분류 프로그램 제작 !</h2>\n<h3 id=\"content\" style=\"position:relative;\"><a href=\"#content\" aria-label=\"content permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Content</h3>\n<ol>\n<li>데이터 불러오기 (Tensor Flow)</li>\n<li>데이터 전처리</li>\n<li>모델 생성 (자체 생성 모델)</li>\n<li>학습 및 평가</li>\n</ol>\n<p><strong>시작하기에 앞서, 이번 게시글은<br>\n전체적인 인공지능 적용에 대한 맥락을 설명하기 위한 글입니다.<br>\n아주 간단한 Deep Learning Layer 몇 종류를 이용했습니다.</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>__version__ <span class=\"token punctuation\">,</span> <span class=\"token string\">'이미지 분류 모델을 만들 라이브러리 tensor flow 입니다'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">2.6.0 이미지 분류 모델을 만들 라이브러리 tensor flow 입니다</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow_datasets <span class=\"token keyword\">as</span> tfds\n\ntfds<span class=\"token punctuation\">.</span>__version__</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">'4.4.0'</code></pre></div>\n<p>tensor flow 에서는 다양한 데이터셋을 이미 제공하고 있다.<br>\n강아지고양이, 음성, 이미지, 텍스트 데이터셋 보유하고 있으니 세부 내용 확인해보고 싶음 해보기</p>\n<p><a href=\"https://www.tensorflow.org/datasets/catalog/overview\">tensor flow link</a></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token punctuation\">(</span>raw_train<span class=\"token punctuation\">,</span> raw_validation<span class=\"token punctuation\">,</span> raw_test<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> metadata <span class=\"token operator\">=</span> tfds<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span>\n    <span class=\"token string\">'cats_vs_dogs'</span><span class=\"token punctuation\">,</span>\n    split<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'train[:80%]'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'train[80%:90%]'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'train[90%:]'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n    with_info<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n    as_supervised<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">\u001b[1mDownloading and preparing dataset 786.68 MiB (download: 786.68 MiB, generated: Unknown size, total: 786.68 MiB) to /aiffel/tensorflow_datasets/cats_vs_dogs/4.0.0...\u001b[0m\n\n\n\nDl Completed...: 0 url [00:00, ? url/s]\n\n\n\nDl Size...: 0 MiB [00:00, ? MiB/s]\n\n\n\nGenerating splits...:   0%|          | 0/1 [00:00&lt;?, ? splits/s]\n\n\n\nGenerating train examples...:   0%|          | 0/23262 [00:00&lt;?, ? examples/s]\n\n\nWARNING:absl:1738 images were corrupted and were skipped\n\n\n\nShuffling cats_vs_dogs-train.tfrecord...:   0%|          | 0/23262 [00:00&lt;?, ? examples/s]\n\n\n\u001b[1mDataset cats_vs_dogs downloaded and prepared to /aiffel/tensorflow_datasets/cats_vs_dogs/4.0.0. Subsequent calls will reuse this data.\u001b[0m</code></pre></div>\n<hr>\n<p>“WARNING:absl:1738 images were corrupted and were skipped”라는 경고가 나타날 수 있습니다. 우선 무시하시면 됩니다.<br>\n1738 장의 사진은 쓸 수 없다는 뜻입니다.<br>\n이런 것들은 tf 사이트 데이터셋 설명에서 확인 가능합니다</p>\n<p><img src=\"/a0b5d21d105e7623091003cd8f24e715/1.png\" alt=\"PNG\"></p>\n<p>1738이 currupted 되어있다 되어있져?<br>\n그리고 밑에 Split을 보면 23262 장의 사진이 있음을 확인 가능합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>raw_train<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>raw_validation<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>raw_test<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">&lt;PrefetchDataset shapes: ((None, None, 3), ()), types: (tf.uint8, tf.int64)>\n&lt;PrefetchDataset shapes: ((None, None, 3), ()), types: (tf.uint8, tf.int64)>\n&lt;PrefetchDataset shapes: ((None, None, 3), ()), types: (tf.uint8, tf.int64)></code></pre></div>\n<p>잘 변수로 지정되어있음을 알 수 있다.</p>\n<p>모든 데이터셋은 (image, label)의 형태를 가집니다.<br>\n((None, None, 3), ())가 이를 나타내죠.</p>\n<p>여기에서 앞에 있는 (None, None, 3)은 image의 shape를,<br>\n뒤의 ()는 정답 카테고리인 label의 shape를 의미합니다.</p>\n<p>이미지는 (height, width, channel)로 3차원 데이터이기 때문에<br>\n(None, None, 3)과 같이 나타났습니다.</p>\n<p>이때 height와 width가 None으로 나타난 이유는<br>\n모든 사진들의 크기가 제각각이기 때문입니다.<br>\n하나의 값으로 나타낼 수 없으니 None 으로 표기됩니다.</p>\n<h2 id=\"1-데이터-전처리\" style=\"position:relative;\"><a href=\"#1-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%84%EC%B2%98%EB%A6%AC\" aria-label=\"1 데이터 전처리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. 데이터 전처리</h2>\n<p>자 데이터를 불러왔으니 깔끔하게 처리해야지</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt\n<span class=\"token operator\">%</span>matplotlib inline\n<span class=\"token operator\">%</span>config InlineBackend<span class=\"token punctuation\">.</span>figure_format <span class=\"token operator\">=</span> <span class=\"token string\">'retina'</span></code></pre></div>\n<p>데이터를 어떻게 처리할지 고민하기 위해서 우리가 가져온 데이터를<br>\n스리슬쩍 들여다 보자.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">plt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\">#전체 칸바스 크기</span>\n\nget_label_name <span class=\"token operator\">=</span> metadata<span class=\"token punctuation\">.</span>features<span class=\"token punctuation\">[</span><span class=\"token string\">'label'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>int2str \n\n<span class=\"token keyword\">for</span> idx<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> label<span class=\"token punctuation\">)</span> <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>raw_train<span class=\"token punctuation\">.</span>take<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>  <span class=\"token comment\"># 10개의 데이터를 따로 가져 옵니다.</span>\n    plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">,</span> idx<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token comment\">#10개의 사진을 꺼내보겠음 판 꺼냄</span>\n    plt<span class=\"token punctuation\">.</span>imshow<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'label </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>label<span class=\"token punctuation\">}</span></span><span class=\"token string\">: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>get_label_name<span class=\"token punctuation\">(</span>label<span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">'</span></span><span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>axis<span class=\"token punctuation\">(</span><span class=\"token string\">'off'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 52.222222222222214%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAABYlAAAWJQFJUiTwAAADNUlEQVQozwEqA9X8AIqJkgD//98A////AMO5kgB3WDdNSEEedTo8GXVNPhk/ZaBgEHmIfyydqbYmQ1NdExwaDgDtw1sA+tJ9AINtQwDq4d4A////APPr5AD+//8AAFRRVXZ3b1uhs6N3pberglF4UzK5Uz8l/084If9nSSKWfZBZlauFYPGwinHwXFdTjxsNAFlZSSOsdWE0qW1YK2GQjItZeXNvqm9rZ6WMi41yAH99cNVdUET/aFQ9/5eHYphRSiCoaDIj/2kxIP9URSCKfn9YrJh7Z/+WdWD/kXdknRgcHalJQC//gXRf/3RnVLJHRUGgOjs3/1FQSf9+cmfIAJGOd6pnWETjVlA16V1YP3hmWy66djUh/2w8Hv9BQxWWmqiFsoKQcP98gWz/vr22p2VQLoNrVTHpkH5k6W1lWY1xa2eBf3t365GKhOeWiIGhAFNcVgs1RDgPP15WEGeUaARIQiCARywXuXBNJrpdVSVojaKGNXuSWVxlc0hbqbCpOUAAAAeWdT0TemUwEkY3CQz///8B////Av///wH///8BAP///wAAAAACAAAAAf/h3wAHDjcdAA4wNgAJJC8NF0YZXmtnAKaqfQCZkWkApKqsAC8ZAwDm3M0Aq6SWAD88NgAREhYsV1NCWi8sGlcqKBk3AGJdTqPPo4nb166a4bl+bHNZUEKsiXZc/3BlVf86NDKUP0hXQntxaYKWf2d5goWQQhwXFEGPjo58amhneywsMz5PTDSRWFI0/1tTMP9EPya3AGhgVcqWemj/hnRq/7mUh5CegU2sqoxe/6KLaP+FZz2MQlBmtaejoP+2nYX/fIGIplZSUaSOhID/cmxo/0xKS6xeVzN/VFE//1ZSPP9KQyypAIh9bs+akob/l5KH/761qpSrmnezvJ9t/6mQav92bmOTW2h/p4OJlP+IhYL/dXyCm15XUZtwZ2H/d3Fq/2xmYaIrKBiEdXRs/3Jya/9CPSqvAIVxX22snYuRs6eWlcO2oUyFgnqOspRn156Se9ZtdHh8e36JEoSJkCuIk5gqp6mqGFZPSRlxb2csfXZtLq2clBBBQDKBmZmT+Lm2svZJRDOf3gpvCUkCLewAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/d16b019357261570c527d6ef9965d80a/37523/output_13_0.png\"\n        srcset=\"/static/d16b019357261570c527d6ef9965d80a/e9ff0/output_13_0.png 180w,\n/static/d16b019357261570c527d6ef9965d80a/f21e7/output_13_0.png 360w,\n/static/d16b019357261570c527d6ef9965d80a/37523/output_13_0.png 720w,\n/static/d16b019357261570c527d6ef9965d80a/302a4/output_13_0.png 1080w,\n/static/d16b019357261570c527d6ef9965d80a/ee3fb/output_13_0.png 1144w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>자 봐라, 이미지 크기가 다 제각각이네?</p>\n<p>올바른 학습을 위해서는 이미지 사이즈부터 제대로 맞춰줘야 한다.</p>\n<p>format_example() 함수로 이미지를 같은 포멧으로 맞춥니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">IMG_SIZE <span class=\"token operator\">=</span> <span class=\"token number\">160</span> <span class=\"token comment\"># 리사이징할 이미지의 크기</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">format_example</span><span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> label<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    image <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>cast<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> tf<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># image=float(image)같은 타입캐스팅의  텐서플로우 버전입니다.</span>\n    image <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>image<span class=\"token operator\">/</span><span class=\"token number\">127.5</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> <span class=\"token number\">1</span> <span class=\"token comment\"># 픽셀값의 scale 수정</span>\n    image <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>image<span class=\"token punctuation\">.</span>resize<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>IMG_SIZE<span class=\"token punctuation\">,</span> IMG_SIZE<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> image<span class=\"token punctuation\">,</span> label</code></pre></div>\n<p>픽셀값의 scale 을 수정햇다는 것은 픽셀값을 정규화햇다는 말과 근사하다.<br>\n0~ 255인 픽셀값을 127.5로 나누면 0~ 2가된다. 그걸 1로 뺐으니<br>\n-1~1 사이의 값으로 변했다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">train <span class=\"token operator\">=</span> raw_train<span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span>format_example<span class=\"token punctuation\">)</span>\nvalidation <span class=\"token operator\">=</span> raw_validation<span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span>format_example<span class=\"token punctuation\">)</span>\ntest <span class=\"token operator\">=</span> raw_test<span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span>format_example<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>train<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>validation<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>test<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">&lt;MapDataset shapes: ((160, 160, 3), ()), types: (tf.float32, tf.int64)>\n&lt;MapDataset shapes: ((160, 160, 3), ()), types: (tf.float32, tf.int64)>\n&lt;MapDataset shapes: ((160, 160, 3), ()), types: (tf.float32, tf.int64)></code></pre></div>\n<p>map 메서드로 모든 raw_** 의 정보를 format_example 의 함수로 변환시켜주었다.<br>\n변환된 후의 내용물은 다음과 같다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">plt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n\nget_label_name <span class=\"token operator\">=</span> metadata<span class=\"token punctuation\">.</span>features<span class=\"token punctuation\">[</span><span class=\"token string\">'label'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>int2str\n\n<span class=\"token keyword\">for</span> idx<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> label<span class=\"token punctuation\">)</span> <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>train<span class=\"token punctuation\">.</span>take<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">,</span> idx<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n    image <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>image <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> <span class=\"token number\">2</span>\n    plt<span class=\"token punctuation\">.</span>imshow<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'label </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>label<span class=\"token punctuation\">}</span></span><span class=\"token string\">: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>get_label_name<span class=\"token punctuation\">(</span>label<span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">'</span></span><span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>axis<span class=\"token punctuation\">(</span><span class=\"token string\">'off'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 47.77777777777777%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAABYlAAAWJQFJUiTwAAADNUlEQVQozwEqA9X8AFVQQz6LiGA8iYpjLaqATg9FOB5BLzYROS4uETd1hUwNboNbOLayrzyCiIw9NT09D11FEC1aSiFAXUsbO2dNDRdmZWghR0RBQVdRTzx/fX0uAGdgVf6smnL/uKV8xI1tS2pkSCr/OzQe9l8/IexxgURcioJW6ryGYveWe2j/NjUyZyIZA8toVy/8eWY//29dN4SNiIWhfHhz/29rZ/aVk5PkAF5VS/88Jx7/d2VMyW5vN25kQCP/ayoh/l09IPJgcTtgiHde8p1/b/+Nblf/hndsaxgdIdJPRjj/f3Zp/3FnV4kuLSimGx8Z/zM2Lf1yZFXrAHZnVf9hVTb/ZFtC1WZoNHRiPyX/fzQd/1NFHv9ueklllaKC/3iFaP+PkIL/xsK7cVJELN10Xz3/l4l3/2deUpFmYV2vendz/5GJhP+WiID4AFtURmpUWkFrQkc8UlBPJy48MBxsXDwgZ2lYL2NsdU8oj6N8Ymh/P2d2gWhryMa4LH1SD1WDYitpdmA4blpOMjjPxcJEw7m1brSsqmeqoqFhAP/60AD///cA28a0AElFKAD/4HcA//+xAKeMTgBFTj4A///lAP//kgDb3rYApqefANafTQD//9UA48OPAHRrVQD/+dkA////AP///wDEuKcAALOPdsLovqfCyJR/lkQ4OkxZUEbGbGVavDo2N7EhJTRBZGZtsqOMdr6Xh3m/aHKGSjo0MJqvrq7BW1lWxz4+QWNHRTh4Xlg8yVBJLLxCPSerAJ9/a/+PeW3/uJCB04RsTnSef1D/n4ts/4tzUP8vLTBlbniF/cazoP+oloT/ZHCAcW1nZNyUiYb/Z2Jf/0xLS5BbVTOvT0s0/1tUOP9IQir3AJqQg/94dW//t6uey6OXgW+5nm3/sZNl/52JbPVDRlJganiO9KGbmP+IgXz/X2lxbGVcVtN3bWj/cGtl/19cWYo4NCGofn53/2xtZ/9IQi/tAK+gjuWqoJLmy72nsHl+gGChjnHprZNq3oSGgtReZm1UeX+P032Dit+AhYjlgoWHXVxVT7d1cGnke3Rs7HFqY3hBQjaRmpqV7cvIw91GQTHOUnqDylKzWK4AAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/1271a3703b5b224b0557b0d74541dd9c/37523/output_19_0.png\"\n        srcset=\"/static/1271a3703b5b224b0557b0d74541dd9c/e9ff0/output_19_0.png 180w,\n/static/1271a3703b5b224b0557b0d74541dd9c/f21e7/output_19_0.png 360w,\n/static/1271a3703b5b224b0557b0d74541dd9c/37523/output_19_0.png 720w,\n/static/1271a3703b5b224b0557b0d74541dd9c/302a4/output_19_0.png 1080w,\n/static/1271a3703b5b224b0557b0d74541dd9c/ee3fb/output_19_0.png 1144w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>데이터 전처리 끝~</p>\n<hr>\n<h2 id=\"2-모델-생성-및-학습\" style=\"position:relative;\"><a href=\"#2-%EB%AA%A8%EB%8D%B8-%EC%83%9D%EC%84%B1-%EB%B0%8F-%ED%95%99%EC%8A%B5\" aria-label=\"2 모델 생성 및 학습 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2 모델 생성 및 학습</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>models <span class=\"token keyword\">import</span> Sequential\n<span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers <span class=\"token keyword\">import</span> Dense<span class=\"token punctuation\">,</span> Conv2D<span class=\"token punctuation\">,</span> Flatten<span class=\"token punctuation\">,</span> MaxPooling2D\n</code></pre></div>\n<p>models 에는 모델 자체를 구축하기 위한 함수가 있고  그 안의 Sequential 함수 안에 여러가지 layer 들이 들어갈 수 있다.<br>\nlayers 에는 모델의 구성 요소인 여러가지 종류의 layer(층) 함수들을 가지고 있다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">model <span class=\"token operator\">=</span> Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n    Conv2D<span class=\"token punctuation\">(</span>filters<span class=\"token operator\">=</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token string\">'same'</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">,</span> input_shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">160</span><span class=\"token punctuation\">,</span> <span class=\"token number\">160</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    MaxPooling2D<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    Conv2D<span class=\"token punctuation\">(</span>filters<span class=\"token operator\">=</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token string\">'same'</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    MaxPooling2D<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    Conv2D<span class=\"token punctuation\">(</span>filters<span class=\"token operator\">=</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token string\">'same'</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    MaxPooling2D<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    Flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    Dense<span class=\"token punctuation\">(</span>units<span class=\"token operator\">=</span><span class=\"token number\">512</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    Dense<span class=\"token punctuation\">(</span>units<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>딥러닝에서는 <strong>레이어</strong> 라는 개념을 자세하게 공부한다.<br>\n여기서는</p>\n<ul>\n<li>Conv2D</li>\n<li>MaxPooling2D</li>\n<li>Flatten</li>\n<li>Dense</li>\n</ul>\n<p>라는 네 레이어를 사용했다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">model<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_3 (Conv2D)            (None, 160, 160, 16)      448       \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 80, 80, 16)        0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 80, 80, 32)        4640      \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 40, 40, 32)        0         \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 40, 40, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_5 (MaxPooling2 (None, 20, 20, 64)        0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 25600)             0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 512)               13107712  \n_________________________________________________________________\ndense_3 (Dense)              (None, 2)                 1026      \n=================================================================\nTotal params: 13,132,322\nTrainable params: 13,132,322\nNon-trainable params: 0\n_________________________________________________________________</code></pre></div>\n<p>모델을 만들었으니 학습시켜보자.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">learning_rate <span class=\"token operator\">=</span> <span class=\"token number\">0.0001</span>\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span>tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>optimizers<span class=\"token punctuation\">.</span>RMSprop<span class=\"token punctuation\">(</span>lr<span class=\"token operator\">=</span>learning_rate<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n              loss<span class=\"token operator\">=</span>tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>losses<span class=\"token punctuation\">.</span>sparse_categorical_crossentropy<span class=\"token punctuation\">,</span>\n              metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n</code></pre></div>\n<p>학습시키기 위해서는 Optimer , Loss, Metrics 가 필요하다.</p>\n<p>opt : 학습을 어떤 방식으로 시킬 것인지<br>\nloss : 모델이 학습해나가야 할 방향 (이 경우는 확률분포)<br>\nmetrics : [accuracy, precision, recall]</p>\n<p>아직은 실행하기 전이다. 지금은 사전 작업만 거친 상태</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">BATCH_SIZE <span class=\"token operator\">=</span> <span class=\"token number\">32</span>\nSHUFFLE_BUFFER_SIZE <span class=\"token operator\">=</span> <span class=\"token number\">1000</span>\n\ntrain_batches <span class=\"token operator\">=</span> train<span class=\"token punctuation\">.</span>shuffle<span class=\"token punctuation\">(</span>SHUFFLE_BUFFER_SIZE<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>batch<span class=\"token punctuation\">(</span>BATCH_SIZE<span class=\"token punctuation\">)</span>\nvalidation_batches <span class=\"token operator\">=</span> validation<span class=\"token punctuation\">.</span>batch<span class=\"token punctuation\">(</span>BATCH_SIZE<span class=\"token punctuation\">)</span>\ntest_batches <span class=\"token operator\">=</span> test<span class=\"token punctuation\">.</span>batch<span class=\"token punctuation\">(</span>BATCH_SIZE<span class=\"token punctuation\">)</span></code></pre></div>\n<p>이렇게 train 데이터를 통으로 넣지 않고 32개씩 끊어 넣는 이유는\n랜덤한 32개의 사진들을 묶어 여러개의 Decision Tree 를 만들어 ansamble 하기 위함</p>\n<p>train_batches 의 데이터를 확인해보자</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">for</span> image_batch<span class=\"token punctuation\">,</span> label_batch <span class=\"token keyword\">in</span> train_batches<span class=\"token punctuation\">.</span>take<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">pass</span>\n\nimage_batch<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">,</span> label_batch<span class=\"token punctuation\">.</span>shape</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">(TensorShape([32, 160, 160, 3]), TensorShape([32]))</code></pre></div>\n<p>모델 학습 전에 초기 모델의 성능을 테스트해볼까? validation data 로 모델을 평가해보자<br>\n20번의 예측을 해보고 loss 와 accuracy를 구해보자</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">validation_steps <span class=\"token operator\">=</span> <span class=\"token number\">20</span>\nloss0<span class=\"token punctuation\">,</span> accuracy0 <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>validation_batches<span class=\"token punctuation\">,</span> steps<span class=\"token operator\">=</span>validation_steps<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"initial loss: {:.2f}\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>loss0<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"initial accuracy: {:.2f}\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>accuracy0<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">10/20 [==============>...............] - ETA: 0s - loss: 0.6924 - accuracy: 0.5156\n\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\n\n\n20/20 [==============================] - 3s 32ms/step - loss: 0.6919 - accuracy: 0.5172\ninitial loss: 0.69\ninitial accuracy: 0.52\n\n\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9</code></pre></div>\n<p>보면 아무것도 하기 전에 모델 evaluate 는 걍 뭐 아무것도 모른다.\n이제 이걸 학습시켜보자</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">EPOCHS <span class=\"token operator\">=</span> <span class=\"token number\">10</span>\nhistory <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>train_batches<span class=\"token punctuation\">,</span>\n                    epochs<span class=\"token operator\">=</span>EPOCHS<span class=\"token punctuation\">,</span>\n                    validation_data<span class=\"token operator\">=</span>validation_batches<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Epoch 1/10\n170/582 [=======>......................] - ETA: 18s - loss: 0.5444 - accuracy: 0.7250\n\nCorrupt JPEG data: 99 extraneous bytes before marker 0xd9\n\n\n202/582 [=========>....................] - ETA: 17s - loss: 0.5408 - accuracy: 0.7274\n\nWarning: unknown JFIF revision number 0.00\n\n\n212/582 [=========>....................] - ETA: 16s - loss: 0.5427 - accuracy: 0.7258\n\nCorrupt JPEG data: 396 extraneous bytes before marker 0xd9\n\n\n284/582 [=============>................] - ETA: 13s - loss: 0.5408 - accuracy: 0.7272\n\nCorrupt JPEG data: 65 extraneous bytes before marker 0xd9\n\n\n492/582 [========================>.....] - ETA: 3s - loss: 0.5280 - accuracy: 0.7363\n\nCorrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n\n\n504/582 [========================>.....] - ETA: 3s - loss: 0.5277 - accuracy: 0.7360\n\nCorrupt JPEG data: 128 extraneous bytes before marker 0xd9\n\n\n516/582 [=========================>....] - ETA: 2s - loss: 0.5271 - accuracy: 0.7372\n\nCorrupt JPEG data: 239 extraneous bytes before marker 0xd9\n\n\n542/582 [==========================>...] - ETA: 1s - loss: 0.5269 - accuracy: 0.7374\n\nCorrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n\n\n550/582 [===========================>..] - ETA: 1s - loss: 0.5271 - accuracy: 0.7372\n\nCorrupt JPEG data: 228 extraneous bytes before marker 0xd9\n\n\n582/582 [==============================] - ETA: 0s - loss: 0.5259 - accuracy: 0.7389\n\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 214 extraneous bytes before marker 0xd9\n\n\n582/582 [==============================] - 29s 48ms/step - loss: 0.5259 - accuracy: 0.7389 - val_loss: 0.5102 - val_accuracy: 0.7502\nEpoch 2/10\n169/582 [=======>......................] - ETA: 18s - loss: 0.4561 - accuracy: 0.7898\n\nCorrupt JPEG data: 99 extraneous bytes before marker 0xd9\n\n\n201/582 [=========>....................] - ETA: 16s - loss: 0.4553 - accuracy: 0.7886\n\nWarning: unknown JFIF revision number 0.00\n\n\n213/582 [=========>....................] - ETA: 16s - loss: 0.4548 - accuracy: 0.7893\n\nCorrupt JPEG data: 396 extraneous bytes before marker 0xd9\n\n\n283/582 [=============>................] - ETA: 13s - loss: 0.4483 - accuracy: 0.7911\n\nCorrupt JPEG data: 65 extraneous bytes before marker 0xd9\n\n\n492/582 [========================>.....] - ETA: 3s - loss: 0.4446 - accuracy: 0.7943\n\nCorrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n\n\n506/582 [=========================>....] - ETA: 3s - loss: 0.4450 - accuracy: 0.7947\n\nCorrupt JPEG data: 128 extraneous bytes before marker 0xd9\n\n\n516/582 [=========================>....] - ETA: 2s - loss: 0.4445 - accuracy: 0.7951\n\nCorrupt JPEG data: 239 extraneous bytes before marker 0xd9\n\n\n542/582 [==========================>...] - ETA: 1s - loss: 0.4437 - accuracy: 0.7953\n\nCorrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n\n\n548/582 [===========================>..] - ETA: 1s - loss: 0.4433 - accuracy: 0.7952\n\nCorrupt JPEG data: 228 extraneous bytes before marker 0xd9\n\n\n580/582 [============================>.] - ETA: 0s - loss: 0.4425 - accuracy: 0.7956\n\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 214 extraneous bytes before marker 0xd9\n\n\n582/582 [==============================] - 28s 47ms/step - loss: 0.4422 - accuracy: 0.7958 - val_loss: 0.5503 - val_accuracy: 0.7386\nEpoch 3/10\n169/582 [=======>......................] - ETA: 18s - loss: 0.3937 - accuracy: 0.8229\n\nCorrupt JPEG data: 99 extraneous bytes before marker 0xd9\n\n\n201/582 [=========>....................] - ETA: 16s - loss: 0.3927 - accuracy: 0.8232\n\nWarning: unknown JFIF revision number 0.00\n\n\n213/582 [=========>....................] - ETA: 16s - loss: 0.3927 - accuracy: 0.8234\n\nCorrupt JPEG data: 396 extraneous bytes before marker 0xd9\n\n\n283/582 [=============>................] - ETA: 13s - loss: 0.3870 - accuracy: 0.8266\n\nCorrupt JPEG data: 65 extraneous bytes before marker 0xd9\n\n\n492/582 [========================>.....] - ETA: 3s - loss: 0.3836 - accuracy: 0.8281\n\nCorrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n\n\n506/582 [=========================>....] - ETA: 3s - loss: 0.3843 - accuracy: 0.8278\n\nCorrupt JPEG data: 128 extraneous bytes before marker 0xd9\n\n\n516/582 [=========================>....] - ETA: 2s - loss: 0.3836 - accuracy: 0.8281\n\nCorrupt JPEG data: 239 extraneous bytes before marker 0xd9\n\n\n543/582 [==========================>...] - ETA: 1s - loss: 0.3820 - accuracy: 0.8288\n\nCorrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n\n\n549/582 [===========================>..] - ETA: 1s - loss: 0.3814 - accuracy: 0.8292\n\nCorrupt JPEG data: 228 extraneous bytes before marker 0xd9\n\n\n581/582 [============================>.] - ETA: 0s - loss: 0.3800 - accuracy: 0.8289\n\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 214 extraneous bytes before marker 0xd9\n\n\n582/582 [==============================] - 28s 47ms/step - loss: 0.3799 - accuracy: 0.8290 - val_loss: 0.4954 - val_accuracy: 0.7674\nEpoch 4/10\n169/582 [=======>......................] - ETA: 18s - loss: 0.3449 - accuracy: 0.8460\n\nCorrupt JPEG data: 99 extraneous bytes before marker 0xd9\n\n\n201/582 [=========>....................] - ETA: 16s - loss: 0.3404 - accuracy: 0.8469\n\nWarning: unknown JFIF revision number 0.00\n\n\n213/582 [=========>....................] - ETA: 16s - loss: 0.3395 - accuracy: 0.8480\n\nCorrupt JPEG data: 396 extraneous bytes before marker 0xd9\n\n\n283/582 [=============>................] - ETA: 12s - loss: 0.3357 - accuracy: 0.8520\n\nCorrupt JPEG data: 65 extraneous bytes before marker 0xd9\n\n\n492/582 [========================>.....] - ETA: 3s - loss: 0.3270 - accuracy: 0.8581\n\nCorrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n\n\n506/582 [=========================>....] - ETA: 3s - loss: 0.3273 - accuracy: 0.8581\n\nCorrupt JPEG data: 128 extraneous bytes before marker 0xd9\n\n\n516/582 [=========================>....] - ETA: 2s - loss: 0.3260 - accuracy: 0.8586\n\nCorrupt JPEG data: 239 extraneous bytes before marker 0xd9\n\n\n542/582 [==========================>...] - ETA: 1s - loss: 0.3256 - accuracy: 0.8590\n\nCorrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n\n\n550/582 [===========================>..] - ETA: 1s - loss: 0.3252 - accuracy: 0.8593\n\nCorrupt JPEG data: 228 extraneous bytes before marker 0xd9\n\n\n580/582 [============================>.] - ETA: 0s - loss: 0.3244 - accuracy: 0.8602\n\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 214 extraneous bytes before marker 0xd9\n\n\n582/582 [==============================] - 28s 47ms/step - loss: 0.3244 - accuracy: 0.8602 - val_loss: 0.4858 - val_accuracy: 0.7825\nEpoch 5/10\n170/582 [=======>......................] - ETA: 18s - loss: 0.2913 - accuracy: 0.8765\n\nCorrupt JPEG data: 99 extraneous bytes before marker 0xd9\n\n\n202/582 [=========>....................] - ETA: 16s - loss: 0.2866 - accuracy: 0.8790\n\nWarning: unknown JFIF revision number 0.00\n\n\n212/582 [=========>....................] - ETA: 16s - loss: 0.2868 - accuracy: 0.8791\n\nCorrupt JPEG data: 396 extraneous bytes before marker 0xd9\n\n\n284/582 [=============>................] - ETA: 12s - loss: 0.2804 - accuracy: 0.8825\n\nCorrupt JPEG data: 65 extraneous bytes before marker 0xd9\n\n\n493/582 [========================>.....] - ETA: 3s - loss: 0.2756 - accuracy: 0.8869\n\nCorrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n\n\n505/582 [=========================>....] - ETA: 3s - loss: 0.2740 - accuracy: 0.8876\n\nCorrupt JPEG data: 128 extraneous bytes before marker 0xd9\n\n\n515/582 [=========================>....] - ETA: 2s - loss: 0.2733 - accuracy: 0.8877\n\nCorrupt JPEG data: 239 extraneous bytes before marker 0xd9\n\n\n543/582 [==========================>...] - ETA: 1s - loss: 0.2732 - accuracy: 0.8886\n\nCorrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n\n\n549/582 [===========================>..] - ETA: 1s - loss: 0.2727 - accuracy: 0.8889\n\nCorrupt JPEG data: 228 extraneous bytes before marker 0xd9\n\n\n581/582 [============================>.] - ETA: 0s - loss: 0.2720 - accuracy: 0.8886\n\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 214 extraneous bytes before marker 0xd9\n\n\n582/582 [==============================] - 28s 46ms/step - loss: 0.2721 - accuracy: 0.8885 - val_loss: 0.4933 - val_accuracy: 0.7919\nEpoch 6/10\n169/582 [=======>......................] - ETA: 18s - loss: 0.2373 - accuracy: 0.9051\n\nCorrupt JPEG data: 99 extraneous bytes before marker 0xd9\n\n\n201/582 [=========>....................] - ETA: 16s - loss: 0.2335 - accuracy: 0.9083\n\nWarning: unknown JFIF revision number 0.00\n\n\n211/582 [=========>....................] - ETA: 16s - loss: 0.2331 - accuracy: 0.9083\n\nCorrupt JPEG data: 396 extraneous bytes before marker 0xd9\n\n\n283/582 [=============>................] - ETA: 13s - loss: 0.2268 - accuracy: 0.9110\n\nCorrupt JPEG data: 65 extraneous bytes before marker 0xd9\n\n\n493/582 [========================>.....] - ETA: 3s - loss: 0.2216 - accuracy: 0.9123\n\nCorrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n\n\n505/582 [=========================>....] - ETA: 3s - loss: 0.2209 - accuracy: 0.9127\n\nCorrupt JPEG data: 128 extraneous bytes before marker 0xd9\n\n\n516/582 [=========================>....] - ETA: 2s - loss: 0.2196 - accuracy: 0.9133\n\nCorrupt JPEG data: 239 extraneous bytes before marker 0xd9\n\n\n542/582 [==========================>...] - ETA: 1s - loss: 0.2178 - accuracy: 0.9147\n\nCorrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n\n\n548/582 [===========================>..] - ETA: 1s - loss: 0.2171 - accuracy: 0.9150\n\nCorrupt JPEG data: 228 extraneous bytes before marker 0xd9\n\n\n580/582 [============================>.] - ETA: 0s - loss: 0.2163 - accuracy: 0.9152\n\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 214 extraneous bytes before marker 0xd9\n\n\n582/582 [==============================] - 29s 47ms/step - loss: 0.2162 - accuracy: 0.9153 - val_loss: 0.6168 - val_accuracy: 0.7601\nEpoch 7/10\n169/582 [=======>......................] - ETA: 18s - loss: 0.1858 - accuracy: 0.9310\n\nCorrupt JPEG data: 99 extraneous bytes before marker 0xd9\n\n\n201/582 [=========>....................] - ETA: 16s - loss: 0.1836 - accuracy: 0.9331\n\nWarning: unknown JFIF revision number 0.00\n\n\n213/582 [=========>....................] - ETA: 16s - loss: 0.1820 - accuracy: 0.9341\n\nCorrupt JPEG data: 396 extraneous bytes before marker 0xd9\n\n\n283/582 [=============>................] - ETA: 13s - loss: 0.1783 - accuracy: 0.9361\n\nCorrupt JPEG data: 65 extraneous bytes before marker 0xd9\n\n\n493/582 [========================>.....] - ETA: 3s - loss: 0.1724 - accuracy: 0.9365\n\nCorrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n\n\n505/582 [=========================>....] - ETA: 3s - loss: 0.1717 - accuracy: 0.9369\n\nCorrupt JPEG data: 128 extraneous bytes before marker 0xd9\n\n\n515/582 [=========================>....] - ETA: 2s - loss: 0.1709 - accuracy: 0.9374\n\nCorrupt JPEG data: 239 extraneous bytes before marker 0xd9\n\n\n543/582 [==========================>...] - ETA: 1s - loss: 0.1699 - accuracy: 0.9378\n\nCorrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n\n\n549/582 [===========================>..] - ETA: 1s - loss: 0.1698 - accuracy: 0.9378\n\nCorrupt JPEG data: 228 extraneous bytes before marker 0xd9\n\n\n581/582 [============================>.] - ETA: 0s - loss: 0.1678 - accuracy: 0.9382\n\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 214 extraneous bytes before marker 0xd9\n\n\n582/582 [==============================] - 28s 47ms/step - loss: 0.1677 - accuracy: 0.9382 - val_loss: 0.6220 - val_accuracy: 0.7627\nEpoch 8/10\n170/582 [=======>......................] - ETA: 18s - loss: 0.1322 - accuracy: 0.9537\n\nCorrupt JPEG data: 99 extraneous bytes before marker 0xd9\n\n\n202/582 [=========>....................] - ETA: 16s - loss: 0.1317 - accuracy: 0.9547\n\nWarning: unknown JFIF revision number 0.00\n\n\n212/582 [=========>....................] - ETA: 16s - loss: 0.1293 - accuracy: 0.9558\n\nCorrupt JPEG data: 396 extraneous bytes before marker 0xd9\n\n\n284/582 [=============>................] - ETA: 13s - loss: 0.1267 - accuracy: 0.9558\n\nCorrupt JPEG data: 65 extraneous bytes before marker 0xd9\n\n\n493/582 [========================>.....] - ETA: 3s - loss: 0.1241 - accuracy: 0.9564\n\nCorrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n\n\n505/582 [=========================>....] - ETA: 3s - loss: 0.1237 - accuracy: 0.9566\n\nCorrupt JPEG data: 128 extraneous bytes before marker 0xd9\n\n\n515/582 [=========================>....] - ETA: 2s - loss: 0.1235 - accuracy: 0.9567\n\nCorrupt JPEG data: 239 extraneous bytes before marker 0xd9\n\n\n542/582 [==========================>...] - ETA: 1s - loss: 0.1223 - accuracy: 0.9574\n\nCorrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n\n\n550/582 [===========================>..] - ETA: 1s - loss: 0.1219 - accuracy: 0.9577\n\nCorrupt JPEG data: 228 extraneous bytes before marker 0xd9\n\n\n580/582 [============================>.] - ETA: 0s - loss: 0.1210 - accuracy: 0.9580\n\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 214 extraneous bytes before marker 0xd9\n\n\n582/582 [==============================] - 28s 47ms/step - loss: 0.1209 - accuracy: 0.9581 - val_loss: 0.6818 - val_accuracy: 0.7623\nEpoch 9/10\n170/582 [=======>......................] - ETA: 18s - loss: 0.0973 - accuracy: 0.9688\n\nCorrupt JPEG data: 99 extraneous bytes before marker 0xd9\n\n\n202/582 [=========>....................] - ETA: 16s - loss: 0.0932 - accuracy: 0.9711\n\nWarning: unknown JFIF revision number 0.00\n\n\n212/582 [=========>....................] - ETA: 16s - loss: 0.0942 - accuracy: 0.9704\n\nCorrupt JPEG data: 396 extraneous bytes before marker 0xd9\n\n\n284/582 [=============>................] - ETA: 13s - loss: 0.0915 - accuracy: 0.9712\n\nCorrupt JPEG data: 65 extraneous bytes before marker 0xd9\n\n\n492/582 [========================>.....] - ETA: 3s - loss: 0.0893 - accuracy: 0.9715\n\nCorrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n\n\n506/582 [=========================>....] - ETA: 3s - loss: 0.0888 - accuracy: 0.9719\n\nCorrupt JPEG data: 128 extraneous bytes before marker 0xd9\n\n\n516/582 [=========================>....] - ETA: 2s - loss: 0.0883 - accuracy: 0.9721\n\nCorrupt JPEG data: 239 extraneous bytes before marker 0xd9\n\n\n542/582 [==========================>...] - ETA: 1s - loss: 0.0880 - accuracy: 0.9722\n\nCorrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n\n\n550/582 [===========================>..] - ETA: 1s - loss: 0.0874 - accuracy: 0.9725\n\nCorrupt JPEG data: 228 extraneous bytes before marker 0xd9\n\n\n580/582 [============================>.] - ETA: 0s - loss: 0.0875 - accuracy: 0.9725\n\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 214 extraneous bytes before marker 0xd9\n\n\n582/582 [==============================] - 28s 47ms/step - loss: 0.0874 - accuracy: 0.9725 - val_loss: 0.6500 - val_accuracy: 0.7863\nEpoch 10/10\n170/582 [=======>......................] - ETA: 18s - loss: 0.0692 - accuracy: 0.9783\n\nCorrupt JPEG data: 99 extraneous bytes before marker 0xd9\n\n\n202/582 [=========>....................] - ETA: 17s - loss: 0.0681 - accuracy: 0.9785\n\nWarning: unknown JFIF revision number 0.00\n\n\n212/582 [=========>....................] - ETA: 16s - loss: 0.0674 - accuracy: 0.9788\n\nCorrupt JPEG data: 396 extraneous bytes before marker 0xd9\n\n\n284/582 [=============>................] - ETA: 13s - loss: 0.0648 - accuracy: 0.9798\n\nCorrupt JPEG data: 65 extraneous bytes before marker 0xd9\n\n\n493/582 [========================>.....] - ETA: 3s - loss: 0.0626 - accuracy: 0.9816\n\nCorrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n\n\n505/582 [=========================>....] - ETA: 3s - loss: 0.0624 - accuracy: 0.9817\n\nCorrupt JPEG data: 128 extraneous bytes before marker 0xd9\n\n\n515/582 [=========================>....] - ETA: 2s - loss: 0.0621 - accuracy: 0.9820\n\nCorrupt JPEG data: 239 extraneous bytes before marker 0xd9\n\n\n543/582 [==========================>...] - ETA: 1s - loss: 0.0610 - accuracy: 0.9826\n\nCorrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n\n\n549/582 [===========================>..] - ETA: 1s - loss: 0.0615 - accuracy: 0.9825\n\nCorrupt JPEG data: 228 extraneous bytes before marker 0xd9\n\n\n581/582 [============================>.] - ETA: 0s - loss: 0.0614 - accuracy: 0.9827\n\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 214 extraneous bytes before marker 0xd9\n\n\n582/582 [==============================] - 29s 47ms/step - loss: 0.0613 - accuracy: 0.9827 - val_loss: 0.6904 - val_accuracy: 0.7889</code></pre></div>\n<p>다음은 학습시킨 모델에 대한 그래프 보고이다</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">for</span> image_batch<span class=\"token punctuation\">,</span> label_batch <span class=\"token keyword\">in</span> test_batches<span class=\"token punctuation\">.</span>take<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    images <span class=\"token operator\">=</span> image_batch\n    labels <span class=\"token operator\">=</span> label_batch\n    predictions <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>image_batch<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">pass</span>\n\npredictions</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">array([[9.9999702e-01, 2.9417115e-06],\n       [8.3842850e-01, 1.6157144e-01],\n       [7.4218982e-01, 2.5781012e-01],\n       [9.9970847e-01, 2.9155653e-04],\n       [9.9640131e-01, 3.5986665e-03],\n       [7.8427315e-02, 9.2157269e-01],\n       [1.8649189e-02, 9.8135078e-01],\n       [9.1933328e-01, 8.0666728e-02],\n       [9.4125561e-02, 9.0587437e-01],\n       [7.8091651e-02, 9.2190832e-01],\n       [1.1057696e-01, 8.8942307e-01],\n       [9.2630666e-01, 7.3693395e-02],\n       [9.9996006e-01, 3.9985713e-05],\n       [4.6824862e-05, 9.9995315e-01],\n       [9.9207205e-01, 7.9279514e-03],\n       [9.9890709e-01, 1.0929310e-03],\n       [3.1051392e-02, 9.6894866e-01],\n       [5.8752208e-09, 1.0000000e+00],\n       [8.3172768e-01, 1.6827232e-01],\n       [9.9952376e-01, 4.7630019e-04],\n       [7.9531687e-01, 2.0468311e-01],\n       [9.9072027e-01, 9.2797335e-03],\n       [9.9999344e-01, 6.5057743e-06],\n       [9.1565454e-01, 8.4345400e-02],\n       [9.9570221e-01, 4.2977203e-03],\n       [1.0600092e-02, 9.8939985e-01],\n       [9.9997663e-01, 2.3377719e-05],\n       [1.0107538e-01, 8.9892459e-01],\n       [9.9934202e-01, 6.5792818e-04],\n       [9.9927968e-01, 7.2028313e-04],\n       [9.9999619e-01, 3.7975171e-06],\n       [2.8957015e-01, 7.1042985e-01]], dtype=float32)</code></pre></div>\n<p>이것이 바로 우리의 정확도이다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n\npredictions <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>predictions<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\npredictions</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">array([0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n       0, 0, 0, 1, 0, 1, 0, 0, 0, 1])</code></pre></div>\n<p>이제 32장의 image 와 32개의 label , 32개의 prediction 을 얻었다\n최종 확인을 해보자</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">plt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">20</span><span class=\"token punctuation\">,</span> <span class=\"token number\">12</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">for</span> idx<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> label<span class=\"token punctuation\">,</span> prediction<span class=\"token punctuation\">)</span> <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">zip</span><span class=\"token punctuation\">(</span>images<span class=\"token punctuation\">,</span> labels<span class=\"token punctuation\">,</span> predictions<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span> <span class=\"token number\">8</span><span class=\"token punctuation\">,</span> idx<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n    image <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>image <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> <span class=\"token number\">2</span>\n    plt<span class=\"token punctuation\">.</span>imshow<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">)</span>\n    correct <span class=\"token operator\">=</span> label <span class=\"token operator\">==</span> prediction\n    title <span class=\"token operator\">=</span> <span class=\"token string-interpolation\"><span class=\"token string\">f'real: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>label<span class=\"token punctuation\">}</span></span><span class=\"token string\"> / pred :</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>prediction<span class=\"token punctuation\">}</span></span><span class=\"token string\">\\n </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>correct<span class=\"token punctuation\">}</span></span><span class=\"token string\">!'</span></span>\n    <span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> correct<span class=\"token punctuation\">:</span>\n        plt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span>title<span class=\"token punctuation\">,</span> fontdict<span class=\"token operator\">=</span><span class=\"token punctuation\">{</span><span class=\"token string\">'color'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'red'</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n        plt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span>title<span class=\"token punctuation\">,</span> fontdict<span class=\"token operator\">=</span><span class=\"token punctuation\">{</span><span class=\"token string\">'color'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'blue'</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>axis<span class=\"token punctuation\">(</span><span class=\"token string\">'off'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 59.44444444444444%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAABYlAAAWJQFJUiTwAAAD10lEQVQozwHMAzP8AHt+llZbXIBmh4aHNreNhmuldGpKSx8VSGoxKmxJOzQ3YmGAZYF9j1FwbX5CbWyGbipGQzheU1NhdG1wWFVfaTtmZ3xxZF1iOL+HhVq/dmlmAG9va/SAfnn/a2Zeq4Z5Zf+di3nUhnZo0IZ5bf9oY1yqiYJ4/6ihl+Wdnp6/mZCM/2hRSapweWH/aXp29lxjW69zcmL/cGVbqpx4VPiZcUv/AG1iVpyKhH+vLyQXbGZON7dkVECHv7mqhcnCu7iRk5FsdXFzsH94cpKijH56ZFNav1AgHWxzZk6pWWZonV1oa29oZmPGbmVSbG1PJp9GOyO2AM6tpk/WsK9co5OFMWgtH2FqMxlDfXybQUJDb2BTVFIymZmxXMbH3kkTDBQ8JChGZBwpNTOHgjxXtZE5T0E3RjUyLE9na219M////1GOjJ5dALKhm/Kqkor/q6OaqE0+Lv9eVUjSpJmXzm9oav96enmoh4eA/7e3s+OFhX+9nJmS/3NvV6iUiRH/o3kY80k/N60fIBz/UlRQqKCioPUyNzn/AOfUz6TCo5y21L2ucY15Zr+ek4eOm4aGi19UXsGLhItxY2FiuEhEQZqgoKSA4uLqyOXoxnGBcgCxZ1QBpXByXnVVVU3PNC8ucSQkJqcvMDq/AEgrKUhaMzNVZW1eLLi2yViFhYk9el5TO3FSWVm0sKktkKTHVHaInEMoFhg2NCY+XFFDQC5fWHhQlpGqSQ4QHzEAAAxfHB8uL4WGoEtaXHVVADIrI+41LSX/WF5MpZKSff9vcV3OZ1E2ykExGv+Cc16leHhq/5eflN9ORDW6Vk9B/2JcT6WQhn//hnZp7319d6lraWj/Ky0spF9jW/FtcWf/AD80Kq1MQTfAT1M9eGlqS8lZVz2Wc1tFk11MOsunjXF4gHpswpWUh6J6dWaHcnFp03h5d3jb0sm6kG1ercrKw3va4ePaSEtReFZYUK9oamHJAEA/WURdXolRZGZfKqN+aFW3qJI6VFhpOMS63FXLzdQreoGsUKqz0D8yGBM0MxwsWEtDRixXQ1tNOiA2Rmtmbi6XkLRar7LOLK5/b0ilblZRADEzMuVpbG//f3hqn76yif+dk2/HMC8pw1ROSv+trK6fbGxr/4iMjtdIOy2zTjsm/zkrGp9ubWr4TlBW535pXaS7q5H/wK+fn5iMe+m5r57/AH5sW8iBd2nfXlU+i5R9VulzWjeue3h3q2VfYeuVlqCLoKiw4Jqgp7xodnqdXmhm9CQjIYujn5XYiISDyWckMY+IWkz8lGlai4iEb8uklXrpdIjI2btfkaMAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/ec1ce97527379951f010a8c71cac03f3/37523/output_42_0.png\"\n        srcset=\"/static/ec1ce97527379951f010a8c71cac03f3/e9ff0/output_42_0.png 180w,\n/static/ec1ce97527379951f010a8c71cac03f3/f21e7/output_42_0.png 360w,\n/static/ec1ce97527379951f010a8c71cac03f3/37523/output_42_0.png 720w,\n/static/ec1ce97527379951f010a8c71cac03f3/302a4/output_42_0.png 1080w,\n/static/ec1ce97527379951f010a8c71cac03f3/07a9c/output_42_0.png 1440w,\n/static/ec1ce97527379951f010a8c71cac03f3/fbae3/output_42_0.png 2260w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">count <span class=\"token operator\">=</span> <span class=\"token number\">0</span>   <span class=\"token comment\"># 정답을 맞춘 개수</span>\n<span class=\"token keyword\">for</span> image<span class=\"token punctuation\">,</span> label<span class=\"token punctuation\">,</span> prediction <span class=\"token keyword\">in</span> <span class=\"token builtin\">zip</span><span class=\"token punctuation\">(</span>images<span class=\"token punctuation\">,</span> labels<span class=\"token punctuation\">,</span> predictions<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    correct <span class=\"token operator\">=</span> label <span class=\"token operator\">==</span> prediction\n    <span class=\"token keyword\">if</span> correct<span class=\"token punctuation\">:</span>\n        count <span class=\"token operator\">=</span> count <span class=\"token operator\">+</span> <span class=\"token number\">1</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>count <span class=\"token operator\">/</span> <span class=\"token number\">32</span> <span class=\"token operator\">*</span> <span class=\"token number\">100</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">71.875</code></pre></div>\n<p>중간에 들어가있는 딥러닝 모델이 단순한 구조이기 때문에<br>\n좋은 결과가 나오고 있지는 않다.</p>\n<p>다만 중간의 모델구조를 변경한다면 더 좋은 결과를<br>\n끌어낼 수 있을 것이다.</p>\n<div class=\"table-of-contents\">\n<ul>\n<li>\n<p><a href=\"#%EA%B0%95%EC%95%84%EC%A7%80--%EA%B3%A0%EC%96%91%EC%9D%B4-%EB%B6%84%EB%A5%98-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%A8-%EC%A0%9C%EC%9E%91-\">강아지 &#x26; 고양이 분류 프로그램 제작 !</a></p>\n<ul>\n<li><a href=\"#content\">Content</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#1-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%84%EC%B2%98%EB%A6%AC\">1. 데이터 전처리</a></p>\n</li>\n<li>\n<p><a href=\"#2-%EB%AA%A8%EB%8D%B8-%EC%83%9D%EC%84%B1-%EB%B0%8F-%ED%95%99%EC%8A%B5\">2 모델 생성 및 학습</a></p>\n</li>\n</ul>\n</div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"></code></pre></div>","excerpt":"인공지능 기초 🚶‍♂️: 사진 분류 프로그램 맛보기 강아지 & 고양이 분류 프로그램 제작 ! Content 데이터 불러오기 (Tensor Flow) 데이터 전처리 모델 생성 (자체 생성 모델) 학습 및 평가 시작하기에 앞서, 이번 게시글은 전체적인 인공지능 적용에 대한 맥락을 설명하기 위한 글입니다. 아주 간단한 Deep Learning Layer 몇 종류를 이용했습니다. tensor flow 에서는 다양한 데이터셋을 이미 제공하고 있다. 강아지고양이, 음성, 이미지, 텍스트 데이터셋 보유하고 있으니 세부 내용 확인해보고 싶음 해보기 tensor flow link “WARNING:absl:1738 images were corrupted and were skipped”라는 경고가 나타날 수 있습니다. 우선 무시하시면 됩니다. 1738 장의 사진은 쓸 수 없다는 뜻입니다. 이런 것들은 tf 사이트 데이터셋 설명에서 확인 가능합니다 PNG 1738이 currupted 되어있다 되어있져? 그리…","frontmatter":{"date":"April 21, 2022","title":"인공지능 기초 사진 분류 프로그램 맛보기","categories":"STUDY","author":"하성민","emoji":"😁"},"fields":{"slug":"/DML_AI1/"}},"next":{"id":"6f2cd6e3-4d52-59b8-8a55-7fe83eb9f0c7","html":"<h1 id=\"span-stylebackground-color-fff5b1임베딩이란span\" style=\"position:relative;\"><a href=\"#span-stylebackground-color-fff5b1%EC%9E%84%EB%B2%A0%EB%94%A9%EC%9D%B4%EB%9E%80span\" aria-label=\"span stylebackground color fff5b1임베딩이란span permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><span style='background-color: #fff5b1'>임베딩이란..?</span></h1>\n<p>단어를 표현하기 위해서는 적어도 1차원에서는 안된다 (의미가 담기기엔 작다)</p>\n<p>그래서 벡터의 <strong>특정 차원을 직접</strong> 만들어 의미를 직접 mapping 해야 하고,<br>\n이를 희소 표현 (Sparse Representation) 이라고 한다.</p>\n<hr>\n<p>반면에 그냥 차원은 일정하게 256차원 이렇게 정해놓고</p>\n<p>유사한 맥락에서 자주 나오는 단어들은 의미가 비슷하다고 판단하는 방식을\n분포 가설 (distribution hypothesis) 이라고 한다. 그리고 이 가설을 통해 분산표현 (distribution Representation) 이라고 한다.</p>\n<p>맥락이라 함은 단어 좌우에 함께 위치하는 단어를 의미한다.</p>\n<hr>\n<p>분산표현 은 희소표현 과 달리 단어 간 유사도를 구할 수 있다.</p>\n<p>embedding 레이어라는 것은</p>\n<p>이 단어의 분산표현을 구현하기 위한 레이어!!!!!!!!!!!!!!!!!!!!!!</p>\n<p>우리가 단어를 n 개 쓸거야~ k차원으로 구현해조~ 하면</p>\n<p>컴퓨터가 n x k 형태의 분산표현 사전을 만든다.</p>\n<p>이게 weihght 이 되는 거고 파라미터가 된다.</p>\n<hr>\n<p>이 임베딩을 훈련시키기 위해</p>\n<p>word2vec , FastText, Glove, ELMo 등이 있는 거임 방법들이</p>\n<hr>\n<h2 id=\"임베딩-레이어는-컴퓨터가-알아먹는-단어사전이다\" style=\"position:relative;\"><a href=\"#%EC%9E%84%EB%B2%A0%EB%94%A9-%EB%A0%88%EC%9D%B4%EC%96%B4%EB%8A%94-%EC%BB%B4%ED%93%A8%ED%84%B0%EA%B0%80-%EC%95%8C%EC%95%84%EB%A8%B9%EB%8A%94-%EB%8B%A8%EC%96%B4%EC%82%AC%EC%A0%84%EC%9D%B4%EB%8B%A4\" aria-label=\"임베딩 레이어는 컴퓨터가 알아먹는 단어사전이다 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>임베딩 레이어는 컴퓨터가 알아먹는 단어사전이다.</h2>\n<p>weight 은</p>\n<ol>\n<li>단어의 개수</li>\n<li>임베딩 사이즈</li>\n</ol>\n<p>로 정의된다.</p>\n<p>임베딩 레이어는 input 데이터를 분산 데이터로 연결해주니 LUT 룩업 테이블<br>\n이라고도 한다.</p>\n<p>그것은 원-핫 인코딩 이라고도 하는데</p>\n<hr>\n<p>원핫 인코딩 자체는 sparse 표현이지만</p>\n<p>embedding 이랑 함께 결합하여 쓰이면 유용하다.</p>\n<p>각 단어가 있으면 그걸 Linear 연산 을 통해 차원값을 만들어낸다!!!</p>\n<p>예를 들어</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 287px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 12.777777777777777%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAADCAYAAACTWi8uAAAACXBIWXMAABJ0AAASdAHeZh94AAAAjUlEQVQI142NSQ6FMAxDORDQBRWlhZYOdJAQCMH9z+Kv5AR/8RTLdpLuOA4QrTXknJlaK3s0Syl/5aSJzhiDYRjwPA/meca6rriuC33fc5lKQgh83wcpJZZlwfu+vHOeJ0IIGMcR931j2zZ0WmsuUkBaKcWaPCrs+45pmhBj5GP0NKXEuXOOodx7D2stfhmHaHQ1aP1BAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/976040ccf895245ecd1bba60556db4fd/480fd/1.png\"\n        srcset=\"/static/976040ccf895245ecd1bba60556db4fd/e9ff0/1.png 180w,\n/static/976040ccf895245ecd1bba60556db4fd/480fd/1.png 287w\"\n        sizes=\"(max-width: 287px) 100vw, 287px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>8차원의 원핫 인코딩이 있다고 해보자</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 306px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 82.77777777777777%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAARCAYAAADdRIy+AAAACXBIWXMAABJ0AAASdAHeZh94AAACA0lEQVQ4y1XUV26CQQwEYA6EkIDQS0jonSSkQB5y/1Ns9Fkyggdrl7U9nrHNXxkOh+Xl5aXMZrPy/PxcBoNBORwOxftisSjr9bo8PT2VRqNxs2az+fD7/r0iablclvP5XObzeWm32+V4PEaB9/f3uLdarVKv1yOBuSuSwO5ZtAKs2+0GGJDv7++y3++DtZP1er3wMQR+f3/L29tbKLlcLhFLUTCcTqeRMJlMwrHZbG4Br6+v0QaV+/3+rSViVqtVKNtutxHLguFoNIogTgAkfn19ldPpFGwxqtVqcSoO6PPzs3x8fMRdj8fjcYETDCEDxNCjRKYFEshUWYxE74p7d0dC3gNDlVVykuNOCrbX6zWk8gHZ7XYxQAoowTQlB8OUrG9OYBhIZNiaoAQqgN/7nJjymf5DD4GZmh5h8ff3F6yq1eptC7K3TmvFxJIegCqboP64k4YFcCDMFiiqOMth5A67U3hjCFCQKgIE/vz8BAuMyeEDrsf6hiW5ftvVXK9g6AeTZBiq5TS9YdjpdEIF2bl/LO+3HmazOZieYCjIvwGAoVDiTol/iD7zMz3UqgDM7b9fizSFJPNrSxZOMCr4tUDuw1CyR/qR0gEJdJKdXyUg4pJx5gRgTjd7k3+7/NJgA5BJysX2zo8dDD5nJavnx0HFXAdv7vy+SPeDsyrJUH+BUfoPcWxfmb0L+yUAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/0f1db7efd568945b6793d92387ce9a0e/98b92/2.png\"\n        srcset=\"/static/0f1db7efd568945b6793d92387ce9a0e/e9ff0/2.png 180w,\n/static/0f1db7efd568945b6793d92387ce9a0e/98b92/2.png 306w\"\n        sizes=\"(max-width: 306px) 100vw, 306px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>이런 가중치 를 가진 레이어가 있다고 치면\n저 위의 1 0 0 0 0 0 0 0 에 각 하나의  [ _ _ ] 가 들어가게 되고,</p>\n<p>그 결과값으로 [_ _ ] 의 형태 1 개가 나오겠지 (원핫인코딩의 행이 1이니까)</p>\n<p>그럼 원핫 인코딩이</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 311px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 90.55555555555556%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAASCAYAAABb0P4QAAAACXBIWXMAABJ0AAASdAHeZh94AAABtUlEQVQ4y33UR3LDMBBEUd1IOYvK+f73geuhqmnSsr2gEDTz0ROAwXa7Lc/ns+x2uzIej8v1ei3L5bKO0+m03G63Mp/Py/F4LJvNphwOh7Jarcp+v68+5vf7vTRNU/0H6/W6bgADXC6XFgiUNRAbIGAwc/851LwCh8NhdbIxmUwqPKfOZrPyeDwq+Hw+VyClRDiAD1sRtgr9nE6nVqH5YrGoAMCso4wjIHsqKYygChyNRjW8KKQopwIacwCAA4ApTT5fr9e3QkAnMKYQHEBeALPuFiVKEzJb+z0gg+QwhZI7ioVFGZuAwaJQFL2QhQNKYXJJGYX2gTk7iKNRRMkh217IgJQAAAKkysLhRBnAbyHz7SmkAkDIyV2UdhvbXpQC+j4auwvsAhgk5BQlwJ8K+fYUgrzf7wqUYAq0ApAwoxyk2+Bpcr4tMI3NEJBRQqQQxBrEAQmTyuylA3qNHYUSHIVAxlQ1d/tfhYBRKDRzjsbu1eNonbyB+nQA34+iUEJhGjuPQq5iwksOFefPqwfCMcnPk5Q+THGiOA2efLJJ0WpR5CIPKoeEkWeLE4h196YA5LVJW30B2hRjj0mVs9kAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/fc04f86827c4c59964a4496cc71898b4/ffa0f/3.png\"\n        srcset=\"/static/fc04f86827c4c59964a4496cc71898b4/e9ff0/3.png 180w,\n/static/fc04f86827c4c59964a4496cc71898b4/ffa0f/3.png 311w\"\n        sizes=\"(max-width: 311px) 100vw, 311px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>이렇게 10 개 있으면<br>\n10개에 대한 [_ _ ] 값이 나올 것이다. 그럼 그것이<br>\n바로 유사도를 나타내는 벡터값이 될 수 있다.</p>\n<hr>\n<p>다시 말해서 임베딩 레이어란</p>\n<ol>\n<li>단어들을 원핫 인코딩 한다.</li>\n<li>선형변환(레이어 씌우기) 를 한다.</li>\n<li>각 단어들을 {index : 선형변환값 } 으로 저장</li>\n</ol>\n<p>을 해주는 레이어 인 것!!!!!!</p>\n<p>보여주는 코드는 다음과 같다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n\nsome_words <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>constant<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">57</span><span class=\"token punctuation\">,</span> <span class=\"token number\">35</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># 3번 단어 / 57번 단어 / 35번 단어로 이루어진 한 문장입니다.</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Embedding을 진행할 문장:\"</span><span class=\"token punctuation\">,</span> some_words<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\nembedding_layer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Embedding<span class=\"token punctuation\">(</span>input_dim<span class=\"token operator\">=</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span> output_dim<span class=\"token operator\">=</span><span class=\"token number\">100</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># 총 64개의 단어를 포함한 Embedding 레이어를 선언할 것이고,</span>\n<span class=\"token comment\"># 각 단어는 100차원으로 분산 표현 할 것입니다.</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Embedding된 문장:\"</span><span class=\"token punctuation\">,</span> embedding_layer<span class=\"token punctuation\">(</span>some_words<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Embedding Layer의 Weight 형태:\"</span><span class=\"token punctuation\">,</span> embedding_layer<span class=\"token punctuation\">.</span>weights<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Embedding을 진행할 문장: (1, 3)\nEmbedding된 문장: (1, 3, 100)\nEmbedding Layer의 Weight 형태: (64, 100)</code></pre></div>\n<h4 id=\"근데-임베딩-레이어는-미분을-할수-없는-애라-어떤-연산-결과를\" style=\"position:relative;\"><a href=\"#%EA%B7%BC%EB%8D%B0-%EC%9E%84%EB%B2%A0%EB%94%A9-%EB%A0%88%EC%9D%B4%EC%96%B4%EB%8A%94-%EB%AF%B8%EB%B6%84%EC%9D%84-%ED%95%A0%EC%88%98-%EC%97%86%EB%8A%94-%EC%95%A0%EB%9D%BC-%EC%96%B4%EB%96%A4-%EC%97%B0%EC%82%B0-%EA%B2%B0%EA%B3%BC%EB%A5%BC\" aria-label=\"근데 임베딩 레이어는 미분을 할수 없는 애라 어떤 연산 결과를 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>근데 임베딩 레이어는 미분을 할수 없는 애라 어떤 연산 결과를</h4>\n<h4 id=\"임베딩-레이어에-적으면-안된다네\" style=\"position:relative;\"><a href=\"#%EC%9E%84%EB%B2%A0%EB%94%A9-%EB%A0%88%EC%9D%B4%EC%96%B4%EC%97%90-%EC%A0%81%EC%9C%BC%EB%A9%B4-%EC%95%88%EB%90%9C%EB%8B%A4%EB%84%A4\" aria-label=\"임베딩 레이어에 적으면 안된다네 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>임베딩 레이어에 적으면 안된다네</h4>\n<h2 id=\"그런-임베딩-레이어와-함께-쓰는-문장-특화-레이어\" style=\"position:relative;\"><a href=\"#%EA%B7%B8%EB%9F%B0-%EC%9E%84%EB%B2%A0%EB%94%A9-%EB%A0%88%EC%9D%B4%EC%96%B4%EC%99%80-%ED%95%A8%EA%BB%98-%EC%93%B0%EB%8A%94-%EB%AC%B8%EC%9E%A5-%ED%8A%B9%ED%99%94-%EB%A0%88%EC%9D%B4%EC%96%B4\" aria-label=\"그런 임베딩 레이어와 함께 쓰는 문장 특화 레이어 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>그런 임베딩 레이어와 함께 쓰는 문장 특화 레이어</h2>\n<h1 id=\"recurrent-layer\" style=\"position:relative;\"><a href=\"#recurrent-layer\" aria-label=\"recurrent layer permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Recurrent layer</h1>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 67.77777777777777%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAABJ0AAASdAHeZh94AAABjklEQVQ4y5VUS0+EMBjk//8Fr3rw4ElPmmjUPZio8RFX1/jCFVZ26YPS0sJCGUPVFRWMO8kktE3nm37fBK+ua7TZYEYF9i8CnI5eMZ/PHU1RoSxLFEXh1g1+3m3ooQX7ITh+pVjfHWHv7AVCCKRCgKkSEUnBOQMhFFVVLUTb8N6V7TeH2uS48WcYR+zXhU987v/psC3atf8fekon8CeXIDxcCGij8BgOEc4esSy8p+AaO8crGD0PYOvKcTK7w8HFGob+nuuhlBKUUvi+D5pMwDiBUhkk55BxjDRN3XlDb0rHGJxv4Cm8XFRJZIyTqy3c+kduqg211u6iKTJkWrp1VZbIpYTRGnmeI1Oq1cP6e7NtXqCu7PJPXjQUXwOx1iJjFLlSyw+lK9giivCwtYmXwWFv3noddmUrCQIM11bh72y7PvW57Ax287w2m2OjFOL7OyRh4FrRhy7XHmUUjHNQxsA5R5IIUM4glHJSrsiHo/Z3r8Ouyu5noDUIIYimU6QyhTEGMSEuk018Kms7Bd8AaahDWzAmluoAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/17aa24ec4bd035038c60ced1da695ffa/37523/4.png\"\n        srcset=\"/static/17aa24ec4bd035038c60ced1da695ffa/e9ff0/4.png 180w,\n/static/17aa24ec4bd035038c60ced1da695ffa/f21e7/4.png 360w,\n/static/17aa24ec4bd035038c60ced1da695ffa/37523/4.png 720w,\n/static/17aa24ec4bd035038c60ced1da695ffa/aa08e/4.png 967w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<ul>\n<li>딥러닝에서 시퀀스 데이터는 순차적인 특성을 꼭 지닌다.</li>\n</ul>\n<p>이런 순차 데이터를 처리하는 레이어가 recurrent layer</p>\n<p>RNN 은 단 하나의 Weight 를 순차적으로 업데이트 한다.</p>\n<p>다음은 RNN 의 예시이다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">sentence <span class=\"token operator\">=</span> <span class=\"token string\">\"What time is it ?\"</span>\ndic <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token string\">\"is\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"it\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"What\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"time\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"?\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">4</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"RNN에 입력할 문장:\"</span><span class=\"token punctuation\">,</span> sentence<span class=\"token punctuation\">)</span>\n\nsentence_tensor <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>constant<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span>dic<span class=\"token punctuation\">[</span>word<span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> word <span class=\"token keyword\">in</span> sentence<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Embedding을 위해 단어 매핑:\"</span><span class=\"token punctuation\">,</span> sentence_tensor<span class=\"token punctuation\">.</span>numpy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"입력 문장 데이터 형태:\"</span><span class=\"token punctuation\">,</span> sentence_tensor<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n\nembedding_layer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Embedding<span class=\"token punctuation\">(</span>input_dim<span class=\"token operator\">=</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>dic<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> output_dim<span class=\"token operator\">=</span><span class=\"token number\">100</span><span class=\"token punctuation\">)</span>\nemb_out <span class=\"token operator\">=</span> embedding_layer<span class=\"token punctuation\">(</span>sentence_tensor<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\nEmbedding 결과:\"</span><span class=\"token punctuation\">,</span> emb_out<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Embedding Layer의 Weight 형태:\"</span><span class=\"token punctuation\">,</span> embedding_layer<span class=\"token punctuation\">.</span>weights<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n\nrnn_seq_layer <span class=\"token operator\">=</span> \\\ntf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>SimpleRNN<span class=\"token punctuation\">(</span>units<span class=\"token operator\">=</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span> return_sequences<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> use_bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\nrnn_seq_out <span class=\"token operator\">=</span> rnn_seq_layer<span class=\"token punctuation\">(</span>emb_out<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\nRNN 결과 (모든 Step Output):\"</span><span class=\"token punctuation\">,</span> rnn_seq_out<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Simple RNN Layer의 Weight 형태:\"</span><span class=\"token punctuation\">,</span> rnn_seq_layer<span class=\"token punctuation\">.</span>weights<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n\nrnn_fin_layer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>SimpleRNN<span class=\"token punctuation\">(</span>units<span class=\"token operator\">=</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span> use_bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\nrnn_fin_out <span class=\"token operator\">=</span> rnn_fin_layer<span class=\"token punctuation\">(</span>emb_out<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\nRNN 결과 (최종 Step Output):\"</span><span class=\"token punctuation\">,</span> rnn_fin_out<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Simple RNN Layer의 Weight 형태:\"</span><span class=\"token punctuation\">,</span> rnn_fin_layer<span class=\"token punctuation\">.</span>weights<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">RNN에 입력할 문장: What time is it ?\nEmbedding을 위해 단어 매핑: [[2 3 0 1 4]]\n입력 문장 데이터 형태: (1, 5)\n\nEmbedding 결과: (1, 5, 100)\nEmbedding Layer의 Weight 형태: (5, 100)\n\nRNN 결과 (모든 Step Output): (1, 5, 64)\nRNN Layer의 Weight 형태: (100, 64)\n\nRNN 결과 (최종 Step Output): (1, 64)\nRNN Layer의 Weight 형태: (100, 64)</code></pre></div>\n<p>어떤 문장이 긍정인지 부정인지 나누기 위해서라면 문장을 모두 읽은 후,<br>\n최종 Step의 Output만 확인해도 판단이 가능하다.</p>\n<p>하지만 문장을 생성하는 경우라면<br>\n이전 단어를 입력으로 받아 생성된<br>\n모든 다음 단어, 즉 모든 Step에 대한 Output이 필요하다.</p>\n<p>모든 step 의 output 은 <code class=\"language-text\"> return_sequences=True</code> 로 조절 가능하다</p>\n<p>위의 결과를 보면 결국 마지막에 남는 Weight 은 (100, 64)로 똑같은 값을 가진다.</p>\n<h4 id=\"위의-코드는-아래의-lstm-사용-코드와-동일하다\" style=\"position:relative;\"><a href=\"#%EC%9C%84%EC%9D%98-%EC%BD%94%EB%93%9C%EB%8A%94-%EC%95%84%EB%9E%98%EC%9D%98-lstm-%EC%82%AC%EC%9A%A9-%EC%BD%94%EB%93%9C%EC%99%80-%EB%8F%99%EC%9D%BC%ED%95%98%EB%8B%A4\" aria-label=\"위의 코드는 아래의 lstm 사용 코드와 동일하다 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>위의 코드는 아래의 LSTM 사용 코드와 동일하다</h4>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">lstm_seq_layer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>LSTM<span class=\"token punctuation\">(</span>units<span class=\"token operator\">=</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span> return_sequences<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> use_bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\nlstm_seq_out <span class=\"token operator\">=</span> lstm_seq_layer<span class=\"token punctuation\">(</span>emb_out<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\nLSTM 결과 (모든 Step Output):\"</span><span class=\"token punctuation\">,</span> lstm_seq_out<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"LSTM Layer의 Weight 형태:\"</span><span class=\"token punctuation\">,</span> lstm_seq_layer<span class=\"token punctuation\">.</span>weights<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n\nlstm_fin_layer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>LSTM<span class=\"token punctuation\">(</span>units<span class=\"token operator\">=</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span> use_bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\nlstm_fin_out <span class=\"token operator\">=</span> lstm_fin_layer<span class=\"token punctuation\">(</span>emb_out<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\nLSTM 결과 (최종 Step Output):\"</span><span class=\"token punctuation\">,</span> lstm_fin_out<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"LSTM Layer의 Weight 형태:\"</span><span class=\"token punctuation\">,</span> lstm_fin_layer<span class=\"token punctuation\">.</span>weights<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n\nLSTM 결과 (모든 Step Output): (1, 5, 64)\nLSTM Layer의 Weight 형태: (100, 256)\nWARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n\nLSTM 결과 (최종 Step Output): (1, 64)\nLSTM Layer의 Weight 형태: (100, 256)</code></pre></div>\n<p>잠깐잠깐 LSTM 이 뭔데 갑자기 나와..?</p>\n<h1 id=\"recuurent-layer---lstm\" style=\"position:relative;\"><a href=\"#recuurent-layer---lstm\" aria-label=\"recuurent layer   lstm permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Recuurent layer - LSTM</h1>\n<p>; Long short Term memory</p>\n<p>얘도 RNN 레이어의 일종이다.</p>\n<hr>\n<p>딥러닝은 back propagation 으로 가중치의 미분을 구한 다음 업데이트한다.</p>\n<p>가중치를 업데이트 하는 RNN 의 특성상, input 이 길수록 초기 단어의 미분값이<br>\n매우 작아지거나 커지는 현상이 발생한다.</p>\n<p>이 현상을 기울기 소실 (vanishing) 혹은 포화 (exploding) 이라고 한다.</p>\n<p>LSTM 은 일반 RNN보다 4배 큰 가중치 값을 가진다.<br>\n위를 보면 RNN =(100,64) , LSTM = (100,256) 인거를 보면 된다.</p>\n<p>하지만 단순히 weight 가 4배 ‘많은’ 게 아니라 4베 ‘다양한’ 것이다.</p>\n<p>각 weight 는 <code class=\"language-text\">Gate</code> 라는 구조에 포함되어 기억할 정보, 전달할 정보를 결정한다.</p>\n<p>LSTM 에는 <code class=\"language-text\">Cell state</code> 를 통해서 긴 문장의 앞부분도 손실 없이 저장해준다.<br>\n앞서 언급한 Gate 가 Cell state 에 정보를 추가/삭제 한다.</p>\n<hr>\n<h3 id=\"자세한-설명\" style=\"position:relative;\"><a href=\"#%EC%9E%90%EC%84%B8%ED%95%9C-%EC%84%A4%EB%AA%85\" aria-label=\"자세한 설명 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>자세한 설명</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 61.11111111111111%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAABJ0AAASdAHeZh94AAABuklEQVQoz41T2U7bUBDN/38EP1DxQFWplLZIkARsbGeBFESTOC2CgEli+/ou3n3QTApqSlp6peOZsUfHZ5bbEkJgdHmFdqeL/mCI9skpbMdlv9fvwz5zMTi/wNFxGyeWBcfz+Pvt3Rx06qbB76dVliXCKEIQBFgsl0ikxCoMkSQJlFKIhYBUiuM4jhmUr7RmgqZpNtDCf5yqLre+b36p2yCkR1mUEMUjFsUMQepjkf9gPGYzBNkUD2aKNDeo6/qVoq0K5/dz2FdfcGi/g3f7Fe3BHjqj97D8fXSvP8CefoLldaC1ebOa1rPs8aKPz71dXEc2dj/u4PK+i5/pEJPIgS89ZLXivDRNGcYYSCmRZRmDYhrwC+FN8g2Du0M4/gGOh3uYRDZ86WKaePBVD6ZKOC/PcybUWvPQKCZCiglMmJcpbuQI38UpfO1ilroYCwu+cjBRDsbiDKF54B6+WfKzo8sYslpC1yFUtWLLfr2CaeKNyf5zKFVVcS/WJRgoaaDZaobR6TpWeqvC5s/FpiTqBTWVLEEbDakk+2Sp2bTYWZ4zAYkoimJjD1+V/NelrqqXqdItIn/9I7WV8AkqA5dZu1PQRAAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/7407f12fa125bfc200e45f2922c3e77a/37523/5.png\"\n        srcset=\"/static/7407f12fa125bfc200e45f2922c3e77a/e9ff0/5.png 180w,\n/static/7407f12fa125bfc200e45f2922c3e77a/f21e7/5.png 360w,\n/static/7407f12fa125bfc200e45f2922c3e77a/37523/5.png 720w,\n/static/7407f12fa125bfc200e45f2922c3e77a/5b481/5.png 846w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<h2 id=\"아래의-그림은-하나의-활성함수를-지닌-기본-rnn-이다\" style=\"position:relative;\"><a href=\"#%EC%95%84%EB%9E%98%EC%9D%98-%EA%B7%B8%EB%A6%BC%EC%9D%80-%ED%95%98%EB%82%98%EC%9D%98-%ED%99%9C%EC%84%B1%ED%95%A8%EC%88%98%EB%A5%BC-%EC%A7%80%EB%8B%8C-%EA%B8%B0%EB%B3%B8-rnn-%EC%9D%B4%EB%8B%A4\" aria-label=\"아래의 그림은 하나의 활성함수를 지닌 기본 rnn 이다 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>아래의 그림은 하나의 활성함수를 지닌 기본 RNN 이다.</h2>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 41.11111111111111%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAABJ0AAASdAHeZh94AAABnUlEQVQoz2WS226bUBBF+f9fqdQ+9SFWL0qkpsFJsImb4GADxsEQMObO4WpWVZw2abul0Uh7NGse9ki81XBqy6mBawSv3ou/W/uslA3/qiprbiYLhuOANAwDTVfTdBVVIzjSYZomRV6MpF9+01YM9ETxgaetM0JEU1C1groViLpgra9GX8qrGCNVsMs7nPqeTaFiZArbYI3mXqNH11i5ihbIqLsL5rrM9vCImd+yFYtxz8xnmMmcQxQiJWKPWd6gJ1M+z95jV3MsoWD5SzRfZu6ec7X8wMyeoEWXaM4tRrDA6VWu1mfIxgSnW2BmCvvQPwFXuYyeysjm2Qg3yimh2PHD+8631Ue+qu9YZzJ2p+CVa7zCwBBTZs4X7rxz7GaGVSh0fYtUtyV2eM9zabGvbbzCHBeS4oDlPhBUG3xhj/NdviKtQ/aJw1OyxBcWz6WJk+p4mUXf90hbL+RSNU6BHl+Ta9qOT9MHuo7/0r5QHnGD9K/P+C0pFxVBnL0BNcRJRBTHaKZNnCSkaULy0rM0Rbe2uL5PVVWnO8Pwp34CjpFXKhO+FB8AAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/efb88d54d6e244dde8264612aedfae4e/37523/6.png\"\n        srcset=\"/static/efb88d54d6e244dde8264612aedfae4e/e9ff0/6.png 180w,\n/static/efb88d54d6e244dde8264612aedfae4e/f21e7/6.png 360w,\n/static/efb88d54d6e244dde8264612aedfae4e/37523/6.png 720w,\n/static/efb88d54d6e244dde8264612aedfae4e/d2a60/6.png 807w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<h2 id=\"이와-달리-lstm-은-한-레이어의-4-가지-가중치-존재\" style=\"position:relative;\"><a href=\"#%EC%9D%B4%EC%99%80-%EB%8B%AC%EB%A6%AC-lstm-%EC%9D%80-%ED%95%9C-%EB%A0%88%EC%9D%B4%EC%96%B4%EC%9D%98-4-%EA%B0%80%EC%A7%80-%EA%B0%80%EC%A4%91%EC%B9%98-%EC%A1%B4%EC%9E%AC\" aria-label=\"이와 달리 lstm 은 한 레이어의 4 가지 가중치 존재 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>이와 달리 LSTM 은 한 레이어의 4 가지 가중치 존재</h2>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 62.77777777777778%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAABJ0AAASdAHeZh94AAACSUlEQVQ4y2WT2XLaQBBF+f8/yFOqksfk0YmzFcTEjgOOgYDNKjFCG6sEQhubOKkZFjtOV3VNT8/tO92aqxwvbOmHaNWBivf7vXJpabyid2+QZdk/+N1uR/dOsErWap+TBTK53WxVYjb26NR1FWfZE+E63dCsdA/5XcZO+nanzhvlFqv0SDiOBhhBAzfp4ERtRFDH8Fo4U4E+q2L4DwivTn/+h4ZRZuhZDJYPOHEHN+1iR21V7wezA+Fg+YixrnAnvvI4vUYkv9G9GrXOLb/0S26aHyhrX8iX3lP8fUF/3ESPy7S8n5T0zxhplV5QZuw5sD8SiuSOm+5H7s1v9JM7+n6dplGmUHnN5dUrflTe8L32juv6J0yvixaVqNkFrjsXGGmF7qKEF4yPIy/7iEVdjSzbN8NHLL9HW6tR04s07bJyMa/TtmqYroYZNBRW1lhhEzNoMvMnhw5vGzpBmB6ebH90oKE7DL3wpQjomiNaYnSAZ/8dkxPulGS15sS43qwJlwFNzUBYDlG4JAgW+L5PHEf0DIt2f8A+27Fnf5aWlJNcc/DU3El7z7V2ks7L/ElOp/UU57IjUGoxy3ZnwGGfnePtdnsmfu4nojAMnzpcBi5W/y1D+4rThXPbZhUESMrxeEy1WmU2m6nRi8Wi2ssL5/M5hUKBfD5/+IZypNHQxRx0ME2dOE5I0xRDCEbDoQJNJhNFKm2xWGDbNq7rqs43mw1CCOXnX08S2LbLdOqd29c0DcdxVBeWZalYWpIkRFGkMJJQWhzH51f+C2xa1dRk9vPYAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/2d8c740ce607bdb9f8c58d091eca361f/37523/7.png\"\n        srcset=\"/static/2d8c740ce607bdb9f8c58d091eca361f/e9ff0/7.png 180w,\n/static/2d8c740ce607bdb9f8c58d091eca361f/f21e7/7.png 360w,\n/static/2d8c740ce607bdb9f8c58d091eca361f/37523/7.png 720w,\n/static/2d8c740ce607bdb9f8c58d091eca361f/42d54/7.png 858w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>LSTM 이 가진 가장 큰 특징은 상단에 가로로 그어진 Cell ctate 이다.</p>\n<p>얘는 컨베이어 벨트처럼 작은 선형변환을 아주 조금씩 하면서 정보가 나아간다.</p>\n<p>LSTM 은 이 능력을 gate 라고 불리는 구조로 조금씩 변형시킨다.</p>\n<p>Gate = 시그모이드 와 pointwise 곱셈으로 이루어진 정보전달 방법</p>\n<p>시그모이드의 output 은 0과 1로만 이루어져 있어 보낼 정보와 막을 정보를 고른다</p>\n<p>LSTM 은 3개의 gate 값을 가지고 있다. 이 3개로 CELL STATE 에 보낼 값을 제어한다.</p>\n<p>3개의 GATE 는 다음과 같다.</p>\n<ol>\n<li>forgat gate layer</li>\n</ol>\n<p>cell state 에서 지울 값 선정</p>\n<ol start=\"2\">\n<li>input gate layer</li>\n</ol>\n<p>새로운 cell state 를 기존 cell state 에 반영할 정도를 선정</p>\n<ul>\n<li>(여기서 원래 본연의 가중치를 통해 이전 1,2번에서 정한 일 해줌)</li>\n</ul>\n<ol start=\"3\">\n<li>output gate layer</li>\n</ol>\n<p>cell state 로 필터된 output 배출</p>\n<hr>\n<p>1번 , 2번, - 번, 4번 이렇게 총 4번의 레이어 활동으로 LSTM 은 작동한다.</p>\n<hr>\n<p>이 외에도 뭐</p>\n<p>엿보기 LSTM,, GRU,,,</p>\n<p>BIRNN 등 뭐 이것저것 많다\n아래 코드는 양방향(Bidirectional) RNN 코드임</p>\n<p>양방향이라서 가중치가 두배임 앞 뒤에서 가야되니까</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n\nsentence <span class=\"token operator\">=</span> <span class=\"token string\">\"What time is it ?\"</span>\ndic <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token string\">\"is\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"it\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"What\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"time\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"?\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">4</span>\n<span class=\"token punctuation\">}</span>\n\nsentence_tensor <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>constant<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span>dic<span class=\"token punctuation\">[</span>word<span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> word <span class=\"token keyword\">in</span> sentence<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nembedding_layer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Embedding<span class=\"token punctuation\">(</span>input_dim<span class=\"token operator\">=</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>dic<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> output_dim<span class=\"token operator\">=</span><span class=\"token number\">100</span><span class=\"token punctuation\">)</span>\nemb_out <span class=\"token operator\">=</span> embedding_layer<span class=\"token punctuation\">(</span>sentence_tensor<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"입력 문장 데이터 형태:\"</span><span class=\"token punctuation\">,</span> emb_out<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n\nbi_rnn <span class=\"token operator\">=</span> \\\ntf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Bidirectional<span class=\"token punctuation\">(</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>SimpleRNN<span class=\"token punctuation\">(</span>units<span class=\"token operator\">=</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span> use_bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> return_sequences<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">)</span>\nbi_out <span class=\"token operator\">=</span> bi_rnn<span class=\"token punctuation\">(</span>emb_out<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Bidirectional RNN 결과 (최종 Step Output):\"</span><span class=\"token punctuation\">,</span> bi_out<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">입력 문장 데이터 형태: (1, 5, 100)\nBidirectional RNN 결과 (최종 Step Output): (1, 5, 128)</code></pre></div>\n<div class=\"table-of-contents\">\n<ul>\n<li>\n<p><a href=\"#%EC%9E%84%EB%B2%A0%EB%94%A9-%EB%A0%88%EC%9D%B4%EC%96%B4%EB%8A%94-%EC%BB%B4%ED%93%A8%ED%84%B0%EA%B0%80-%EC%95%8C%EC%95%84%EB%A8%B9%EB%8A%94-%EB%8B%A8%EC%96%B4%EC%82%AC%EC%A0%84%EC%9D%B4%EB%8B%A4\">임베딩 레이어는 컴퓨터가 알아먹는 단어사전이다.</a></p>\n<ul>\n<li>\n<ul>\n<li><a href=\"#%EA%B7%BC%EB%8D%B0-%EC%9E%84%EB%B2%A0%EB%94%A9-%EB%A0%88%EC%9D%B4%EC%96%B4%EB%8A%94-%EB%AF%B8%EB%B6%84%EC%9D%84-%ED%95%A0%EC%88%98-%EC%97%86%EB%8A%94-%EC%95%A0%EB%9D%BC-%EC%96%B4%EB%96%A4-%EC%97%B0%EC%82%B0-%EA%B2%B0%EA%B3%BC%EB%A5%BC\">근데 임베딩 레이어는 미분을 할수 없는 애라 어떤 연산 결과를</a></li>\n<li><a href=\"#%EC%9E%84%EB%B2%A0%EB%94%A9-%EB%A0%88%EC%9D%B4%EC%96%B4%EC%97%90-%EC%A0%81%EC%9C%BC%EB%A9%B4-%EC%95%88%EB%90%9C%EB%8B%A4%EB%84%A4\">임베딩 레이어에 적으면 안된다네</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><a href=\"#%EA%B7%B8%EB%9F%B0-%EC%9E%84%EB%B2%A0%EB%94%A9-%EB%A0%88%EC%9D%B4%EC%96%B4%EC%99%80-%ED%95%A8%EA%BB%98-%EC%93%B0%EB%8A%94-%EB%AC%B8%EC%9E%A5-%ED%8A%B9%ED%99%94-%EB%A0%88%EC%9D%B4%EC%96%B4\">그런 임베딩 레이어와 함께 쓰는 문장 특화 레이어</a></p>\n<ul>\n<li>\n<ul>\n<li><a href=\"#%EC%9C%84%EC%9D%98-%EC%BD%94%EB%93%9C%EB%8A%94-%EC%95%84%EB%9E%98%EC%9D%98-lstm-%EC%82%AC%EC%9A%A9-%EC%BD%94%EB%93%9C%EC%99%80-%EB%8F%99%EC%9D%BC%ED%95%98%EB%8B%A4\">위의 코드는 아래의 LSTM 사용 코드와 동일하다</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#%EC%9E%90%EC%84%B8%ED%95%9C-%EC%84%A4%EB%AA%85\">자세한 설명</a></p>\n</li>\n</ul>\n</li>\n<li>\n<p><a href=\"#%EC%95%84%EB%9E%98%EC%9D%98-%EA%B7%B8%EB%A6%BC%EC%9D%80-%ED%95%98%EB%82%98%EC%9D%98-%ED%99%9C%EC%84%B1%ED%95%A8%EC%88%98%EB%A5%BC-%EC%A7%80%EB%8B%8C-%EA%B8%B0%EB%B3%B8-rnn-%EC%9D%B4%EB%8B%A4\">아래의 그림은 하나의 활성함수를 지닌 기본 RNN 이다.</a></p>\n</li>\n<li>\n<p><a href=\"#%EC%9D%B4%EC%99%80-%EB%8B%AC%EB%A6%AC-lstm-%EC%9D%80-%ED%95%9C-%EB%A0%88%EC%9D%B4%EC%96%B4%EC%9D%98-4-%EA%B0%80%EC%A7%80-%EA%B0%80%EC%A4%91%EC%B9%98-%EC%A1%B4%EC%9E%AC\">이와 달리 LSTM 은 한 레이어의 4 가지 가중치 존재</a></p>\n</li>\n</ul>\n</div>","frontmatter":{"date":"April 21, 2022","title":"임베딩이란","categories":"STUDY","author":"하성민","emoji":"😁"},"fields":{"slug":"/NLP_4/"}},"prev":{"id":"797d644a-1f24-5817-8dd3-7489d8b62484","html":"<h1 id=\"span-stylebackground-color-fff5b1-tensor-flow-v2-라이브러리를-이용해-딥러닝-모델-생성하기span\" style=\"position:relative;\"><a href=\"#span-stylebackground-color-fff5b1-tensor-flow-v2-%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%B4-%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%AA%A8%EB%8D%B8-%EC%83%9D%EC%84%B1%ED%95%98%EA%B8%B0span\" aria-label=\"span stylebackground color fff5b1 tensor flow v2 라이브러리를 이용해 딥러닝 모델 생성하기span permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><span style='background-color: #fff5b1'>🌠 Tensor flow V2 라이브러리를 이용해 딥러닝 모델 생성하기</span></h1>\n<p>Tensor flow V2 버전에서 딥러닝 모델 작성 방법에는 크게 3가지가 있다.</p>\n<ul>\n<li>Sequential</li>\n<li>Functional : sequential 의 일반화된 개념</li>\n<li>Model Subclassing : 클래스로 구현된 기존 모델을 상속받아 자기 모델 만들기</li>\n</ul>\n<p>순차적으로 어떤 차이가 있고,<br>\n어떤 식으로 제작하는지 알아가보자.</p>\n<hr>\n<h2 id=\"1-sequential-model\" style=\"position:relative;\"><a href=\"#1-sequential-model\" aria-label=\"1 sequential model permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. Sequential Model</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n<span class=\"token keyword\">from</span> tensorflow <span class=\"token keyword\">import</span> keras\n\nmodel <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>__넣고싶은 레이어__<span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>__넣고싶은 레이어__<span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>__넣고싶은 레이어__<span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">20</span><span class=\"token punctuation\">,</span> batch_size<span class=\"token operator\">=</span><span class=\"token number\">16</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>epochs : 모델로 데이터를 학습할 횟수<br>\nbatch_size : 데이터를 소분해 넣을 양</p>\n<p>model = keras.Sequential() 을 활용하면<br>\n딥러닝 모델을 쌓아 나갈 수 있다.</p>\n<p>입력부터 출력까지 순차적(시퀀셜) 으로 add 하면 된다.</p>\n<h4 id=\"but\" style=\"position:relative;\"><a href=\"#but\" aria-label=\"but permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>but,</h4>\n<p>모델의 입력과 출력이 여러개인 경우에는 적합하지 않다.<br>\n(반드시 입력 1개 출력 1가지 여야 함)</p>\n<h2 id=\"2-functional-api\" style=\"position:relative;\"><a href=\"#2-functional-api\" aria-label=\"2 functional api permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. Functional API</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n<span class=\"token keyword\">from</span> tensorflow <span class=\"token keyword\">import</span> keras\n\ninputs <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>Input<span class=\"token punctuation\">(</span>shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>__원하는 입력값 모양__<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nx <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>__넣고싶은 레이어__<span class=\"token punctuation\">(</span>관련 파라미터<span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">input</span><span class=\"token punctuation\">)</span>\nx <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>__넣고싶은 레이어__<span class=\"token punctuation\">(</span>관련 파라미터<span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\noutputs <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>__넣고싶은 레이어__<span class=\"token punctuation\">(</span>관련 파라미터<span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n\nmodel <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>Model<span class=\"token punctuation\">(</span>inputs<span class=\"token operator\">=</span>inputs<span class=\"token punctuation\">,</span> outputs<span class=\"token operator\">=</span>outputs<span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span>y<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> batch_size<span class=\"token operator\">=</span><span class=\"token number\">32</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>model 에 ketas.Model 이 들어간다.<br>\n이것은 우리가 danse 나 Flatten 같은 짜여져 있는 신경망을 쓰는 게 아니라<br>\n직접 input 과 output 을 구성한다.</p>\n<p>때문에 입력과 출력값이 자유롭다</p>\n<hr>\n<p>딥 러닝 모델은 일반적으로 레이어의 DAG Directed Acyclic graph 이다.<br>\n레이어의 그래프를 bulid 한다는 뜻이다.</p>\n<h2 id=\"3-subclassing\" style=\"position:relative;\"><a href=\"#3-subclassing\" aria-label=\"3 subclassing permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. Subclassing</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n<span class=\"token keyword\">from</span> tensorflow <span class=\"token keyword\">import</span> keras\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">CustomModel</span><span class=\"token punctuation\">(</span>keras<span class=\"token punctuation\">.</span>Model<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span>CustomModel<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>__정의하고자 하는 레이어__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>__정의하고자 하는 레이어__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>__정의하고자 하는 레이어__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    \n    <span class=\"token keyword\">def</span> <span class=\"token function\">call</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>__정의하고자 하는 레이어__<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>__정의하고자 하는 레이어__<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>__정의하고자 하는 레이어__<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        \n        <span class=\"token keyword\">return</span> x\n    \nmodel <span class=\"token operator\">=</span> CustomModel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span>y<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> batch_size<span class=\"token operator\">=</span><span class=\"token number\">32</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>제일 자유로운 모델링이 가능한 subclassing</p>\n<h1 id=\"이를-바탕으로-직접-구현해보자\" style=\"position:relative;\"><a href=\"#%EC%9D%B4%EB%A5%BC-%EB%B0%94%ED%83%95%EC%9C%BC%EB%A1%9C-%EC%A7%81%EC%A0%91-%EA%B5%AC%ED%98%84%ED%95%B4%EB%B3%B4%EC%9E%90\" aria-label=\"이를 바탕으로 직접 구현해보자 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>이를 바탕으로 직접 구현해보자</h1>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n<span class=\"token keyword\">from</span> tensorflow <span class=\"token keyword\">import</span> keras\n<span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 데이터 구성부분</span>\nmnist <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>datasets<span class=\"token punctuation\">.</span>mnist\n\n<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span> y_test<span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> mnist<span class=\"token punctuation\">.</span>load_data<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nx_train<span class=\"token punctuation\">,</span> x_test <span class=\"token operator\">=</span> x_train <span class=\"token operator\">/</span> <span class=\"token number\">255.0</span><span class=\"token punctuation\">,</span> x_test <span class=\"token operator\">/</span> <span class=\"token number\">255.0</span>\n\nx_train<span class=\"token operator\">=</span>x_train<span class=\"token punctuation\">[</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">,</span>np<span class=\"token punctuation\">.</span>newaxis<span class=\"token punctuation\">]</span>\nx_test<span class=\"token operator\">=</span>x_test<span class=\"token punctuation\">[</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">,</span>np<span class=\"token punctuation\">.</span>newaxis<span class=\"token punctuation\">]</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n11493376/11490434 [==============================] - 0s 0us/step\n11501568/11490434 [==============================] - 0s 0us/step\n60000 10000</code></pre></div>\n<h2 id=\"1-sequential-model-1\" style=\"position:relative;\"><a href=\"#1-sequential-model-1\" aria-label=\"1 sequential model 1 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. Sequential model</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># Sequential Model을 구성해주세요.</span>\n<span class=\"token triple-quoted-string string\">\"\"\"\nSpec:\n1. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n2. 64개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n3. Flatten 레이어\n4. 128개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n5. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n\"\"\"</span>\n\n\nmodel <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>models<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span>activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span>activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">128</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span>activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span>\n                           <span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n\n<span class=\"token triple-quoted-string string\">\"\"\"\nmodel.add.Conv2D(32, 3, activation=\"relu\")\nmodel.add.Conv2D(64, 3, activation=\"relu\")\nmodel.add.Flatten()\nmodel.add.Dense(128, activation='relu')\nmodel.add.Dense(10, activation='softmax')\n\"\"\"</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">'\\nmodel.add.Conv2D(32, 3, activation=\"relu\")\\nmodel.add.Conv2D(64, 3, activation=\"relu\")\\nmodel.add.Flatten()\\nmodel.add.Dense(128, activation=\\'relu\\')\\nmodel.add.Dense(10, activation=\\'softmax\\')\\n'</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 모델 학습 설정</span>\n\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span><span class=\"token string\">'adam'</span><span class=\"token punctuation\">,</span>\n              loss<span class=\"token operator\">=</span><span class=\"token string\">'sparse_categorical_crossentropy'</span><span class=\"token punctuation\">,</span>\n              metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span>  y_test<span class=\"token punctuation\">,</span> verbose<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Epoch 1/5\n1875/1875 [==============================] - 31s 3ms/step - loss: 0.1118 - accuracy: 0.9654\nEpoch 2/5\n1875/1875 [==============================] - 5s 3ms/step - loss: 0.0368 - accuracy: 0.9882\nEpoch 3/5\n1875/1875 [==============================] - 5s 3ms/step - loss: 0.0211 - accuracy: 0.9933\nEpoch 4/5\n1875/1875 [==============================] - 5s 3ms/step - loss: 0.0131 - accuracy: 0.9956\nEpoch 5/5\n1875/1875 [==============================] - 5s 3ms/step - loss: 0.0100 - accuracy: 0.9968\n313/313 - 1s - loss: 0.0516 - accuracy: 0.9878\n\n\n\n\n\n[0.051644984632730484, 0.9878000020980835]</code></pre></div>\n<h2 id=\"2-functional-api-1\" style=\"position:relative;\"><a href=\"#2-functional-api-1\" aria-label=\"2 functional api 1 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. Functional API</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">mnist <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>datasets<span class=\"token punctuation\">.</span>mnist\n\n<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span> y_test<span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> mnist<span class=\"token punctuation\">.</span>load_data<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nx_train<span class=\"token punctuation\">,</span> x_test <span class=\"token operator\">=</span> x_train <span class=\"token operator\">/</span> <span class=\"token number\">255.0</span><span class=\"token punctuation\">,</span> x_test <span class=\"token operator\">/</span> <span class=\"token number\">255.0</span>\n\nx_train<span class=\"token operator\">=</span>x_train<span class=\"token punctuation\">[</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">,</span>np<span class=\"token punctuation\">.</span>newaxis<span class=\"token punctuation\">]</span>\nx_test<span class=\"token operator\">=</span>x_test<span class=\"token punctuation\">[</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">,</span>np<span class=\"token punctuation\">.</span>newaxis<span class=\"token punctuation\">]</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">60000 10000</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token triple-quoted-string string\">\"\"\"\nSpec:\n0. (28X28X1) 차원으로 정의된 Input\n1. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n2. 64개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n3. Flatten 레이어\n4. 128개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n5. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n\"\"\"</span>\n\ninputs <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>Input<span class=\"token punctuation\">(</span>shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">28</span><span class=\"token punctuation\">,</span><span class=\"token number\">28</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nx <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span>activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>inputs<span class=\"token punctuation\">)</span>\nx <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span>activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\nx <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\nx <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">128</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\noutputs <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n\nmodel <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>Model<span class=\"token punctuation\">(</span>inputs<span class=\"token operator\">=</span>inputs<span class=\"token punctuation\">,</span> outputs<span class=\"token operator\">=</span>outputs<span class=\"token punctuation\">)</span>\n\n\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span><span class=\"token string\">'adam'</span><span class=\"token punctuation\">,</span>\n              loss<span class=\"token operator\">=</span><span class=\"token string\">'sparse_categorical_crossentropy'</span><span class=\"token punctuation\">,</span>\n              metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span>  y_test<span class=\"token punctuation\">,</span> verbose<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Epoch 1/5\n1875/1875 [==============================] - 7s 3ms/step - loss: 0.1039 - accuracy: 0.9679\nEpoch 2/5\n1875/1875 [==============================] - 6s 3ms/step - loss: 0.0339 - accuracy: 0.9895\nEpoch 3/5\n1875/1875 [==============================] - 6s 3ms/step - loss: 0.0204 - accuracy: 0.9931\nEpoch 4/5\n1875/1875 [==============================] - 6s 3ms/step - loss: 0.0130 - accuracy: 0.9959\nEpoch 5/5\n1875/1875 [==============================] - 6s 3ms/step - loss: 0.0093 - accuracy: 0.9972\n313/313 - 1s - loss: 0.0522 - accuracy: 0.9868\n\n\n\n\n\n[0.05223735421895981, 0.9868000149726868]</code></pre></div>\n<h2 id=\"3-subclassing-api\" style=\"position:relative;\"><a href=\"#3-subclassing-api\" aria-label=\"3 subclassing api permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. Subclassing API</h2>\n<p>keras.models 를 상속받는 클래스를 만드는 것</p>\n<ol>\n<li><strong>init</strong> 메서드에 레이어 선언</li>\n<li>call() 메서드에 forward propagation 방식 체계 구현</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token triple-quoted-string string\">\"\"\"\nSpec:\n0. keras.Model 을 상속받았으며, __init__()와 call() 메서드를 가진 모델 클래스\n1. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n2. 64개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n3. Flatten 레이어\n4. 128개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n5. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n6. call의 입력값이 모델의 Input, call의 리턴값이 모델의 Output\n\"\"\"</span>\n\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">kerasModel</span><span class=\"token punctuation\">(</span>keras<span class=\"token punctuation\">.</span>Model<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        \n        self<span class=\"token punctuation\">.</span>Conv2D32 <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>Conv2D64 <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>Flatten <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>Dense128 <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">128</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>Dense <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span>\n    \n    <span class=\"token keyword\">def</span> <span class=\"token function\">call</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>Conv2D32<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>Conv2D64<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>Dense128<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        output <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        \n        <span class=\"token keyword\">return</span> output\n    \nmodel <span class=\"token operator\">=</span> kerasModel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span><span class=\"token string\">'adam'</span><span class=\"token punctuation\">,</span>\n              loss<span class=\"token operator\">=</span><span class=\"token string\">'sparse_categorical_crossentropy'</span><span class=\"token punctuation\">,</span>\n              metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span>  y_test<span class=\"token punctuation\">,</span> verbose<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Epoch 1/5\n1875/1875 [==============================] - 7s 3ms/step - loss: 0.1011 - accuracy: 0.9689\nEpoch 2/5\n1875/1875 [==============================] - 6s 3ms/step - loss: 0.0339 - accuracy: 0.9893\nEpoch 3/5\n1875/1875 [==============================] - 6s 3ms/step - loss: 0.0184 - accuracy: 0.9938\nEpoch 4/5\n1875/1875 [==============================] - 6s 3ms/step - loss: 0.0136 - accuracy: 0.9954\nEpoch 5/5\n1875/1875 [==============================] - 6s 3ms/step - loss: 0.0078 - accuracy: 0.9973\n313/313 - 1s - loss: 0.0581 - accuracy: 0.9853\n\n\n\n\n\n[0.05812956392765045, 0.9853000044822693]</code></pre></div>\n<p>이건 결론적으로는 model 을 갖다 쓰는거라서<br>\ninput 을 따로 설정안하고<br>\n그리고 call 메서드도 fit 할때 자동으로 써지는 듯 하다.</p>\n<hr>\n<h1 id=\"cifar--100-데이터-예제로-복습\" style=\"position:relative;\"><a href=\"#cifar--100-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%98%88%EC%A0%9C%EB%A1%9C-%EB%B3%B5%EC%8A%B5\" aria-label=\"cifar  100 데이터 예제로 복습 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>CIFAR -100 데이터 예제로 복습</h1>\n<h3 id=\"sequential\" style=\"position:relative;\"><a href=\"#sequential\" aria-label=\"sequential permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Sequential</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 데이터 구성부분</span>\ncifar100 <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>datasets<span class=\"token punctuation\">.</span>cifar100\n\n<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span> y_test<span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> cifar100<span class=\"token punctuation\">.</span>load_data<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nx_train<span class=\"token punctuation\">,</span> x_test <span class=\"token operator\">=</span> x_train <span class=\"token operator\">/</span> <span class=\"token number\">255.0</span><span class=\"token punctuation\">,</span> x_test <span class=\"token operator\">/</span> <span class=\"token number\">255.0</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">50000 10000</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># Sequential Model을 구성해주세요.</span>\n<span class=\"token triple-quoted-string string\">\"\"\"\nSpec:\n1. 16개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n2. pool_size가 2인 MaxPool 레이어\n3. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n4. pool_size가 2인 MaxPool 레이어\n5. 256개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n6. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n\"\"\"</span>\n\nmodel <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>models<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span>activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>MaxPool2D<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span>activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>MaxPool2D<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">256</span><span class=\"token punctuation\">,</span>activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">100</span><span class=\"token punctuation\">,</span>activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">model<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span><span class=\"token string\">'adam'</span><span class=\"token punctuation\">,</span>\n              loss<span class=\"token operator\">=</span><span class=\"token string\">'sparse_categorical_crossentropy'</span><span class=\"token punctuation\">,</span>\n              metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span>  y_test<span class=\"token punctuation\">,</span> verbose<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Epoch 1/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\nEpoch 2/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\nEpoch 3/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\nEpoch 4/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\nEpoch 5/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\n313/313 - 1s - loss: nan - accuracy: 0.0100\n\n\n\n\n\n[nan, 0.009999999776482582]</code></pre></div>\n<h3 id=\"functional\" style=\"position:relative;\"><a href=\"#functional\" aria-label=\"functional permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Functional</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token triple-quoted-string string\">\"\"\"\nSpec:\n0. (32X32X3) 차원으로 정의된 Input\n1. 16개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n2. pool_size가 2인 MaxPool 레이어\n3. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n4. pool_size가 2인 MaxPool 레이어\n5. 256개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n6. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n\"\"\"</span>\n\ninputs <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>Input<span class=\"token punctuation\">(</span>shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nx <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span>activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>inputs<span class=\"token punctuation\">)</span>\nx <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>MaxPool2D<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\nx <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span>activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\nx <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>MaxPool2D<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\nx <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\nx <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">256</span><span class=\"token punctuation\">,</span>activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\noutputs <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">100</span><span class=\"token punctuation\">,</span>activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n\nmodel <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>Model<span class=\"token punctuation\">(</span>inputs<span class=\"token operator\">=</span>inputs<span class=\"token punctuation\">,</span> outputs<span class=\"token operator\">=</span>outputs<span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span><span class=\"token string\">'adam'</span><span class=\"token punctuation\">,</span>\n               loss<span class=\"token operator\">=</span><span class=\"token string\">'sparse_categorical_crossentropy'</span><span class=\"token punctuation\">,</span>\n               metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> epochs <span class=\"token operator\">=</span> <span class=\"token number\">5</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span> y_test<span class=\"token punctuation\">,</span> verbose <span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Epoch 1/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\nEpoch 2/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\nEpoch 3/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\nEpoch 4/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\nEpoch 5/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\n313/313 - 1s - loss: nan - accuracy: 0.0100\n\n\n\n\n\n[nan, 0.009999999776482582]</code></pre></div>\n<h3 id=\"subclass-api\" style=\"position:relative;\"><a href=\"#subclass-api\" aria-label=\"subclass api permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Subclass API</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token triple-quoted-string string\">\"\"\"\nSpec:\n0. keras.Model 을 상속받았으며, __init__()와 call() 메서드를 가진 모델 클래스\n1. 16개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n2. pool_size가 2인 MaxPool 레이어\n3. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n4. pool_size가 2인 MaxPool 레이어\n5. 256개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n6. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n7. call의 입력값이 모델의 Input, call의 리턴값이 모델의 Output\n\"\"\"</span>\n\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">kerasModel</span><span class=\"token punctuation\">(</span>keras<span class=\"token punctuation\">.</span>Model<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        \n        self<span class=\"token punctuation\">.</span>Conv2D16 <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>Conv2D32 <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>Maxpool <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>MaxPool2D<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>Flatten <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>Dense256 <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">256</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>Dense <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span>\n    \n    <span class=\"token keyword\">def</span> <span class=\"token function\">call</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>Conv2D16<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>Maxpool<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>Conv2D32<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>Maxpool<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>Dense256<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        output <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        \n        <span class=\"token keyword\">return</span> output\n    \nmodel <span class=\"token operator\">=</span> kerasModel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span><span class=\"token string\">'adam'</span><span class=\"token punctuation\">,</span>\n              loss<span class=\"token operator\">=</span><span class=\"token string\">'sparse_categorical_crossentropy'</span><span class=\"token punctuation\">,</span>\n              metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span>  y_test<span class=\"token punctuation\">,</span> verbose<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Epoch 1/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\nEpoch 2/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\nEpoch 3/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\nEpoch 4/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\nEpoch 5/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\n313/313 - 1s - loss: nan - accuracy: 0.0100\n\n\n\n\n\n[nan, 0.009999999776482582]</code></pre></div>\n<hr>\n<p>우리는 model.compile 에 있어서 계속 동일한 구성을 유지했다.</p>\n<p>잠시 인공지능 학습 과정을 복기해보자.</p>\n<ol>\n<li>Forward Propagation</li>\n<li>Loss 값 계산</li>\n<li>중간 레이어 값 및 loss 를 활용한 chain rule 방식의 Back propagation</li>\n<li>parameter update</li>\n<li>repeat</li>\n</ol>\n<p>이런 과정이 tf v2 에서는 fit 에 다 담겨있다.</p>\n<p>tf.gredient tape 는 propagation 동안 진행되는 모든 연산의 중간 레이어 값을<br>\ntape 에 기록한다.</p>\n<p>이를 이용해 gredient 를 계산하고 tape 를 폐기한다.</p>\n<p>우리는 이 tape 값을 이용해 고급기법을 이용할 수 있다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n<span class=\"token keyword\">from</span> tensorflow <span class=\"token keyword\">import</span> keras\n\n<span class=\"token comment\"># 데이터 구성부분</span>\ncifar100 <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>datasets<span class=\"token punctuation\">.</span>cifar100\n\n<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span> y_test<span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> cifar100<span class=\"token punctuation\">.</span>load_data<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nx_train<span class=\"token punctuation\">,</span> x_test <span class=\"token operator\">=</span> x_train <span class=\"token operator\">/</span> <span class=\"token number\">255.0</span><span class=\"token punctuation\">,</span> x_test <span class=\"token operator\">/</span> <span class=\"token number\">255.0</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 모델 구성부분</span>\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">CustomModel</span><span class=\"token punctuation\">(</span>keras<span class=\"token punctuation\">.</span>Model<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>conv1 <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>maxpool1 <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>MaxPool2D<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>conv2 <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>maxpool2 <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>MaxPool2D<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>flatten <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>fc1 <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">256</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>fc2 <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">100</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">call</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>conv1<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>maxpool1<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>conv2<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>maxpool2<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>flatten<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>fc1<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>fc2<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">return</span> x\n\nmodel <span class=\"token operator\">=</span> CustomModel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">50000 10000</code></pre></div>\n<p>지금까지는</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">model<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span><span class=\"token string\">'adam'</span><span class=\"token punctuation\">,</span>\n              loss<span class=\"token operator\">=</span><span class=\"token string\">'sparse_categorical_crossentropy'</span><span class=\"token punctuation\">,</span>\n              metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>에서 알아서 loss 를 통해 학습 파라미터를 수정할 수 있게 해주었다.</p>\n<p>이번에는 tape.gradient() 를 통해서<br>\n매 스텝 마다 발생하는 gredient 를 export,<br>\noptimizer.apply_grediens() 를 통해 발생한 gredient 가<br>\nmodel.trainable_variables 를 통해 파라미터를 업데이터 하도록 한다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">loss_func <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>losses<span class=\"token punctuation\">.</span>SparseCategoricalCrossentropy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\noptimizer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>optimizers<span class=\"token punctuation\">.</span>Adam<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># tf.GradientTape()를 활용한 train_step</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">train_step</span><span class=\"token punctuation\">(</span>features<span class=\"token punctuation\">,</span> labels<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> tf<span class=\"token punctuation\">.</span>GradientTape<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> tape<span class=\"token punctuation\">:</span>\n        predictions <span class=\"token operator\">=</span> model<span class=\"token punctuation\">(</span>features<span class=\"token punctuation\">)</span>\n        loss <span class=\"token operator\">=</span> loss_func<span class=\"token punctuation\">(</span>labels<span class=\"token punctuation\">,</span> predictions<span class=\"token punctuation\">)</span>\n        gradients <span class=\"token operator\">=</span> tape<span class=\"token punctuation\">.</span>gradient<span class=\"token punctuation\">(</span>loss<span class=\"token punctuation\">,</span> model<span class=\"token punctuation\">.</span>trainable_variables<span class=\"token punctuation\">)</span>\n    optimizer<span class=\"token punctuation\">.</span>apply_gradients<span class=\"token punctuation\">(</span><span class=\"token builtin\">zip</span><span class=\"token punctuation\">(</span>gradients<span class=\"token punctuation\">,</span> model<span class=\"token punctuation\">.</span>trainable_variables<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> loss</code></pre></div>\n<p>위의 train_step 메서드가 바로<br>\nfit 을 통해 1번 epoch 하는 동안의 안에서 이루어지는 steps 들의 진행방식을 나타낸것.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> time\n<span class=\"token keyword\">def</span> <span class=\"token function\">train_model</span><span class=\"token punctuation\">(</span>batch_size<span class=\"token operator\">=</span><span class=\"token number\">32</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    start <span class=\"token operator\">=</span> time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">for</span> epoch <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        x_batch <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n        y_batch <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">for</span> step<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">)</span> <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">zip</span><span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            x_batch<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n            y_batch<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>y<span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">if</span> step <span class=\"token operator\">%</span> batch_size <span class=\"token operator\">==</span> batch_size<span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">:</span>\n                loss <span class=\"token operator\">=</span> train_step<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span>x_batch<span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>np<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span>y_batch<span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>np<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n                x_batch <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n                y_batch <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Epoch %d: last batch loss = %.4f'</span> <span class=\"token operator\">%</span> <span class=\"token punctuation\">(</span>epoch<span class=\"token punctuation\">,</span> <span class=\"token builtin\">float</span><span class=\"token punctuation\">(</span>loss<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"It took {} seconds\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> start<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\ntrain_model<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Epoch 0: last batch loss = 3.2522\nEpoch 1: last batch loss = 2.6932\nEpoch 2: last batch loss = 2.4441\nEpoch 3: last batch loss = 2.3071\nEpoch 4: last batch loss = 2.2136\nIt took 85.202951669693 seconds</code></pre></div>\n<p>위 두 함수의 연계사용이\nfit 메서드를 풀어 쓴 것이다.</p>\n<p>쉽게 말하면</p>\n<p>데이터들을 batch_size 만큼 끊어서<br>\n그 끊은 만큼의 x_train(feature) 를 넣어 모델 신경망에 넣고 돌려\n예측한 y_train 값을 반환하고</p>\n<p>실제 y_trian(label) 값과 예측한 y_trian 값을 손실함수(loss) 를 돌려<br>\n그 출력 값으로 Back propagation 을 통해 모델 내부 가중치를 새로운 가중치로 update</p>\n<p>자 그럼 손실값은 한 1epochs 에 배치사이즈 돌린만큼 나오겠지?<br>\n(위의 경우 32배치사이즈 이므로 데이터가 100개면 한 epochs 당 loss 가 3개 나오지)\n하지만 출력되는 loss 는 맨 마지막 배치의 loss 이다.</p>\n<p>이 과정을 epoch 횟수 만큼 반복하는 것이다.</p>\n<p>이게 fit 메서드가 하는 일.</p>\n<hr>\n<p>이걸 굳이 끄집어내서 보는 이유는</p>\n<p>우리가 강화학습 또는 GAN 을 시행할 때\n이 내부 train_step 의 재구성을 해야 하므로!!!!!</p>\n<hr>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">prediction <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span> batch_size<span class=\"token operator\">=</span>x_test<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> verbose<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\ntemp <span class=\"token operator\">=</span> <span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>squeeze<span class=\"token punctuation\">(</span>y_test<span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> np<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>prediction<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\ntemp<span class=\"token operator\">/</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>y_test<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># Accuracy</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">1/1 [==============================] - 1s 822ms/step\n\n\n\n\n\n0.346</code></pre></div>\n<p>일단 epoch 해봣으니 결과값도 이렇게 도출이 된다.</p>\n<div class=\"table-of-contents\">\n<ul>\n<li>\n<p><a href=\"#1-sequential-model\">1. Sequential Model</a></p>\n<ul>\n<li>\n<ul>\n<li><a href=\"#but\">but,</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><a href=\"#2-functional-api\">2. Functional API</a></p>\n</li>\n<li>\n<p><a href=\"#3-subclassing\">3. Subclassing</a></p>\n</li>\n<li>\n<p><a href=\"#1-sequential-model-1\">1. Sequential model</a></p>\n</li>\n<li>\n<p><a href=\"#2-functional-api-1\">2. Functional API</a></p>\n</li>\n<li>\n<p><a href=\"#3-subclassing-api\">3. Subclassing API</a></p>\n<ul>\n<li><a href=\"#sequential\">Sequential</a></li>\n<li><a href=\"#functional\">Functional</a></li>\n<li><a href=\"#subclass-api\">Subclass API</a></li>\n</ul>\n</li>\n</ul>\n</div>","frontmatter":{"date":"April 21, 2022","title":"Keras 딥러닝 모델","categories":"STUDY","author":"하성민","emoji":"😁"},"fields":{"slug":"/DML_keras2/"}},"site":{"siteMetadata":{"siteUrl":"https://xman227.github.io","comments":{"utterances":{"repo":"xman227/blog_comments"}}}}},"pageContext":{"slug":"/DML_AI1/","nextSlug":"/NLP_4/","prevSlug":"/DML_keras2/"}},
    "staticQueryHashes": ["1073350324","1956554647","2938748437"]}