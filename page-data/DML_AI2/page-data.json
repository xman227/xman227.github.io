{
    "componentChunkName": "component---src-templates-blog-template-js",
    "path": "/DML_AI2/",
    "result": {"data":{"cur":{"id":"594039ec-3322-5302-b54c-d19ecd03dc20","html":"<h1 id=\"span-stylebackground-color-fff5b1딥러닝모델-vgg-16--️span\" style=\"position:relative;\"><a href=\"#span-stylebackground-color-fff5b1%EB%94%A5%EB%9F%AC%EB%8B%9D%EB%AA%A8%EB%8D%B8-vgg-16--%EF%B8%8Fspan\" aria-label=\"span stylebackground color fff5b1딥러닝모델 vgg 16  ️span permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><span style='background-color: #fff5b1'>딥러닝모델 VGG-16  🚶🏽‍♂️</span></h1>\n<p>오늘 구현한 모델은 VGG-16 이다.</p>\n<h2 id=\"목차\" style=\"position:relative;\"><a href=\"#%EB%AA%A9%EC%B0%A8\" aria-label=\"목차 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>목차</h2>\n<ol>\n<li>데이터 불러오기</li>\n<li>VGG-16 생성</li>\n<li>본인의 과업에 맞게 VGG-16 개선</li>\n</ol>\n<p>이 모델은 미국에서 진행한 이미지 인식 대회 ILSVRC 에서<br>\n2014년 준우승을 한 모델이다! (물론 지금은 더 좋은게 많이 있다)</p>\n<p>하지만 계속 발전되는 Deep Learning 모델을 이해하기 위해선<br>\n기본적인 구조를 갖춘 VGG-16 의 모델 이해가 필요하다.</p>\n<p>본 게시글에서는 VGG-16 를 Tensorflow 라이브러리에서 불러와<br>\n사용하는 방법을 제시한다.</p>\n<p>모델 사용에는 tensorflow 실습 데이터인\n<code class=\"language-text\">cats vs dogs</code> 를 사용했다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n<span class=\"token keyword\">import</span> tensorflow_datasets <span class=\"token keyword\">as</span> tfds\n<span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt\n<span class=\"token operator\">%</span>matplotlib inline\n<span class=\"token operator\">%</span>config InlineBackend<span class=\"token punctuation\">.</span>figure_format <span class=\"token operator\">=</span> <span class=\"token string\">'retina'</span>\n\n\n\n<span class=\"token punctuation\">(</span>raw_train<span class=\"token punctuation\">,</span> raw_validation<span class=\"token punctuation\">,</span> raw_test<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> metadata <span class=\"token operator\">=</span> tfds<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span>\n    <span class=\"token string\">'cats_vs_dogs'</span><span class=\"token punctuation\">,</span>\n    split<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'train[:80%]'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'train[80%:90%]'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'train[90%:]'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n    with_info<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n    as_supervised<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">)</span>\n\nIMG_SIZE <span class=\"token operator\">=</span> <span class=\"token number\">160</span> <span class=\"token comment\"># 리사이징할 이미지의 크기</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">format_example</span><span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> label<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    image <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>cast<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> tf<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># image=float(image)같은 타입캐스팅의  텐서플로우 버전입니다.</span>\n    image <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>image<span class=\"token operator\">/</span><span class=\"token number\">127.5</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> <span class=\"token number\">1</span> <span class=\"token comment\"># 픽셀값의 scale 수정</span>\n    image <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>image<span class=\"token punctuation\">.</span>resize<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>IMG_SIZE<span class=\"token punctuation\">,</span> IMG_SIZE<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> image<span class=\"token punctuation\">,</span> label\n\ntrain <span class=\"token operator\">=</span> raw_train<span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span>format_example<span class=\"token punctuation\">)</span>\nvalidation <span class=\"token operator\">=</span> raw_validation<span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span>format_example<span class=\"token punctuation\">)</span>\ntest <span class=\"token operator\">=</span> raw_test<span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span>format_example<span class=\"token punctuation\">)</span>\n</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">\u001b[1mDownloading and preparing dataset 786.68 MiB (download: 786.68 MiB, generated: Unknown size, total: 786.68 MiB) to /aiffel/tensorflow_datasets/cats_vs_dogs/4.0.0...\u001b[0m\n\n\n\nDl Completed...: 0 url [00:00, ? url/s]\n\n\n\nDl Size...: 0 MiB [00:00, ? MiB/s]\n\n\n\nGenerating splits...:   0%|          | 0/1 [00:00&lt;?, ? splits/s]\n\n\n\nGenerating train examples...:   0%|          | 0/23262 [00:00&lt;?, ? examples/s]\n\n\nWARNING:absl:1738 images were corrupted and were skipped\n\n\n\nShuffling cats_vs_dogs-train.tfrecord...:   0%|          | 0/23262 [00:00&lt;?, ? examples/s]\n\n\n\u001b[1mDataset cats_vs_dogs downloaded and prepared to /aiffel/tensorflow_datasets/cats_vs_dogs/4.0.0. Subsequent calls will reuse this data.\u001b[0m</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">plt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n\nget_label_name <span class=\"token operator\">=</span> metadata<span class=\"token punctuation\">.</span>features<span class=\"token punctuation\">[</span><span class=\"token string\">'label'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>int2str\n\n<span class=\"token keyword\">for</span> idx<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> label<span class=\"token punctuation\">)</span> <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>train<span class=\"token punctuation\">.</span>take<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">,</span> idx<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n    image <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>image <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> <span class=\"token number\">2</span>\n    plt<span class=\"token punctuation\">.</span>imshow<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'label </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>label<span class=\"token punctuation\">}</span></span><span class=\"token string\">: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>get_label_name<span class=\"token punctuation\">(</span>label<span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">'</span></span><span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>axis<span class=\"token punctuation\">(</span><span class=\"token string\">'off'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 47.77777777777777%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAABYlAAAWJQFJUiTwAAADNUlEQVQozwEqA9X8AFVQQz6LiGA8iYpjLaqATg9FOB5BLzYROS4uETd1hUwNboNbOLayrzyCiIw9NT09D11FEC1aSiFAXUsbO2dNDRdmZWghR0RBQVdRTzx/fX0uAGdgVf6smnL/uKV8xI1tS2pkSCr/OzQe9l8/IexxgURcioJW6ryGYveWe2j/NjUyZyIZA8toVy/8eWY//29dN4SNiIWhfHhz/29rZ/aVk5PkAF5VS/88Jx7/d2VMyW5vN25kQCP/ayoh/l09IPJgcTtgiHde8p1/b/+Nblf/hndsaxgdIdJPRjj/f3Zp/3FnV4kuLSimGx8Z/zM2Lf1yZFXrAHZnVf9hVTb/ZFtC1WZoNHRiPyX/fzQd/1NFHv9ueklllaKC/3iFaP+PkIL/xsK7cVJELN10Xz3/l4l3/2deUpFmYV2vendz/5GJhP+WiID4AFtURmpUWkFrQkc8UlBPJy48MBxsXDwgZ2lYL2NsdU8oj6N8Ymh/P2d2gWhryMa4LH1SD1WDYitpdmA4blpOMjjPxcJEw7m1brSsqmeqoqFhAP/60AD///cA28a0AElFKAD/4HcA//+xAKeMTgBFTj4A///lAP//kgDb3rYApqefANafTQD//9UA48OPAHRrVQD/+dkA////AP///wDEuKcAALOPdsLovqfCyJR/lkQ4OkxZUEbGbGVavDo2N7EhJTRBZGZtsqOMdr6Xh3m/aHKGSjo0MJqvrq7BW1lWxz4+QWNHRTh4Xlg8yVBJLLxCPSerAJ9/a/+PeW3/uJCB04RsTnSef1D/n4ts/4tzUP8vLTBlbniF/cazoP+oloT/ZHCAcW1nZNyUiYb/Z2Jf/0xLS5BbVTOvT0s0/1tUOP9IQir3AJqQg/94dW//t6uey6OXgW+5nm3/sZNl/52JbPVDRlJganiO9KGbmP+IgXz/X2lxbGVcVtN3bWj/cGtl/19cWYo4NCGofn53/2xtZ/9IQi/tAK+gjuWqoJLmy72nsHl+gGChjnHprZNq3oSGgtReZm1UeX+P032Dit+AhYjlgoWHXVxVT7d1cGnke3Rs7HFqY3hBQjaRmpqV7cvIw91GQTHOUnqDylKzWK4AAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/1271a3703b5b224b0557b0d74541dd9c/37523/output_2_0.png\"\n        srcset=\"/static/1271a3703b5b224b0557b0d74541dd9c/e9ff0/output_2_0.png 180w,\n/static/1271a3703b5b224b0557b0d74541dd9c/f21e7/output_2_0.png 360w,\n/static/1271a3703b5b224b0557b0d74541dd9c/37523/output_2_0.png 720w,\n/static/1271a3703b5b224b0557b0d74541dd9c/302a4/output_2_0.png 1080w,\n/static/1271a3703b5b224b0557b0d74541dd9c/ee3fb/output_2_0.png 1144w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<h3 id=\"vgg-16-불러오기\" style=\"position:relative;\"><a href=\"#vgg-16-%EB%B6%88%EB%9F%AC%EC%98%A4%EA%B8%B0\" aria-label=\"vgg 16 불러오기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>VGG 16 불러오기</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">feature_batch <span class=\"token operator\">=</span> base_model<span class=\"token punctuation\">(</span>image_batch<span class=\"token punctuation\">)</span>\nfeature_batch<span class=\"token punctuation\">.</span>shape</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">TensorShape([32, 5, 5, 512])</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">base_model<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Model: \"vgg16\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 160, 160, 3)]     0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 160, 160, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 160, 160, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 80, 80, 64)        0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 80, 80, 128)       73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 80, 80, 128)       147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 40, 40, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 40, 40, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 40, 40, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 40, 40, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 20, 20, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 20, 20, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 20, 20, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 20, 20, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 10, 10, 512)       0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 10, 10, 512)       2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 10, 10, 512)       2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 10, 10, 512)       2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 5, 5, 512)         0         \n=================================================================\nTotal params: 14,714,688\nTrainable params: 14,714,688\nNon-trainable params: 0\n_________________________________________________________________</code></pre></div>\n<p>18층으로 구성되어 있다.</p>\n<p>해당 사이트에서 전문적인 내용을 다룬다.</p>\n<p><a href=\"https://neurohive.io/en/popular-networks/vgg16/\">자세한 내용을 보시려면</a></p>\n<p>이 모델은 해당 그림을 구현하고 있다.</p>\n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 565px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 62.22222222222222%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAABJ0AAASdAHeZh94AAABuElEQVQoz52Sz2sTQRzF9w8RwZungp68efMP8FgPgheh/4Jn/QcEoSIowYOtpb0IHryp/4ERTZO02R8m7e5kszvZndnZbPKRGdtQYirUBw+WZebNe9/v88qypNKKUSyYyClRGJBNJlRVhcVisbgSPXtpvljwZPs9h/1j0vGYc1xVbCm48+kLjzcf4R92KIoCmWUopf7PYW+YsvX0GR933jqBcRTS63bJZb4UXcX55XXwPnz9zN2Hm/w88qE2jIKAcRTR7XQIBgNSIUjTFCkldV0j85wsy1yS+Xzu/jVN42i/vdZBi437D+gdBzTFFDEcIuOY0WhEJQThYIDv+0zC0D1w1O9TCkFezTjNC6IkJc6nyCx1D3mt/V1ubtzmx/c2GOMEsyQmEQJTFGil/kQ/c2HJWdx1ob3ddwdcv3aDdvsbKMWvIKDS2tm/OKfKGFclS6U1xpi1S/Oev3jFrTv38IPIubAzWleb/OSUJI6JogiRJGit1wu+fLPH9us9pjLDmPrSqsiyJAxDR7uky2rldfsBclogROK2tnpg6XbeoLVyo/hXP72L8VYPWlgB68ZGnM1mf/VwVfA3ueuPgaIpqCoAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"VGG\" title=\"VGG\" src=\"/static/70208de06e060390432303c3020768e8/07eba/VGG.png\" srcset=\"/static/70208de06e060390432303c3020768e8/e9ff0/VGG.png 180w,\n/static/70208de06e060390432303c3020768e8/f21e7/VGG.png 360w,\n/static/70208de06e060390432303c3020768e8/07eba/VGG.png 565w\" sizes=\"(max-width: 565px) 100vw, 565px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n<p>그림의 세 번째 파란상자를 보면 fully nected 라고 되어있는데,<br>\nfully connected layer 의 오타이다. 순방향 신경망을 의미한다.</p>\n<p>18층으로 구성되어있으나 VGG-16 인 이유는<br>\nconvolution layer 와 fully connected layer 만 포함했기 때문이다.<br>\n이 두 개의 총 합은 16개이다.</p>\n<p>현재 파이썬에 불러온 모델 상에는\n마지막 maxfooling 까지만 구현되어있다.</p>\n<p>때문에 마지막 네 개의 층을 직접 도입해보기로 하자!</p>\n<h3 id=\"vgg-16-개선\" style=\"position:relative;\"><a href=\"#vgg-16-%EA%B0%9C%EC%84%A0\" aria-label=\"vgg 16 개선 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>VGG-16 개선</h3>\n<hr>\n<p>마지막 layer 까지 제공해주지 않는 이유는<br>\n우리가 입력하는 input 데이터에 따라 output 데이터도<br>\n달라지기 때문이다.</p>\n<p>마지막 layer 인 Dense layer (Fully connected layer) 에 넣어주기 위해서는 input data 를 Flatten 시킨 후 입력하여야 한다.</p>\n<p>우리 shape 는 32,5,5,512 라서 이거 한줄로 만들어줄건데</p>\n<p>아래는 Flatten의 예시이다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n\nimage <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                  <span class=\"token punctuation\">[</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nflattened_image <span class=\"token operator\">=</span> image<span class=\"token punctuation\">.</span>flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Original image:\\n\"</span><span class=\"token punctuation\">,</span> image<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Original image shape:\"</span><span class=\"token punctuation\">,</span> image<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Flattened image:\\n\"</span><span class=\"token punctuation\">,</span> flattened_image<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Flattened image shape:\"</span><span class=\"token punctuation\">,</span> flattened_image<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Original image:\n [[1 2]\n [3 4]]\nOriginal image shape: (2, 2)\n\nFlattened image:\n [1 2 3 4]\nFlattened image shape: (4,)</code></pre></div>\n<p>이처럼 차원이 존재하는 배열데이터를 한 줄로<br>\n이어준다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"></code></pre></div>\n<p>아 근데 이거 말고 더 좋은게 있데</p>\n<p>그게 바로 Global Average Pooling</p>\n<p>3차원의 tensor 가 있을때 (예를 들어, 가로, 세로, 채널)<br>\n겹겹이 쌓여있는 2차원 배열의 평균을 구한 후 하나로 축소하는 방법</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">global_average_layer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>GlobalAveragePooling2D<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># global Average 사용</span>\n\nfeature_batch_average <span class=\"token operator\">=</span> global_average_layer<span class=\"token punctuation\">(</span>feature_batch<span class=\"token punctuation\">)</span>\n<span class=\"token comment\">#만든 glo aver 를 이어 붙이기</span>\n\ndense_layer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">512</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span>\nprediction_layer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># feature_batch_averag가 dense_layer를 거친 결과가 다시 prediction_layer를 거치게 되면</span>\nprediction_batch <span class=\"token operator\">=</span> prediction_layer<span class=\"token punctuation\">(</span>dense_layer<span class=\"token punctuation\">(</span>feature_batch_average<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>  \n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>prediction_batch<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># 사용</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">(32, 2)</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">base_model<span class=\"token punctuation\">.</span>trainable <span class=\"token operator\">=</span> <span class=\"token boolean\">False</span>\n\nmodel <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n  base_model<span class=\"token punctuation\">,</span>\n  global_average_layer<span class=\"token punctuation\">,</span>\n  dense_layer<span class=\"token punctuation\">,</span>\n  prediction_layer\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n</code></pre></div>\n<p>이게 최종 모델이다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">model<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nvgg16 (Functional)           (None, 5, 5, 512)         14714688  \n_________________________________________________________________\nglobal_average_pooling2d (Gl (None, 512)               0         \n_________________________________________________________________\ndense (Dense)                (None, 512)               262656    \n_________________________________________________________________\ndense_1 (Dense)              (None, 2)                 1026      \n=================================================================\nTotal params: 14,978,370\nTrainable params: 263,682\nNon-trainable params: 14,714,688\n_________________________________________________________________</code></pre></div>\n<p>VGG16 모델 밑으로 Flatten(Global_average), Dense 레이어 2개가<br>\n들어갔다.</p>\n<p>모델의 사용은 다음 게시글에 이어서 쓰도록 한다.</p>\n<div class=\"table-of-contents\">\n<ul>\n<li>\n<p><a href=\"#%EB%AA%A9%EC%B0%A8\">목차</a></p>\n<ul>\n<li><a href=\"#vgg-16-%EB%B6%88%EB%9F%AC%EC%98%A4%EA%B8%B0\">VGG 16 불러오기</a></li>\n<li><a href=\"#vgg-16-%EA%B0%9C%EC%84%A0\">VGG-16 개선</a></li>\n</ul>\n</li>\n</ul>\n</div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"></code></pre></div>","excerpt":"딥러닝모델 VGG-16  🚶🏽‍♂️ 오늘 구현한 모델은 VGG-16 이다. 목차 데이터 불러오기 VGG-16 생성 본인의 과업에 맞게 VGG-16 개선 이 모델은 미국에서 진행한 이미지 인식 대회 ILSVRC 에서 2014년 준우승을 한 모델이다! (물론 지금은 더 좋은게 많이 있다) 하지만 계속 발전되는 Deep Learning 모델을 이해하기 위해선 기본적인 구조를 갖춘 VGG-16 의 모델 이해가 필요하다. 본 게시글에서는 VGG-16 를 Tensorflow 라이브러리에서 불러와 사용하는 방법을 제시한다. 모델 사용에는 tensorflow 실습 데이터인\n 를 사용했다.  VGG 16 불러오기 18층으로 구성되어 있다. 해당 사이트에서 전문적인 내용을 다룬다. 자세한 내용을 보시려면 이 모델은 해당 그림을 구현하고 있다. 그림의 세 번째 파란상자를 보면 fully nected 라고 되어있는데, fully connected layer 의 오타이다. 순방향 신경망을 의미한다. 18층으로 …","frontmatter":{"date":"April 21, 2022","title":"VGG16","categories":"STUDY","author":"하성민","emoji":"😁"},"fields":{"slug":"/DML_AI2/"}},"next":{"id":"178ea2b3-2dfd-599d-86ad-b2669c612f60","html":"<h1 id=\"span-stylebackground-color-fff4f5인공지능-기초-️-사진-분류-프로그램-맛보기span\" style=\"position:relative;\"><a href=\"#span-stylebackground-color-fff4f5%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-%EA%B8%B0%EC%B4%88-%EF%B8%8F-%EC%82%AC%EC%A7%84-%EB%B6%84%EB%A5%98-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%A8-%EB%A7%9B%EB%B3%B4%EA%B8%B0span\" aria-label=\"span stylebackground color fff4f5인공지능 기초 ️ 사진 분류 프로그램 맛보기span permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><span style='background-color: #fff4f5'>인공지능 기초 🚶‍♂️: 사진 분류 프로그램 맛보기</span></h1>\n<h2 id=\"강아지--고양이-분류-프로그램-제작-\" style=\"position:relative;\"><a href=\"#%EA%B0%95%EC%95%84%EC%A7%80--%EA%B3%A0%EC%96%91%EC%9D%B4-%EB%B6%84%EB%A5%98-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%A8-%EC%A0%9C%EC%9E%91-\" aria-label=\"강아지  고양이 분류 프로그램 제작  permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>강아지 &#x26; 고양이 분류 프로그램 제작 !</h2>\n<h3 id=\"content\" style=\"position:relative;\"><a href=\"#content\" aria-label=\"content permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Content</h3>\n<ol>\n<li>데이터 불러오기 (Tensor Flow)</li>\n<li>데이터 전처리</li>\n<li>모델 생성 (자체 생성 모델)</li>\n<li>학습 및 평가</li>\n</ol>\n<p><strong>시작하기에 앞서, 이번 게시글은<br>\n전체적인 인공지능 적용에 대한 맥락을 설명하기 위한 글입니다.<br>\n아주 간단한 Deep Learning Layer 몇 종류를 이용했습니다.</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>__version__ <span class=\"token punctuation\">,</span> <span class=\"token string\">'이미지 분류 모델을 만들 라이브러리 tensor flow 입니다'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">2.6.0 이미지 분류 모델을 만들 라이브러리 tensor flow 입니다</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow_datasets <span class=\"token keyword\">as</span> tfds\n\ntfds<span class=\"token punctuation\">.</span>__version__</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">'4.4.0'</code></pre></div>\n<p>tensor flow 에서는 다양한 데이터셋을 이미 제공하고 있다.<br>\n강아지고양이, 음성, 이미지, 텍스트 데이터셋 보유하고 있으니 세부 내용 확인해보고 싶음 해보기</p>\n<p><a href=\"https://www.tensorflow.org/datasets/catalog/overview\">tensor flow link</a></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token punctuation\">(</span>raw_train<span class=\"token punctuation\">,</span> raw_validation<span class=\"token punctuation\">,</span> raw_test<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> metadata <span class=\"token operator\">=</span> tfds<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span>\n    <span class=\"token string\">'cats_vs_dogs'</span><span class=\"token punctuation\">,</span>\n    split<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'train[:80%]'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'train[80%:90%]'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'train[90%:]'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n    with_info<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n    as_supervised<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">\u001b[1mDownloading and preparing dataset 786.68 MiB (download: 786.68 MiB, generated: Unknown size, total: 786.68 MiB) to /aiffel/tensorflow_datasets/cats_vs_dogs/4.0.0...\u001b[0m\n\n\n\nDl Completed...: 0 url [00:00, ? url/s]\n\n\n\nDl Size...: 0 MiB [00:00, ? MiB/s]\n\n\n\nGenerating splits...:   0%|          | 0/1 [00:00&lt;?, ? splits/s]\n\n\n\nGenerating train examples...:   0%|          | 0/23262 [00:00&lt;?, ? examples/s]\n\n\nWARNING:absl:1738 images were corrupted and were skipped\n\n\n\nShuffling cats_vs_dogs-train.tfrecord...:   0%|          | 0/23262 [00:00&lt;?, ? examples/s]\n\n\n\u001b[1mDataset cats_vs_dogs downloaded and prepared to /aiffel/tensorflow_datasets/cats_vs_dogs/4.0.0. Subsequent calls will reuse this data.\u001b[0m</code></pre></div>\n<hr>\n<p>“WARNING:absl:1738 images were corrupted and were skipped”라는 경고가 나타날 수 있습니다. 우선 무시하시면 됩니다.<br>\n1738 장의 사진은 쓸 수 없다는 뜻입니다.<br>\n이런 것들은 tf 사이트 데이터셋 설명에서 확인 가능합니다</p>\n<p><img src=\"/a0b5d21d105e7623091003cd8f24e715/1.png\" alt=\"PNG\"></p>\n<p>1738이 currupted 되어있다 되어있져?<br>\n그리고 밑에 Split을 보면 23262 장의 사진이 있음을 확인 가능합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>raw_train<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>raw_validation<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>raw_test<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">&lt;PrefetchDataset shapes: ((None, None, 3), ()), types: (tf.uint8, tf.int64)>\n&lt;PrefetchDataset shapes: ((None, None, 3), ()), types: (tf.uint8, tf.int64)>\n&lt;PrefetchDataset shapes: ((None, None, 3), ()), types: (tf.uint8, tf.int64)></code></pre></div>\n<p>잘 변수로 지정되어있음을 알 수 있다.</p>\n<p>모든 데이터셋은 (image, label)의 형태를 가집니다.<br>\n((None, None, 3), ())가 이를 나타내죠.</p>\n<p>여기에서 앞에 있는 (None, None, 3)은 image의 shape를,<br>\n뒤의 ()는 정답 카테고리인 label의 shape를 의미합니다.</p>\n<p>이미지는 (height, width, channel)로 3차원 데이터이기 때문에<br>\n(None, None, 3)과 같이 나타났습니다.</p>\n<p>이때 height와 width가 None으로 나타난 이유는<br>\n모든 사진들의 크기가 제각각이기 때문입니다.<br>\n하나의 값으로 나타낼 수 없으니 None 으로 표기됩니다.</p>\n<h2 id=\"1-데이터-전처리\" style=\"position:relative;\"><a href=\"#1-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%84%EC%B2%98%EB%A6%AC\" aria-label=\"1 데이터 전처리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. 데이터 전처리</h2>\n<p>자 데이터를 불러왔으니 깔끔하게 처리해야지</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt\n<span class=\"token operator\">%</span>matplotlib inline\n<span class=\"token operator\">%</span>config InlineBackend<span class=\"token punctuation\">.</span>figure_format <span class=\"token operator\">=</span> <span class=\"token string\">'retina'</span></code></pre></div>\n<p>데이터를 어떻게 처리할지 고민하기 위해서 우리가 가져온 데이터를<br>\n스리슬쩍 들여다 보자.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">plt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\">#전체 칸바스 크기</span>\n\nget_label_name <span class=\"token operator\">=</span> metadata<span class=\"token punctuation\">.</span>features<span class=\"token punctuation\">[</span><span class=\"token string\">'label'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>int2str \n\n<span class=\"token keyword\">for</span> idx<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> label<span class=\"token punctuation\">)</span> <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>raw_train<span class=\"token punctuation\">.</span>take<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>  <span class=\"token comment\"># 10개의 데이터를 따로 가져 옵니다.</span>\n    plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">,</span> idx<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token comment\">#10개의 사진을 꺼내보겠음 판 꺼냄</span>\n    plt<span class=\"token punctuation\">.</span>imshow<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'label </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>label<span class=\"token punctuation\">}</span></span><span class=\"token string\">: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>get_label_name<span class=\"token punctuation\">(</span>label<span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">'</span></span><span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>axis<span class=\"token punctuation\">(</span><span class=\"token string\">'off'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 52.222222222222214%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAABYlAAAWJQFJUiTwAAADNUlEQVQozwEqA9X8AIqJkgD//98A////AMO5kgB3WDdNSEEedTo8GXVNPhk/ZaBgEHmIfyydqbYmQ1NdExwaDgDtw1sA+tJ9AINtQwDq4d4A////APPr5AD+//8AAFRRVXZ3b1uhs6N3pberglF4UzK5Uz8l/084If9nSSKWfZBZlauFYPGwinHwXFdTjxsNAFlZSSOsdWE0qW1YK2GQjItZeXNvqm9rZ6WMi41yAH99cNVdUET/aFQ9/5eHYphRSiCoaDIj/2kxIP9URSCKfn9YrJh7Z/+WdWD/kXdknRgcHalJQC//gXRf/3RnVLJHRUGgOjs3/1FQSf9+cmfIAJGOd6pnWETjVlA16V1YP3hmWy66djUh/2w8Hv9BQxWWmqiFsoKQcP98gWz/vr22p2VQLoNrVTHpkH5k6W1lWY1xa2eBf3t365GKhOeWiIGhAFNcVgs1RDgPP15WEGeUaARIQiCARywXuXBNJrpdVSVojaKGNXuSWVxlc0hbqbCpOUAAAAeWdT0TemUwEkY3CQz///8B////Av///wH///8BAP///wAAAAACAAAAAf/h3wAHDjcdAA4wNgAJJC8NF0YZXmtnAKaqfQCZkWkApKqsAC8ZAwDm3M0Aq6SWAD88NgAREhYsV1NCWi8sGlcqKBk3AGJdTqPPo4nb166a4bl+bHNZUEKsiXZc/3BlVf86NDKUP0hXQntxaYKWf2d5goWQQhwXFEGPjo58amhneywsMz5PTDSRWFI0/1tTMP9EPya3AGhgVcqWemj/hnRq/7mUh5CegU2sqoxe/6KLaP+FZz2MQlBmtaejoP+2nYX/fIGIplZSUaSOhID/cmxo/0xKS6xeVzN/VFE//1ZSPP9KQyypAIh9bs+akob/l5KH/761qpSrmnezvJ9t/6mQav92bmOTW2h/p4OJlP+IhYL/dXyCm15XUZtwZ2H/d3Fq/2xmYaIrKBiEdXRs/3Jya/9CPSqvAIVxX22snYuRs6eWlcO2oUyFgnqOspRn156Se9ZtdHh8e36JEoSJkCuIk5gqp6mqGFZPSRlxb2csfXZtLq2clBBBQDKBmZmT+Lm2svZJRDOf3gpvCUkCLewAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/d16b019357261570c527d6ef9965d80a/37523/output_13_0.png\"\n        srcset=\"/static/d16b019357261570c527d6ef9965d80a/e9ff0/output_13_0.png 180w,\n/static/d16b019357261570c527d6ef9965d80a/f21e7/output_13_0.png 360w,\n/static/d16b019357261570c527d6ef9965d80a/37523/output_13_0.png 720w,\n/static/d16b019357261570c527d6ef9965d80a/302a4/output_13_0.png 1080w,\n/static/d16b019357261570c527d6ef9965d80a/ee3fb/output_13_0.png 1144w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>자 봐라, 이미지 크기가 다 제각각이네?</p>\n<p>올바른 학습을 위해서는 이미지 사이즈부터 제대로 맞춰줘야 한다.</p>\n<p>format_example() 함수로 이미지를 같은 포멧으로 맞춥니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">IMG_SIZE <span class=\"token operator\">=</span> <span class=\"token number\">160</span> <span class=\"token comment\"># 리사이징할 이미지의 크기</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">format_example</span><span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> label<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    image <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>cast<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> tf<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># image=float(image)같은 타입캐스팅의  텐서플로우 버전입니다.</span>\n    image <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>image<span class=\"token operator\">/</span><span class=\"token number\">127.5</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> <span class=\"token number\">1</span> <span class=\"token comment\"># 픽셀값의 scale 수정</span>\n    image <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>image<span class=\"token punctuation\">.</span>resize<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>IMG_SIZE<span class=\"token punctuation\">,</span> IMG_SIZE<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> image<span class=\"token punctuation\">,</span> label</code></pre></div>\n<p>픽셀값의 scale 을 수정햇다는 것은 픽셀값을 정규화햇다는 말과 근사하다.<br>\n0~ 255인 픽셀값을 127.5로 나누면 0~ 2가된다. 그걸 1로 뺐으니<br>\n-1~1 사이의 값으로 변했다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">train <span class=\"token operator\">=</span> raw_train<span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span>format_example<span class=\"token punctuation\">)</span>\nvalidation <span class=\"token operator\">=</span> raw_validation<span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span>format_example<span class=\"token punctuation\">)</span>\ntest <span class=\"token operator\">=</span> raw_test<span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span>format_example<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>train<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>validation<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>test<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">&lt;MapDataset shapes: ((160, 160, 3), ()), types: (tf.float32, tf.int64)>\n&lt;MapDataset shapes: ((160, 160, 3), ()), types: (tf.float32, tf.int64)>\n&lt;MapDataset shapes: ((160, 160, 3), ()), types: (tf.float32, tf.int64)></code></pre></div>\n<p>map 메서드로 모든 raw_** 의 정보를 format_example 의 함수로 변환시켜주었다.<br>\n변환된 후의 내용물은 다음과 같다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">plt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n\nget_label_name <span class=\"token operator\">=</span> metadata<span class=\"token punctuation\">.</span>features<span class=\"token punctuation\">[</span><span class=\"token string\">'label'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>int2str\n\n<span class=\"token keyword\">for</span> idx<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> label<span class=\"token punctuation\">)</span> <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>train<span class=\"token punctuation\">.</span>take<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">,</span> idx<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n    image <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>image <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> <span class=\"token number\">2</span>\n    plt<span class=\"token punctuation\">.</span>imshow<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'label </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>label<span class=\"token punctuation\">}</span></span><span class=\"token string\">: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>get_label_name<span class=\"token punctuation\">(</span>label<span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">'</span></span><span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>axis<span class=\"token punctuation\">(</span><span class=\"token string\">'off'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 47.77777777777777%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAABYlAAAWJQFJUiTwAAADNUlEQVQozwEqA9X8AFVQQz6LiGA8iYpjLaqATg9FOB5BLzYROS4uETd1hUwNboNbOLayrzyCiIw9NT09D11FEC1aSiFAXUsbO2dNDRdmZWghR0RBQVdRTzx/fX0uAGdgVf6smnL/uKV8xI1tS2pkSCr/OzQe9l8/IexxgURcioJW6ryGYveWe2j/NjUyZyIZA8toVy/8eWY//29dN4SNiIWhfHhz/29rZ/aVk5PkAF5VS/88Jx7/d2VMyW5vN25kQCP/ayoh/l09IPJgcTtgiHde8p1/b/+Nblf/hndsaxgdIdJPRjj/f3Zp/3FnV4kuLSimGx8Z/zM2Lf1yZFXrAHZnVf9hVTb/ZFtC1WZoNHRiPyX/fzQd/1NFHv9ueklllaKC/3iFaP+PkIL/xsK7cVJELN10Xz3/l4l3/2deUpFmYV2vendz/5GJhP+WiID4AFtURmpUWkFrQkc8UlBPJy48MBxsXDwgZ2lYL2NsdU8oj6N8Ymh/P2d2gWhryMa4LH1SD1WDYitpdmA4blpOMjjPxcJEw7m1brSsqmeqoqFhAP/60AD///cA28a0AElFKAD/4HcA//+xAKeMTgBFTj4A///lAP//kgDb3rYApqefANafTQD//9UA48OPAHRrVQD/+dkA////AP///wDEuKcAALOPdsLovqfCyJR/lkQ4OkxZUEbGbGVavDo2N7EhJTRBZGZtsqOMdr6Xh3m/aHKGSjo0MJqvrq7BW1lWxz4+QWNHRTh4Xlg8yVBJLLxCPSerAJ9/a/+PeW3/uJCB04RsTnSef1D/n4ts/4tzUP8vLTBlbniF/cazoP+oloT/ZHCAcW1nZNyUiYb/Z2Jf/0xLS5BbVTOvT0s0/1tUOP9IQir3AJqQg/94dW//t6uey6OXgW+5nm3/sZNl/52JbPVDRlJganiO9KGbmP+IgXz/X2lxbGVcVtN3bWj/cGtl/19cWYo4NCGofn53/2xtZ/9IQi/tAK+gjuWqoJLmy72nsHl+gGChjnHprZNq3oSGgtReZm1UeX+P032Dit+AhYjlgoWHXVxVT7d1cGnke3Rs7HFqY3hBQjaRmpqV7cvIw91GQTHOUnqDylKzWK4AAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/1271a3703b5b224b0557b0d74541dd9c/37523/output_19_0.png\"\n        srcset=\"/static/1271a3703b5b224b0557b0d74541dd9c/e9ff0/output_19_0.png 180w,\n/static/1271a3703b5b224b0557b0d74541dd9c/f21e7/output_19_0.png 360w,\n/static/1271a3703b5b224b0557b0d74541dd9c/37523/output_19_0.png 720w,\n/static/1271a3703b5b224b0557b0d74541dd9c/302a4/output_19_0.png 1080w,\n/static/1271a3703b5b224b0557b0d74541dd9c/ee3fb/output_19_0.png 1144w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>데이터 전처리 끝~</p>\n<hr>\n<h2 id=\"2-모델-생성-및-학습\" style=\"position:relative;\"><a href=\"#2-%EB%AA%A8%EB%8D%B8-%EC%83%9D%EC%84%B1-%EB%B0%8F-%ED%95%99%EC%8A%B5\" aria-label=\"2 모델 생성 및 학습 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2 모델 생성 및 학습</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>models <span class=\"token keyword\">import</span> Sequential\n<span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers <span class=\"token keyword\">import</span> Dense<span class=\"token punctuation\">,</span> Conv2D<span class=\"token punctuation\">,</span> Flatten<span class=\"token punctuation\">,</span> MaxPooling2D\n</code></pre></div>\n<p>models 에는 모델 자체를 구축하기 위한 함수가 있고  그 안의 Sequential 함수 안에 여러가지 layer 들이 들어갈 수 있다.<br>\nlayers 에는 모델의 구성 요소인 여러가지 종류의 layer(층) 함수들을 가지고 있다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">model <span class=\"token operator\">=</span> Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n    Conv2D<span class=\"token punctuation\">(</span>filters<span class=\"token operator\">=</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token string\">'same'</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">,</span> input_shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">160</span><span class=\"token punctuation\">,</span> <span class=\"token number\">160</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    MaxPooling2D<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    Conv2D<span class=\"token punctuation\">(</span>filters<span class=\"token operator\">=</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token string\">'same'</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    MaxPooling2D<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    Conv2D<span class=\"token punctuation\">(</span>filters<span class=\"token operator\">=</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token string\">'same'</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    MaxPooling2D<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    Flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    Dense<span class=\"token punctuation\">(</span>units<span class=\"token operator\">=</span><span class=\"token number\">512</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    Dense<span class=\"token punctuation\">(</span>units<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>딥러닝에서는 <strong>레이어</strong> 라는 개념을 자세하게 공부한다.<br>\n여기서는</p>\n<ul>\n<li>Conv2D</li>\n<li>MaxPooling2D</li>\n<li>Flatten</li>\n<li>Dense</li>\n</ul>\n<p>라는 네 레이어를 사용했다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">model<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_3 (Conv2D)            (None, 160, 160, 16)      448       \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 80, 80, 16)        0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 80, 80, 32)        4640      \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 40, 40, 32)        0         \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 40, 40, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_5 (MaxPooling2 (None, 20, 20, 64)        0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 25600)             0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 512)               13107712  \n_________________________________________________________________\ndense_3 (Dense)              (None, 2)                 1026      \n=================================================================\nTotal params: 13,132,322\nTrainable params: 13,132,322\nNon-trainable params: 0\n_________________________________________________________________</code></pre></div>\n<p>모델을 만들었으니 학습시켜보자.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">learning_rate <span class=\"token operator\">=</span> <span class=\"token number\">0.0001</span>\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span>tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>optimizers<span class=\"token punctuation\">.</span>RMSprop<span class=\"token punctuation\">(</span>lr<span class=\"token operator\">=</span>learning_rate<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n              loss<span class=\"token operator\">=</span>tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>losses<span class=\"token punctuation\">.</span>sparse_categorical_crossentropy<span class=\"token punctuation\">,</span>\n              metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n</code></pre></div>\n<p>학습시키기 위해서는 Optimer , Loss, Metrics 가 필요하다.</p>\n<p>opt : 학습을 어떤 방식으로 시킬 것인지<br>\nloss : 모델이 학습해나가야 할 방향 (이 경우는 확률분포)<br>\nmetrics : [accuracy, precision, recall]</p>\n<p>아직은 실행하기 전이다. 지금은 사전 작업만 거친 상태</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">BATCH_SIZE <span class=\"token operator\">=</span> <span class=\"token number\">32</span>\nSHUFFLE_BUFFER_SIZE <span class=\"token operator\">=</span> <span class=\"token number\">1000</span>\n\ntrain_batches <span class=\"token operator\">=</span> train<span class=\"token punctuation\">.</span>shuffle<span class=\"token punctuation\">(</span>SHUFFLE_BUFFER_SIZE<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>batch<span class=\"token punctuation\">(</span>BATCH_SIZE<span class=\"token punctuation\">)</span>\nvalidation_batches <span class=\"token operator\">=</span> validation<span class=\"token punctuation\">.</span>batch<span class=\"token punctuation\">(</span>BATCH_SIZE<span class=\"token punctuation\">)</span>\ntest_batches <span class=\"token operator\">=</span> test<span class=\"token punctuation\">.</span>batch<span class=\"token punctuation\">(</span>BATCH_SIZE<span class=\"token punctuation\">)</span></code></pre></div>\n<p>이렇게 train 데이터를 통으로 넣지 않고 32개씩 끊어 넣는 이유는\n랜덤한 32개의 사진들을 묶어 여러개의 Decision Tree 를 만들어 ansamble 하기 위함</p>\n<p>train_batches 의 데이터를 확인해보자</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">for</span> image_batch<span class=\"token punctuation\">,</span> label_batch <span class=\"token keyword\">in</span> train_batches<span class=\"token punctuation\">.</span>take<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">pass</span>\n\nimage_batch<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">,</span> label_batch<span class=\"token punctuation\">.</span>shape</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">(TensorShape([32, 160, 160, 3]), TensorShape([32]))</code></pre></div>\n<p>모델 학습 전에 초기 모델의 성능을 테스트해볼까? validation data 로 모델을 평가해보자<br>\n20번의 예측을 해보고 loss 와 accuracy를 구해보자</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">validation_steps <span class=\"token operator\">=</span> <span class=\"token number\">20</span>\nloss0<span class=\"token punctuation\">,</span> accuracy0 <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>validation_batches<span class=\"token punctuation\">,</span> steps<span class=\"token operator\">=</span>validation_steps<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"initial loss: {:.2f}\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>loss0<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"initial accuracy: {:.2f}\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>accuracy0<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">10/20 [==============>...............] - ETA: 0s - loss: 0.6924 - accuracy: 0.5156\n\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\n\n\n20/20 [==============================] - 3s 32ms/step - loss: 0.6919 - accuracy: 0.5172\ninitial loss: 0.69\ninitial accuracy: 0.52\n\n\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9</code></pre></div>\n<p>보면 아무것도 하기 전에 모델 evaluate 는 걍 뭐 아무것도 모른다.\n이제 이걸 학습시켜보자</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">EPOCHS <span class=\"token operator\">=</span> <span class=\"token number\">10</span>\nhistory <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>train_batches<span class=\"token punctuation\">,</span>\n                    epochs<span class=\"token operator\">=</span>EPOCHS<span class=\"token punctuation\">,</span>\n                    validation_data<span class=\"token operator\">=</span>validation_batches<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Epoch 1/10\n170/582 [=======>......................] - ETA: 18s - loss: 0.5444 - accuracy: 0.7250\n\nCorrupt JPEG data: 99 extraneous bytes before marker 0xd9\n\n\n202/582 [=========>....................] - ETA: 17s - loss: 0.5408 - accuracy: 0.7274\n\nWarning: unknown JFIF revision number 0.00\n\n\n212/582 [=========>....................] - ETA: 16s - loss: 0.5427 - accuracy: 0.7258\n\nCorrupt JPEG data: 396 extraneous bytes before marker 0xd9\n\n\n284/582 [=============>................] - ETA: 13s - loss: 0.5408 - accuracy: 0.7272\n\nCorrupt JPEG data: 65 extraneous bytes before marker 0xd9\n\n\n492/582 [========================>.....] - ETA: 3s - loss: 0.5280 - accuracy: 0.7363\n\nCorrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n\n\n504/582 [========================>.....] - ETA: 3s - loss: 0.5277 - accuracy: 0.7360\n\nCorrupt JPEG data: 128 extraneous bytes before marker 0xd9\n\n\n516/582 [=========================>....] - ETA: 2s - loss: 0.5271 - accuracy: 0.7372\n\nCorrupt JPEG data: 239 extraneous bytes before marker 0xd9\n\n\n542/582 [==========================>...] - ETA: 1s - loss: 0.5269 - accuracy: 0.7374\n\nCorrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n\n\n550/582 [===========================>..] - ETA: 1s - loss: 0.5271 - accuracy: 0.7372\n\nCorrupt JPEG data: 228 extraneous bytes before marker 0xd9\n\n\n582/582 [==============================] - ETA: 0s - loss: 0.5259 - accuracy: 0.7389\n\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 214 extraneous bytes before marker 0xd9\n\n\n582/582 [==============================] - 29s 48ms/step - loss: 0.5259 - accuracy: 0.7389 - val_loss: 0.5102 - val_accuracy: 0.7502\nEpoch 2/10\n169/582 [=======>......................] - ETA: 18s - loss: 0.4561 - accuracy: 0.7898\n\nCorrupt JPEG data: 99 extraneous bytes before marker 0xd9\n\n\n201/582 [=========>....................] - ETA: 16s - loss: 0.4553 - accuracy: 0.7886\n\nWarning: unknown JFIF revision number 0.00\n\n\n213/582 [=========>....................] - ETA: 16s - loss: 0.4548 - accuracy: 0.7893\n\nCorrupt JPEG data: 396 extraneous bytes before marker 0xd9\n\n\n283/582 [=============>................] - ETA: 13s - loss: 0.4483 - accuracy: 0.7911\n\nCorrupt JPEG data: 65 extraneous bytes before marker 0xd9\n\n\n492/582 [========================>.....] - ETA: 3s - loss: 0.4446 - accuracy: 0.7943\n\nCorrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n\n\n506/582 [=========================>....] - ETA: 3s - loss: 0.4450 - accuracy: 0.7947\n\nCorrupt JPEG data: 128 extraneous bytes before marker 0xd9\n\n\n516/582 [=========================>....] - ETA: 2s - loss: 0.4445 - accuracy: 0.7951\n\nCorrupt JPEG data: 239 extraneous bytes before marker 0xd9\n\n\n542/582 [==========================>...] - ETA: 1s - loss: 0.4437 - accuracy: 0.7953\n\nCorrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n\n\n548/582 [===========================>..] - ETA: 1s - loss: 0.4433 - accuracy: 0.7952\n\nCorrupt JPEG data: 228 extraneous bytes before marker 0xd9\n\n\n580/582 [============================>.] - ETA: 0s - loss: 0.4425 - accuracy: 0.7956\n\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 214 extraneous bytes before marker 0xd9\n\n\n582/582 [==============================] - 28s 47ms/step - loss: 0.4422 - accuracy: 0.7958 - val_loss: 0.5503 - val_accuracy: 0.7386\nEpoch 3/10\n169/582 [=======>......................] - ETA: 18s - loss: 0.3937 - accuracy: 0.8229\n\nCorrupt JPEG data: 99 extraneous bytes before marker 0xd9\n\n\n201/582 [=========>....................] - ETA: 16s - loss: 0.3927 - accuracy: 0.8232\n\nWarning: unknown JFIF revision number 0.00\n\n\n213/582 [=========>....................] - ETA: 16s - loss: 0.3927 - accuracy: 0.8234\n\nCorrupt JPEG data: 396 extraneous bytes before marker 0xd9\n\n\n283/582 [=============>................] - ETA: 13s - loss: 0.3870 - accuracy: 0.8266\n\nCorrupt JPEG data: 65 extraneous bytes before marker 0xd9\n\n\n492/582 [========================>.....] - ETA: 3s - loss: 0.3836 - accuracy: 0.8281\n\nCorrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n\n\n506/582 [=========================>....] - ETA: 3s - loss: 0.3843 - accuracy: 0.8278\n\nCorrupt JPEG data: 128 extraneous bytes before marker 0xd9\n\n\n516/582 [=========================>....] - ETA: 2s - loss: 0.3836 - accuracy: 0.8281\n\nCorrupt JPEG data: 239 extraneous bytes before marker 0xd9\n\n\n543/582 [==========================>...] - ETA: 1s - loss: 0.3820 - accuracy: 0.8288\n\nCorrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n\n\n549/582 [===========================>..] - ETA: 1s - loss: 0.3814 - accuracy: 0.8292\n\nCorrupt JPEG data: 228 extraneous bytes before marker 0xd9\n\n\n581/582 [============================>.] - ETA: 0s - loss: 0.3800 - accuracy: 0.8289\n\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 214 extraneous bytes before marker 0xd9\n\n\n582/582 [==============================] - 28s 47ms/step - loss: 0.3799 - accuracy: 0.8290 - val_loss: 0.4954 - val_accuracy: 0.7674\nEpoch 4/10\n169/582 [=======>......................] - ETA: 18s - loss: 0.3449 - accuracy: 0.8460\n\nCorrupt JPEG data: 99 extraneous bytes before marker 0xd9\n\n\n201/582 [=========>....................] - ETA: 16s - loss: 0.3404 - accuracy: 0.8469\n\nWarning: unknown JFIF revision number 0.00\n\n\n213/582 [=========>....................] - ETA: 16s - loss: 0.3395 - accuracy: 0.8480\n\nCorrupt JPEG data: 396 extraneous bytes before marker 0xd9\n\n\n283/582 [=============>................] - ETA: 12s - loss: 0.3357 - accuracy: 0.8520\n\nCorrupt JPEG data: 65 extraneous bytes before marker 0xd9\n\n\n492/582 [========================>.....] - ETA: 3s - loss: 0.3270 - accuracy: 0.8581\n\nCorrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n\n\n506/582 [=========================>....] - ETA: 3s - loss: 0.3273 - accuracy: 0.8581\n\nCorrupt JPEG data: 128 extraneous bytes before marker 0xd9\n\n\n516/582 [=========================>....] - ETA: 2s - loss: 0.3260 - accuracy: 0.8586\n\nCorrupt JPEG data: 239 extraneous bytes before marker 0xd9\n\n\n542/582 [==========================>...] - ETA: 1s - loss: 0.3256 - accuracy: 0.8590\n\nCorrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n\n\n550/582 [===========================>..] - ETA: 1s - loss: 0.3252 - accuracy: 0.8593\n\nCorrupt JPEG data: 228 extraneous bytes before marker 0xd9\n\n\n580/582 [============================>.] - ETA: 0s - loss: 0.3244 - accuracy: 0.8602\n\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 214 extraneous bytes before marker 0xd9\n\n\n582/582 [==============================] - 28s 47ms/step - loss: 0.3244 - accuracy: 0.8602 - val_loss: 0.4858 - val_accuracy: 0.7825\nEpoch 5/10\n170/582 [=======>......................] - ETA: 18s - loss: 0.2913 - accuracy: 0.8765\n\nCorrupt JPEG data: 99 extraneous bytes before marker 0xd9\n\n\n202/582 [=========>....................] - ETA: 16s - loss: 0.2866 - accuracy: 0.8790\n\nWarning: unknown JFIF revision number 0.00\n\n\n212/582 [=========>....................] - ETA: 16s - loss: 0.2868 - accuracy: 0.8791\n\nCorrupt JPEG data: 396 extraneous bytes before marker 0xd9\n\n\n284/582 [=============>................] - ETA: 12s - loss: 0.2804 - accuracy: 0.8825\n\nCorrupt JPEG data: 65 extraneous bytes before marker 0xd9\n\n\n493/582 [========================>.....] - ETA: 3s - loss: 0.2756 - accuracy: 0.8869\n\nCorrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n\n\n505/582 [=========================>....] - ETA: 3s - loss: 0.2740 - accuracy: 0.8876\n\nCorrupt JPEG data: 128 extraneous bytes before marker 0xd9\n\n\n515/582 [=========================>....] - ETA: 2s - loss: 0.2733 - accuracy: 0.8877\n\nCorrupt JPEG data: 239 extraneous bytes before marker 0xd9\n\n\n543/582 [==========================>...] - ETA: 1s - loss: 0.2732 - accuracy: 0.8886\n\nCorrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n\n\n549/582 [===========================>..] - ETA: 1s - loss: 0.2727 - accuracy: 0.8889\n\nCorrupt JPEG data: 228 extraneous bytes before marker 0xd9\n\n\n581/582 [============================>.] - ETA: 0s - loss: 0.2720 - accuracy: 0.8886\n\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 214 extraneous bytes before marker 0xd9\n\n\n582/582 [==============================] - 28s 46ms/step - loss: 0.2721 - accuracy: 0.8885 - val_loss: 0.4933 - val_accuracy: 0.7919\nEpoch 6/10\n169/582 [=======>......................] - ETA: 18s - loss: 0.2373 - accuracy: 0.9051\n\nCorrupt JPEG data: 99 extraneous bytes before marker 0xd9\n\n\n201/582 [=========>....................] - ETA: 16s - loss: 0.2335 - accuracy: 0.9083\n\nWarning: unknown JFIF revision number 0.00\n\n\n211/582 [=========>....................] - ETA: 16s - loss: 0.2331 - accuracy: 0.9083\n\nCorrupt JPEG data: 396 extraneous bytes before marker 0xd9\n\n\n283/582 [=============>................] - ETA: 13s - loss: 0.2268 - accuracy: 0.9110\n\nCorrupt JPEG data: 65 extraneous bytes before marker 0xd9\n\n\n493/582 [========================>.....] - ETA: 3s - loss: 0.2216 - accuracy: 0.9123\n\nCorrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n\n\n505/582 [=========================>....] - ETA: 3s - loss: 0.2209 - accuracy: 0.9127\n\nCorrupt JPEG data: 128 extraneous bytes before marker 0xd9\n\n\n516/582 [=========================>....] - ETA: 2s - loss: 0.2196 - accuracy: 0.9133\n\nCorrupt JPEG data: 239 extraneous bytes before marker 0xd9\n\n\n542/582 [==========================>...] - ETA: 1s - loss: 0.2178 - accuracy: 0.9147\n\nCorrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n\n\n548/582 [===========================>..] - ETA: 1s - loss: 0.2171 - accuracy: 0.9150\n\nCorrupt JPEG data: 228 extraneous bytes before marker 0xd9\n\n\n580/582 [============================>.] - ETA: 0s - loss: 0.2163 - accuracy: 0.9152\n\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 214 extraneous bytes before marker 0xd9\n\n\n582/582 [==============================] - 29s 47ms/step - loss: 0.2162 - accuracy: 0.9153 - val_loss: 0.6168 - val_accuracy: 0.7601\nEpoch 7/10\n169/582 [=======>......................] - ETA: 18s - loss: 0.1858 - accuracy: 0.9310\n\nCorrupt JPEG data: 99 extraneous bytes before marker 0xd9\n\n\n201/582 [=========>....................] - ETA: 16s - loss: 0.1836 - accuracy: 0.9331\n\nWarning: unknown JFIF revision number 0.00\n\n\n213/582 [=========>....................] - ETA: 16s - loss: 0.1820 - accuracy: 0.9341\n\nCorrupt JPEG data: 396 extraneous bytes before marker 0xd9\n\n\n283/582 [=============>................] - ETA: 13s - loss: 0.1783 - accuracy: 0.9361\n\nCorrupt JPEG data: 65 extraneous bytes before marker 0xd9\n\n\n493/582 [========================>.....] - ETA: 3s - loss: 0.1724 - accuracy: 0.9365\n\nCorrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n\n\n505/582 [=========================>....] - ETA: 3s - loss: 0.1717 - accuracy: 0.9369\n\nCorrupt JPEG data: 128 extraneous bytes before marker 0xd9\n\n\n515/582 [=========================>....] - ETA: 2s - loss: 0.1709 - accuracy: 0.9374\n\nCorrupt JPEG data: 239 extraneous bytes before marker 0xd9\n\n\n543/582 [==========================>...] - ETA: 1s - loss: 0.1699 - accuracy: 0.9378\n\nCorrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n\n\n549/582 [===========================>..] - ETA: 1s - loss: 0.1698 - accuracy: 0.9378\n\nCorrupt JPEG data: 228 extraneous bytes before marker 0xd9\n\n\n581/582 [============================>.] - ETA: 0s - loss: 0.1678 - accuracy: 0.9382\n\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 214 extraneous bytes before marker 0xd9\n\n\n582/582 [==============================] - 28s 47ms/step - loss: 0.1677 - accuracy: 0.9382 - val_loss: 0.6220 - val_accuracy: 0.7627\nEpoch 8/10\n170/582 [=======>......................] - ETA: 18s - loss: 0.1322 - accuracy: 0.9537\n\nCorrupt JPEG data: 99 extraneous bytes before marker 0xd9\n\n\n202/582 [=========>....................] - ETA: 16s - loss: 0.1317 - accuracy: 0.9547\n\nWarning: unknown JFIF revision number 0.00\n\n\n212/582 [=========>....................] - ETA: 16s - loss: 0.1293 - accuracy: 0.9558\n\nCorrupt JPEG data: 396 extraneous bytes before marker 0xd9\n\n\n284/582 [=============>................] - ETA: 13s - loss: 0.1267 - accuracy: 0.9558\n\nCorrupt JPEG data: 65 extraneous bytes before marker 0xd9\n\n\n493/582 [========================>.....] - ETA: 3s - loss: 0.1241 - accuracy: 0.9564\n\nCorrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n\n\n505/582 [=========================>....] - ETA: 3s - loss: 0.1237 - accuracy: 0.9566\n\nCorrupt JPEG data: 128 extraneous bytes before marker 0xd9\n\n\n515/582 [=========================>....] - ETA: 2s - loss: 0.1235 - accuracy: 0.9567\n\nCorrupt JPEG data: 239 extraneous bytes before marker 0xd9\n\n\n542/582 [==========================>...] - ETA: 1s - loss: 0.1223 - accuracy: 0.9574\n\nCorrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n\n\n550/582 [===========================>..] - ETA: 1s - loss: 0.1219 - accuracy: 0.9577\n\nCorrupt JPEG data: 228 extraneous bytes before marker 0xd9\n\n\n580/582 [============================>.] - ETA: 0s - loss: 0.1210 - accuracy: 0.9580\n\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 214 extraneous bytes before marker 0xd9\n\n\n582/582 [==============================] - 28s 47ms/step - loss: 0.1209 - accuracy: 0.9581 - val_loss: 0.6818 - val_accuracy: 0.7623\nEpoch 9/10\n170/582 [=======>......................] - ETA: 18s - loss: 0.0973 - accuracy: 0.9688\n\nCorrupt JPEG data: 99 extraneous bytes before marker 0xd9\n\n\n202/582 [=========>....................] - ETA: 16s - loss: 0.0932 - accuracy: 0.9711\n\nWarning: unknown JFIF revision number 0.00\n\n\n212/582 [=========>....................] - ETA: 16s - loss: 0.0942 - accuracy: 0.9704\n\nCorrupt JPEG data: 396 extraneous bytes before marker 0xd9\n\n\n284/582 [=============>................] - ETA: 13s - loss: 0.0915 - accuracy: 0.9712\n\nCorrupt JPEG data: 65 extraneous bytes before marker 0xd9\n\n\n492/582 [========================>.....] - ETA: 3s - loss: 0.0893 - accuracy: 0.9715\n\nCorrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n\n\n506/582 [=========================>....] - ETA: 3s - loss: 0.0888 - accuracy: 0.9719\n\nCorrupt JPEG data: 128 extraneous bytes before marker 0xd9\n\n\n516/582 [=========================>....] - ETA: 2s - loss: 0.0883 - accuracy: 0.9721\n\nCorrupt JPEG data: 239 extraneous bytes before marker 0xd9\n\n\n542/582 [==========================>...] - ETA: 1s - loss: 0.0880 - accuracy: 0.9722\n\nCorrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n\n\n550/582 [===========================>..] - ETA: 1s - loss: 0.0874 - accuracy: 0.9725\n\nCorrupt JPEG data: 228 extraneous bytes before marker 0xd9\n\n\n580/582 [============================>.] - ETA: 0s - loss: 0.0875 - accuracy: 0.9725\n\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 214 extraneous bytes before marker 0xd9\n\n\n582/582 [==============================] - 28s 47ms/step - loss: 0.0874 - accuracy: 0.9725 - val_loss: 0.6500 - val_accuracy: 0.7863\nEpoch 10/10\n170/582 [=======>......................] - ETA: 18s - loss: 0.0692 - accuracy: 0.9783\n\nCorrupt JPEG data: 99 extraneous bytes before marker 0xd9\n\n\n202/582 [=========>....................] - ETA: 17s - loss: 0.0681 - accuracy: 0.9785\n\nWarning: unknown JFIF revision number 0.00\n\n\n212/582 [=========>....................] - ETA: 16s - loss: 0.0674 - accuracy: 0.9788\n\nCorrupt JPEG data: 396 extraneous bytes before marker 0xd9\n\n\n284/582 [=============>................] - ETA: 13s - loss: 0.0648 - accuracy: 0.9798\n\nCorrupt JPEG data: 65 extraneous bytes before marker 0xd9\n\n\n493/582 [========================>.....] - ETA: 3s - loss: 0.0626 - accuracy: 0.9816\n\nCorrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n\n\n505/582 [=========================>....] - ETA: 3s - loss: 0.0624 - accuracy: 0.9817\n\nCorrupt JPEG data: 128 extraneous bytes before marker 0xd9\n\n\n515/582 [=========================>....] - ETA: 2s - loss: 0.0621 - accuracy: 0.9820\n\nCorrupt JPEG data: 239 extraneous bytes before marker 0xd9\n\n\n543/582 [==========================>...] - ETA: 1s - loss: 0.0610 - accuracy: 0.9826\n\nCorrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n\n\n549/582 [===========================>..] - ETA: 1s - loss: 0.0615 - accuracy: 0.9825\n\nCorrupt JPEG data: 228 extraneous bytes before marker 0xd9\n\n\n581/582 [============================>.] - ETA: 0s - loss: 0.0614 - accuracy: 0.9827\n\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 214 extraneous bytes before marker 0xd9\n\n\n582/582 [==============================] - 29s 47ms/step - loss: 0.0613 - accuracy: 0.9827 - val_loss: 0.6904 - val_accuracy: 0.7889</code></pre></div>\n<p>다음은 학습시킨 모델에 대한 그래프 보고이다</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">for</span> image_batch<span class=\"token punctuation\">,</span> label_batch <span class=\"token keyword\">in</span> test_batches<span class=\"token punctuation\">.</span>take<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    images <span class=\"token operator\">=</span> image_batch\n    labels <span class=\"token operator\">=</span> label_batch\n    predictions <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>image_batch<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">pass</span>\n\npredictions</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">array([[9.9999702e-01, 2.9417115e-06],\n       [8.3842850e-01, 1.6157144e-01],\n       [7.4218982e-01, 2.5781012e-01],\n       [9.9970847e-01, 2.9155653e-04],\n       [9.9640131e-01, 3.5986665e-03],\n       [7.8427315e-02, 9.2157269e-01],\n       [1.8649189e-02, 9.8135078e-01],\n       [9.1933328e-01, 8.0666728e-02],\n       [9.4125561e-02, 9.0587437e-01],\n       [7.8091651e-02, 9.2190832e-01],\n       [1.1057696e-01, 8.8942307e-01],\n       [9.2630666e-01, 7.3693395e-02],\n       [9.9996006e-01, 3.9985713e-05],\n       [4.6824862e-05, 9.9995315e-01],\n       [9.9207205e-01, 7.9279514e-03],\n       [9.9890709e-01, 1.0929310e-03],\n       [3.1051392e-02, 9.6894866e-01],\n       [5.8752208e-09, 1.0000000e+00],\n       [8.3172768e-01, 1.6827232e-01],\n       [9.9952376e-01, 4.7630019e-04],\n       [7.9531687e-01, 2.0468311e-01],\n       [9.9072027e-01, 9.2797335e-03],\n       [9.9999344e-01, 6.5057743e-06],\n       [9.1565454e-01, 8.4345400e-02],\n       [9.9570221e-01, 4.2977203e-03],\n       [1.0600092e-02, 9.8939985e-01],\n       [9.9997663e-01, 2.3377719e-05],\n       [1.0107538e-01, 8.9892459e-01],\n       [9.9934202e-01, 6.5792818e-04],\n       [9.9927968e-01, 7.2028313e-04],\n       [9.9999619e-01, 3.7975171e-06],\n       [2.8957015e-01, 7.1042985e-01]], dtype=float32)</code></pre></div>\n<p>이것이 바로 우리의 정확도이다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n\npredictions <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>predictions<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\npredictions</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">array([0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n       0, 0, 0, 1, 0, 1, 0, 0, 0, 1])</code></pre></div>\n<p>이제 32장의 image 와 32개의 label , 32개의 prediction 을 얻었다\n최종 확인을 해보자</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">plt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">20</span><span class=\"token punctuation\">,</span> <span class=\"token number\">12</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">for</span> idx<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> label<span class=\"token punctuation\">,</span> prediction<span class=\"token punctuation\">)</span> <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">zip</span><span class=\"token punctuation\">(</span>images<span class=\"token punctuation\">,</span> labels<span class=\"token punctuation\">,</span> predictions<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span> <span class=\"token number\">8</span><span class=\"token punctuation\">,</span> idx<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n    image <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>image <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> <span class=\"token number\">2</span>\n    plt<span class=\"token punctuation\">.</span>imshow<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">)</span>\n    correct <span class=\"token operator\">=</span> label <span class=\"token operator\">==</span> prediction\n    title <span class=\"token operator\">=</span> <span class=\"token string-interpolation\"><span class=\"token string\">f'real: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>label<span class=\"token punctuation\">}</span></span><span class=\"token string\"> / pred :</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>prediction<span class=\"token punctuation\">}</span></span><span class=\"token string\">\\n </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>correct<span class=\"token punctuation\">}</span></span><span class=\"token string\">!'</span></span>\n    <span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> correct<span class=\"token punctuation\">:</span>\n        plt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span>title<span class=\"token punctuation\">,</span> fontdict<span class=\"token operator\">=</span><span class=\"token punctuation\">{</span><span class=\"token string\">'color'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'red'</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n        plt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span>title<span class=\"token punctuation\">,</span> fontdict<span class=\"token operator\">=</span><span class=\"token punctuation\">{</span><span class=\"token string\">'color'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'blue'</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>axis<span class=\"token punctuation\">(</span><span class=\"token string\">'off'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 59.44444444444444%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAABYlAAAWJQFJUiTwAAAD10lEQVQozwHMAzP8AHt+llZbXIBmh4aHNreNhmuldGpKSx8VSGoxKmxJOzQ3YmGAZYF9j1FwbX5CbWyGbipGQzheU1NhdG1wWFVfaTtmZ3xxZF1iOL+HhVq/dmlmAG9va/SAfnn/a2Zeq4Z5Zf+di3nUhnZo0IZ5bf9oY1yqiYJ4/6ihl+Wdnp6/mZCM/2hRSapweWH/aXp29lxjW69zcmL/cGVbqpx4VPiZcUv/AG1iVpyKhH+vLyQXbGZON7dkVECHv7mqhcnCu7iRk5FsdXFzsH94cpKijH56ZFNav1AgHWxzZk6pWWZonV1oa29oZmPGbmVSbG1PJp9GOyO2AM6tpk/WsK9co5OFMWgtH2FqMxlDfXybQUJDb2BTVFIymZmxXMbH3kkTDBQ8JChGZBwpNTOHgjxXtZE5T0E3RjUyLE9na219M////1GOjJ5dALKhm/Kqkor/q6OaqE0+Lv9eVUjSpJmXzm9oav96enmoh4eA/7e3s+OFhX+9nJmS/3NvV6iUiRH/o3kY80k/N60fIBz/UlRQqKCioPUyNzn/AOfUz6TCo5y21L2ucY15Zr+ek4eOm4aGi19UXsGLhItxY2FiuEhEQZqgoKSA4uLqyOXoxnGBcgCxZ1QBpXByXnVVVU3PNC8ucSQkJqcvMDq/AEgrKUhaMzNVZW1eLLi2yViFhYk9el5TO3FSWVm0sKktkKTHVHaInEMoFhg2NCY+XFFDQC5fWHhQlpGqSQ4QHzEAAAxfHB8uL4WGoEtaXHVVADIrI+41LSX/WF5MpZKSff9vcV3OZ1E2ykExGv+Cc16leHhq/5eflN9ORDW6Vk9B/2JcT6WQhn//hnZp7319d6lraWj/Ky0spF9jW/FtcWf/AD80Kq1MQTfAT1M9eGlqS8lZVz2Wc1tFk11MOsunjXF4gHpswpWUh6J6dWaHcnFp03h5d3jb0sm6kG1ercrKw3va4ePaSEtReFZYUK9oamHJAEA/WURdXolRZGZfKqN+aFW3qJI6VFhpOMS63FXLzdQreoGsUKqz0D8yGBM0MxwsWEtDRixXQ1tNOiA2Rmtmbi6XkLRar7LOLK5/b0ilblZRADEzMuVpbG//f3hqn76yif+dk2/HMC8pw1ROSv+trK6fbGxr/4iMjtdIOy2zTjsm/zkrGp9ubWr4TlBW535pXaS7q5H/wK+fn5iMe+m5r57/AH5sW8iBd2nfXlU+i5R9VulzWjeue3h3q2VfYeuVlqCLoKiw4Jqgp7xodnqdXmhm9CQjIYujn5XYiISDyWckMY+IWkz8lGlai4iEb8uklXrpdIjI2btfkaMAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/ec1ce97527379951f010a8c71cac03f3/37523/output_42_0.png\"\n        srcset=\"/static/ec1ce97527379951f010a8c71cac03f3/e9ff0/output_42_0.png 180w,\n/static/ec1ce97527379951f010a8c71cac03f3/f21e7/output_42_0.png 360w,\n/static/ec1ce97527379951f010a8c71cac03f3/37523/output_42_0.png 720w,\n/static/ec1ce97527379951f010a8c71cac03f3/302a4/output_42_0.png 1080w,\n/static/ec1ce97527379951f010a8c71cac03f3/07a9c/output_42_0.png 1440w,\n/static/ec1ce97527379951f010a8c71cac03f3/fbae3/output_42_0.png 2260w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">count <span class=\"token operator\">=</span> <span class=\"token number\">0</span>   <span class=\"token comment\"># 정답을 맞춘 개수</span>\n<span class=\"token keyword\">for</span> image<span class=\"token punctuation\">,</span> label<span class=\"token punctuation\">,</span> prediction <span class=\"token keyword\">in</span> <span class=\"token builtin\">zip</span><span class=\"token punctuation\">(</span>images<span class=\"token punctuation\">,</span> labels<span class=\"token punctuation\">,</span> predictions<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    correct <span class=\"token operator\">=</span> label <span class=\"token operator\">==</span> prediction\n    <span class=\"token keyword\">if</span> correct<span class=\"token punctuation\">:</span>\n        count <span class=\"token operator\">=</span> count <span class=\"token operator\">+</span> <span class=\"token number\">1</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>count <span class=\"token operator\">/</span> <span class=\"token number\">32</span> <span class=\"token operator\">*</span> <span class=\"token number\">100</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">71.875</code></pre></div>\n<p>중간에 들어가있는 딥러닝 모델이 단순한 구조이기 때문에<br>\n좋은 결과가 나오고 있지는 않다.</p>\n<p>다만 중간의 모델구조를 변경한다면 더 좋은 결과를<br>\n끌어낼 수 있을 것이다.</p>\n<div class=\"table-of-contents\">\n<ul>\n<li>\n<p><a href=\"#%EA%B0%95%EC%95%84%EC%A7%80--%EA%B3%A0%EC%96%91%EC%9D%B4-%EB%B6%84%EB%A5%98-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%A8-%EC%A0%9C%EC%9E%91-\">강아지 &#x26; 고양이 분류 프로그램 제작 !</a></p>\n<ul>\n<li><a href=\"#content\">Content</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#1-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%84%EC%B2%98%EB%A6%AC\">1. 데이터 전처리</a></p>\n</li>\n<li>\n<p><a href=\"#2-%EB%AA%A8%EB%8D%B8-%EC%83%9D%EC%84%B1-%EB%B0%8F-%ED%95%99%EC%8A%B5\">2 모델 생성 및 학습</a></p>\n</li>\n</ul>\n</div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"></code></pre></div>","frontmatter":{"date":"April 21, 2022","title":"인공지능 기초 사진 분류 프로그램 맛보기","categories":"STUDY","author":"하성민","emoji":"😁"},"fields":{"slug":"/DML_AI1/"}},"prev":{"id":"797d644a-1f24-5817-8dd3-7489d8b62484","html":"<h1 id=\"span-stylebackground-color-fff5b1-tensor-flow-v2-라이브러리를-이용해-딥러닝-모델-생성하기span\" style=\"position:relative;\"><a href=\"#span-stylebackground-color-fff5b1-tensor-flow-v2-%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%B4-%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%AA%A8%EB%8D%B8-%EC%83%9D%EC%84%B1%ED%95%98%EA%B8%B0span\" aria-label=\"span stylebackground color fff5b1 tensor flow v2 라이브러리를 이용해 딥러닝 모델 생성하기span permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><span style='background-color: #fff5b1'>🌠 Tensor flow V2 라이브러리를 이용해 딥러닝 모델 생성하기</span></h1>\n<p>Tensor flow V2 버전에서 딥러닝 모델 작성 방법에는 크게 3가지가 있다.</p>\n<ul>\n<li>Sequential</li>\n<li>Functional : sequential 의 일반화된 개념</li>\n<li>Model Subclassing : 클래스로 구현된 기존 모델을 상속받아 자기 모델 만들기</li>\n</ul>\n<p>순차적으로 어떤 차이가 있고,<br>\n어떤 식으로 제작하는지 알아가보자.</p>\n<hr>\n<h2 id=\"1-sequential-model\" style=\"position:relative;\"><a href=\"#1-sequential-model\" aria-label=\"1 sequential model permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. Sequential Model</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n<span class=\"token keyword\">from</span> tensorflow <span class=\"token keyword\">import</span> keras\n\nmodel <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>__넣고싶은 레이어__<span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>__넣고싶은 레이어__<span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>__넣고싶은 레이어__<span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">20</span><span class=\"token punctuation\">,</span> batch_size<span class=\"token operator\">=</span><span class=\"token number\">16</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>epochs : 모델로 데이터를 학습할 횟수<br>\nbatch_size : 데이터를 소분해 넣을 양</p>\n<p>model = keras.Sequential() 을 활용하면<br>\n딥러닝 모델을 쌓아 나갈 수 있다.</p>\n<p>입력부터 출력까지 순차적(시퀀셜) 으로 add 하면 된다.</p>\n<h4 id=\"but\" style=\"position:relative;\"><a href=\"#but\" aria-label=\"but permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>but,</h4>\n<p>모델의 입력과 출력이 여러개인 경우에는 적합하지 않다.<br>\n(반드시 입력 1개 출력 1가지 여야 함)</p>\n<h2 id=\"2-functional-api\" style=\"position:relative;\"><a href=\"#2-functional-api\" aria-label=\"2 functional api permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. Functional API</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n<span class=\"token keyword\">from</span> tensorflow <span class=\"token keyword\">import</span> keras\n\ninputs <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>Input<span class=\"token punctuation\">(</span>shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>__원하는 입력값 모양__<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nx <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>__넣고싶은 레이어__<span class=\"token punctuation\">(</span>관련 파라미터<span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">input</span><span class=\"token punctuation\">)</span>\nx <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>__넣고싶은 레이어__<span class=\"token punctuation\">(</span>관련 파라미터<span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\noutputs <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>__넣고싶은 레이어__<span class=\"token punctuation\">(</span>관련 파라미터<span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n\nmodel <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>Model<span class=\"token punctuation\">(</span>inputs<span class=\"token operator\">=</span>inputs<span class=\"token punctuation\">,</span> outputs<span class=\"token operator\">=</span>outputs<span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span>y<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> batch_size<span class=\"token operator\">=</span><span class=\"token number\">32</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>model 에 ketas.Model 이 들어간다.<br>\n이것은 우리가 danse 나 Flatten 같은 짜여져 있는 신경망을 쓰는 게 아니라<br>\n직접 input 과 output 을 구성한다.</p>\n<p>때문에 입력과 출력값이 자유롭다</p>\n<hr>\n<p>딥 러닝 모델은 일반적으로 레이어의 DAG Directed Acyclic graph 이다.<br>\n레이어의 그래프를 bulid 한다는 뜻이다.</p>\n<h2 id=\"3-subclassing\" style=\"position:relative;\"><a href=\"#3-subclassing\" aria-label=\"3 subclassing permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. Subclassing</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n<span class=\"token keyword\">from</span> tensorflow <span class=\"token keyword\">import</span> keras\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">CustomModel</span><span class=\"token punctuation\">(</span>keras<span class=\"token punctuation\">.</span>Model<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span>CustomModel<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>__정의하고자 하는 레이어__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>__정의하고자 하는 레이어__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>__정의하고자 하는 레이어__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    \n    <span class=\"token keyword\">def</span> <span class=\"token function\">call</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>__정의하고자 하는 레이어__<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>__정의하고자 하는 레이어__<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>__정의하고자 하는 레이어__<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        \n        <span class=\"token keyword\">return</span> x\n    \nmodel <span class=\"token operator\">=</span> CustomModel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span>y<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> batch_size<span class=\"token operator\">=</span><span class=\"token number\">32</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>제일 자유로운 모델링이 가능한 subclassing</p>\n<h1 id=\"이를-바탕으로-직접-구현해보자\" style=\"position:relative;\"><a href=\"#%EC%9D%B4%EB%A5%BC-%EB%B0%94%ED%83%95%EC%9C%BC%EB%A1%9C-%EC%A7%81%EC%A0%91-%EA%B5%AC%ED%98%84%ED%95%B4%EB%B3%B4%EC%9E%90\" aria-label=\"이를 바탕으로 직접 구현해보자 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>이를 바탕으로 직접 구현해보자</h1>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n<span class=\"token keyword\">from</span> tensorflow <span class=\"token keyword\">import</span> keras\n<span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 데이터 구성부분</span>\nmnist <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>datasets<span class=\"token punctuation\">.</span>mnist\n\n<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span> y_test<span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> mnist<span class=\"token punctuation\">.</span>load_data<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nx_train<span class=\"token punctuation\">,</span> x_test <span class=\"token operator\">=</span> x_train <span class=\"token operator\">/</span> <span class=\"token number\">255.0</span><span class=\"token punctuation\">,</span> x_test <span class=\"token operator\">/</span> <span class=\"token number\">255.0</span>\n\nx_train<span class=\"token operator\">=</span>x_train<span class=\"token punctuation\">[</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">,</span>np<span class=\"token punctuation\">.</span>newaxis<span class=\"token punctuation\">]</span>\nx_test<span class=\"token operator\">=</span>x_test<span class=\"token punctuation\">[</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">,</span>np<span class=\"token punctuation\">.</span>newaxis<span class=\"token punctuation\">]</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n11493376/11490434 [==============================] - 0s 0us/step\n11501568/11490434 [==============================] - 0s 0us/step\n60000 10000</code></pre></div>\n<h2 id=\"1-sequential-model-1\" style=\"position:relative;\"><a href=\"#1-sequential-model-1\" aria-label=\"1 sequential model 1 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. Sequential model</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># Sequential Model을 구성해주세요.</span>\n<span class=\"token triple-quoted-string string\">\"\"\"\nSpec:\n1. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n2. 64개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n3. Flatten 레이어\n4. 128개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n5. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n\"\"\"</span>\n\n\nmodel <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>models<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span>activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span>activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">128</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span>activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span>\n                           <span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n\n<span class=\"token triple-quoted-string string\">\"\"\"\nmodel.add.Conv2D(32, 3, activation=\"relu\")\nmodel.add.Conv2D(64, 3, activation=\"relu\")\nmodel.add.Flatten()\nmodel.add.Dense(128, activation='relu')\nmodel.add.Dense(10, activation='softmax')\n\"\"\"</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">'\\nmodel.add.Conv2D(32, 3, activation=\"relu\")\\nmodel.add.Conv2D(64, 3, activation=\"relu\")\\nmodel.add.Flatten()\\nmodel.add.Dense(128, activation=\\'relu\\')\\nmodel.add.Dense(10, activation=\\'softmax\\')\\n'</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 모델 학습 설정</span>\n\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span><span class=\"token string\">'adam'</span><span class=\"token punctuation\">,</span>\n              loss<span class=\"token operator\">=</span><span class=\"token string\">'sparse_categorical_crossentropy'</span><span class=\"token punctuation\">,</span>\n              metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span>  y_test<span class=\"token punctuation\">,</span> verbose<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Epoch 1/5\n1875/1875 [==============================] - 31s 3ms/step - loss: 0.1118 - accuracy: 0.9654\nEpoch 2/5\n1875/1875 [==============================] - 5s 3ms/step - loss: 0.0368 - accuracy: 0.9882\nEpoch 3/5\n1875/1875 [==============================] - 5s 3ms/step - loss: 0.0211 - accuracy: 0.9933\nEpoch 4/5\n1875/1875 [==============================] - 5s 3ms/step - loss: 0.0131 - accuracy: 0.9956\nEpoch 5/5\n1875/1875 [==============================] - 5s 3ms/step - loss: 0.0100 - accuracy: 0.9968\n313/313 - 1s - loss: 0.0516 - accuracy: 0.9878\n\n\n\n\n\n[0.051644984632730484, 0.9878000020980835]</code></pre></div>\n<h2 id=\"2-functional-api-1\" style=\"position:relative;\"><a href=\"#2-functional-api-1\" aria-label=\"2 functional api 1 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. Functional API</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">mnist <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>datasets<span class=\"token punctuation\">.</span>mnist\n\n<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span> y_test<span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> mnist<span class=\"token punctuation\">.</span>load_data<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nx_train<span class=\"token punctuation\">,</span> x_test <span class=\"token operator\">=</span> x_train <span class=\"token operator\">/</span> <span class=\"token number\">255.0</span><span class=\"token punctuation\">,</span> x_test <span class=\"token operator\">/</span> <span class=\"token number\">255.0</span>\n\nx_train<span class=\"token operator\">=</span>x_train<span class=\"token punctuation\">[</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">,</span>np<span class=\"token punctuation\">.</span>newaxis<span class=\"token punctuation\">]</span>\nx_test<span class=\"token operator\">=</span>x_test<span class=\"token punctuation\">[</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">,</span>np<span class=\"token punctuation\">.</span>newaxis<span class=\"token punctuation\">]</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">60000 10000</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token triple-quoted-string string\">\"\"\"\nSpec:\n0. (28X28X1) 차원으로 정의된 Input\n1. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n2. 64개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n3. Flatten 레이어\n4. 128개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n5. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n\"\"\"</span>\n\ninputs <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>Input<span class=\"token punctuation\">(</span>shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">28</span><span class=\"token punctuation\">,</span><span class=\"token number\">28</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nx <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span>activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>inputs<span class=\"token punctuation\">)</span>\nx <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span>activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\nx <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\nx <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">128</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\noutputs <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n\nmodel <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>Model<span class=\"token punctuation\">(</span>inputs<span class=\"token operator\">=</span>inputs<span class=\"token punctuation\">,</span> outputs<span class=\"token operator\">=</span>outputs<span class=\"token punctuation\">)</span>\n\n\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span><span class=\"token string\">'adam'</span><span class=\"token punctuation\">,</span>\n              loss<span class=\"token operator\">=</span><span class=\"token string\">'sparse_categorical_crossentropy'</span><span class=\"token punctuation\">,</span>\n              metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span>  y_test<span class=\"token punctuation\">,</span> verbose<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Epoch 1/5\n1875/1875 [==============================] - 7s 3ms/step - loss: 0.1039 - accuracy: 0.9679\nEpoch 2/5\n1875/1875 [==============================] - 6s 3ms/step - loss: 0.0339 - accuracy: 0.9895\nEpoch 3/5\n1875/1875 [==============================] - 6s 3ms/step - loss: 0.0204 - accuracy: 0.9931\nEpoch 4/5\n1875/1875 [==============================] - 6s 3ms/step - loss: 0.0130 - accuracy: 0.9959\nEpoch 5/5\n1875/1875 [==============================] - 6s 3ms/step - loss: 0.0093 - accuracy: 0.9972\n313/313 - 1s - loss: 0.0522 - accuracy: 0.9868\n\n\n\n\n\n[0.05223735421895981, 0.9868000149726868]</code></pre></div>\n<h2 id=\"3-subclassing-api\" style=\"position:relative;\"><a href=\"#3-subclassing-api\" aria-label=\"3 subclassing api permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. Subclassing API</h2>\n<p>keras.models 를 상속받는 클래스를 만드는 것</p>\n<ol>\n<li><strong>init</strong> 메서드에 레이어 선언</li>\n<li>call() 메서드에 forward propagation 방식 체계 구현</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token triple-quoted-string string\">\"\"\"\nSpec:\n0. keras.Model 을 상속받았으며, __init__()와 call() 메서드를 가진 모델 클래스\n1. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n2. 64개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n3. Flatten 레이어\n4. 128개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n5. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n6. call의 입력값이 모델의 Input, call의 리턴값이 모델의 Output\n\"\"\"</span>\n\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">kerasModel</span><span class=\"token punctuation\">(</span>keras<span class=\"token punctuation\">.</span>Model<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        \n        self<span class=\"token punctuation\">.</span>Conv2D32 <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>Conv2D64 <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>Flatten <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>Dense128 <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">128</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>Dense <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span>\n    \n    <span class=\"token keyword\">def</span> <span class=\"token function\">call</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>Conv2D32<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>Conv2D64<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>Dense128<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        output <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        \n        <span class=\"token keyword\">return</span> output\n    \nmodel <span class=\"token operator\">=</span> kerasModel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span><span class=\"token string\">'adam'</span><span class=\"token punctuation\">,</span>\n              loss<span class=\"token operator\">=</span><span class=\"token string\">'sparse_categorical_crossentropy'</span><span class=\"token punctuation\">,</span>\n              metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span>  y_test<span class=\"token punctuation\">,</span> verbose<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Epoch 1/5\n1875/1875 [==============================] - 7s 3ms/step - loss: 0.1011 - accuracy: 0.9689\nEpoch 2/5\n1875/1875 [==============================] - 6s 3ms/step - loss: 0.0339 - accuracy: 0.9893\nEpoch 3/5\n1875/1875 [==============================] - 6s 3ms/step - loss: 0.0184 - accuracy: 0.9938\nEpoch 4/5\n1875/1875 [==============================] - 6s 3ms/step - loss: 0.0136 - accuracy: 0.9954\nEpoch 5/5\n1875/1875 [==============================] - 6s 3ms/step - loss: 0.0078 - accuracy: 0.9973\n313/313 - 1s - loss: 0.0581 - accuracy: 0.9853\n\n\n\n\n\n[0.05812956392765045, 0.9853000044822693]</code></pre></div>\n<p>이건 결론적으로는 model 을 갖다 쓰는거라서<br>\ninput 을 따로 설정안하고<br>\n그리고 call 메서드도 fit 할때 자동으로 써지는 듯 하다.</p>\n<hr>\n<h1 id=\"cifar--100-데이터-예제로-복습\" style=\"position:relative;\"><a href=\"#cifar--100-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%98%88%EC%A0%9C%EB%A1%9C-%EB%B3%B5%EC%8A%B5\" aria-label=\"cifar  100 데이터 예제로 복습 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>CIFAR -100 데이터 예제로 복습</h1>\n<h3 id=\"sequential\" style=\"position:relative;\"><a href=\"#sequential\" aria-label=\"sequential permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Sequential</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 데이터 구성부분</span>\ncifar100 <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>datasets<span class=\"token punctuation\">.</span>cifar100\n\n<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span> y_test<span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> cifar100<span class=\"token punctuation\">.</span>load_data<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nx_train<span class=\"token punctuation\">,</span> x_test <span class=\"token operator\">=</span> x_train <span class=\"token operator\">/</span> <span class=\"token number\">255.0</span><span class=\"token punctuation\">,</span> x_test <span class=\"token operator\">/</span> <span class=\"token number\">255.0</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">50000 10000</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># Sequential Model을 구성해주세요.</span>\n<span class=\"token triple-quoted-string string\">\"\"\"\nSpec:\n1. 16개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n2. pool_size가 2인 MaxPool 레이어\n3. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n4. pool_size가 2인 MaxPool 레이어\n5. 256개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n6. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n\"\"\"</span>\n\nmodel <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>models<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span>activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>MaxPool2D<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span>activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>MaxPool2D<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">256</span><span class=\"token punctuation\">,</span>activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">100</span><span class=\"token punctuation\">,</span>activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">model<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span><span class=\"token string\">'adam'</span><span class=\"token punctuation\">,</span>\n              loss<span class=\"token operator\">=</span><span class=\"token string\">'sparse_categorical_crossentropy'</span><span class=\"token punctuation\">,</span>\n              metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span>  y_test<span class=\"token punctuation\">,</span> verbose<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Epoch 1/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\nEpoch 2/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\nEpoch 3/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\nEpoch 4/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\nEpoch 5/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\n313/313 - 1s - loss: nan - accuracy: 0.0100\n\n\n\n\n\n[nan, 0.009999999776482582]</code></pre></div>\n<h3 id=\"functional\" style=\"position:relative;\"><a href=\"#functional\" aria-label=\"functional permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Functional</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token triple-quoted-string string\">\"\"\"\nSpec:\n0. (32X32X3) 차원으로 정의된 Input\n1. 16개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n2. pool_size가 2인 MaxPool 레이어\n3. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n4. pool_size가 2인 MaxPool 레이어\n5. 256개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n6. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n\"\"\"</span>\n\ninputs <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>Input<span class=\"token punctuation\">(</span>shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nx <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span>activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>inputs<span class=\"token punctuation\">)</span>\nx <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>MaxPool2D<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\nx <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span>activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\nx <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>MaxPool2D<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\nx <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\nx <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">256</span><span class=\"token punctuation\">,</span>activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\noutputs <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">100</span><span class=\"token punctuation\">,</span>activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n\nmodel <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>Model<span class=\"token punctuation\">(</span>inputs<span class=\"token operator\">=</span>inputs<span class=\"token punctuation\">,</span> outputs<span class=\"token operator\">=</span>outputs<span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span><span class=\"token string\">'adam'</span><span class=\"token punctuation\">,</span>\n               loss<span class=\"token operator\">=</span><span class=\"token string\">'sparse_categorical_crossentropy'</span><span class=\"token punctuation\">,</span>\n               metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> epochs <span class=\"token operator\">=</span> <span class=\"token number\">5</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span> y_test<span class=\"token punctuation\">,</span> verbose <span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Epoch 1/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\nEpoch 2/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\nEpoch 3/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\nEpoch 4/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\nEpoch 5/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\n313/313 - 1s - loss: nan - accuracy: 0.0100\n\n\n\n\n\n[nan, 0.009999999776482582]</code></pre></div>\n<h3 id=\"subclass-api\" style=\"position:relative;\"><a href=\"#subclass-api\" aria-label=\"subclass api permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Subclass API</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token triple-quoted-string string\">\"\"\"\nSpec:\n0. keras.Model 을 상속받았으며, __init__()와 call() 메서드를 가진 모델 클래스\n1. 16개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n2. pool_size가 2인 MaxPool 레이어\n3. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n4. pool_size가 2인 MaxPool 레이어\n5. 256개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n6. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n7. call의 입력값이 모델의 Input, call의 리턴값이 모델의 Output\n\"\"\"</span>\n\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">kerasModel</span><span class=\"token punctuation\">(</span>keras<span class=\"token punctuation\">.</span>Model<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        \n        self<span class=\"token punctuation\">.</span>Conv2D16 <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>Conv2D32 <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>Maxpool <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>MaxPool2D<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>Flatten <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>Dense256 <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">256</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>Dense <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span>\n    \n    <span class=\"token keyword\">def</span> <span class=\"token function\">call</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>Conv2D16<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>Maxpool<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>Conv2D32<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>Maxpool<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>Dense256<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        output <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        \n        <span class=\"token keyword\">return</span> output\n    \nmodel <span class=\"token operator\">=</span> kerasModel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span><span class=\"token string\">'adam'</span><span class=\"token punctuation\">,</span>\n              loss<span class=\"token operator\">=</span><span class=\"token string\">'sparse_categorical_crossentropy'</span><span class=\"token punctuation\">,</span>\n              metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span>  y_test<span class=\"token punctuation\">,</span> verbose<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Epoch 1/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\nEpoch 2/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\nEpoch 3/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\nEpoch 4/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\nEpoch 5/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\n313/313 - 1s - loss: nan - accuracy: 0.0100\n\n\n\n\n\n[nan, 0.009999999776482582]</code></pre></div>\n<hr>\n<p>우리는 model.compile 에 있어서 계속 동일한 구성을 유지했다.</p>\n<p>잠시 인공지능 학습 과정을 복기해보자.</p>\n<ol>\n<li>Forward Propagation</li>\n<li>Loss 값 계산</li>\n<li>중간 레이어 값 및 loss 를 활용한 chain rule 방식의 Back propagation</li>\n<li>parameter update</li>\n<li>repeat</li>\n</ol>\n<p>이런 과정이 tf v2 에서는 fit 에 다 담겨있다.</p>\n<p>tf.gredient tape 는 propagation 동안 진행되는 모든 연산의 중간 레이어 값을<br>\ntape 에 기록한다.</p>\n<p>이를 이용해 gredient 를 계산하고 tape 를 폐기한다.</p>\n<p>우리는 이 tape 값을 이용해 고급기법을 이용할 수 있다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n<span class=\"token keyword\">from</span> tensorflow <span class=\"token keyword\">import</span> keras\n\n<span class=\"token comment\"># 데이터 구성부분</span>\ncifar100 <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>datasets<span class=\"token punctuation\">.</span>cifar100\n\n<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span> y_test<span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> cifar100<span class=\"token punctuation\">.</span>load_data<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nx_train<span class=\"token punctuation\">,</span> x_test <span class=\"token operator\">=</span> x_train <span class=\"token operator\">/</span> <span class=\"token number\">255.0</span><span class=\"token punctuation\">,</span> x_test <span class=\"token operator\">/</span> <span class=\"token number\">255.0</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 모델 구성부분</span>\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">CustomModel</span><span class=\"token punctuation\">(</span>keras<span class=\"token punctuation\">.</span>Model<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>conv1 <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>maxpool1 <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>MaxPool2D<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>conv2 <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>maxpool2 <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>MaxPool2D<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>flatten <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>fc1 <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">256</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>fc2 <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">100</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">call</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>conv1<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>maxpool1<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>conv2<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>maxpool2<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>flatten<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>fc1<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>fc2<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">return</span> x\n\nmodel <span class=\"token operator\">=</span> CustomModel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">50000 10000</code></pre></div>\n<p>지금까지는</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">model<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span><span class=\"token string\">'adam'</span><span class=\"token punctuation\">,</span>\n              loss<span class=\"token operator\">=</span><span class=\"token string\">'sparse_categorical_crossentropy'</span><span class=\"token punctuation\">,</span>\n              metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>에서 알아서 loss 를 통해 학습 파라미터를 수정할 수 있게 해주었다.</p>\n<p>이번에는 tape.gradient() 를 통해서<br>\n매 스텝 마다 발생하는 gredient 를 export,<br>\noptimizer.apply_grediens() 를 통해 발생한 gredient 가<br>\nmodel.trainable_variables 를 통해 파라미터를 업데이터 하도록 한다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">loss_func <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>losses<span class=\"token punctuation\">.</span>SparseCategoricalCrossentropy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\noptimizer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>optimizers<span class=\"token punctuation\">.</span>Adam<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># tf.GradientTape()를 활용한 train_step</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">train_step</span><span class=\"token punctuation\">(</span>features<span class=\"token punctuation\">,</span> labels<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> tf<span class=\"token punctuation\">.</span>GradientTape<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> tape<span class=\"token punctuation\">:</span>\n        predictions <span class=\"token operator\">=</span> model<span class=\"token punctuation\">(</span>features<span class=\"token punctuation\">)</span>\n        loss <span class=\"token operator\">=</span> loss_func<span class=\"token punctuation\">(</span>labels<span class=\"token punctuation\">,</span> predictions<span class=\"token punctuation\">)</span>\n        gradients <span class=\"token operator\">=</span> tape<span class=\"token punctuation\">.</span>gradient<span class=\"token punctuation\">(</span>loss<span class=\"token punctuation\">,</span> model<span class=\"token punctuation\">.</span>trainable_variables<span class=\"token punctuation\">)</span>\n    optimizer<span class=\"token punctuation\">.</span>apply_gradients<span class=\"token punctuation\">(</span><span class=\"token builtin\">zip</span><span class=\"token punctuation\">(</span>gradients<span class=\"token punctuation\">,</span> model<span class=\"token punctuation\">.</span>trainable_variables<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> loss</code></pre></div>\n<p>위의 train_step 메서드가 바로<br>\nfit 을 통해 1번 epoch 하는 동안의 안에서 이루어지는 steps 들의 진행방식을 나타낸것.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> time\n<span class=\"token keyword\">def</span> <span class=\"token function\">train_model</span><span class=\"token punctuation\">(</span>batch_size<span class=\"token operator\">=</span><span class=\"token number\">32</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    start <span class=\"token operator\">=</span> time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">for</span> epoch <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        x_batch <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n        y_batch <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">for</span> step<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">)</span> <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">zip</span><span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            x_batch<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n            y_batch<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>y<span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">if</span> step <span class=\"token operator\">%</span> batch_size <span class=\"token operator\">==</span> batch_size<span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">:</span>\n                loss <span class=\"token operator\">=</span> train_step<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span>x_batch<span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>np<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span>y_batch<span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>np<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n                x_batch <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n                y_batch <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Epoch %d: last batch loss = %.4f'</span> <span class=\"token operator\">%</span> <span class=\"token punctuation\">(</span>epoch<span class=\"token punctuation\">,</span> <span class=\"token builtin\">float</span><span class=\"token punctuation\">(</span>loss<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"It took {} seconds\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> start<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\ntrain_model<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Epoch 0: last batch loss = 3.2522\nEpoch 1: last batch loss = 2.6932\nEpoch 2: last batch loss = 2.4441\nEpoch 3: last batch loss = 2.3071\nEpoch 4: last batch loss = 2.2136\nIt took 85.202951669693 seconds</code></pre></div>\n<p>위 두 함수의 연계사용이\nfit 메서드를 풀어 쓴 것이다.</p>\n<p>쉽게 말하면</p>\n<p>데이터들을 batch_size 만큼 끊어서<br>\n그 끊은 만큼의 x_train(feature) 를 넣어 모델 신경망에 넣고 돌려\n예측한 y_train 값을 반환하고</p>\n<p>실제 y_trian(label) 값과 예측한 y_trian 값을 손실함수(loss) 를 돌려<br>\n그 출력 값으로 Back propagation 을 통해 모델 내부 가중치를 새로운 가중치로 update</p>\n<p>자 그럼 손실값은 한 1epochs 에 배치사이즈 돌린만큼 나오겠지?<br>\n(위의 경우 32배치사이즈 이므로 데이터가 100개면 한 epochs 당 loss 가 3개 나오지)\n하지만 출력되는 loss 는 맨 마지막 배치의 loss 이다.</p>\n<p>이 과정을 epoch 횟수 만큼 반복하는 것이다.</p>\n<p>이게 fit 메서드가 하는 일.</p>\n<hr>\n<p>이걸 굳이 끄집어내서 보는 이유는</p>\n<p>우리가 강화학습 또는 GAN 을 시행할 때\n이 내부 train_step 의 재구성을 해야 하므로!!!!!</p>\n<hr>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">prediction <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span> batch_size<span class=\"token operator\">=</span>x_test<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> verbose<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\ntemp <span class=\"token operator\">=</span> <span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>squeeze<span class=\"token punctuation\">(</span>y_test<span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> np<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>prediction<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\ntemp<span class=\"token operator\">/</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>y_test<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># Accuracy</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">1/1 [==============================] - 1s 822ms/step\n\n\n\n\n\n0.346</code></pre></div>\n<p>일단 epoch 해봣으니 결과값도 이렇게 도출이 된다.</p>\n<div class=\"table-of-contents\">\n<ul>\n<li>\n<p><a href=\"#1-sequential-model\">1. Sequential Model</a></p>\n<ul>\n<li>\n<ul>\n<li><a href=\"#but\">but,</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><a href=\"#2-functional-api\">2. Functional API</a></p>\n</li>\n<li>\n<p><a href=\"#3-subclassing\">3. Subclassing</a></p>\n</li>\n<li>\n<p><a href=\"#1-sequential-model-1\">1. Sequential model</a></p>\n</li>\n<li>\n<p><a href=\"#2-functional-api-1\">2. Functional API</a></p>\n</li>\n<li>\n<p><a href=\"#3-subclassing-api\">3. Subclassing API</a></p>\n<ul>\n<li><a href=\"#sequential\">Sequential</a></li>\n<li><a href=\"#functional\">Functional</a></li>\n<li><a href=\"#subclass-api\">Subclass API</a></li>\n</ul>\n</li>\n</ul>\n</div>","frontmatter":{"date":"April 21, 2022","title":"Keras 딥러닝 모델","categories":"STUDY","author":"하성민","emoji":"😁"},"fields":{"slug":"/DML_keras2/"}},"site":{"siteMetadata":{"siteUrl":"https://xman227.github.io","comments":{"utterances":{"repo":"xman227/blog_comments"}}}}},"pageContext":{"slug":"/DML_AI2/","nextSlug":"/DML_AI1/","prevSlug":"/DML_keras2/"}},
    "staticQueryHashes": ["1073350324","1956554647","2938748437"]}