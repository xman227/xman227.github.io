{
    "componentChunkName": "component---src-templates-blog-template-js",
    "path": "/DML_AI2/",
    "result": {"data":{"cur":{"id":"594039ec-3322-5302-b54c-d19ecd03dc20","html":"<h1 id=\"span-stylebackground-color-fff5b1딥러닝모델-vgg-16--️span\" style=\"position:relative;\"><a href=\"#span-stylebackground-color-fff5b1%EB%94%A5%EB%9F%AC%EB%8B%9D%EB%AA%A8%EB%8D%B8-vgg-16--%EF%B8%8Fspan\" aria-label=\"span stylebackground color fff5b1딥러닝모델 vgg 16  ️span permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><span style='background-color: #fff5b1'>딥러닝모델 VGG-16  🚶🏽‍♂️</span></h1>\n<p>오늘 구현한 모델은 VGG-16 이다.</p>\n<h2 id=\"목차\" style=\"position:relative;\"><a href=\"#%EB%AA%A9%EC%B0%A8\" aria-label=\"목차 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>목차</h2>\n<ol>\n<li>데이터 불러오기</li>\n<li>VGG-16 생성</li>\n<li>본인의 과업에 맞게 VGG-16 개선</li>\n</ol>\n<p>이 모델은 미국에서 진행한 이미지 인식 대회 ILSVRC 에서<br>\n2014년 준우승을 한 모델이다! (물론 지금은 더 좋은게 많이 있다)</p>\n<p>하지만 계속 발전되는 Deep Learning 모델을 이해하기 위해선<br>\n기본적인 구조를 갖춘 VGG-16 의 모델 이해가 필요하다.</p>\n<p>본 게시글에서는 VGG-16 를 Tensorflow 라이브러리에서 불러와<br>\n사용하는 방법을 제시한다.</p>\n<p>모델 사용에는 tensorflow 실습 데이터인\n<code class=\"language-text\">cats vs dogs</code> 를 사용했다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n<span class=\"token keyword\">import</span> tensorflow_datasets <span class=\"token keyword\">as</span> tfds\n<span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt\n<span class=\"token operator\">%</span>matplotlib inline\n<span class=\"token operator\">%</span>config InlineBackend<span class=\"token punctuation\">.</span>figure_format <span class=\"token operator\">=</span> <span class=\"token string\">'retina'</span>\n\n\n\n<span class=\"token punctuation\">(</span>raw_train<span class=\"token punctuation\">,</span> raw_validation<span class=\"token punctuation\">,</span> raw_test<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> metadata <span class=\"token operator\">=</span> tfds<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span>\n    <span class=\"token string\">'cats_vs_dogs'</span><span class=\"token punctuation\">,</span>\n    split<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'train[:80%]'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'train[80%:90%]'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'train[90%:]'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n    with_info<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n    as_supervised<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">)</span>\n\nIMG_SIZE <span class=\"token operator\">=</span> <span class=\"token number\">160</span> <span class=\"token comment\"># 리사이징할 이미지의 크기</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">format_example</span><span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> label<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    image <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>cast<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> tf<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># image=float(image)같은 타입캐스팅의  텐서플로우 버전입니다.</span>\n    image <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>image<span class=\"token operator\">/</span><span class=\"token number\">127.5</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> <span class=\"token number\">1</span> <span class=\"token comment\"># 픽셀값의 scale 수정</span>\n    image <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>image<span class=\"token punctuation\">.</span>resize<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>IMG_SIZE<span class=\"token punctuation\">,</span> IMG_SIZE<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> image<span class=\"token punctuation\">,</span> label\n\ntrain <span class=\"token operator\">=</span> raw_train<span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span>format_example<span class=\"token punctuation\">)</span>\nvalidation <span class=\"token operator\">=</span> raw_validation<span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span>format_example<span class=\"token punctuation\">)</span>\ntest <span class=\"token operator\">=</span> raw_test<span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span>format_example<span class=\"token punctuation\">)</span>\n</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">\u001b[1mDownloading and preparing dataset 786.68 MiB (download: 786.68 MiB, generated: Unknown size, total: 786.68 MiB) to /aiffel/tensorflow_datasets/cats_vs_dogs/4.0.0...\u001b[0m\n\n\n\nDl Completed...: 0 url [00:00, ? url/s]\n\n\n\nDl Size...: 0 MiB [00:00, ? MiB/s]\n\n\n\nGenerating splits...:   0%|          | 0/1 [00:00&lt;?, ? splits/s]\n\n\n\nGenerating train examples...:   0%|          | 0/23262 [00:00&lt;?, ? examples/s]\n\n\nWARNING:absl:1738 images were corrupted and were skipped\n\n\n\nShuffling cats_vs_dogs-train.tfrecord...:   0%|          | 0/23262 [00:00&lt;?, ? examples/s]\n\n\n\u001b[1mDataset cats_vs_dogs downloaded and prepared to /aiffel/tensorflow_datasets/cats_vs_dogs/4.0.0. Subsequent calls will reuse this data.\u001b[0m</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">plt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n\nget_label_name <span class=\"token operator\">=</span> metadata<span class=\"token punctuation\">.</span>features<span class=\"token punctuation\">[</span><span class=\"token string\">'label'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>int2str\n\n<span class=\"token keyword\">for</span> idx<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> label<span class=\"token punctuation\">)</span> <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>train<span class=\"token punctuation\">.</span>take<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">,</span> idx<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n    image <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>image <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> <span class=\"token number\">2</span>\n    plt<span class=\"token punctuation\">.</span>imshow<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'label </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>label<span class=\"token punctuation\">}</span></span><span class=\"token string\">: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>get_label_name<span class=\"token punctuation\">(</span>label<span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">'</span></span><span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>axis<span class=\"token punctuation\">(</span><span class=\"token string\">'off'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 47.77777777777777%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAABYlAAAWJQFJUiTwAAADNUlEQVQozwEqA9X8AFVQQz6LiGA8iYpjLaqATg9FOB5BLzYROS4uETd1hUwNboNbOLayrzyCiIw9NT09D11FEC1aSiFAXUsbO2dNDRdmZWghR0RBQVdRTzx/fX0uAGdgVf6smnL/uKV8xI1tS2pkSCr/OzQe9l8/IexxgURcioJW6ryGYveWe2j/NjUyZyIZA8toVy/8eWY//29dN4SNiIWhfHhz/29rZ/aVk5PkAF5VS/88Jx7/d2VMyW5vN25kQCP/ayoh/l09IPJgcTtgiHde8p1/b/+Nblf/hndsaxgdIdJPRjj/f3Zp/3FnV4kuLSimGx8Z/zM2Lf1yZFXrAHZnVf9hVTb/ZFtC1WZoNHRiPyX/fzQd/1NFHv9ueklllaKC/3iFaP+PkIL/xsK7cVJELN10Xz3/l4l3/2deUpFmYV2vendz/5GJhP+WiID4AFtURmpUWkFrQkc8UlBPJy48MBxsXDwgZ2lYL2NsdU8oj6N8Ymh/P2d2gWhryMa4LH1SD1WDYitpdmA4blpOMjjPxcJEw7m1brSsqmeqoqFhAP/60AD///cA28a0AElFKAD/4HcA//+xAKeMTgBFTj4A///lAP//kgDb3rYApqefANafTQD//9UA48OPAHRrVQD/+dkA////AP///wDEuKcAALOPdsLovqfCyJR/lkQ4OkxZUEbGbGVavDo2N7EhJTRBZGZtsqOMdr6Xh3m/aHKGSjo0MJqvrq7BW1lWxz4+QWNHRTh4Xlg8yVBJLLxCPSerAJ9/a/+PeW3/uJCB04RsTnSef1D/n4ts/4tzUP8vLTBlbniF/cazoP+oloT/ZHCAcW1nZNyUiYb/Z2Jf/0xLS5BbVTOvT0s0/1tUOP9IQir3AJqQg/94dW//t6uey6OXgW+5nm3/sZNl/52JbPVDRlJganiO9KGbmP+IgXz/X2lxbGVcVtN3bWj/cGtl/19cWYo4NCGofn53/2xtZ/9IQi/tAK+gjuWqoJLmy72nsHl+gGChjnHprZNq3oSGgtReZm1UeX+P032Dit+AhYjlgoWHXVxVT7d1cGnke3Rs7HFqY3hBQjaRmpqV7cvIw91GQTHOUnqDylKzWK4AAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/1271a3703b5b224b0557b0d74541dd9c/37523/output_2_0.png\"\n        srcset=\"/static/1271a3703b5b224b0557b0d74541dd9c/e9ff0/output_2_0.png 180w,\n/static/1271a3703b5b224b0557b0d74541dd9c/f21e7/output_2_0.png 360w,\n/static/1271a3703b5b224b0557b0d74541dd9c/37523/output_2_0.png 720w,\n/static/1271a3703b5b224b0557b0d74541dd9c/302a4/output_2_0.png 1080w,\n/static/1271a3703b5b224b0557b0d74541dd9c/ee3fb/output_2_0.png 1144w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<h3 id=\"vgg-16-불러오기\" style=\"position:relative;\"><a href=\"#vgg-16-%EB%B6%88%EB%9F%AC%EC%98%A4%EA%B8%B0\" aria-label=\"vgg 16 불러오기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>VGG 16 불러오기</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">feature_batch <span class=\"token operator\">=</span> base_model<span class=\"token punctuation\">(</span>image_batch<span class=\"token punctuation\">)</span>\nfeature_batch<span class=\"token punctuation\">.</span>shape</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">TensorShape([32, 5, 5, 512])</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">base_model<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Model: \"vgg16\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 160, 160, 3)]     0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 160, 160, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 160, 160, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 80, 80, 64)        0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 80, 80, 128)       73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 80, 80, 128)       147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 40, 40, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 40, 40, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 40, 40, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 40, 40, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 20, 20, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 20, 20, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 20, 20, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 20, 20, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 10, 10, 512)       0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 10, 10, 512)       2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 10, 10, 512)       2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 10, 10, 512)       2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 5, 5, 512)         0         \n=================================================================\nTotal params: 14,714,688\nTrainable params: 14,714,688\nNon-trainable params: 0\n_________________________________________________________________</code></pre></div>\n<p>18층으로 구성되어 있다.</p>\n<p>해당 사이트에서 전문적인 내용을 다룬다.</p>\n<p><a href=\"https://neurohive.io/en/popular-networks/vgg16/\">자세한 내용을 보시려면</a></p>\n<p>이 모델은 해당 그림을 구현하고 있다.</p>\n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 565px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 62.22222222222222%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAABJ0AAASdAHeZh94AAABuElEQVQoz52Sz2sTQRzF9w8RwZungp68efMP8FgPgheh/4Jn/QcEoSIowYOtpb0IHryp/4ERTZO02R8m7e5kszvZndnZbPKRGdtQYirUBw+WZebNe9/v88qypNKKUSyYyClRGJBNJlRVhcVisbgSPXtpvljwZPs9h/1j0vGYc1xVbCm48+kLjzcf4R92KIoCmWUopf7PYW+YsvX0GR933jqBcRTS63bJZb4UXcX55XXwPnz9zN2Hm/w88qE2jIKAcRTR7XQIBgNSIUjTFCkldV0j85wsy1yS+Xzu/jVN42i/vdZBi437D+gdBzTFFDEcIuOY0WhEJQThYIDv+0zC0D1w1O9TCkFezTjNC6IkJc6nyCx1D3mt/V1ubtzmx/c2GOMEsyQmEQJTFGil/kQ/c2HJWdx1ob3ddwdcv3aDdvsbKMWvIKDS2tm/OKfKGFclS6U1xpi1S/Oev3jFrTv38IPIubAzWleb/OSUJI6JogiRJGit1wu+fLPH9us9pjLDmPrSqsiyJAxDR7uky2rldfsBclogROK2tnpg6XbeoLVyo/hXP72L8VYPWlgB68ZGnM1mf/VwVfA3ueuPgaIpqCoAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"VGG\" title=\"VGG\" src=\"/static/70208de06e060390432303c3020768e8/07eba/VGG.png\" srcset=\"/static/70208de06e060390432303c3020768e8/e9ff0/VGG.png 180w,\n/static/70208de06e060390432303c3020768e8/f21e7/VGG.png 360w,\n/static/70208de06e060390432303c3020768e8/07eba/VGG.png 565w\" sizes=\"(max-width: 565px) 100vw, 565px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n<p>그림의 세 번째 파란상자를 보면 fully nected 라고 되어있는데,<br>\nfully connected layer 의 오타이다. 순방향 신경망을 의미한다.</p>\n<p>18층으로 구성되어있으나 VGG-16 인 이유는<br>\nconvolution layer 와 fully connected layer 만 포함했기 때문이다.<br>\n이 두 개의 총 합은 16개이다.</p>\n<p>현재 파이썬에 불러온 모델 상에는\n마지막 maxfooling 까지만 구현되어있다.</p>\n<p>때문에 마지막 네 개의 층을 직접 도입해보기로 하자!</p>\n<h3 id=\"vgg-16-개선\" style=\"position:relative;\"><a href=\"#vgg-16-%EA%B0%9C%EC%84%A0\" aria-label=\"vgg 16 개선 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>VGG-16 개선</h3>\n<hr>\n<p>마지막 layer 까지 제공해주지 않는 이유는<br>\n우리가 입력하는 input 데이터에 따라 output 데이터도<br>\n달라지기 때문이다.</p>\n<p>마지막 layer 인 Dense layer (Fully connected layer) 에 넣어주기 위해서는 input data 를 Flatten 시킨 후 입력하여야 한다.</p>\n<p>우리 shape 는 32,5,5,512 라서 이거 한줄로 만들어줄건데</p>\n<p>아래는 Flatten의 예시이다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n\nimage <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                  <span class=\"token punctuation\">[</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nflattened_image <span class=\"token operator\">=</span> image<span class=\"token punctuation\">.</span>flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Original image:\\n\"</span><span class=\"token punctuation\">,</span> image<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Original image shape:\"</span><span class=\"token punctuation\">,</span> image<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Flattened image:\\n\"</span><span class=\"token punctuation\">,</span> flattened_image<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Flattened image shape:\"</span><span class=\"token punctuation\">,</span> flattened_image<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Original image:\n [[1 2]\n [3 4]]\nOriginal image shape: (2, 2)\n\nFlattened image:\n [1 2 3 4]\nFlattened image shape: (4,)</code></pre></div>\n<p>이처럼 차원이 존재하는 배열데이터를 한 줄로<br>\n이어준다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"></code></pre></div>\n<p>아 근데 이거 말고 더 좋은게 있데</p>\n<p>그게 바로 Global Average Pooling</p>\n<p>3차원의 tensor 가 있을때 (예를 들어, 가로, 세로, 채널)<br>\n겹겹이 쌓여있는 2차원 배열의 평균을 구한 후 하나로 축소하는 방법</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">global_average_layer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>GlobalAveragePooling2D<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># global Average 사용</span>\n\nfeature_batch_average <span class=\"token operator\">=</span> global_average_layer<span class=\"token punctuation\">(</span>feature_batch<span class=\"token punctuation\">)</span>\n<span class=\"token comment\">#만든 glo aver 를 이어 붙이기</span>\n\ndense_layer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">512</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span>\nprediction_layer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># feature_batch_averag가 dense_layer를 거친 결과가 다시 prediction_layer를 거치게 되면</span>\nprediction_batch <span class=\"token operator\">=</span> prediction_layer<span class=\"token punctuation\">(</span>dense_layer<span class=\"token punctuation\">(</span>feature_batch_average<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>  \n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>prediction_batch<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># 사용</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">(32, 2)</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">base_model<span class=\"token punctuation\">.</span>trainable <span class=\"token operator\">=</span> <span class=\"token boolean\">False</span>\n\nmodel <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n  base_model<span class=\"token punctuation\">,</span>\n  global_average_layer<span class=\"token punctuation\">,</span>\n  dense_layer<span class=\"token punctuation\">,</span>\n  prediction_layer\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n</code></pre></div>\n<p>이게 최종 모델이다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">model<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nvgg16 (Functional)           (None, 5, 5, 512)         14714688  \n_________________________________________________________________\nglobal_average_pooling2d (Gl (None, 512)               0         \n_________________________________________________________________\ndense (Dense)                (None, 512)               262656    \n_________________________________________________________________\ndense_1 (Dense)              (None, 2)                 1026      \n=================================================================\nTotal params: 14,978,370\nTrainable params: 263,682\nNon-trainable params: 14,714,688\n_________________________________________________________________</code></pre></div>\n<p>VGG16 모델 밑으로 Flatten(Global_average), Dense 레이어 2개가<br>\n들어갔다.</p>\n<p>모델의 사용은 다음 게시글에 이어서 쓰도록 한다.</p>\n<div class=\"table-of-contents\">\n<ul>\n<li>\n<p><a href=\"#%EB%AA%A9%EC%B0%A8\">목차</a></p>\n<ul>\n<li><a href=\"#vgg-16-%EB%B6%88%EB%9F%AC%EC%98%A4%EA%B8%B0\">VGG 16 불러오기</a></li>\n<li><a href=\"#vgg-16-%EA%B0%9C%EC%84%A0\">VGG-16 개선</a></li>\n</ul>\n</li>\n</ul>\n</div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"></code></pre></div>","excerpt":"딥러닝모델 VGG-16  🚶🏽‍♂️ 오늘 구현한 모델은 VGG-16 이다. 목차 데이터 불러오기 VGG-16 생성 본인의 과업에 맞게 VGG-16 개선 이 모델은 미국에서 진행한 이미지 인식 대회 ILSVRC 에서 2014년 준우승을 한 모델이다! (물론 지금은 더 좋은게 많이 있다) 하지만 계속 발전되는 Deep Learning 모델을 이해하기 위해선 기본적인 구조를 갖춘 VGG-16 의 모델 이해가 필요하다. 본 게시글에서는 VGG-16 를 Tensorflow 라이브러리에서 불러와 사용하는 방법을 제시한다. 모델 사용에는 tensorflow 실습 데이터인\n 를 사용했다.  VGG 16 불러오기 18층으로 구성되어 있다. 해당 사이트에서 전문적인 내용을 다룬다. 자세한 내용을 보시려면 이 모델은 해당 그림을 구현하고 있다. 그림의 세 번째 파란상자를 보면 fully nected 라고 되어있는데, fully connected layer 의 오타이다. 순방향 신경망을 의미한다. 18층으로 …","frontmatter":{"date":"April 21, 2022","title":"VGG16","categories":"beginner","author":"하성민","emoji":"😁"},"fields":{"slug":"/DML_AI2/"}},"next":{"id":"6f2cd6e3-4d52-59b8-8a55-7fe83eb9f0c7","html":"<h1 id=\"span-stylebackground-color-fff5b1임베딩이란span\" style=\"position:relative;\"><a href=\"#span-stylebackground-color-fff5b1%EC%9E%84%EB%B2%A0%EB%94%A9%EC%9D%B4%EB%9E%80span\" aria-label=\"span stylebackground color fff5b1임베딩이란span permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><span style='background-color: #fff5b1'>임베딩이란..?</span></h1>\n<p>단어를 표현하기 위해서는 적어도 1차원에서는 안된다 (의미가 담기기엔 작다)</p>\n<p>그래서 벡터의 <strong>특정 차원을 직접</strong> 만들어 의미를 직접 mapping 해야 하고,<br>\n이를 희소 표현 (Sparse Representation) 이라고 한다.</p>\n<hr>\n<p>반면에 그냥 차원은 일정하게 256차원 이렇게 정해놓고</p>\n<p>유사한 맥락에서 자주 나오는 단어들은 의미가 비슷하다고 판단하는 방식을\n분포 가설 (distribution hypothesis) 이라고 한다. 그리고 이 가설을 통해 분산표현 (distribution Representation) 이라고 한다.</p>\n<p>맥락이라 함은 단어 좌우에 함께 위치하는 단어를 의미한다.</p>\n<hr>\n<p>분산표현 은 희소표현 과 달리 단어 간 유사도를 구할 수 있다.</p>\n<p>embedding 레이어라는 것은</p>\n<p>이 단어의 분산표현을 구현하기 위한 레이어!!!!!!!!!!!!!!!!!!!!!!</p>\n<p>우리가 단어를 n 개 쓸거야~ k차원으로 구현해조~ 하면</p>\n<p>컴퓨터가 n x k 형태의 분산표현 사전을 만든다.</p>\n<p>이게 weihght 이 되는 거고 파라미터가 된다.</p>\n<hr>\n<p>이 임베딩을 훈련시키기 위해</p>\n<p>word2vec , FastText, Glove, ELMo 등이 있는 거임 방법들이</p>\n<hr>\n<h2 id=\"임베딩-레이어는-컴퓨터가-알아먹는-단어사전이다\" style=\"position:relative;\"><a href=\"#%EC%9E%84%EB%B2%A0%EB%94%A9-%EB%A0%88%EC%9D%B4%EC%96%B4%EB%8A%94-%EC%BB%B4%ED%93%A8%ED%84%B0%EA%B0%80-%EC%95%8C%EC%95%84%EB%A8%B9%EB%8A%94-%EB%8B%A8%EC%96%B4%EC%82%AC%EC%A0%84%EC%9D%B4%EB%8B%A4\" aria-label=\"임베딩 레이어는 컴퓨터가 알아먹는 단어사전이다 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>임베딩 레이어는 컴퓨터가 알아먹는 단어사전이다.</h2>\n<p>weight 은</p>\n<ol>\n<li>단어의 개수</li>\n<li>임베딩 사이즈</li>\n</ol>\n<p>로 정의된다.</p>\n<p>임베딩 레이어는 input 데이터를 분산 데이터로 연결해주니 LUT 룩업 테이블<br>\n이라고도 한다.</p>\n<p>그것은 원-핫 인코딩 이라고도 하는데</p>\n<hr>\n<p>원핫 인코딩 자체는 sparse 표현이지만</p>\n<p>embedding 이랑 함께 결합하여 쓰이면 유용하다.</p>\n<p>각 단어가 있으면 그걸 Linear 연산 을 통해 차원값을 만들어낸다!!!</p>\n<p>예를 들어</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 287px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 12.777777777777777%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAADCAYAAACTWi8uAAAACXBIWXMAABJ0AAASdAHeZh94AAAAjUlEQVQI142NSQ6FMAxDORDQBRWlhZYOdJAQCMH9z+Kv5AR/8RTLdpLuOA4QrTXknJlaK3s0Syl/5aSJzhiDYRjwPA/meca6rriuC33fc5lKQgh83wcpJZZlwfu+vHOeJ0IIGMcR931j2zZ0WmsuUkBaKcWaPCrs+45pmhBj5GP0NKXEuXOOodx7D2stfhmHaHQ1aP1BAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/976040ccf895245ecd1bba60556db4fd/480fd/1.png\"\n        srcset=\"/static/976040ccf895245ecd1bba60556db4fd/e9ff0/1.png 180w,\n/static/976040ccf895245ecd1bba60556db4fd/480fd/1.png 287w\"\n        sizes=\"(max-width: 287px) 100vw, 287px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>8차원의 원핫 인코딩이 있다고 해보자</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 306px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 82.77777777777777%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAARCAYAAADdRIy+AAAACXBIWXMAABJ0AAASdAHeZh94AAACA0lEQVQ4y1XUV26CQQwEYA6EkIDQS0jonSSkQB5y/1Ns9Fkyggdrl7U9nrHNXxkOh+Xl5aXMZrPy/PxcBoNBORwOxftisSjr9bo8PT2VRqNxs2az+fD7/r0iablclvP5XObzeWm32+V4PEaB9/f3uLdarVKv1yOBuSuSwO5ZtAKs2+0GGJDv7++y3++DtZP1er3wMQR+f3/L29tbKLlcLhFLUTCcTqeRMJlMwrHZbG4Br6+v0QaV+/3+rSViVqtVKNtutxHLguFoNIogTgAkfn19ldPpFGwxqtVqcSoO6PPzs3x8fMRdj8fjcYETDCEDxNCjRKYFEshUWYxE74p7d0dC3gNDlVVykuNOCrbX6zWk8gHZ7XYxQAoowTQlB8OUrG9OYBhIZNiaoAQqgN/7nJjymf5DD4GZmh5h8ff3F6yq1eptC7K3TmvFxJIegCqboP64k4YFcCDMFiiqOMth5A67U3hjCFCQKgIE/vz8BAuMyeEDrsf6hiW5ftvVXK9g6AeTZBiq5TS9YdjpdEIF2bl/LO+3HmazOZieYCjIvwGAoVDiTol/iD7zMz3UqgDM7b9fizSFJPNrSxZOMCr4tUDuw1CyR/qR0gEJdJKdXyUg4pJx5gRgTjd7k3+7/NJgA5BJysX2zo8dDD5nJavnx0HFXAdv7vy+SPeDsyrJUH+BUfoPcWxfmb0L+yUAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/0f1db7efd568945b6793d92387ce9a0e/98b92/2.png\"\n        srcset=\"/static/0f1db7efd568945b6793d92387ce9a0e/e9ff0/2.png 180w,\n/static/0f1db7efd568945b6793d92387ce9a0e/98b92/2.png 306w\"\n        sizes=\"(max-width: 306px) 100vw, 306px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>이런 가중치 를 가진 레이어가 있다고 치면\n저 위의 1 0 0 0 0 0 0 0 에 각 하나의  [ _ _ ] 가 들어가게 되고,</p>\n<p>그 결과값으로 [_ _ ] 의 형태 1 개가 나오겠지 (원핫인코딩의 행이 1이니까)</p>\n<p>그럼 원핫 인코딩이</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 311px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 90.55555555555556%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAASCAYAAABb0P4QAAAACXBIWXMAABJ0AAASdAHeZh94AAABtUlEQVQ4y33UR3LDMBBEUd1IOYvK+f73geuhqmnSsr2gEDTz0ROAwXa7Lc/ns+x2uzIej8v1ei3L5bKO0+m03G63Mp/Py/F4LJvNphwOh7Jarcp+v68+5vf7vTRNU/0H6/W6bgADXC6XFgiUNRAbIGAwc/851LwCh8NhdbIxmUwqPKfOZrPyeDwq+Hw+VyClRDiAD1sRtgr9nE6nVqH5YrGoAMCso4wjIHsqKYygChyNRjW8KKQopwIacwCAA4ApTT5fr9e3QkAnMKYQHEBeALPuFiVKEzJb+z0gg+QwhZI7ioVFGZuAwaJQFL2QhQNKYXJJGYX2gTk7iKNRRMkh217IgJQAAAKkysLhRBnAbyHz7SmkAkDIyV2UdhvbXpQC+j4auwvsAhgk5BQlwJ8K+fYUgrzf7wqUYAq0ApAwoxyk2+Bpcr4tMI3NEJBRQqQQxBrEAQmTyuylA3qNHYUSHIVAxlQ1d/tfhYBRKDRzjsbu1eNonbyB+nQA34+iUEJhGjuPQq5iwksOFefPqwfCMcnPk5Q+THGiOA2efLJJ0WpR5CIPKoeEkWeLE4h196YA5LVJW30B2hRjj0mVs9kAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/fc04f86827c4c59964a4496cc71898b4/ffa0f/3.png\"\n        srcset=\"/static/fc04f86827c4c59964a4496cc71898b4/e9ff0/3.png 180w,\n/static/fc04f86827c4c59964a4496cc71898b4/ffa0f/3.png 311w\"\n        sizes=\"(max-width: 311px) 100vw, 311px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>이렇게 10 개 있으면<br>\n10개에 대한 [_ _ ] 값이 나올 것이다. 그럼 그것이<br>\n바로 유사도를 나타내는 벡터값이 될 수 있다.</p>\n<hr>\n<p>다시 말해서 임베딩 레이어란</p>\n<ol>\n<li>단어들을 원핫 인코딩 한다.</li>\n<li>선형변환(레이어 씌우기) 를 한다.</li>\n<li>각 단어들을 {index : 선형변환값 } 으로 저장</li>\n</ol>\n<p>을 해주는 레이어 인 것!!!!!!</p>\n<p>보여주는 코드는 다음과 같다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n\nsome_words <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>constant<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">57</span><span class=\"token punctuation\">,</span> <span class=\"token number\">35</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># 3번 단어 / 57번 단어 / 35번 단어로 이루어진 한 문장입니다.</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Embedding을 진행할 문장:\"</span><span class=\"token punctuation\">,</span> some_words<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\nembedding_layer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Embedding<span class=\"token punctuation\">(</span>input_dim<span class=\"token operator\">=</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span> output_dim<span class=\"token operator\">=</span><span class=\"token number\">100</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># 총 64개의 단어를 포함한 Embedding 레이어를 선언할 것이고,</span>\n<span class=\"token comment\"># 각 단어는 100차원으로 분산 표현 할 것입니다.</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Embedding된 문장:\"</span><span class=\"token punctuation\">,</span> embedding_layer<span class=\"token punctuation\">(</span>some_words<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Embedding Layer의 Weight 형태:\"</span><span class=\"token punctuation\">,</span> embedding_layer<span class=\"token punctuation\">.</span>weights<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Embedding을 진행할 문장: (1, 3)\nEmbedding된 문장: (1, 3, 100)\nEmbedding Layer의 Weight 형태: (64, 100)</code></pre></div>\n<h4 id=\"근데-임베딩-레이어는-미분을-할수-없는-애라-어떤-연산-결과를\" style=\"position:relative;\"><a href=\"#%EA%B7%BC%EB%8D%B0-%EC%9E%84%EB%B2%A0%EB%94%A9-%EB%A0%88%EC%9D%B4%EC%96%B4%EB%8A%94-%EB%AF%B8%EB%B6%84%EC%9D%84-%ED%95%A0%EC%88%98-%EC%97%86%EB%8A%94-%EC%95%A0%EB%9D%BC-%EC%96%B4%EB%96%A4-%EC%97%B0%EC%82%B0-%EA%B2%B0%EA%B3%BC%EB%A5%BC\" aria-label=\"근데 임베딩 레이어는 미분을 할수 없는 애라 어떤 연산 결과를 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>근데 임베딩 레이어는 미분을 할수 없는 애라 어떤 연산 결과를</h4>\n<h4 id=\"임베딩-레이어에-적으면-안된다네\" style=\"position:relative;\"><a href=\"#%EC%9E%84%EB%B2%A0%EB%94%A9-%EB%A0%88%EC%9D%B4%EC%96%B4%EC%97%90-%EC%A0%81%EC%9C%BC%EB%A9%B4-%EC%95%88%EB%90%9C%EB%8B%A4%EB%84%A4\" aria-label=\"임베딩 레이어에 적으면 안된다네 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>임베딩 레이어에 적으면 안된다네</h4>\n<h2 id=\"그런-임베딩-레이어와-함께-쓰는-문장-특화-레이어\" style=\"position:relative;\"><a href=\"#%EA%B7%B8%EB%9F%B0-%EC%9E%84%EB%B2%A0%EB%94%A9-%EB%A0%88%EC%9D%B4%EC%96%B4%EC%99%80-%ED%95%A8%EA%BB%98-%EC%93%B0%EB%8A%94-%EB%AC%B8%EC%9E%A5-%ED%8A%B9%ED%99%94-%EB%A0%88%EC%9D%B4%EC%96%B4\" aria-label=\"그런 임베딩 레이어와 함께 쓰는 문장 특화 레이어 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>그런 임베딩 레이어와 함께 쓰는 문장 특화 레이어</h2>\n<h1 id=\"recurrent-layer\" style=\"position:relative;\"><a href=\"#recurrent-layer\" aria-label=\"recurrent layer permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Recurrent layer</h1>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 67.77777777777777%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAABJ0AAASdAHeZh94AAABjklEQVQ4y5VUS0+EMBjk//8Fr3rw4ElPmmjUPZio8RFX1/jCFVZ26YPS0sJCGUPVFRWMO8kktE3nm37fBK+ua7TZYEYF9i8CnI5eMZ/PHU1RoSxLFEXh1g1+3m3ooQX7ITh+pVjfHWHv7AVCCKRCgKkSEUnBOQMhFFVVLUTb8N6V7TeH2uS48WcYR+zXhU987v/psC3atf8fekon8CeXIDxcCGij8BgOEc4esSy8p+AaO8crGD0PYOvKcTK7w8HFGob+nuuhlBKUUvi+D5pMwDiBUhkk55BxjDRN3XlDb0rHGJxv4Cm8XFRJZIyTqy3c+kduqg211u6iKTJkWrp1VZbIpYTRGnmeI1Oq1cP6e7NtXqCu7PJPXjQUXwOx1iJjFLlSyw+lK9giivCwtYmXwWFv3noddmUrCQIM11bh72y7PvW57Ax287w2m2OjFOL7OyRh4FrRhy7XHmUUjHNQxsA5R5IIUM4glHJSrsiHo/Z3r8Ouyu5noDUIIYimU6QyhTEGMSEuk018Kms7Bd8AaahDWzAmluoAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/17aa24ec4bd035038c60ced1da695ffa/37523/4.png\"\n        srcset=\"/static/17aa24ec4bd035038c60ced1da695ffa/e9ff0/4.png 180w,\n/static/17aa24ec4bd035038c60ced1da695ffa/f21e7/4.png 360w,\n/static/17aa24ec4bd035038c60ced1da695ffa/37523/4.png 720w,\n/static/17aa24ec4bd035038c60ced1da695ffa/aa08e/4.png 967w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<ul>\n<li>딥러닝에서 시퀀스 데이터는 순차적인 특성을 꼭 지닌다.</li>\n</ul>\n<p>이런 순차 데이터를 처리하는 레이어가 recurrent layer</p>\n<p>RNN 은 단 하나의 Weight 를 순차적으로 업데이트 한다.</p>\n<p>다음은 RNN 의 예시이다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">sentence <span class=\"token operator\">=</span> <span class=\"token string\">\"What time is it ?\"</span>\ndic <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token string\">\"is\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"it\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"What\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"time\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"?\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">4</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"RNN에 입력할 문장:\"</span><span class=\"token punctuation\">,</span> sentence<span class=\"token punctuation\">)</span>\n\nsentence_tensor <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>constant<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span>dic<span class=\"token punctuation\">[</span>word<span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> word <span class=\"token keyword\">in</span> sentence<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Embedding을 위해 단어 매핑:\"</span><span class=\"token punctuation\">,</span> sentence_tensor<span class=\"token punctuation\">.</span>numpy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"입력 문장 데이터 형태:\"</span><span class=\"token punctuation\">,</span> sentence_tensor<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n\nembedding_layer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Embedding<span class=\"token punctuation\">(</span>input_dim<span class=\"token operator\">=</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>dic<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> output_dim<span class=\"token operator\">=</span><span class=\"token number\">100</span><span class=\"token punctuation\">)</span>\nemb_out <span class=\"token operator\">=</span> embedding_layer<span class=\"token punctuation\">(</span>sentence_tensor<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\nEmbedding 결과:\"</span><span class=\"token punctuation\">,</span> emb_out<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Embedding Layer의 Weight 형태:\"</span><span class=\"token punctuation\">,</span> embedding_layer<span class=\"token punctuation\">.</span>weights<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n\nrnn_seq_layer <span class=\"token operator\">=</span> \\\ntf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>SimpleRNN<span class=\"token punctuation\">(</span>units<span class=\"token operator\">=</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span> return_sequences<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> use_bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\nrnn_seq_out <span class=\"token operator\">=</span> rnn_seq_layer<span class=\"token punctuation\">(</span>emb_out<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\nRNN 결과 (모든 Step Output):\"</span><span class=\"token punctuation\">,</span> rnn_seq_out<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Simple RNN Layer의 Weight 형태:\"</span><span class=\"token punctuation\">,</span> rnn_seq_layer<span class=\"token punctuation\">.</span>weights<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n\nrnn_fin_layer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>SimpleRNN<span class=\"token punctuation\">(</span>units<span class=\"token operator\">=</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span> use_bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\nrnn_fin_out <span class=\"token operator\">=</span> rnn_fin_layer<span class=\"token punctuation\">(</span>emb_out<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\nRNN 결과 (최종 Step Output):\"</span><span class=\"token punctuation\">,</span> rnn_fin_out<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Simple RNN Layer의 Weight 형태:\"</span><span class=\"token punctuation\">,</span> rnn_fin_layer<span class=\"token punctuation\">.</span>weights<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">RNN에 입력할 문장: What time is it ?\nEmbedding을 위해 단어 매핑: [[2 3 0 1 4]]\n입력 문장 데이터 형태: (1, 5)\n\nEmbedding 결과: (1, 5, 100)\nEmbedding Layer의 Weight 형태: (5, 100)\n\nRNN 결과 (모든 Step Output): (1, 5, 64)\nRNN Layer의 Weight 형태: (100, 64)\n\nRNN 결과 (최종 Step Output): (1, 64)\nRNN Layer의 Weight 형태: (100, 64)</code></pre></div>\n<p>어떤 문장이 긍정인지 부정인지 나누기 위해서라면 문장을 모두 읽은 후,<br>\n최종 Step의 Output만 확인해도 판단이 가능하다.</p>\n<p>하지만 문장을 생성하는 경우라면<br>\n이전 단어를 입력으로 받아 생성된<br>\n모든 다음 단어, 즉 모든 Step에 대한 Output이 필요하다.</p>\n<p>모든 step 의 output 은 <code class=\"language-text\"> return_sequences=True</code> 로 조절 가능하다</p>\n<p>위의 결과를 보면 결국 마지막에 남는 Weight 은 (100, 64)로 똑같은 값을 가진다.</p>\n<h4 id=\"위의-코드는-아래의-lstm-사용-코드와-동일하다\" style=\"position:relative;\"><a href=\"#%EC%9C%84%EC%9D%98-%EC%BD%94%EB%93%9C%EB%8A%94-%EC%95%84%EB%9E%98%EC%9D%98-lstm-%EC%82%AC%EC%9A%A9-%EC%BD%94%EB%93%9C%EC%99%80-%EB%8F%99%EC%9D%BC%ED%95%98%EB%8B%A4\" aria-label=\"위의 코드는 아래의 lstm 사용 코드와 동일하다 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>위의 코드는 아래의 LSTM 사용 코드와 동일하다</h4>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">lstm_seq_layer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>LSTM<span class=\"token punctuation\">(</span>units<span class=\"token operator\">=</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span> return_sequences<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> use_bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\nlstm_seq_out <span class=\"token operator\">=</span> lstm_seq_layer<span class=\"token punctuation\">(</span>emb_out<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\nLSTM 결과 (모든 Step Output):\"</span><span class=\"token punctuation\">,</span> lstm_seq_out<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"LSTM Layer의 Weight 형태:\"</span><span class=\"token punctuation\">,</span> lstm_seq_layer<span class=\"token punctuation\">.</span>weights<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n\nlstm_fin_layer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>LSTM<span class=\"token punctuation\">(</span>units<span class=\"token operator\">=</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span> use_bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\nlstm_fin_out <span class=\"token operator\">=</span> lstm_fin_layer<span class=\"token punctuation\">(</span>emb_out<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\nLSTM 결과 (최종 Step Output):\"</span><span class=\"token punctuation\">,</span> lstm_fin_out<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"LSTM Layer의 Weight 형태:\"</span><span class=\"token punctuation\">,</span> lstm_fin_layer<span class=\"token punctuation\">.</span>weights<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n\nLSTM 결과 (모든 Step Output): (1, 5, 64)\nLSTM Layer의 Weight 형태: (100, 256)\nWARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n\nLSTM 결과 (최종 Step Output): (1, 64)\nLSTM Layer의 Weight 형태: (100, 256)</code></pre></div>\n<p>잠깐잠깐 LSTM 이 뭔데 갑자기 나와..?</p>\n<h1 id=\"recuurent-layer---lstm\" style=\"position:relative;\"><a href=\"#recuurent-layer---lstm\" aria-label=\"recuurent layer   lstm permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Recuurent layer - LSTM</h1>\n<p>; Long short Term memory</p>\n<p>얘도 RNN 레이어의 일종이다.</p>\n<hr>\n<p>딥러닝은 back propagation 으로 가중치의 미분을 구한 다음 업데이트한다.</p>\n<p>가중치를 업데이트 하는 RNN 의 특성상, input 이 길수록 초기 단어의 미분값이<br>\n매우 작아지거나 커지는 현상이 발생한다.</p>\n<p>이 현상을 기울기 소실 (vanishing) 혹은 포화 (exploding) 이라고 한다.</p>\n<p>LSTM 은 일반 RNN보다 4배 큰 가중치 값을 가진다.<br>\n위를 보면 RNN =(100,64) , LSTM = (100,256) 인거를 보면 된다.</p>\n<p>하지만 단순히 weight 가 4배 ‘많은’ 게 아니라 4베 ‘다양한’ 것이다.</p>\n<p>각 weight 는 <code class=\"language-text\">Gate</code> 라는 구조에 포함되어 기억할 정보, 전달할 정보를 결정한다.</p>\n<p>LSTM 에는 <code class=\"language-text\">Cell state</code> 를 통해서 긴 문장의 앞부분도 손실 없이 저장해준다.<br>\n앞서 언급한 Gate 가 Cell state 에 정보를 추가/삭제 한다.</p>\n<hr>\n<h3 id=\"자세한-설명\" style=\"position:relative;\"><a href=\"#%EC%9E%90%EC%84%B8%ED%95%9C-%EC%84%A4%EB%AA%85\" aria-label=\"자세한 설명 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>자세한 설명</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 61.11111111111111%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAABJ0AAASdAHeZh94AAABuklEQVQoz41T2U7bUBDN/38EP1DxQFWplLZIkARsbGeBFESTOC2CgEli+/ou3n3QTApqSlp6peOZsUfHZ5bbEkJgdHmFdqeL/mCI9skpbMdlv9fvwz5zMTi/wNFxGyeWBcfz+Pvt3Rx06qbB76dVliXCKEIQBFgsl0ikxCoMkSQJlFKIhYBUiuM4jhmUr7RmgqZpNtDCf5yqLre+b36p2yCkR1mUEMUjFsUMQepjkf9gPGYzBNkUD2aKNDeo6/qVoq0K5/dz2FdfcGi/g3f7Fe3BHjqj97D8fXSvP8CefoLldaC1ebOa1rPs8aKPz71dXEc2dj/u4PK+i5/pEJPIgS89ZLXivDRNGcYYSCmRZRmDYhrwC+FN8g2Du0M4/gGOh3uYRDZ86WKaePBVD6ZKOC/PcybUWvPQKCZCiglMmJcpbuQI38UpfO1ilroYCwu+cjBRDsbiDKF54B6+WfKzo8sYslpC1yFUtWLLfr2CaeKNyf5zKFVVcS/WJRgoaaDZaobR6TpWeqvC5s/FpiTqBTWVLEEbDakk+2Sp2bTYWZ4zAYkoimJjD1+V/NelrqqXqdItIn/9I7WV8AkqA5dZu1PQRAAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/7407f12fa125bfc200e45f2922c3e77a/37523/5.png\"\n        srcset=\"/static/7407f12fa125bfc200e45f2922c3e77a/e9ff0/5.png 180w,\n/static/7407f12fa125bfc200e45f2922c3e77a/f21e7/5.png 360w,\n/static/7407f12fa125bfc200e45f2922c3e77a/37523/5.png 720w,\n/static/7407f12fa125bfc200e45f2922c3e77a/5b481/5.png 846w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<h2 id=\"아래의-그림은-하나의-활성함수를-지닌-기본-rnn-이다\" style=\"position:relative;\"><a href=\"#%EC%95%84%EB%9E%98%EC%9D%98-%EA%B7%B8%EB%A6%BC%EC%9D%80-%ED%95%98%EB%82%98%EC%9D%98-%ED%99%9C%EC%84%B1%ED%95%A8%EC%88%98%EB%A5%BC-%EC%A7%80%EB%8B%8C-%EA%B8%B0%EB%B3%B8-rnn-%EC%9D%B4%EB%8B%A4\" aria-label=\"아래의 그림은 하나의 활성함수를 지닌 기본 rnn 이다 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>아래의 그림은 하나의 활성함수를 지닌 기본 RNN 이다.</h2>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 41.11111111111111%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAABJ0AAASdAHeZh94AAABnUlEQVQoz2WS226bUBBF+f9fqdQ+9SFWL0qkpsFJsImb4GADxsEQMObO4WpWVZw2abul0Uh7NGse9ki81XBqy6mBawSv3ou/W/uslA3/qiprbiYLhuOANAwDTVfTdBVVIzjSYZomRV6MpF9+01YM9ETxgaetM0JEU1C1groViLpgra9GX8qrGCNVsMs7nPqeTaFiZArbYI3mXqNH11i5ihbIqLsL5rrM9vCImd+yFYtxz8xnmMmcQxQiJWKPWd6gJ1M+z95jV3MsoWD5SzRfZu6ec7X8wMyeoEWXaM4tRrDA6VWu1mfIxgSnW2BmCvvQPwFXuYyeysjm2Qg3yimh2PHD+8631Ue+qu9YZzJ2p+CVa7zCwBBTZs4X7rxz7GaGVSh0fYtUtyV2eM9zabGvbbzCHBeS4oDlPhBUG3xhj/NdviKtQ/aJw1OyxBcWz6WJk+p4mUXf90hbL+RSNU6BHl+Ta9qOT9MHuo7/0r5QHnGD9K/P+C0pFxVBnL0BNcRJRBTHaKZNnCSkaULy0rM0Rbe2uL5PVVWnO8Pwp34CjpFXKhO+FB8AAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/efb88d54d6e244dde8264612aedfae4e/37523/6.png\"\n        srcset=\"/static/efb88d54d6e244dde8264612aedfae4e/e9ff0/6.png 180w,\n/static/efb88d54d6e244dde8264612aedfae4e/f21e7/6.png 360w,\n/static/efb88d54d6e244dde8264612aedfae4e/37523/6.png 720w,\n/static/efb88d54d6e244dde8264612aedfae4e/d2a60/6.png 807w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<h2 id=\"이와-달리-lstm-은-한-레이어의-4-가지-가중치-존재\" style=\"position:relative;\"><a href=\"#%EC%9D%B4%EC%99%80-%EB%8B%AC%EB%A6%AC-lstm-%EC%9D%80-%ED%95%9C-%EB%A0%88%EC%9D%B4%EC%96%B4%EC%9D%98-4-%EA%B0%80%EC%A7%80-%EA%B0%80%EC%A4%91%EC%B9%98-%EC%A1%B4%EC%9E%AC\" aria-label=\"이와 달리 lstm 은 한 레이어의 4 가지 가중치 존재 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>이와 달리 LSTM 은 한 레이어의 4 가지 가중치 존재</h2>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 62.77777777777778%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAABJ0AAASdAHeZh94AAACSUlEQVQ4y2WT2XLaQBBF+f8/yFOqksfk0YmzFcTEjgOOgYDNKjFCG6sEQhubOKkZFjtOV3VNT8/tO92aqxwvbOmHaNWBivf7vXJpabyid2+QZdk/+N1uR/dOsErWap+TBTK53WxVYjb26NR1FWfZE+E63dCsdA/5XcZO+nanzhvlFqv0SDiOBhhBAzfp4ERtRFDH8Fo4U4E+q2L4DwivTn/+h4ZRZuhZDJYPOHEHN+1iR21V7wezA+Fg+YixrnAnvvI4vUYkv9G9GrXOLb/0S26aHyhrX8iX3lP8fUF/3ESPy7S8n5T0zxhplV5QZuw5sD8SiuSOm+5H7s1v9JM7+n6dplGmUHnN5dUrflTe8L32juv6J0yvixaVqNkFrjsXGGmF7qKEF4yPIy/7iEVdjSzbN8NHLL9HW6tR04s07bJyMa/TtmqYroYZNBRW1lhhEzNoMvMnhw5vGzpBmB6ebH90oKE7DL3wpQjomiNaYnSAZ/8dkxPulGS15sS43qwJlwFNzUBYDlG4JAgW+L5PHEf0DIt2f8A+27Fnf5aWlJNcc/DU3El7z7V2ks7L/ElOp/UU57IjUGoxy3ZnwGGfnePtdnsmfu4nojAMnzpcBi5W/y1D+4rThXPbZhUESMrxeEy1WmU2m6nRi8Wi2ssL5/M5hUKBfD5/+IZypNHQxRx0ME2dOE5I0xRDCEbDoQJNJhNFKm2xWGDbNq7rqs43mw1CCOXnX08S2LbLdOqd29c0DcdxVBeWZalYWpIkRFGkMJJQWhzH51f+C2xa1dRk9vPYAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/2d8c740ce607bdb9f8c58d091eca361f/37523/7.png\"\n        srcset=\"/static/2d8c740ce607bdb9f8c58d091eca361f/e9ff0/7.png 180w,\n/static/2d8c740ce607bdb9f8c58d091eca361f/f21e7/7.png 360w,\n/static/2d8c740ce607bdb9f8c58d091eca361f/37523/7.png 720w,\n/static/2d8c740ce607bdb9f8c58d091eca361f/42d54/7.png 858w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>LSTM 이 가진 가장 큰 특징은 상단에 가로로 그어진 Cell ctate 이다.</p>\n<p>얘는 컨베이어 벨트처럼 작은 선형변환을 아주 조금씩 하면서 정보가 나아간다.</p>\n<p>LSTM 은 이 능력을 gate 라고 불리는 구조로 조금씩 변형시킨다.</p>\n<p>Gate = 시그모이드 와 pointwise 곱셈으로 이루어진 정보전달 방법</p>\n<p>시그모이드의 output 은 0과 1로만 이루어져 있어 보낼 정보와 막을 정보를 고른다</p>\n<p>LSTM 은 3개의 gate 값을 가지고 있다. 이 3개로 CELL STATE 에 보낼 값을 제어한다.</p>\n<p>3개의 GATE 는 다음과 같다.</p>\n<ol>\n<li>forgat gate layer</li>\n</ol>\n<p>cell state 에서 지울 값 선정</p>\n<ol start=\"2\">\n<li>input gate layer</li>\n</ol>\n<p>새로운 cell state 를 기존 cell state 에 반영할 정도를 선정</p>\n<ul>\n<li>(여기서 원래 본연의 가중치를 통해 이전 1,2번에서 정한 일 해줌)</li>\n</ul>\n<ol start=\"3\">\n<li>output gate layer</li>\n</ol>\n<p>cell state 로 필터된 output 배출</p>\n<hr>\n<p>1번 , 2번, - 번, 4번 이렇게 총 4번의 레이어 활동으로 LSTM 은 작동한다.</p>\n<hr>\n<p>이 외에도 뭐</p>\n<p>엿보기 LSTM,, GRU,,,</p>\n<p>BIRNN 등 뭐 이것저것 많다\n아래 코드는 양방향(Bidirectional) RNN 코드임</p>\n<p>양방향이라서 가중치가 두배임 앞 뒤에서 가야되니까</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n\nsentence <span class=\"token operator\">=</span> <span class=\"token string\">\"What time is it ?\"</span>\ndic <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token string\">\"is\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"it\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"What\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"time\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"?\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">4</span>\n<span class=\"token punctuation\">}</span>\n\nsentence_tensor <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>constant<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span>dic<span class=\"token punctuation\">[</span>word<span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> word <span class=\"token keyword\">in</span> sentence<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nembedding_layer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Embedding<span class=\"token punctuation\">(</span>input_dim<span class=\"token operator\">=</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>dic<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> output_dim<span class=\"token operator\">=</span><span class=\"token number\">100</span><span class=\"token punctuation\">)</span>\nemb_out <span class=\"token operator\">=</span> embedding_layer<span class=\"token punctuation\">(</span>sentence_tensor<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"입력 문장 데이터 형태:\"</span><span class=\"token punctuation\">,</span> emb_out<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n\nbi_rnn <span class=\"token operator\">=</span> \\\ntf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Bidirectional<span class=\"token punctuation\">(</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>SimpleRNN<span class=\"token punctuation\">(</span>units<span class=\"token operator\">=</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span> use_bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> return_sequences<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">)</span>\nbi_out <span class=\"token operator\">=</span> bi_rnn<span class=\"token punctuation\">(</span>emb_out<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Bidirectional RNN 결과 (최종 Step Output):\"</span><span class=\"token punctuation\">,</span> bi_out<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">입력 문장 데이터 형태: (1, 5, 100)\nBidirectional RNN 결과 (최종 Step Output): (1, 5, 128)</code></pre></div>\n<div class=\"table-of-contents\">\n<ul>\n<li>\n<p><a href=\"#%EC%9E%84%EB%B2%A0%EB%94%A9-%EB%A0%88%EC%9D%B4%EC%96%B4%EB%8A%94-%EC%BB%B4%ED%93%A8%ED%84%B0%EA%B0%80-%EC%95%8C%EC%95%84%EB%A8%B9%EB%8A%94-%EB%8B%A8%EC%96%B4%EC%82%AC%EC%A0%84%EC%9D%B4%EB%8B%A4\">임베딩 레이어는 컴퓨터가 알아먹는 단어사전이다.</a></p>\n<ul>\n<li>\n<ul>\n<li><a href=\"#%EA%B7%BC%EB%8D%B0-%EC%9E%84%EB%B2%A0%EB%94%A9-%EB%A0%88%EC%9D%B4%EC%96%B4%EB%8A%94-%EB%AF%B8%EB%B6%84%EC%9D%84-%ED%95%A0%EC%88%98-%EC%97%86%EB%8A%94-%EC%95%A0%EB%9D%BC-%EC%96%B4%EB%96%A4-%EC%97%B0%EC%82%B0-%EA%B2%B0%EA%B3%BC%EB%A5%BC\">근데 임베딩 레이어는 미분을 할수 없는 애라 어떤 연산 결과를</a></li>\n<li><a href=\"#%EC%9E%84%EB%B2%A0%EB%94%A9-%EB%A0%88%EC%9D%B4%EC%96%B4%EC%97%90-%EC%A0%81%EC%9C%BC%EB%A9%B4-%EC%95%88%EB%90%9C%EB%8B%A4%EB%84%A4\">임베딩 레이어에 적으면 안된다네</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><a href=\"#%EA%B7%B8%EB%9F%B0-%EC%9E%84%EB%B2%A0%EB%94%A9-%EB%A0%88%EC%9D%B4%EC%96%B4%EC%99%80-%ED%95%A8%EA%BB%98-%EC%93%B0%EB%8A%94-%EB%AC%B8%EC%9E%A5-%ED%8A%B9%ED%99%94-%EB%A0%88%EC%9D%B4%EC%96%B4\">그런 임베딩 레이어와 함께 쓰는 문장 특화 레이어</a></p>\n<ul>\n<li>\n<ul>\n<li><a href=\"#%EC%9C%84%EC%9D%98-%EC%BD%94%EB%93%9C%EB%8A%94-%EC%95%84%EB%9E%98%EC%9D%98-lstm-%EC%82%AC%EC%9A%A9-%EC%BD%94%EB%93%9C%EC%99%80-%EB%8F%99%EC%9D%BC%ED%95%98%EB%8B%A4\">위의 코드는 아래의 LSTM 사용 코드와 동일하다</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#%EC%9E%90%EC%84%B8%ED%95%9C-%EC%84%A4%EB%AA%85\">자세한 설명</a></p>\n</li>\n</ul>\n</li>\n<li>\n<p><a href=\"#%EC%95%84%EB%9E%98%EC%9D%98-%EA%B7%B8%EB%A6%BC%EC%9D%80-%ED%95%98%EB%82%98%EC%9D%98-%ED%99%9C%EC%84%B1%ED%95%A8%EC%88%98%EB%A5%BC-%EC%A7%80%EB%8B%8C-%EA%B8%B0%EB%B3%B8-rnn-%EC%9D%B4%EB%8B%A4\">아래의 그림은 하나의 활성함수를 지닌 기본 RNN 이다.</a></p>\n</li>\n<li>\n<p><a href=\"#%EC%9D%B4%EC%99%80-%EB%8B%AC%EB%A6%AC-lstm-%EC%9D%80-%ED%95%9C-%EB%A0%88%EC%9D%B4%EC%96%B4%EC%9D%98-4-%EA%B0%80%EC%A7%80-%EA%B0%80%EC%A4%91%EC%B9%98-%EC%A1%B4%EC%9E%AC\">이와 달리 LSTM 은 한 레이어의 4 가지 가중치 존재</a></p>\n</li>\n</ul>\n</div>","frontmatter":{"date":"April 21, 2022","title":"임베딩이란","categories":"NLP","author":"하성민","emoji":"😁"},"fields":{"slug":"/NLP_4/"}},"prev":{"id":"178ea2b3-2dfd-599d-86ad-b2669c612f60","html":"<h1 id=\"span-stylebackground-color-fff4f5인공지능-기초-️-사진-분류-프로그램-맛보기span\" style=\"position:relative;\"><a href=\"#span-stylebackground-color-fff4f5%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-%EA%B8%B0%EC%B4%88-%EF%B8%8F-%EC%82%AC%EC%A7%84-%EB%B6%84%EB%A5%98-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%A8-%EB%A7%9B%EB%B3%B4%EA%B8%B0span\" aria-label=\"span stylebackground color fff4f5인공지능 기초 ️ 사진 분류 프로그램 맛보기span permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><span style='background-color: #fff4f5'>인공지능 기초 🚶‍♂️: 사진 분류 프로그램 맛보기</span></h1>\n<h2 id=\"강아지--고양이-분류-프로그램-제작-\" style=\"position:relative;\"><a href=\"#%EA%B0%95%EC%95%84%EC%A7%80--%EA%B3%A0%EC%96%91%EC%9D%B4-%EB%B6%84%EB%A5%98-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%A8-%EC%A0%9C%EC%9E%91-\" aria-label=\"강아지  고양이 분류 프로그램 제작  permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>강아지 &#x26; 고양이 분류 프로그램 제작 !</h2>\n<h3 id=\"content\" style=\"position:relative;\"><a href=\"#content\" aria-label=\"content permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Content</h3>\n<ol>\n<li>데이터 불러오기 (Tensor Flow)</li>\n<li>데이터 전처리</li>\n<li>모델 생성 (자체 생성 모델)</li>\n<li>학습 및 평가</li>\n</ol>\n<p><strong>시작하기에 앞서, 이번 게시글은<br>\n전체적인 인공지능 적용에 대한 맥락을 설명하기 위한 글입니다.<br>\n아주 간단한 Deep Learning Layer 몇 종류를 이용했습니다.</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>__version__ <span class=\"token punctuation\">,</span> <span class=\"token string\">'이미지 분류 모델을 만들 라이브러리 tensor flow 입니다'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">2.6.0 이미지 분류 모델을 만들 라이브러리 tensor flow 입니다</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow_datasets <span class=\"token keyword\">as</span> tfds\n\ntfds<span class=\"token punctuation\">.</span>__version__</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">'4.4.0'</code></pre></div>\n<p>tensor flow 에서는 다양한 데이터셋을 이미 제공하고 있다.<br>\n강아지고양이, 음성, 이미지, 텍스트 데이터셋 보유하고 있으니 세부 내용 확인해보고 싶음 해보기</p>\n<p><a href=\"https://www.tensorflow.org/datasets/catalog/overview\">tensor flow link</a></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token punctuation\">(</span>raw_train<span class=\"token punctuation\">,</span> raw_validation<span class=\"token punctuation\">,</span> raw_test<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> metadata <span class=\"token operator\">=</span> tfds<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span>\n    <span class=\"token string\">'cats_vs_dogs'</span><span class=\"token punctuation\">,</span>\n    split<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'train[:80%]'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'train[80%:90%]'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'train[90%:]'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n    with_info<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n    as_supervised<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">\u001b[1mDownloading and preparing dataset 786.68 MiB (download: 786.68 MiB, generated: Unknown size, total: 786.68 MiB) to /aiffel/tensorflow_datasets/cats_vs_dogs/4.0.0...\u001b[0m\n\n\n\nDl Completed...: 0 url [00:00, ? url/s]\n\n\n\nDl Size...: 0 MiB [00:00, ? MiB/s]\n\n\n\nGenerating splits...:   0%|          | 0/1 [00:00&lt;?, ? splits/s]\n\n\n\nGenerating train examples...:   0%|          | 0/23262 [00:00&lt;?, ? examples/s]\n\n\nWARNING:absl:1738 images were corrupted and were skipped\n\n\n\nShuffling cats_vs_dogs-train.tfrecord...:   0%|          | 0/23262 [00:00&lt;?, ? examples/s]\n\n\n\u001b[1mDataset cats_vs_dogs downloaded and prepared to /aiffel/tensorflow_datasets/cats_vs_dogs/4.0.0. Subsequent calls will reuse this data.\u001b[0m</code></pre></div>\n<hr>\n<p>“WARNING:absl:1738 images were corrupted and were skipped”라는 경고가 나타날 수 있습니다. 우선 무시하시면 됩니다.<br>\n1738 장의 사진은 쓸 수 없다는 뜻입니다.<br>\n이런 것들은 tf 사이트 데이터셋 설명에서 확인 가능합니다</p>\n<p><img src=\"/a0b5d21d105e7623091003cd8f24e715/1.png\" alt=\"PNG\"></p>\n<p>1738이 currupted 되어있다 되어있져?<br>\n그리고 밑에 Split을 보면 23262 장의 사진이 있음을 확인 가능합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>raw_train<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>raw_validation<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>raw_test<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">&lt;PrefetchDataset shapes: ((None, None, 3), ()), types: (tf.uint8, tf.int64)>\n&lt;PrefetchDataset shapes: ((None, None, 3), ()), types: (tf.uint8, tf.int64)>\n&lt;PrefetchDataset shapes: ((None, None, 3), ()), types: (tf.uint8, tf.int64)></code></pre></div>\n<p>잘 변수로 지정되어있음을 알 수 있다.</p>\n<p>모든 데이터셋은 (image, label)의 형태를 가집니다.<br>\n((None, None, 3), ())가 이를 나타내죠.</p>\n<p>여기에서 앞에 있는 (None, None, 3)은 image의 shape를,<br>\n뒤의 ()는 정답 카테고리인 label의 shape를 의미합니다.</p>\n<p>이미지는 (height, width, channel)로 3차원 데이터이기 때문에<br>\n(None, None, 3)과 같이 나타났습니다.</p>\n<p>이때 height와 width가 None으로 나타난 이유는<br>\n모든 사진들의 크기가 제각각이기 때문입니다.<br>\n하나의 값으로 나타낼 수 없으니 None 으로 표기됩니다.</p>\n<h2 id=\"1-데이터-전처리\" style=\"position:relative;\"><a href=\"#1-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%84%EC%B2%98%EB%A6%AC\" aria-label=\"1 데이터 전처리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. 데이터 전처리</h2>\n<p>자 데이터를 불러왔으니 깔끔하게 처리해야지</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt\n<span class=\"token operator\">%</span>matplotlib inline\n<span class=\"token operator\">%</span>config InlineBackend<span class=\"token punctuation\">.</span>figure_format <span class=\"token operator\">=</span> <span class=\"token string\">'retina'</span></code></pre></div>\n<p>데이터를 어떻게 처리할지 고민하기 위해서 우리가 가져온 데이터를<br>\n스리슬쩍 들여다 보자.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">plt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\">#전체 칸바스 크기</span>\n\nget_label_name <span class=\"token operator\">=</span> metadata<span class=\"token punctuation\">.</span>features<span class=\"token punctuation\">[</span><span class=\"token string\">'label'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>int2str \n\n<span class=\"token keyword\">for</span> idx<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> label<span class=\"token punctuation\">)</span> <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>raw_train<span class=\"token punctuation\">.</span>take<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>  <span class=\"token comment\"># 10개의 데이터를 따로 가져 옵니다.</span>\n    plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">,</span> idx<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token comment\">#10개의 사진을 꺼내보겠음 판 꺼냄</span>\n    plt<span class=\"token punctuation\">.</span>imshow<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'label </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>label<span class=\"token punctuation\">}</span></span><span class=\"token string\">: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>get_label_name<span class=\"token punctuation\">(</span>label<span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">'</span></span><span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>axis<span class=\"token punctuation\">(</span><span class=\"token string\">'off'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 52.222222222222214%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAABYlAAAWJQFJUiTwAAADNUlEQVQozwEqA9X8AIqJkgD//98A////AMO5kgB3WDdNSEEedTo8GXVNPhk/ZaBgEHmIfyydqbYmQ1NdExwaDgDtw1sA+tJ9AINtQwDq4d4A////APPr5AD+//8AAFRRVXZ3b1uhs6N3pberglF4UzK5Uz8l/084If9nSSKWfZBZlauFYPGwinHwXFdTjxsNAFlZSSOsdWE0qW1YK2GQjItZeXNvqm9rZ6WMi41yAH99cNVdUET/aFQ9/5eHYphRSiCoaDIj/2kxIP9URSCKfn9YrJh7Z/+WdWD/kXdknRgcHalJQC//gXRf/3RnVLJHRUGgOjs3/1FQSf9+cmfIAJGOd6pnWETjVlA16V1YP3hmWy66djUh/2w8Hv9BQxWWmqiFsoKQcP98gWz/vr22p2VQLoNrVTHpkH5k6W1lWY1xa2eBf3t365GKhOeWiIGhAFNcVgs1RDgPP15WEGeUaARIQiCARywXuXBNJrpdVSVojaKGNXuSWVxlc0hbqbCpOUAAAAeWdT0TemUwEkY3CQz///8B////Av///wH///8BAP///wAAAAACAAAAAf/h3wAHDjcdAA4wNgAJJC8NF0YZXmtnAKaqfQCZkWkApKqsAC8ZAwDm3M0Aq6SWAD88NgAREhYsV1NCWi8sGlcqKBk3AGJdTqPPo4nb166a4bl+bHNZUEKsiXZc/3BlVf86NDKUP0hXQntxaYKWf2d5goWQQhwXFEGPjo58amhneywsMz5PTDSRWFI0/1tTMP9EPya3AGhgVcqWemj/hnRq/7mUh5CegU2sqoxe/6KLaP+FZz2MQlBmtaejoP+2nYX/fIGIplZSUaSOhID/cmxo/0xKS6xeVzN/VFE//1ZSPP9KQyypAIh9bs+akob/l5KH/761qpSrmnezvJ9t/6mQav92bmOTW2h/p4OJlP+IhYL/dXyCm15XUZtwZ2H/d3Fq/2xmYaIrKBiEdXRs/3Jya/9CPSqvAIVxX22snYuRs6eWlcO2oUyFgnqOspRn156Se9ZtdHh8e36JEoSJkCuIk5gqp6mqGFZPSRlxb2csfXZtLq2clBBBQDKBmZmT+Lm2svZJRDOf3gpvCUkCLewAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/d16b019357261570c527d6ef9965d80a/37523/output_13_0.png\"\n        srcset=\"/static/d16b019357261570c527d6ef9965d80a/e9ff0/output_13_0.png 180w,\n/static/d16b019357261570c527d6ef9965d80a/f21e7/output_13_0.png 360w,\n/static/d16b019357261570c527d6ef9965d80a/37523/output_13_0.png 720w,\n/static/d16b019357261570c527d6ef9965d80a/302a4/output_13_0.png 1080w,\n/static/d16b019357261570c527d6ef9965d80a/ee3fb/output_13_0.png 1144w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>자 봐라, 이미지 크기가 다 제각각이네?</p>\n<p>올바른 학습을 위해서는 이미지 사이즈부터 제대로 맞춰줘야 한다.</p>\n<p>format_example() 함수로 이미지를 같은 포멧으로 맞춥니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">IMG_SIZE <span class=\"token operator\">=</span> <span class=\"token number\">160</span> <span class=\"token comment\"># 리사이징할 이미지의 크기</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">format_example</span><span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> label<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    image <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>cast<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> tf<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># image=float(image)같은 타입캐스팅의  텐서플로우 버전입니다.</span>\n    image <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>image<span class=\"token operator\">/</span><span class=\"token number\">127.5</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> <span class=\"token number\">1</span> <span class=\"token comment\"># 픽셀값의 scale 수정</span>\n    image <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>image<span class=\"token punctuation\">.</span>resize<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>IMG_SIZE<span class=\"token punctuation\">,</span> IMG_SIZE<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> image<span class=\"token punctuation\">,</span> label</code></pre></div>\n<p>픽셀값의 scale 을 수정햇다는 것은 픽셀값을 정규화햇다는 말과 근사하다.<br>\n0~ 255인 픽셀값을 127.5로 나누면 0~ 2가된다. 그걸 1로 뺐으니<br>\n-1~1 사이의 값으로 변했다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">train <span class=\"token operator\">=</span> raw_train<span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span>format_example<span class=\"token punctuation\">)</span>\nvalidation <span class=\"token operator\">=</span> raw_validation<span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span>format_example<span class=\"token punctuation\">)</span>\ntest <span class=\"token operator\">=</span> raw_test<span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span>format_example<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>train<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>validation<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>test<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">&lt;MapDataset shapes: ((160, 160, 3), ()), types: (tf.float32, tf.int64)>\n&lt;MapDataset shapes: ((160, 160, 3), ()), types: (tf.float32, tf.int64)>\n&lt;MapDataset shapes: ((160, 160, 3), ()), types: (tf.float32, tf.int64)></code></pre></div>\n<p>map 메서드로 모든 raw_** 의 정보를 format_example 의 함수로 변환시켜주었다.<br>\n변환된 후의 내용물은 다음과 같다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">plt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n\nget_label_name <span class=\"token operator\">=</span> metadata<span class=\"token punctuation\">.</span>features<span class=\"token punctuation\">[</span><span class=\"token string\">'label'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>int2str\n\n<span class=\"token keyword\">for</span> idx<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> label<span class=\"token punctuation\">)</span> <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>train<span class=\"token punctuation\">.</span>take<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">,</span> idx<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n    image <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>image <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> <span class=\"token number\">2</span>\n    plt<span class=\"token punctuation\">.</span>imshow<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'label </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>label<span class=\"token punctuation\">}</span></span><span class=\"token string\">: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>get_label_name<span class=\"token punctuation\">(</span>label<span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">'</span></span><span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>axis<span class=\"token punctuation\">(</span><span class=\"token string\">'off'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 47.77777777777777%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAABYlAAAWJQFJUiTwAAADNUlEQVQozwEqA9X8AFVQQz6LiGA8iYpjLaqATg9FOB5BLzYROS4uETd1hUwNboNbOLayrzyCiIw9NT09D11FEC1aSiFAXUsbO2dNDRdmZWghR0RBQVdRTzx/fX0uAGdgVf6smnL/uKV8xI1tS2pkSCr/OzQe9l8/IexxgURcioJW6ryGYveWe2j/NjUyZyIZA8toVy/8eWY//29dN4SNiIWhfHhz/29rZ/aVk5PkAF5VS/88Jx7/d2VMyW5vN25kQCP/ayoh/l09IPJgcTtgiHde8p1/b/+Nblf/hndsaxgdIdJPRjj/f3Zp/3FnV4kuLSimGx8Z/zM2Lf1yZFXrAHZnVf9hVTb/ZFtC1WZoNHRiPyX/fzQd/1NFHv9ueklllaKC/3iFaP+PkIL/xsK7cVJELN10Xz3/l4l3/2deUpFmYV2vendz/5GJhP+WiID4AFtURmpUWkFrQkc8UlBPJy48MBxsXDwgZ2lYL2NsdU8oj6N8Ymh/P2d2gWhryMa4LH1SD1WDYitpdmA4blpOMjjPxcJEw7m1brSsqmeqoqFhAP/60AD///cA28a0AElFKAD/4HcA//+xAKeMTgBFTj4A///lAP//kgDb3rYApqefANafTQD//9UA48OPAHRrVQD/+dkA////AP///wDEuKcAALOPdsLovqfCyJR/lkQ4OkxZUEbGbGVavDo2N7EhJTRBZGZtsqOMdr6Xh3m/aHKGSjo0MJqvrq7BW1lWxz4+QWNHRTh4Xlg8yVBJLLxCPSerAJ9/a/+PeW3/uJCB04RsTnSef1D/n4ts/4tzUP8vLTBlbniF/cazoP+oloT/ZHCAcW1nZNyUiYb/Z2Jf/0xLS5BbVTOvT0s0/1tUOP9IQir3AJqQg/94dW//t6uey6OXgW+5nm3/sZNl/52JbPVDRlJganiO9KGbmP+IgXz/X2lxbGVcVtN3bWj/cGtl/19cWYo4NCGofn53/2xtZ/9IQi/tAK+gjuWqoJLmy72nsHl+gGChjnHprZNq3oSGgtReZm1UeX+P032Dit+AhYjlgoWHXVxVT7d1cGnke3Rs7HFqY3hBQjaRmpqV7cvIw91GQTHOUnqDylKzWK4AAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/1271a3703b5b224b0557b0d74541dd9c/37523/output_19_0.png\"\n        srcset=\"/static/1271a3703b5b224b0557b0d74541dd9c/e9ff0/output_19_0.png 180w,\n/static/1271a3703b5b224b0557b0d74541dd9c/f21e7/output_19_0.png 360w,\n/static/1271a3703b5b224b0557b0d74541dd9c/37523/output_19_0.png 720w,\n/static/1271a3703b5b224b0557b0d74541dd9c/302a4/output_19_0.png 1080w,\n/static/1271a3703b5b224b0557b0d74541dd9c/ee3fb/output_19_0.png 1144w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>데이터 전처리 끝~</p>\n<hr>\n<h2 id=\"2-모델-생성-및-학습\" style=\"position:relative;\"><a href=\"#2-%EB%AA%A8%EB%8D%B8-%EC%83%9D%EC%84%B1-%EB%B0%8F-%ED%95%99%EC%8A%B5\" aria-label=\"2 모델 생성 및 학습 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2 모델 생성 및 학습</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>models <span class=\"token keyword\">import</span> Sequential\n<span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers <span class=\"token keyword\">import</span> Dense<span class=\"token punctuation\">,</span> Conv2D<span class=\"token punctuation\">,</span> Flatten<span class=\"token punctuation\">,</span> MaxPooling2D\n</code></pre></div>\n<p>models 에는 모델 자체를 구축하기 위한 함수가 있고  그 안의 Sequential 함수 안에 여러가지 layer 들이 들어갈 수 있다.<br>\nlayers 에는 모델의 구성 요소인 여러가지 종류의 layer(층) 함수들을 가지고 있다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">model <span class=\"token operator\">=</span> Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n    Conv2D<span class=\"token punctuation\">(</span>filters<span class=\"token operator\">=</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token string\">'same'</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">,</span> input_shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">160</span><span class=\"token punctuation\">,</span> <span class=\"token number\">160</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    MaxPooling2D<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    Conv2D<span class=\"token punctuation\">(</span>filters<span class=\"token operator\">=</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token string\">'same'</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    MaxPooling2D<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    Conv2D<span class=\"token punctuation\">(</span>filters<span class=\"token operator\">=</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token string\">'same'</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    MaxPooling2D<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    Flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    Dense<span class=\"token punctuation\">(</span>units<span class=\"token operator\">=</span><span class=\"token number\">512</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    Dense<span class=\"token punctuation\">(</span>units<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>딥러닝에서는 <strong>레이어</strong> 라는 개념을 자세하게 공부한다.<br>\n여기서는</p>\n<ul>\n<li>Conv2D</li>\n<li>MaxPooling2D</li>\n<li>Flatten</li>\n<li>Dense</li>\n</ul>\n<p>라는 네 레이어를 사용했다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">model<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_3 (Conv2D)            (None, 160, 160, 16)      448       \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 80, 80, 16)        0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 80, 80, 32)        4640      \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 40, 40, 32)        0         \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 40, 40, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_5 (MaxPooling2 (None, 20, 20, 64)        0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 25600)             0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 512)               13107712  \n_________________________________________________________________\ndense_3 (Dense)              (None, 2)                 1026      \n=================================================================\nTotal params: 13,132,322\nTrainable params: 13,132,322\nNon-trainable params: 0\n_________________________________________________________________</code></pre></div>\n<p>모델을 만들었으니 학습시켜보자.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">learning_rate <span class=\"token operator\">=</span> <span class=\"token number\">0.0001</span>\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span>tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>optimizers<span class=\"token punctuation\">.</span>RMSprop<span class=\"token punctuation\">(</span>lr<span class=\"token operator\">=</span>learning_rate<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n              loss<span class=\"token operator\">=</span>tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>losses<span class=\"token punctuation\">.</span>sparse_categorical_crossentropy<span class=\"token punctuation\">,</span>\n              metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n</code></pre></div>\n<p>학습시키기 위해서는 Optimer , Loss, Metrics 가 필요하다.</p>\n<p>opt : 학습을 어떤 방식으로 시킬 것인지<br>\nloss : 모델이 학습해나가야 할 방향 (이 경우는 확률분포)<br>\nmetrics : [accuracy, precision, recall]</p>\n<p>아직은 실행하기 전이다. 지금은 사전 작업만 거친 상태</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">BATCH_SIZE <span class=\"token operator\">=</span> <span class=\"token number\">32</span>\nSHUFFLE_BUFFER_SIZE <span class=\"token operator\">=</span> <span class=\"token number\">1000</span>\n\ntrain_batches <span class=\"token operator\">=</span> train<span class=\"token punctuation\">.</span>shuffle<span class=\"token punctuation\">(</span>SHUFFLE_BUFFER_SIZE<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>batch<span class=\"token punctuation\">(</span>BATCH_SIZE<span class=\"token punctuation\">)</span>\nvalidation_batches <span class=\"token operator\">=</span> validation<span class=\"token punctuation\">.</span>batch<span class=\"token punctuation\">(</span>BATCH_SIZE<span class=\"token punctuation\">)</span>\ntest_batches <span class=\"token operator\">=</span> test<span class=\"token punctuation\">.</span>batch<span class=\"token punctuation\">(</span>BATCH_SIZE<span class=\"token punctuation\">)</span></code></pre></div>\n<p>이렇게 train 데이터를 통으로 넣지 않고 32개씩 끊어 넣는 이유는\n랜덤한 32개의 사진들을 묶어 여러개의 Decision Tree 를 만들어 ansamble 하기 위함</p>\n<p>train_batches 의 데이터를 확인해보자</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">for</span> image_batch<span class=\"token punctuation\">,</span> label_batch <span class=\"token keyword\">in</span> train_batches<span class=\"token punctuation\">.</span>take<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">pass</span>\n\nimage_batch<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">,</span> label_batch<span class=\"token punctuation\">.</span>shape</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">(TensorShape([32, 160, 160, 3]), TensorShape([32]))</code></pre></div>\n<p>모델 학습 전에 초기 모델의 성능을 테스트해볼까? validation data 로 모델을 평가해보자<br>\n20번의 예측을 해보고 loss 와 accuracy를 구해보자</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">validation_steps <span class=\"token operator\">=</span> <span class=\"token number\">20</span>\nloss0<span class=\"token punctuation\">,</span> accuracy0 <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>validation_batches<span class=\"token punctuation\">,</span> steps<span class=\"token operator\">=</span>validation_steps<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"initial loss: {:.2f}\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>loss0<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"initial accuracy: {:.2f}\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>accuracy0<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">10/20 [==============>...............] - ETA: 0s - loss: 0.6924 - accuracy: 0.5156\n\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\n\n\n20/20 [==============================] - 3s 32ms/step - loss: 0.6919 - accuracy: 0.5172\ninitial loss: 0.69\ninitial accuracy: 0.52\n\n\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9</code></pre></div>\n<p>보면 아무것도 하기 전에 모델 evaluate 는 걍 뭐 아무것도 모른다.\n이제 이걸 학습시켜보자</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">EPOCHS <span class=\"token operator\">=</span> <span class=\"token number\">10</span>\nhistory <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>train_batches<span class=\"token punctuation\">,</span>\n                    epochs<span class=\"token operator\">=</span>EPOCHS<span class=\"token punctuation\">,</span>\n                    validation_data<span class=\"token operator\">=</span>validation_batches<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Epoch 1/10\n170/582 [=======>......................] - ETA: 18s - loss: 0.5444 - accuracy: 0.7250\n\nCorrupt JPEG data: 99 extraneous bytes before marker 0xd9\n\n\n202/582 [=========>....................] - ETA: 17s - loss: 0.5408 - accuracy: 0.7274\n\nWarning: unknown JFIF revision number 0.00\n\n\n212/582 [=========>....................] - ETA: 16s - loss: 0.5427 - accuracy: 0.7258\n\nCorrupt JPEG data: 396 extraneous bytes before marker 0xd9\n\n\n284/582 [=============>................] - ETA: 13s - loss: 0.5408 - accuracy: 0.7272\n\nCorrupt JPEG data: 65 extraneous bytes before marker 0xd9\n\n\n492/582 [========================>.....] - ETA: 3s - loss: 0.5280 - accuracy: 0.7363\n\nCorrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n\n\n504/582 [========================>.....] - ETA: 3s - loss: 0.5277 - accuracy: 0.7360\n\nCorrupt JPEG data: 128 extraneous bytes before marker 0xd9\n\n\n516/582 [=========================>....] - ETA: 2s - loss: 0.5271 - accuracy: 0.7372\n\nCorrupt JPEG data: 239 extraneous bytes before marker 0xd9\n\n\n542/582 [==========================>...] - ETA: 1s - loss: 0.5269 - accuracy: 0.7374\n\nCorrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n\n\n550/582 [===========================>..] - ETA: 1s - loss: 0.5271 - accuracy: 0.7372\n\nCorrupt JPEG data: 228 extraneous bytes before marker 0xd9\n\n\n582/582 [==============================] - ETA: 0s - loss: 0.5259 - accuracy: 0.7389\n\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 214 extraneous bytes before marker 0xd9\n\n\n582/582 [==============================] - 29s 48ms/step - loss: 0.5259 - accuracy: 0.7389 - val_loss: 0.5102 - val_accuracy: 0.7502\nEpoch 2/10\n169/582 [=======>......................] - ETA: 18s - loss: 0.4561 - accuracy: 0.7898\n\nCorrupt JPEG data: 99 extraneous bytes before marker 0xd9\n\n\n201/582 [=========>....................] - ETA: 16s - loss: 0.4553 - accuracy: 0.7886\n\nWarning: unknown JFIF revision number 0.00\n\n\n213/582 [=========>....................] - ETA: 16s - loss: 0.4548 - accuracy: 0.7893\n\nCorrupt JPEG data: 396 extraneous bytes before marker 0xd9\n\n\n283/582 [=============>................] - ETA: 13s - loss: 0.4483 - accuracy: 0.7911\n\nCorrupt JPEG data: 65 extraneous bytes before marker 0xd9\n\n\n492/582 [========================>.....] - ETA: 3s - loss: 0.4446 - accuracy: 0.7943\n\nCorrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n\n\n506/582 [=========================>....] - ETA: 3s - loss: 0.4450 - accuracy: 0.7947\n\nCorrupt JPEG data: 128 extraneous bytes before marker 0xd9\n\n\n516/582 [=========================>....] - ETA: 2s - loss: 0.4445 - accuracy: 0.7951\n\nCorrupt JPEG data: 239 extraneous bytes before marker 0xd9\n\n\n542/582 [==========================>...] - ETA: 1s - loss: 0.4437 - accuracy: 0.7953\n\nCorrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n\n\n548/582 [===========================>..] - ETA: 1s - loss: 0.4433 - accuracy: 0.7952\n\nCorrupt JPEG data: 228 extraneous bytes before marker 0xd9\n\n\n580/582 [============================>.] - ETA: 0s - loss: 0.4425 - accuracy: 0.7956\n\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 214 extraneous bytes before marker 0xd9\n\n\n582/582 [==============================] - 28s 47ms/step - loss: 0.4422 - accuracy: 0.7958 - val_loss: 0.5503 - val_accuracy: 0.7386\nEpoch 3/10\n169/582 [=======>......................] - ETA: 18s - loss: 0.3937 - accuracy: 0.8229\n\nCorrupt JPEG data: 99 extraneous bytes before marker 0xd9\n\n\n201/582 [=========>....................] - ETA: 16s - loss: 0.3927 - accuracy: 0.8232\n\nWarning: unknown JFIF revision number 0.00\n\n\n213/582 [=========>....................] - ETA: 16s - loss: 0.3927 - accuracy: 0.8234\n\nCorrupt JPEG data: 396 extraneous bytes before marker 0xd9\n\n\n283/582 [=============>................] - ETA: 13s - loss: 0.3870 - accuracy: 0.8266\n\nCorrupt JPEG data: 65 extraneous bytes before marker 0xd9\n\n\n492/582 [========================>.....] - ETA: 3s - loss: 0.3836 - accuracy: 0.8281\n\nCorrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n\n\n506/582 [=========================>....] - ETA: 3s - loss: 0.3843 - accuracy: 0.8278\n\nCorrupt JPEG data: 128 extraneous bytes before marker 0xd9\n\n\n516/582 [=========================>....] - ETA: 2s - loss: 0.3836 - accuracy: 0.8281\n\nCorrupt JPEG data: 239 extraneous bytes before marker 0xd9\n\n\n543/582 [==========================>...] - ETA: 1s - loss: 0.3820 - accuracy: 0.8288\n\nCorrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n\n\n549/582 [===========================>..] - ETA: 1s - loss: 0.3814 - accuracy: 0.8292\n\nCorrupt JPEG data: 228 extraneous bytes before marker 0xd9\n\n\n581/582 [============================>.] - ETA: 0s - loss: 0.3800 - accuracy: 0.8289\n\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 214 extraneous bytes before marker 0xd9\n\n\n582/582 [==============================] - 28s 47ms/step - loss: 0.3799 - accuracy: 0.8290 - val_loss: 0.4954 - val_accuracy: 0.7674\nEpoch 4/10\n169/582 [=======>......................] - ETA: 18s - loss: 0.3449 - accuracy: 0.8460\n\nCorrupt JPEG data: 99 extraneous bytes before marker 0xd9\n\n\n201/582 [=========>....................] - ETA: 16s - loss: 0.3404 - accuracy: 0.8469\n\nWarning: unknown JFIF revision number 0.00\n\n\n213/582 [=========>....................] - ETA: 16s - loss: 0.3395 - accuracy: 0.8480\n\nCorrupt JPEG data: 396 extraneous bytes before marker 0xd9\n\n\n283/582 [=============>................] - ETA: 12s - loss: 0.3357 - accuracy: 0.8520\n\nCorrupt JPEG data: 65 extraneous bytes before marker 0xd9\n\n\n492/582 [========================>.....] - ETA: 3s - loss: 0.3270 - accuracy: 0.8581\n\nCorrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n\n\n506/582 [=========================>....] - ETA: 3s - loss: 0.3273 - accuracy: 0.8581\n\nCorrupt JPEG data: 128 extraneous bytes before marker 0xd9\n\n\n516/582 [=========================>....] - ETA: 2s - loss: 0.3260 - accuracy: 0.8586\n\nCorrupt JPEG data: 239 extraneous bytes before marker 0xd9\n\n\n542/582 [==========================>...] - ETA: 1s - loss: 0.3256 - accuracy: 0.8590\n\nCorrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n\n\n550/582 [===========================>..] - ETA: 1s - loss: 0.3252 - accuracy: 0.8593\n\nCorrupt JPEG data: 228 extraneous bytes before marker 0xd9\n\n\n580/582 [============================>.] - ETA: 0s - loss: 0.3244 - accuracy: 0.8602\n\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 214 extraneous bytes before marker 0xd9\n\n\n582/582 [==============================] - 28s 47ms/step - loss: 0.3244 - accuracy: 0.8602 - val_loss: 0.4858 - val_accuracy: 0.7825\nEpoch 5/10\n170/582 [=======>......................] - ETA: 18s - loss: 0.2913 - accuracy: 0.8765\n\nCorrupt JPEG data: 99 extraneous bytes before marker 0xd9\n\n\n202/582 [=========>....................] - ETA: 16s - loss: 0.2866 - accuracy: 0.8790\n\nWarning: unknown JFIF revision number 0.00\n\n\n212/582 [=========>....................] - ETA: 16s - loss: 0.2868 - accuracy: 0.8791\n\nCorrupt JPEG data: 396 extraneous bytes before marker 0xd9\n\n\n284/582 [=============>................] - ETA: 12s - loss: 0.2804 - accuracy: 0.8825\n\nCorrupt JPEG data: 65 extraneous bytes before marker 0xd9\n\n\n493/582 [========================>.....] - ETA: 3s - loss: 0.2756 - accuracy: 0.8869\n\nCorrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n\n\n505/582 [=========================>....] - ETA: 3s - loss: 0.2740 - accuracy: 0.8876\n\nCorrupt JPEG data: 128 extraneous bytes before marker 0xd9\n\n\n515/582 [=========================>....] - ETA: 2s - loss: 0.2733 - accuracy: 0.8877\n\nCorrupt JPEG data: 239 extraneous bytes before marker 0xd9\n\n\n543/582 [==========================>...] - ETA: 1s - loss: 0.2732 - accuracy: 0.8886\n\nCorrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n\n\n549/582 [===========================>..] - ETA: 1s - loss: 0.2727 - accuracy: 0.8889\n\nCorrupt JPEG data: 228 extraneous bytes before marker 0xd9\n\n\n581/582 [============================>.] - ETA: 0s - loss: 0.2720 - accuracy: 0.8886\n\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 214 extraneous bytes before marker 0xd9\n\n\n582/582 [==============================] - 28s 46ms/step - loss: 0.2721 - accuracy: 0.8885 - val_loss: 0.4933 - val_accuracy: 0.7919\nEpoch 6/10\n169/582 [=======>......................] - ETA: 18s - loss: 0.2373 - accuracy: 0.9051\n\nCorrupt JPEG data: 99 extraneous bytes before marker 0xd9\n\n\n201/582 [=========>....................] - ETA: 16s - loss: 0.2335 - accuracy: 0.9083\n\nWarning: unknown JFIF revision number 0.00\n\n\n211/582 [=========>....................] - ETA: 16s - loss: 0.2331 - accuracy: 0.9083\n\nCorrupt JPEG data: 396 extraneous bytes before marker 0xd9\n\n\n283/582 [=============>................] - ETA: 13s - loss: 0.2268 - accuracy: 0.9110\n\nCorrupt JPEG data: 65 extraneous bytes before marker 0xd9\n\n\n493/582 [========================>.....] - ETA: 3s - loss: 0.2216 - accuracy: 0.9123\n\nCorrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n\n\n505/582 [=========================>....] - ETA: 3s - loss: 0.2209 - accuracy: 0.9127\n\nCorrupt JPEG data: 128 extraneous bytes before marker 0xd9\n\n\n516/582 [=========================>....] - ETA: 2s - loss: 0.2196 - accuracy: 0.9133\n\nCorrupt JPEG data: 239 extraneous bytes before marker 0xd9\n\n\n542/582 [==========================>...] - ETA: 1s - loss: 0.2178 - accuracy: 0.9147\n\nCorrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n\n\n548/582 [===========================>..] - ETA: 1s - loss: 0.2171 - accuracy: 0.9150\n\nCorrupt JPEG data: 228 extraneous bytes before marker 0xd9\n\n\n580/582 [============================>.] - ETA: 0s - loss: 0.2163 - accuracy: 0.9152\n\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 214 extraneous bytes before marker 0xd9\n\n\n582/582 [==============================] - 29s 47ms/step - loss: 0.2162 - accuracy: 0.9153 - val_loss: 0.6168 - val_accuracy: 0.7601\nEpoch 7/10\n169/582 [=======>......................] - ETA: 18s - loss: 0.1858 - accuracy: 0.9310\n\nCorrupt JPEG data: 99 extraneous bytes before marker 0xd9\n\n\n201/582 [=========>....................] - ETA: 16s - loss: 0.1836 - accuracy: 0.9331\n\nWarning: unknown JFIF revision number 0.00\n\n\n213/582 [=========>....................] - ETA: 16s - loss: 0.1820 - accuracy: 0.9341\n\nCorrupt JPEG data: 396 extraneous bytes before marker 0xd9\n\n\n283/582 [=============>................] - ETA: 13s - loss: 0.1783 - accuracy: 0.9361\n\nCorrupt JPEG data: 65 extraneous bytes before marker 0xd9\n\n\n493/582 [========================>.....] - ETA: 3s - loss: 0.1724 - accuracy: 0.9365\n\nCorrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n\n\n505/582 [=========================>....] - ETA: 3s - loss: 0.1717 - accuracy: 0.9369\n\nCorrupt JPEG data: 128 extraneous bytes before marker 0xd9\n\n\n515/582 [=========================>....] - ETA: 2s - loss: 0.1709 - accuracy: 0.9374\n\nCorrupt JPEG data: 239 extraneous bytes before marker 0xd9\n\n\n543/582 [==========================>...] - ETA: 1s - loss: 0.1699 - accuracy: 0.9378\n\nCorrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n\n\n549/582 [===========================>..] - ETA: 1s - loss: 0.1698 - accuracy: 0.9378\n\nCorrupt JPEG data: 228 extraneous bytes before marker 0xd9\n\n\n581/582 [============================>.] - ETA: 0s - loss: 0.1678 - accuracy: 0.9382\n\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 214 extraneous bytes before marker 0xd9\n\n\n582/582 [==============================] - 28s 47ms/step - loss: 0.1677 - accuracy: 0.9382 - val_loss: 0.6220 - val_accuracy: 0.7627\nEpoch 8/10\n170/582 [=======>......................] - ETA: 18s - loss: 0.1322 - accuracy: 0.9537\n\nCorrupt JPEG data: 99 extraneous bytes before marker 0xd9\n\n\n202/582 [=========>....................] - ETA: 16s - loss: 0.1317 - accuracy: 0.9547\n\nWarning: unknown JFIF revision number 0.00\n\n\n212/582 [=========>....................] - ETA: 16s - loss: 0.1293 - accuracy: 0.9558\n\nCorrupt JPEG data: 396 extraneous bytes before marker 0xd9\n\n\n284/582 [=============>................] - ETA: 13s - loss: 0.1267 - accuracy: 0.9558\n\nCorrupt JPEG data: 65 extraneous bytes before marker 0xd9\n\n\n493/582 [========================>.....] - ETA: 3s - loss: 0.1241 - accuracy: 0.9564\n\nCorrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n\n\n505/582 [=========================>....] - ETA: 3s - loss: 0.1237 - accuracy: 0.9566\n\nCorrupt JPEG data: 128 extraneous bytes before marker 0xd9\n\n\n515/582 [=========================>....] - ETA: 2s - loss: 0.1235 - accuracy: 0.9567\n\nCorrupt JPEG data: 239 extraneous bytes before marker 0xd9\n\n\n542/582 [==========================>...] - ETA: 1s - loss: 0.1223 - accuracy: 0.9574\n\nCorrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n\n\n550/582 [===========================>..] - ETA: 1s - loss: 0.1219 - accuracy: 0.9577\n\nCorrupt JPEG data: 228 extraneous bytes before marker 0xd9\n\n\n580/582 [============================>.] - ETA: 0s - loss: 0.1210 - accuracy: 0.9580\n\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 214 extraneous bytes before marker 0xd9\n\n\n582/582 [==============================] - 28s 47ms/step - loss: 0.1209 - accuracy: 0.9581 - val_loss: 0.6818 - val_accuracy: 0.7623\nEpoch 9/10\n170/582 [=======>......................] - ETA: 18s - loss: 0.0973 - accuracy: 0.9688\n\nCorrupt JPEG data: 99 extraneous bytes before marker 0xd9\n\n\n202/582 [=========>....................] - ETA: 16s - loss: 0.0932 - accuracy: 0.9711\n\nWarning: unknown JFIF revision number 0.00\n\n\n212/582 [=========>....................] - ETA: 16s - loss: 0.0942 - accuracy: 0.9704\n\nCorrupt JPEG data: 396 extraneous bytes before marker 0xd9\n\n\n284/582 [=============>................] - ETA: 13s - loss: 0.0915 - accuracy: 0.9712\n\nCorrupt JPEG data: 65 extraneous bytes before marker 0xd9\n\n\n492/582 [========================>.....] - ETA: 3s - loss: 0.0893 - accuracy: 0.9715\n\nCorrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n\n\n506/582 [=========================>....] - ETA: 3s - loss: 0.0888 - accuracy: 0.9719\n\nCorrupt JPEG data: 128 extraneous bytes before marker 0xd9\n\n\n516/582 [=========================>....] - ETA: 2s - loss: 0.0883 - accuracy: 0.9721\n\nCorrupt JPEG data: 239 extraneous bytes before marker 0xd9\n\n\n542/582 [==========================>...] - ETA: 1s - loss: 0.0880 - accuracy: 0.9722\n\nCorrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n\n\n550/582 [===========================>..] - ETA: 1s - loss: 0.0874 - accuracy: 0.9725\n\nCorrupt JPEG data: 228 extraneous bytes before marker 0xd9\n\n\n580/582 [============================>.] - ETA: 0s - loss: 0.0875 - accuracy: 0.9725\n\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 214 extraneous bytes before marker 0xd9\n\n\n582/582 [==============================] - 28s 47ms/step - loss: 0.0874 - accuracy: 0.9725 - val_loss: 0.6500 - val_accuracy: 0.7863\nEpoch 10/10\n170/582 [=======>......................] - ETA: 18s - loss: 0.0692 - accuracy: 0.9783\n\nCorrupt JPEG data: 99 extraneous bytes before marker 0xd9\n\n\n202/582 [=========>....................] - ETA: 17s - loss: 0.0681 - accuracy: 0.9785\n\nWarning: unknown JFIF revision number 0.00\n\n\n212/582 [=========>....................] - ETA: 16s - loss: 0.0674 - accuracy: 0.9788\n\nCorrupt JPEG data: 396 extraneous bytes before marker 0xd9\n\n\n284/582 [=============>................] - ETA: 13s - loss: 0.0648 - accuracy: 0.9798\n\nCorrupt JPEG data: 65 extraneous bytes before marker 0xd9\n\n\n493/582 [========================>.....] - ETA: 3s - loss: 0.0626 - accuracy: 0.9816\n\nCorrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n\n\n505/582 [=========================>....] - ETA: 3s - loss: 0.0624 - accuracy: 0.9817\n\nCorrupt JPEG data: 128 extraneous bytes before marker 0xd9\n\n\n515/582 [=========================>....] - ETA: 2s - loss: 0.0621 - accuracy: 0.9820\n\nCorrupt JPEG data: 239 extraneous bytes before marker 0xd9\n\n\n543/582 [==========================>...] - ETA: 1s - loss: 0.0610 - accuracy: 0.9826\n\nCorrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n\n\n549/582 [===========================>..] - ETA: 1s - loss: 0.0615 - accuracy: 0.9825\n\nCorrupt JPEG data: 228 extraneous bytes before marker 0xd9\n\n\n581/582 [============================>.] - ETA: 0s - loss: 0.0614 - accuracy: 0.9827\n\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 214 extraneous bytes before marker 0xd9\n\n\n582/582 [==============================] - 29s 47ms/step - loss: 0.0613 - accuracy: 0.9827 - val_loss: 0.6904 - val_accuracy: 0.7889</code></pre></div>\n<p>다음은 학습시킨 모델에 대한 그래프 보고이다</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">for</span> image_batch<span class=\"token punctuation\">,</span> label_batch <span class=\"token keyword\">in</span> test_batches<span class=\"token punctuation\">.</span>take<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    images <span class=\"token operator\">=</span> image_batch\n    labels <span class=\"token operator\">=</span> label_batch\n    predictions <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>image_batch<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">pass</span>\n\npredictions</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">array([[9.9999702e-01, 2.9417115e-06],\n       [8.3842850e-01, 1.6157144e-01],\n       [7.4218982e-01, 2.5781012e-01],\n       [9.9970847e-01, 2.9155653e-04],\n       [9.9640131e-01, 3.5986665e-03],\n       [7.8427315e-02, 9.2157269e-01],\n       [1.8649189e-02, 9.8135078e-01],\n       [9.1933328e-01, 8.0666728e-02],\n       [9.4125561e-02, 9.0587437e-01],\n       [7.8091651e-02, 9.2190832e-01],\n       [1.1057696e-01, 8.8942307e-01],\n       [9.2630666e-01, 7.3693395e-02],\n       [9.9996006e-01, 3.9985713e-05],\n       [4.6824862e-05, 9.9995315e-01],\n       [9.9207205e-01, 7.9279514e-03],\n       [9.9890709e-01, 1.0929310e-03],\n       [3.1051392e-02, 9.6894866e-01],\n       [5.8752208e-09, 1.0000000e+00],\n       [8.3172768e-01, 1.6827232e-01],\n       [9.9952376e-01, 4.7630019e-04],\n       [7.9531687e-01, 2.0468311e-01],\n       [9.9072027e-01, 9.2797335e-03],\n       [9.9999344e-01, 6.5057743e-06],\n       [9.1565454e-01, 8.4345400e-02],\n       [9.9570221e-01, 4.2977203e-03],\n       [1.0600092e-02, 9.8939985e-01],\n       [9.9997663e-01, 2.3377719e-05],\n       [1.0107538e-01, 8.9892459e-01],\n       [9.9934202e-01, 6.5792818e-04],\n       [9.9927968e-01, 7.2028313e-04],\n       [9.9999619e-01, 3.7975171e-06],\n       [2.8957015e-01, 7.1042985e-01]], dtype=float32)</code></pre></div>\n<p>이것이 바로 우리의 정확도이다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n\npredictions <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>predictions<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\npredictions</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">array([0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n       0, 0, 0, 1, 0, 1, 0, 0, 0, 1])</code></pre></div>\n<p>이제 32장의 image 와 32개의 label , 32개의 prediction 을 얻었다\n최종 확인을 해보자</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">plt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">20</span><span class=\"token punctuation\">,</span> <span class=\"token number\">12</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">for</span> idx<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> label<span class=\"token punctuation\">,</span> prediction<span class=\"token punctuation\">)</span> <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">zip</span><span class=\"token punctuation\">(</span>images<span class=\"token punctuation\">,</span> labels<span class=\"token punctuation\">,</span> predictions<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span> <span class=\"token number\">8</span><span class=\"token punctuation\">,</span> idx<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n    image <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>image <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> <span class=\"token number\">2</span>\n    plt<span class=\"token punctuation\">.</span>imshow<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">)</span>\n    correct <span class=\"token operator\">=</span> label <span class=\"token operator\">==</span> prediction\n    title <span class=\"token operator\">=</span> <span class=\"token string-interpolation\"><span class=\"token string\">f'real: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>label<span class=\"token punctuation\">}</span></span><span class=\"token string\"> / pred :</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>prediction<span class=\"token punctuation\">}</span></span><span class=\"token string\">\\n </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>correct<span class=\"token punctuation\">}</span></span><span class=\"token string\">!'</span></span>\n    <span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> correct<span class=\"token punctuation\">:</span>\n        plt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span>title<span class=\"token punctuation\">,</span> fontdict<span class=\"token operator\">=</span><span class=\"token punctuation\">{</span><span class=\"token string\">'color'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'red'</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n        plt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span>title<span class=\"token punctuation\">,</span> fontdict<span class=\"token operator\">=</span><span class=\"token punctuation\">{</span><span class=\"token string\">'color'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'blue'</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>axis<span class=\"token punctuation\">(</span><span class=\"token string\">'off'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 59.44444444444444%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAABYlAAAWJQFJUiTwAAAD10lEQVQozwHMAzP8AHt+llZbXIBmh4aHNreNhmuldGpKSx8VSGoxKmxJOzQ3YmGAZYF9j1FwbX5CbWyGbipGQzheU1NhdG1wWFVfaTtmZ3xxZF1iOL+HhVq/dmlmAG9va/SAfnn/a2Zeq4Z5Zf+di3nUhnZo0IZ5bf9oY1yqiYJ4/6ihl+Wdnp6/mZCM/2hRSapweWH/aXp29lxjW69zcmL/cGVbqpx4VPiZcUv/AG1iVpyKhH+vLyQXbGZON7dkVECHv7mqhcnCu7iRk5FsdXFzsH94cpKijH56ZFNav1AgHWxzZk6pWWZonV1oa29oZmPGbmVSbG1PJp9GOyO2AM6tpk/WsK9co5OFMWgtH2FqMxlDfXybQUJDb2BTVFIymZmxXMbH3kkTDBQ8JChGZBwpNTOHgjxXtZE5T0E3RjUyLE9na219M////1GOjJ5dALKhm/Kqkor/q6OaqE0+Lv9eVUjSpJmXzm9oav96enmoh4eA/7e3s+OFhX+9nJmS/3NvV6iUiRH/o3kY80k/N60fIBz/UlRQqKCioPUyNzn/AOfUz6TCo5y21L2ucY15Zr+ek4eOm4aGi19UXsGLhItxY2FiuEhEQZqgoKSA4uLqyOXoxnGBcgCxZ1QBpXByXnVVVU3PNC8ucSQkJqcvMDq/AEgrKUhaMzNVZW1eLLi2yViFhYk9el5TO3FSWVm0sKktkKTHVHaInEMoFhg2NCY+XFFDQC5fWHhQlpGqSQ4QHzEAAAxfHB8uL4WGoEtaXHVVADIrI+41LSX/WF5MpZKSff9vcV3OZ1E2ykExGv+Cc16leHhq/5eflN9ORDW6Vk9B/2JcT6WQhn//hnZp7319d6lraWj/Ky0spF9jW/FtcWf/AD80Kq1MQTfAT1M9eGlqS8lZVz2Wc1tFk11MOsunjXF4gHpswpWUh6J6dWaHcnFp03h5d3jb0sm6kG1ercrKw3va4ePaSEtReFZYUK9oamHJAEA/WURdXolRZGZfKqN+aFW3qJI6VFhpOMS63FXLzdQreoGsUKqz0D8yGBM0MxwsWEtDRixXQ1tNOiA2Rmtmbi6XkLRar7LOLK5/b0ilblZRADEzMuVpbG//f3hqn76yif+dk2/HMC8pw1ROSv+trK6fbGxr/4iMjtdIOy2zTjsm/zkrGp9ubWr4TlBW535pXaS7q5H/wK+fn5iMe+m5r57/AH5sW8iBd2nfXlU+i5R9VulzWjeue3h3q2VfYeuVlqCLoKiw4Jqgp7xodnqdXmhm9CQjIYujn5XYiISDyWckMY+IWkz8lGlai4iEb8uklXrpdIjI2btfkaMAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/ec1ce97527379951f010a8c71cac03f3/37523/output_42_0.png\"\n        srcset=\"/static/ec1ce97527379951f010a8c71cac03f3/e9ff0/output_42_0.png 180w,\n/static/ec1ce97527379951f010a8c71cac03f3/f21e7/output_42_0.png 360w,\n/static/ec1ce97527379951f010a8c71cac03f3/37523/output_42_0.png 720w,\n/static/ec1ce97527379951f010a8c71cac03f3/302a4/output_42_0.png 1080w,\n/static/ec1ce97527379951f010a8c71cac03f3/07a9c/output_42_0.png 1440w,\n/static/ec1ce97527379951f010a8c71cac03f3/fbae3/output_42_0.png 2260w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">count <span class=\"token operator\">=</span> <span class=\"token number\">0</span>   <span class=\"token comment\"># 정답을 맞춘 개수</span>\n<span class=\"token keyword\">for</span> image<span class=\"token punctuation\">,</span> label<span class=\"token punctuation\">,</span> prediction <span class=\"token keyword\">in</span> <span class=\"token builtin\">zip</span><span class=\"token punctuation\">(</span>images<span class=\"token punctuation\">,</span> labels<span class=\"token punctuation\">,</span> predictions<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    correct <span class=\"token operator\">=</span> label <span class=\"token operator\">==</span> prediction\n    <span class=\"token keyword\">if</span> correct<span class=\"token punctuation\">:</span>\n        count <span class=\"token operator\">=</span> count <span class=\"token operator\">+</span> <span class=\"token number\">1</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>count <span class=\"token operator\">/</span> <span class=\"token number\">32</span> <span class=\"token operator\">*</span> <span class=\"token number\">100</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">71.875</code></pre></div>\n<p>중간에 들어가있는 딥러닝 모델이 단순한 구조이기 때문에<br>\n좋은 결과가 나오고 있지는 않다.</p>\n<p>다만 중간의 모델구조를 변경한다면 더 좋은 결과를<br>\n끌어낼 수 있을 것이다.</p>\n<div class=\"table-of-contents\">\n<ul>\n<li>\n<p><a href=\"#%EA%B0%95%EC%95%84%EC%A7%80--%EA%B3%A0%EC%96%91%EC%9D%B4-%EB%B6%84%EB%A5%98-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%A8-%EC%A0%9C%EC%9E%91-\">강아지 &#x26; 고양이 분류 프로그램 제작 !</a></p>\n<ul>\n<li><a href=\"#content\">Content</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#1-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%84%EC%B2%98%EB%A6%AC\">1. 데이터 전처리</a></p>\n</li>\n<li>\n<p><a href=\"#2-%EB%AA%A8%EB%8D%B8-%EC%83%9D%EC%84%B1-%EB%B0%8F-%ED%95%99%EC%8A%B5\">2 모델 생성 및 학습</a></p>\n</li>\n</ul>\n</div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"></code></pre></div>","frontmatter":{"date":"April 21, 2022","title":"인공지능 기초 사진 분류 프로그램 맛보기","categories":"beginner","author":"하성민","emoji":"😁"},"fields":{"slug":"/DML_AI1/"}},"site":{"siteMetadata":{"siteUrl":"https://xman227.github.io","comments":{"utterances":{"repo":""}}}}},"pageContext":{"slug":"/DML_AI2/","nextSlug":"/NLP_4/","prevSlug":"/DML_AI1/"}},
    "staticQueryHashes": ["1073350324","1956554647","2938748437"]}