{
    "componentChunkName": "component---src-templates-blog-template-js",
    "path": "/DML_AI4/",
    "result": {"data":{"cur":{"id":"485c4944-42ec-5a62-b090-39cf2a45524f","html":"<h1 id=\"span-stylebackground-color-fff5b1ë”¥ëŸ¬ë‹-ë„¤íŠ¸ì›Œí¬ë¥¼-êµ¬ì„±í•˜ëŠ”-ë ˆì´ì–´-ì´ê²Œ-ë­˜ê¹Œspan\" style=\"position:relative;\"><a href=\"#span-stylebackground-color-fff5b1%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC%EB%A5%BC-%EA%B5%AC%EC%84%B1%ED%95%98%EB%8A%94-%EB%A0%88%EC%9D%B4%EC%96%B4-%EC%9D%B4%EA%B2%8C-%EB%AD%98%EA%B9%8Cspan\" aria-label=\"span stylebackground color fff5b1ë”¥ëŸ¬ë‹ ë„¤íŠ¸ì›Œí¬ë¥¼ êµ¬ì„±í•˜ëŠ” ë ˆì´ì–´ ì´ê²Œ ë­˜ê¹Œspan permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><span style='background-color: #fff5b1'>ë”¥ëŸ¬ë‹ ë„¤íŠ¸ì›Œí¬ë¥¼ êµ¬ì„±í•˜ëŠ” ë ˆì´ì–´, ì´ê²Œ ë­˜ê¹Œ?</span></h1>\n<p>ANN : artificial NN ì¸ê³µì‹ ê²½ë§</p>\n<p>ë”¥ëŸ¬ë‹ì€ y = Wx + by=Wx+b ì—ì„œ ìµœì ì˜ <code class=\"language-text\">ë ˆì´ì–´ W(Weight)</code>ê³¼ <code class=\"language-text\">í¸í–¥ b</code>ë¥¼ ì°¾ëŠ” ê³¼ì •!</p>\n<p>ë ˆì´ì–´ ë¡œ ì´ë£¨ì–´ì ¸ ìˆëŠ”ë°.</p>\n<p>ë ˆì´ì–´ : í•˜ë‚˜ì˜ ë¬¼ì²´ê°€ ì—¬ëŸ¬ê°œì˜ ë…¼ë¦¬ì ì¸ ì„¸ë¶€ ê°ì²´ë¡œ êµ¬ì„±ë˜ì–´ ìˆëŠ” ê²½ìš°, ê·¸ ë‚´ë¶€ ê°ì²´ë¥¼ ì´ë¥´ëŠ” ë§</p>\n<p>Linear</p>\n<p>Convolutional</p>\n<p>Embedding</p>\n<p>Recurrent</p>\n<p>ì´ë ‡ê²Œ ìˆìŒ ë ˆì´ì–´ë“¤ì´.</p>\n<p>Fully Connected Layer,<br>\nFeedforward Neural Network,<br>\nMultilayer Perceptrons,<br>\nDense Layerâ€¦</p>\n<p>ë“± ë‹¤ì–‘í•œ ì´ë¦„ìœ¼ë¡œ ë¶ˆë¦¬ì§€ë§Œ ê·¸ ëª¨ë“  ê²ƒë“¤ì€ ê²°êµ­ Linear ë ˆì´ì–´ì— í•´ë‹¹</p>\n<p>ì„ í˜• ëŒ€ìˆ˜í•™ì˜ ì„ í˜•ë³€í™˜ (Linear Transform) ê³¼ ë™ì¼í•œ ê¸°ëŠ¥ì„ í•œë‹¤.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n\nbatch_size <span class=\"token operator\">=</span> <span class=\"token number\">64</span>\nboxes <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>batch_size<span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>     <span class=\"token comment\"># TensorflowëŠ” Batchë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë™ì‘í•˜ê¸°ì—,</span>\n                                         <span class=\"token comment\"># ìš°ë¦¬ëŠ” ì‚¬ê°í˜• 2ê°œ ì„¸íŠ¸ë¥¼ batch_sizeê°œë§Œí¼</span>\n                                         <span class=\"token comment\"># ë§Œë“  í›„ ì²˜ë¦¬ë¥¼ í•˜ê²Œ ë©ë‹ˆë‹¤.</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"1ë‹¨ê³„ ì—°ì‚° ì¤€ë¹„:\"</span><span class=\"token punctuation\">,</span> boxes<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n\nfirst_linear <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span>units<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> use_bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span> \n<span class=\"token comment\"># unitsì€ ì¶œë ¥ ì°¨ì› ìˆ˜ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.</span>\n<span class=\"token comment\"># Weight í–‰ë ¬ ì† ì‹¤ìˆ˜ë¥¼ ì¸ê°„ì˜ ë‡Œ ì† í•˜ë‚˜ì˜ ë‰´ëŸ° 'ìœ ë‹›' ì·¨ê¸‰ì„ í•˜ëŠ” ê±°ì£ !</span>\n\nfirst_out <span class=\"token operator\">=</span> first_linear<span class=\"token punctuation\">(</span>boxes<span class=\"token punctuation\">)</span>\nfirst_out <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>squeeze<span class=\"token punctuation\">(</span>first_out<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># (4, 1)ì„ (4,)ë¡œ ë³€í™˜í•´ì¤ë‹ˆë‹¤.</span>\n                                           <span class=\"token comment\"># (ë¶ˆí•„ìš”í•œ ì°¨ì› ì¶•ì†Œ)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"1ë‹¨ê³„ ì—°ì‚° ê²°ê³¼:\"</span><span class=\"token punctuation\">,</span> first_out<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"1ë‹¨ê³„ Linear Layerì˜ Weight í˜•íƒœ:\"</span><span class=\"token punctuation\">,</span> first_linear<span class=\"token punctuation\">.</span>weights<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\n2ë‹¨ê³„ ì—°ì‚° ì¤€ë¹„:\"</span><span class=\"token punctuation\">,</span> first_out<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n\nsecond_linear <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span>units<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> use_bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\nsecond_out <span class=\"token operator\">=</span> second_linear<span class=\"token punctuation\">(</span>first_out<span class=\"token punctuation\">)</span>\nsecond_out <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>squeeze<span class=\"token punctuation\">(</span>second_out<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"2ë‹¨ê³„ ì—°ì‚° ê²°ê³¼:\"</span><span class=\"token punctuation\">,</span> second_out<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"2ë‹¨ê³„ Linear Layerì˜ Weight í˜•íƒœ:\"</span><span class=\"token punctuation\">,</span> second_linear<span class=\"token punctuation\">.</span>weights<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">1ë‹¨ê³„ ì—°ì‚° ì¤€ë¹„: (64, 4, 2)\n1ë‹¨ê³„ ì—°ì‚° ê²°ê³¼: (64, 4)\n1ë‹¨ê³„ Linear Layerì˜ Weight í˜•íƒœ: (2, 1)\n\n2ë‹¨ê³„ ì—°ì‚° ì¤€ë¹„: (64, 4)\n2ë‹¨ê³„ ì—°ì‚° ê²°ê³¼: (64,)\n2ë‹¨ê³„ Linear Layerì˜ Weight í˜•íƒœ: (4, 1)</code></pre></div>\n<p>ì¶•ì†Œë§Œ í•˜ëŠ” ë°©ì‹</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n\nbatch_size <span class=\"token operator\">=</span> <span class=\"token number\">64</span>\nboxes <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>batch_size<span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"1ë‹¨ê³„ ì—°ì‚° ì¤€ë¹„:\"</span><span class=\"token punctuation\">,</span> boxes<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n\nfirst_linear <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span>units<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> use_bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\nfirst_out <span class=\"token operator\">=</span> first_linear<span class=\"token punctuation\">(</span>boxes<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"1ë‹¨ê³„ ì—°ì‚° ê²°ê³¼:\"</span><span class=\"token punctuation\">,</span> first_out<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"1ë‹¨ê³„ Linear Layerì˜ Weight í˜•íƒœ:\"</span><span class=\"token punctuation\">,</span> first_linear<span class=\"token punctuation\">.</span>weights<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\n2ë‹¨ê³„ ì—°ì‚° ì¤€ë¹„:\"</span><span class=\"token punctuation\">,</span> first_out<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n\nsecond_linear <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span>units<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> use_bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\nsecond_out <span class=\"token operator\">=</span> second_linear<span class=\"token punctuation\">(</span>first_out<span class=\"token punctuation\">)</span>\nsecond_out <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>squeeze<span class=\"token punctuation\">(</span>second_out<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"2ë‹¨ê³„ ì—°ì‚° ê²°ê³¼:\"</span><span class=\"token punctuation\">,</span> second_out<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"2ë‹¨ê³„ Linear Layerì˜ Weight í˜•íƒœ:\"</span><span class=\"token punctuation\">,</span> second_linear<span class=\"token punctuation\">.</span>weights<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\n3ë‹¨ê³„ ì—°ì‚° ì¤€ë¹„:\"</span><span class=\"token punctuation\">,</span> second_out<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n\nthird_linear <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span>units<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> use_bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\nthird_out <span class=\"token operator\">=</span> third_linear<span class=\"token punctuation\">(</span>second_out<span class=\"token punctuation\">)</span>\nthird_out <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>squeeze<span class=\"token punctuation\">(</span>third_out<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"3ë‹¨ê³„ ì—°ì‚° ê²°ê³¼:\"</span><span class=\"token punctuation\">,</span> third_out<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"3ë‹¨ê³„ Linear Layerì˜ Weight í˜•íƒœ:\"</span><span class=\"token punctuation\">,</span> third_linear<span class=\"token punctuation\">.</span>weights<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n\ntotal_params <span class=\"token operator\">=</span> \\\nfirst_linear<span class=\"token punctuation\">.</span>count_params<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> \\\nsecond_linear<span class=\"token punctuation\">.</span>count_params<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> \\\nthird_linear<span class=\"token punctuation\">.</span>count_params<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"ì´ Parameters:\"</span><span class=\"token punctuation\">,</span> total_params<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">1ë‹¨ê³„ ì—°ì‚° ì¤€ë¹„: (64, 4, 2)\n1ë‹¨ê³„ ì—°ì‚° ê²°ê³¼: (64, 4, 3)\n1ë‹¨ê³„ Linear Layerì˜ Weight í˜•íƒœ: (2, 3)\n\n2ë‹¨ê³„ ì—°ì‚° ì¤€ë¹„: (64, 4, 3)\n2ë‹¨ê³„ ì—°ì‚° ê²°ê³¼: (64, 4)\n2ë‹¨ê³„ Linear Layerì˜ Weight í˜•íƒœ: (3, 1)\n\n3ë‹¨ê³„ ì—°ì‚° ì¤€ë¹„: (64, 4)\n3ë‹¨ê³„ ì—°ì‚° ê²°ê³¼: (64,)\n3ë‹¨ê³„ Linear Layerì˜ Weight í˜•íƒœ: (4, 1)\nì´ Parameters: 13</code></pre></div>\n<p>í•œë²ˆ ì¦ê°€(2,3) ì‹œì¼°ë‹¤ê°€ ì¶•ì†Œì‹œí‚¤ëŠ” ë°©ì‹</p>\n<p>íŒŒë¼ë¯¸í„°ë¥¼ ëŠ˜ë¦¬ë©´ (2,3) (3,1) (4,1) = 13  <code class=\"language-text\">(use_bias=False)</code> ì¼ë•Œ\në” ë§ì€ ë°ì´í„°ë¥¼ ë³´ì¡´í•  ìˆ˜ëŠ” ì‡ê²Ÿì§€ë§Œ</p>\n<p><code class=\"language-text\">use_bias</code> í•˜ë©´ 3 + 1 + 1 í•´ì„œ ì´ 18 íŒŒë¼ë¯¸í„°ê°€ ëœë‹¤</p>\n<p>ë„ˆë¬´ ë§ì€ íŒŒë¼ë¯¸í„°ëŠ” ê³¼ì í•©ì„ ì´ˆë˜í•œë‹¤.</p>\n<h3 id=\"convlutional-ë ˆì´ì–´\" style=\"position:relative;\"><a href=\"#convlutional-%EB%A0%88%EC%9D%B4%EC%96%B4\" aria-label=\"convlutional ë ˆì´ì–´ permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>convlutional ë ˆì´ì–´</h3>\n<p>í•„í„°(ì»¤ë„)ë¥¼ ë§Œë“¤ì–´ì„œ ê·¸ í•„í„°ë§Œí¼ì˜ í”½ì…€ê°’ë“¤ì„ ë‹¤ ê³±í•œë‹¤ìŒ ë”í•´ ë‹¤ìŒ ë ˆì´ì–´ë¡œ ì¶œë ¥</p>\n<p><img src=\"attachment:image.png\" alt=\"image.png\"></p>\n<p>ë³´í†µ 3x3 ì‚¬ì´ì¦ˆ ë“±ì˜ ì»¤ë„ì„ ë§Œë“ ë‹¤</p>\n<p>ì»¤ë„ì˜ ì´ë™ ì‚¬ì´ì¦ˆë¥¼ stride ë¼ê³  ë¶€ë¥¸ë‹¤</p>\n<p>convolutional ë ˆì´ì–´ëŠ” í•„í„° ê°œìˆ˜ xí•„í„° ê°€ë¡œ x í•„í„° ì„¸ë¡œ ë¡œ ì´ë£¨ì–´ì§„ weight ê°’ì„ ê°€ì§„ë‹¤</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n\nbatch_size <span class=\"token operator\">=</span> <span class=\"token number\">64</span>\npic <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>batch_size<span class=\"token punctuation\">,</span> <span class=\"token number\">1920</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1080</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"ì…ë ¥ ì´ë¯¸ì§€ ë°ì´í„°:\"</span><span class=\"token punctuation\">,</span> pic<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\nconv_layer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span>filters<span class=\"token operator\">=</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span>\n                                    kernel_size<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                                    strides<span class=\"token operator\">=</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span>\n                                    use_bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\nconv_out <span class=\"token operator\">=</span> conv_layer<span class=\"token punctuation\">(</span>pic<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\nConvolution ê²°ê³¼:\"</span><span class=\"token punctuation\">,</span> conv_out<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Convolution Layerì˜ Parameter ìˆ˜:\"</span><span class=\"token punctuation\">,</span> conv_layer<span class=\"token punctuation\">.</span>count_params<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nflatten_out <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>conv_out<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\n1ì°¨ì›ìœ¼ë¡œ í¼ì¹œ ë°ì´í„°:\"</span><span class=\"token punctuation\">,</span> flatten_out<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n\nlinear_layer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span>units<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> use_bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\nlinear_out <span class=\"token operator\">=</span> linear_layer<span class=\"token punctuation\">(</span>flatten_out<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\nLinear ê²°ê³¼:\"</span><span class=\"token punctuation\">,</span> linear_out<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Linear Layerì˜ Parameter ìˆ˜:\"</span><span class=\"token punctuation\">,</span> linear_layer<span class=\"token punctuation\">.</span>count_params<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">ì…ë ¥ ì´ë¯¸ì§€ ë°ì´í„°: (64, 1920, 1080, 3)\n\nConvolution ê²°ê³¼: (64, 384, 216, 16)\nConvolution Layerì˜ Parameter ìˆ˜: 1200\n\n1ì°¨ì›ìœ¼ë¡œ í¼ì¹œ ë°ì´í„°: (64, 1327104)\n\nLinear ê²°ê³¼: (64, 1)\nLinear Layerì˜ Parameter ìˆ˜: 1327104</code></pre></div>\n<h2 id=\"pooling-layer\" style=\"position:relative;\"><a href=\"#pooling-layer\" aria-label=\"pooling layer permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>pooling layer</h2>\n<p>ì»¨ë³¼ë¥˜ì…”ë„ ë ˆì´ì–´ëŠ” í•„í„° ì‚¬ì´ì¦ˆì— ì˜ì¡´í•˜ê²Œ ëœë‹¤.</p>\n<p>ê·¼ë° í•„í„°ì‚¬ì´ì¦ˆë¥¼ í‚¤ìš°ë‹¤ë³´ë©´ ê²°êµ­ ì»¨ë³¼ë£¨ì…”ë„ ë ˆì´ì–´ì˜ ì •ì²´ì„±ì´ ì•½í•´ì§€ëŠ”ë°</p>\n<p>ê·¸ë˜ì„œ í•„í„°ì‚¬ì´ì¦ˆê°€ ì•„ë‹Œ receptive Field (ìˆ˜ìš© ì˜ì—­)ì„ í‚¤ì›Œì•¼ í•œë‹¤.</p>\n<p>ìˆ˜ìš© ì˜ì—­:  ì¶œë ¥ ë ˆì´ì–´ì˜ ë‰´ëŸ° í•˜ë‚˜ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ì…ë ¥ ë‰´ëŸ°ë“¤ì˜ ê³µê°„ í¬ê¸°\n(ê·¸ëŸ¼ ì»¨ë³¼ë¥˜ì…”ë„ì—ì„œëŠ” ì»¤ë„ì‚¬ì´ì¦ˆì™€ ê°™ë‹¤.)</p>\n<p>ë§¥ìŠ¤í’€ë§ë„ ë§¥ìŠ¤í’€ë§ ì‚¬ì´ì¦ˆê°€ ë‚˜ì™€ì•¼ ë˜ëŠ” ê±° ì•„ë‹Œê°€?</p>\n<p>ë§¥ìŠ¤í’€ë§ì„ í•˜ë©´ ìˆ˜ìš©ì˜ì—­ì˜ í¬ê¸°ëŠ” í‚¤ìš¸ ìˆ˜ ì‡ì§€ë§Œ,<br>\níŒŒë¼ë¯¸í„° ì‚¬ì´ì¦ˆëŠ” ëŠ˜ì§€ ì•ŠëŠ”ë‹¤.</p>\n<p>ì¥ì </p>\n<ol>\n<li>\n<p>translate invariance</p>\n</li>\n<li>\n<p>Non-linear í•¨ìˆ˜ì™€ ë™ì¼í•œ íŠ¹ì§• ì¶”ì¶œ íš¨ê³¼</p>\n</li>\n<li>\n<p>ìˆ˜ìš© ì˜ì—­ (receptive Field) ê·¹ëŒ€í™” íš¨ê³¼</p>\n</li>\n</ol>\n<div class=\"table-of-contents\">\n<ul>\n<li>\n<ul>\n<li><a href=\"#convlutional-%EB%A0%88%EC%9D%B4%EC%96%B4\">convlutional ë ˆì´ì–´</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#pooling-layer\">pooling layer</a></p>\n</li>\n</ul>\n</div>","excerpt":"ë”¥ëŸ¬ë‹ ë„¤íŠ¸ì›Œí¬ë¥¼ êµ¬ì„±í•˜ëŠ” ë ˆì´ì–´, ì´ê²Œ ë­˜ê¹Œ? ANN : artificial NN ì¸ê³µì‹ ê²½ë§ ë”¥ëŸ¬ë‹ì€ y = Wx + by=Wx+b ì—ì„œ ìµœì ì˜ ê³¼ ë¥¼ ì°¾ëŠ” ê³¼ì •! ë ˆì´ì–´ ë¡œ ì´ë£¨ì–´ì ¸ ìˆëŠ”ë°. ë ˆì´ì–´ : í•˜ë‚˜ì˜ ë¬¼ì²´ê°€ ì—¬ëŸ¬ê°œì˜ ë…¼ë¦¬ì ì¸ ì„¸ë¶€ ê°ì²´ë¡œ êµ¬ì„±ë˜ì–´ ìˆëŠ” ê²½ìš°, ê·¸ ë‚´ë¶€ ê°ì²´ë¥¼ ì´ë¥´ëŠ” ë§ Linear Convolutional Embedding Recurrent ì´ë ‡ê²Œ ìˆìŒ ë ˆì´ì–´ë“¤ì´. Fully Connected Layer, Feedforward Neural Network, Multilayer Perceptrons, Dense Layerâ€¦ ë“± ë‹¤ì–‘í•œ ì´ë¦„ìœ¼ë¡œ ë¶ˆë¦¬ì§€ë§Œ ê·¸ ëª¨ë“  ê²ƒë“¤ì€ ê²°êµ­ Linear ë ˆì´ì–´ì— í•´ë‹¹ ì„ í˜• ëŒ€ìˆ˜í•™ì˜ ì„ í˜•ë³€í™˜ (Linear Transform) ê³¼ ë™ì¼í•œ ê¸°ëŠ¥ì„ í•œë‹¤. ì¶•ì†Œë§Œ í•˜ëŠ” ë°©ì‹ í•œë²ˆ ì¦ê°€(2,3) ì‹œì¼°ë‹¤ê°€ ì¶•ì†Œì‹œí‚¤ëŠ” ë°©ì‹ íŒŒë¼ë¯¸í„°ë¥¼ ëŠ˜ë¦¬ë©´ (2,3) (3,1) (4,1) = 13   ì¼ë•Œ\në” ë§ì€ ë°ì´í„°ë¥¼ ë³´ì¡´í•  ìˆ˜ëŠ” ì‡ê²Ÿì§€ë§Œ  í•˜ë©´ 3â€¦","frontmatter":{"date":"April 21, 2022","title":"ì¸ê³µì§€ëŠ¥ ê¸°ì´ˆ ë ˆì´ì–´ ì´í•´í•˜ê¸°","categories":"STUDY","author":"í•˜ì„±ë¯¼","emoji":"ğŸ˜"},"fields":{"slug":"/DML_AI4/"}},"next":{"id":"83c7066c-e6f4-5149-8931-eec9799d05b9","html":"<h1 id=\"span-stylebackground-color-fff5b1ë¯¸ë¦¬-í•™ìŠµëœ-ë”¥ëŸ¬ë‹-pre-trained--deep-learning-ì‚¬ìš©ì²˜span\" style=\"position:relative;\"><a href=\"#span-stylebackground-color-fff5b1%EB%AF%B8%EB%A6%AC-%ED%95%99%EC%8A%B5%EB%90%9C-%EB%94%A5%EB%9F%AC%EB%8B%9D-pre-trained--deep-learning-%EC%82%AC%EC%9A%A9%EC%B2%98span\" aria-label=\"span stylebackground color fff5b1ë¯¸ë¦¬ í•™ìŠµëœ ë”¥ëŸ¬ë‹ pre trained  deep learning ì‚¬ìš©ì²˜span permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><span style='background-color: #fff5b1'>ë¯¸ë¦¬ í•™ìŠµëœ ë”¥ëŸ¬ë‹ Pre-trained  Deep Learning ì‚¬ìš©ì²˜</span></h1>\n<p>ìš”ì¦˜ í•«í•œ ë§Œí¼ ë‹¤ì–‘í•œ ì—°êµ¬ì™€ ê¸°ë²•ì´ ë°œì „ë˜ê³  ìˆë‹¤</p>\n<p>DNN\në”¥ ë‰´ëŸ´ ë„¤íŠ¸ì›Œí¬</p>\n<p>ë” ì¢‹ì€ ë”¥ ë„¤íŠ¸ì›Œí¬ë¥¼ ë§Œë“¤ê¸° ìœ„í•´ ë§ì€ ì¢…ë¥˜ì˜ ë„¤íŠ¸ì›Œí¬ê°€ ìƒê²¼ë‹¤.<br>\nê·¸ ì¤‘ ëª‡ ê°€ì§€ ì‚¬ì „í•™ìŠµëœ pre-trained Network ëŠ”\nTF ë‚˜ Pytorch ë“±ì˜ í”„ë ˆì„ì›Œí¬ ì°¨ì›ìœ¼ë¡œ ì§€ì›í•˜ê³  ìˆë‹¤.</p>\n<hr>\n<p>ìš°ë¦¬ëŠ” ê·¸ ë§ì€ ëª¨ë¸ë“¤ì„ í›‘ì–´ë³¼ ê±´ë°</p>\n<p>íŠ¹íˆ ResNet ê³¼ VGG ë¥¼ ì¤‘ì‹¬ì ìœ¼ë¡œ ë³¼ ê±°ë‹¤</p>\n<h2 id=\"image-net\" style=\"position:relative;\"><a href=\"#image-net\" aria-label=\"image net permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Image Net</h2>\n<p>2010ë…„ ILSVRC 2010 ì„ ì‹œì‘ìœ¼ë¡œ ëŒ€ëŸ‰ì˜ ì´ë¯¸ì§€ ë°ì´í„°ì…‹<br>\në§Œ ê°œê°€ ë„˜ëŠ” ì¹´í…Œê³ ë¦¬ì— 100ë§Œ ì¥ ê·œëª¨ì˜ ì‚¬ì§„ì„ ê°€ì§€ê³  ìˆë‹¤.</p>\n<p>ì´ê±¸ í†µí•´ ë§ì€ ì‚¬ëŒë“¤ì´ ì´ë¯¸ì§€ ë¶„ë¥˜ ì½˜í…ŒìŠ¤íŠ¸ì— ë‚˜ê°€ ë„¤íŠ¸ì›Œí¬ë¥¼ í˜•ì„±í–ˆë‹¤.</p>\n<ol>\n<li>AlexNet</li>\n</ol>\n<p>2011ë…„ ì´ë¯¸ì§€ë„· ì±Œë¦°ì§€ 1ë“± ëª¨ë¸. ë…¼ë¬¸ì €ìì˜ ì´ë¦„ì„ ë•„ë‹¤.<br>\nCNN êµ¬ì¡°ì˜ í™•ì¥íŒì´ë‹¤.<br>\n2ê°œì˜ GPU ë¡œ ë³‘ë ¬ì—°ì‚°ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ ë³‘ë ¬êµ¬ì¡°ë¡œ ì„¤ê³„ë˜ì—ˆë‹¤.</p>\n<p><a href=\"https://bskyvision.com/421\">ìì„¸í•œ ë‚´ìš©</a></p>\n<ul>\n<li>LeNet</li>\n</ul>\n<p>ì´ê±´ ì´ë•Œ ìƒê¸´ê±´ ì•„ë‹ˆì§€ë§Œ 1998ë…„ì— ê°œë°œí•œ CNN ì•Œê³ ë¦¬ì¦˜ ì´ë¦„ì´ë‹¤.</p>\n<p>LeNet-5ëŠ” ì¸í’‹, 3ê°œì˜ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´(C1, C3, C5), 2ê°œì˜ ì„œë¸Œìƒ˜í”Œë§ ë ˆì´ì–´(S2, S4), 1ì¸µì˜ full-connected ë ˆì´ì–´(F6), ì•„ì›ƒí’‹ ë ˆì´ì–´ë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤. ì°¸ê³ ë¡œ C1ë¶€í„° F6ê¹Œì§€ í™œì„±í™” í•¨ìˆ˜ë¡œ tanhì„ ì‚¬ìš©í•œë‹¤.</p>\n<ol start=\"2\">\n<li>VGG (VGG16, VGG19 ë“±)</li>\n</ol>\n<p>2014ë…„ ì´ë¯¸ì§€ë„· ì±Œë¦°ì§€ ì¤€ìš°ìŠ¹ ëª¨ë¸<br>\nì´ë¦„ì²˜ëŸ¼ 16, 19ê°œì˜ ì¸µì„ ì´ë£¸.<br>\në³‘ë ¬êµ¬ì¡°ê°€ ì•„ë‹ˆë‹¤.</p>\n<hr>\n<p>ê·¼ë° ì¶”ì„¸ë¥¼ ë³´ë©´ ê³„ì† ì¸µì´ ê¹Šì–´ì§€ëŠ”ê²Œ<br>\nì¢‹ë‹¤ê³  í•˜ëŠ”ë°,  ì´ê²Œ ë˜</p>\n<p>ë§‰ ì¸µì„í‚¤ìš´ë‹¤ê³ ë§Œ ì¢‹ì€ê²Œ ì•„ë‹ˆë‹¤.</p>\n<p>ë¶€ì‘ìš©ì´ ìˆë‹¤.</p>\n<ul>\n<li>vanishing gradient (ë˜ëŠ” Exoloding Gradient)</li>\n</ul>\n<p>ì™€ ê·¼ë° ì´ê±¸ í•´ê²°í•œ ê²ƒì´</p>\n<ol start=\"3\">\n<li>ResNet</li>\n</ol>\n<p>2015ë…„ ì´ë¯¸ì§€ë„· ì±Œë¦°ì§€ ìš°ìŠ¹ ëª¨ë¸\nSkip connection ì´ë¼ëŠ” êµ¬ì¡°ë¡œ í•´ê²°\n: ë ˆì´ì–´ì˜ ì…ë ¥ì„ ë‹¤ë¥¸ ê³³ì— ì´ì–´ì„œ Gradient ê°€ ê¹Šê²Œ ì´ì–´ì§€ë„ë¡ ë§Œë“œëŠ” êµ¬ì¡°</p>\n<hr>\n<h2 id=\"ì´ì œëŠ”-ì‹¤ìŠµìœ¼ë¡œ-ë§Œë“¤ì–´ë³´ì\" style=\"position:relative;\"><a href=\"#%EC%9D%B4%EC%A0%9C%EB%8A%94-%EC%8B%A4%EC%8A%B5%EC%9C%BC%EB%A1%9C-%EB%A7%8C%EB%93%A4%EC%96%B4%EB%B3%B4%EC%9E%90\" aria-label=\"ì´ì œëŠ” ì‹¤ìŠµìœ¼ë¡œ ë§Œë“¤ì–´ë³´ì permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>ì´ì œëŠ” ì‹¤ìŠµìœ¼ë¡œ ë§Œë“¤ì–´ë³´ì</h2>\n<p><a href=\"https://github.com/keras-team/keras-applications/tree/master/keras_applications\">https://github.com/keras-team/keras-applications/tree/master/keras_applications</a></p>\n<p>ê·¸ëƒ¥ ì—¬ê¸°ì— ë‹¤ ë‹´ê²¨ìˆë‹¤ê³  ë³´ë©´ ëœë‹¤</p>\n<p>keras ì—ì„œ ì§€ì›í•˜ëŠ” pre-trained model ì´ ë‹´ê²¨ìˆë‹¤.\nêµ¿êµ¿ í‚¹ì™•ì§± êµ¿êµ¿ ğŸš¶â€â™‚ï¸ğŸ§“ğŸ‘©ğŸ‘¨</p>\n<div class=\"table-of-contents\">\n<ul>\n<li><a href=\"#image-net\">Image Net</a></li>\n<li><a href=\"#%EC%9D%B4%EC%A0%9C%EB%8A%94-%EC%8B%A4%EC%8A%B5%EC%9C%BC%EB%A1%9C-%EB%A7%8C%EB%93%A4%EC%96%B4%EB%B3%B4%EC%9E%90\">ì´ì œëŠ” ì‹¤ìŠµìœ¼ë¡œ ë§Œë“¤ì–´ë³´ì</a></li>\n</ul>\n</div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"></code></pre></div>","frontmatter":{"date":"April 21, 2022","title":"pre-trained ëª¨ë¸ ê°€ì ¸ì˜¤ëŠ” ë§í¬","categories":"STUDY","author":"í•˜ì„±ë¯¼","emoji":"ğŸ˜"},"fields":{"slug":"/DML_keras3/"}},"prev":{"id":"c23336a2-9dde-5998-a74d-897defbfb439","html":"<h1 id=\"span-stylebackground-color-fff5b1ì •ê·œí™”ë¼ê³ -ë‹¤ê°™ì€-ì •ê·œí™”ê°€-ì•„ë‹ˆë‹¤span\" style=\"position:relative;\"><a href=\"#span-stylebackground-color-fff5b1%EC%A0%95%EA%B7%9C%ED%99%94%EB%9D%BC%EA%B3%A0-%EB%8B%A4%EA%B0%99%EC%9D%80-%EC%A0%95%EA%B7%9C%ED%99%94%EA%B0%80-%EC%95%84%EB%8B%88%EB%8B%A4span\" aria-label=\"span stylebackground color fff5b1ì •ê·œí™”ë¼ê³  ë‹¤ê°™ì€ ì •ê·œí™”ê°€ ì•„ë‹ˆë‹¤span permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><span style='background-color: #fff5b1'>ì •ê·œí™”(ë¼ê³  ë‹¤ê°™ì€ ì •ê·œí™”ê°€ ì•„ë‹ˆë‹¤)</span></h1>\n<p>Regularization : ì •ì¹™í™”ë¼ê³  ë¶ˆë¦¬ë©°, ì˜¤ë²„í”¼íŒ…ì„ í•´ê²°í•˜ê¸° ìœ„í•œ ë°©ë²• ì¤‘ì˜ í•˜ë‚˜</p>\n<p>Regularization ê¸°ë²•ë“¤ì€ ëª¨ë¸ì´ train setì˜ ì •ë‹µì„ ë§íˆì§€ ëª»í•˜ë„ë¡ ì˜¤ë²„í”¼íŒ…ì„ ë°©í•´(train lossê°€ ì¦ê°€) í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤. ê·¸ë˜ì„œ train lossëŠ” ì•½ê°„ ì¦ê°€í•˜ì§€ë§Œ ê²°ê³¼ì ìœ¼ë¡œ, validation lossë‚˜ ìµœì¢…ì ì¸ test lossë¥¼ ê°ì†Œì‹œí‚¤ë ¤ëŠ” ëª©ì </p>\n<p>(ì´ê±´ ì˜¤ë²„í”¼íŒ… ë°©ì§€)</p>\n<hr>\n<p>Normalization : ì •ê·œí™”ë¼ê³  ë¶ˆë¦¬ë©°, ì´ëŠ” ë°ì´í„°ì˜ í˜•íƒœë¥¼ ì¢€ ë” ì˜ë¯¸ ìˆê²Œ, í˜¹ì€ íŠ¸ë ˆì´ë‹ì— ì í•©í•˜ê²Œ ì „ì²˜ë¦¬í•˜ëŠ” ê³¼ì •</p>\n<p>(ì´ê±´ ì „ì²˜ë¦¬)</p>\n<p>ì˜ˆë¥¼ ë“¤ì–´</p>\n<ol>\n<li>ë°ì´í„°ë¥¼ z-socre ë³€í™˜</li>\n<li>0 ê³¼ 1 ì‚¬ì´ ê°’ìœ¼ë¡œ ë¶„í¬ ì¡°ì •</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>datasets <span class=\"token keyword\">import</span> load_iris\n<span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd \n<span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt\n\niris <span class=\"token operator\">=</span> load_iris<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\niris_df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span>data<span class=\"token operator\">=</span>iris<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">,</span> columns<span class=\"token operator\">=</span>iris<span class=\"token punctuation\">.</span>feature_names<span class=\"token punctuation\">)</span>\ntarget_df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span>data<span class=\"token operator\">=</span>iris<span class=\"token punctuation\">.</span>target<span class=\"token punctuation\">,</span> columns<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'species'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 0, 1, 2ë¡œ ë˜ì–´ìˆëŠ” target ë°ì´í„°ë¥¼ </span>\n<span class=\"token comment\"># ì•Œì•„ë³´ê¸° ì‰½ê²Œ 'setosa', 'versicolor', 'virginica'ë¡œ ë°”ê¿‰ë‹ˆë‹¤ </span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">converter</span><span class=\"token punctuation\">(</span>species<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">if</span> species <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> <span class=\"token string\">'setosa'</span>\n    <span class=\"token keyword\">elif</span> species <span class=\"token operator\">==</span> <span class=\"token number\">1</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> <span class=\"token string\">'versicolor'</span>\n    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> <span class=\"token string\">'virginica'</span>\n\ntarget_df<span class=\"token punctuation\">[</span><span class=\"token string\">'species'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> target_df<span class=\"token punctuation\">[</span><span class=\"token string\">'species'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span>converter<span class=\"token punctuation\">)</span>\n\niris_df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>concat<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>iris_df<span class=\"token punctuation\">,</span> target_df<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\niris_df<span class=\"token punctuation\">.</span>head<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}</code></pre></div>\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal length (cm)</th>\n      <th>sepal width (cm)</th>\n      <th>petal length (cm)</th>\n      <th>petal width (cm)</th>\n      <th>species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">X <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>iris_df<span class=\"token punctuation\">[</span><span class=\"token string\">'petal length (cm)'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>a<span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> a <span class=\"token keyword\">in</span> iris_df<span class=\"token punctuation\">.</span>index <span class=\"token keyword\">if</span> iris_df<span class=\"token punctuation\">[</span><span class=\"token string\">'species'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>a<span class=\"token punctuation\">]</span><span class=\"token operator\">==</span><span class=\"token string\">'virginica'</span><span class=\"token punctuation\">]</span>\nY <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>iris_df<span class=\"token punctuation\">[</span><span class=\"token string\">'sepal length (cm)'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>a<span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> a <span class=\"token keyword\">in</span> iris_df<span class=\"token punctuation\">.</span>index <span class=\"token keyword\">if</span> iris_df<span class=\"token punctuation\">[</span><span class=\"token string\">'species'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>a<span class=\"token punctuation\">]</span><span class=\"token operator\">==</span><span class=\"token string\">'virginica'</span><span class=\"token punctuation\">]</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>Y<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">[6.0, 5.1, 5.9, 5.6, 5.8, 6.6, 4.5, 6.3, 5.8, 6.1, 5.1, 5.3, 5.5, 5.0, 5.1, 5.3, 5.5, 6.7, 6.9, 5.0, 5.7, 4.9, 6.7, 4.9, 5.7, 6.0, 4.8, 4.9, 5.6, 5.8, 6.1, 6.4, 5.6, 5.1, 5.6, 6.1, 5.6, 5.5, 4.8, 5.4, 5.6, 5.1, 5.1, 5.9, 5.7, 5.2, 5.0, 5.2, 5.4, 5.1]\n[6.3, 5.8, 7.1, 6.3, 6.5, 7.6, 4.9, 7.3, 6.7, 7.2, 6.5, 6.4, 6.8, 5.7, 5.8, 6.4, 6.5, 7.7, 7.7, 6.0, 6.9, 5.6, 7.7, 6.3, 6.7, 7.2, 6.2, 6.1, 6.4, 7.2, 7.4, 7.9, 6.4, 6.3, 6.1, 7.7, 6.3, 6.4, 6.0, 6.9, 6.7, 6.9, 5.8, 6.8, 6.7, 6.7, 6.3, 6.5, 6.2, 5.9]</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">plt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>scatter<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span>Y<span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'petal-sepal scatter before normalization'</span><span class=\"token punctuation\">)</span> \nplt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">'petal length (cm)'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'sepal length (cm)'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>grid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 336px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 98.88888888888889%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAAsTAAALEwEAmpwYAAADyElEQVQ4y4VUTW8jRRCt2CsQAq0QYCyEIxkkUH5Dbpw4csmFA77APWIv7EqIEz8GbfgIKyGRBC+JVmID68RyPI42cWLHHnvGie2ZsT1jT38WqvbYsCyIlkr9untc/erVa8PBwQFsbW2t9Ho9QEQAgDwAvAYAWQDIJDgHAK8DwFsA8Eay9yYAvJ3MOfrtTc8BKJfLKQC4XSwWP+52u8V6vV5st9s7NF9dXe21Wq3di4uLYqvV2mm327vNZnOn53R22ra9c1g53WtcXv7idOzdYf9m7/Dx4w/Atu2067rguu49pRT+79AaR7E0cBhyVBox5BpHM47HlepnVGaK6FqWdZcxhkIIJoQQcRwLKaUJwpzzJXb9UGilBKIUZ44n2oMJ648iPCyVP1kmrNVq9yihnA8dxzFhlEoh7XMhkCqQnGN7MMHBeIbhNEYphEZEqaXAmlUtmISXl5fgOM4dzjmaQ621kmJZpZLzEpuDCKu2h2fuGIMpxxkzl5iEdLllWQXY3Nx8EQBulUqlr4gV51zSrd44xCCcYTRjeO1PcBYz9CYzvPHHxAq1koZ5HMeashGuVCoFyOVypuWu634uhGFFdPSMcXSCGU65xIvrEVqdAE86I3T96C/mSi0ZEq7VagXIZrPvAMAKaUgMhRBSSamVYFh3A5xMGQ5HIbb6Y3zqBBhNZ0hyCDlnyBhbMjw5OSlAJpN5nxKen59/wUhDrWUQMX3a8bDS9tDxp3jU6OOTxgClVHgThDiNSWtNl1OQ5JJwtVo1DN+lkh3HMSVrRPmkOdTEhkbIJF71J9jsh2Y9imKMhfzvkjOZzHsA8HK5XP6SsRhjxmXdDXTd8XAwnhrxJ9EUh+PI2IjNZTHxr03Z2Nh4yfM86Ha7xjZEn+o5c3xjDxqmWVobTN/MSeHcp1I+a5uFsU9PT42xEbV0/Ehf9Hyjk0qMLRJjJ+Y3mJJzzp/VkDGWThLeTV6H5EJoPu+eTl6NJvH/ianDFEopSclNl73hwCTsdOw7pBcixvMqjSnFAmutn8NKKROIyIixZVnmLafppfxROvqaLCHmZWDiySU27znBNC+aspCDZsuyPgXraT3166Pf4PfS0UfHtfOHnufdHwwG3zUajZ/6/f73QRBs2bb9YDgcfjuZTL6xbfvH6+vrH3zf3+p0Og/oLAiC+47j/Ly9vf0hLEbyb522bRuiKCL8Au0l+6/+Dd8GgNT+/j4s9o6Pjxdnryw3EXGFIvD9dBhG6WSdWltby+bz+Vw+n19dXV3N03p9fZ0uSCcOSbVarVuJdPAn2XYUFtkpGdIAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/613dfaf87366d28da81864efc979bad9/d99f2/output_3_0.png\"\n        srcset=\"/static/613dfaf87366d28da81864efc979bad9/e9ff0/output_3_0.png 180w,\n/static/613dfaf87366d28da81864efc979bad9/d99f2/output_3_0.png 336w\"\n        sizes=\"(max-width: 336px) 100vw, 336px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>preprocessing <span class=\"token keyword\">import</span> minmax_scale\n\n<span class=\"token comment\">#sklearn ì—ì„œ ì§€ì›í•˜ëŠ” minmax_SCALE ë¡œ 0~ 1ê°’ìœ¼ë¡œ ì¡°ì •ë¨</span>\n\nX_scale <span class=\"token operator\">=</span> minmax_scale<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">)</span>\nY_scale <span class=\"token operator\">=</span> minmax_scale<span class=\"token punctuation\">(</span>Y<span class=\"token punctuation\">)</span>\n\nplt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>scatter<span class=\"token punctuation\">(</span>X_scale<span class=\"token punctuation\">,</span>Y_scale<span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'petal-sepal scatter after normalization'</span><span class=\"token punctuation\">)</span> \nplt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">'petal length (cm)'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'sepal length (cm)'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>grid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 330px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 101.11111111111111%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAAsTAAALEwEAmpwYAAADmklEQVQ4y21U2U4cRxStATkKkfI0MIIo9uCED0keYsOj7SzKLzk/wRPihSdreIAw6WDMNBiQmATJJALP1t01vc7S01stN7o13WRIaKlVp1tVt845dyEkf87PzwkAIPyCEPI4f78ihCwSQqqEkC9n/lcIIU9m9iAuqfMAUMKPWq32reM4OqX0FFfTNE8tyzpzXVc3DOPUtu0TxJTSk8BzG8PA1z/cdk7aPeP9MPAa4+HgvPXx9hcMOIeRj46OfkrTFIqHMfYgBinAG8eQcgnDSQIp4xBMMvWv3TPrRNf1+c3NTWJZ1rMkSdT5aQzGAUC9s1hKwf0w4SmX6tsZxfzGCdNRnEHHsN4ohmjc/v7+j3EcYyTJOZcYHJlxziGOpzjNGEjOoOuOgA4iCMYTvA1Zc8EZ9CmtqUTgW6/Xf8CAGEwIITOULwUIIYCzDLWCPYrh/Y0NzY4HzjiG8QT3q0tRBVgYcH19faFWqxFK6fNcssDTSZopb4QEoIMJcCEhTDn4YQJSytxOUWCOq+M4NbKysrJCCFnQNO1VFEVKMuNcRlEMVhAq428sH/7s+nDVC+Av04csS5UVSCDLMsUQV8uyamRpaQlr6JNGo/ECN3AhpLpWcGg5Y7AGkZLW9UK4tcfgDidKBG7Lg6EtGBMoSi6Xy1+jh57nfVdITpiQ19YAmr0B3DghfDAD2LuiwCWAM4pgGE3Li3F+T7Jt24ohdsGnx8fHLzEgJuTKGMiLjw4kGYM4Y9BxhvA3HanEhHECQRirgAVDKeW/DBcXF58SQj47evfuJXqYpJm8tUfy2vDA9MO8bGIYhKqkALPPWHbPQ6zTOw83NjYWdF0npmk+x06ReZZ7XggXbf9/ncL5tJSm+AHJ2MvooaZp3yMTkEKOolT+0XFVWeBhvCg3v2CkAqWKLVNJwVVJ9n1f9fLh4eGrSVE2jMk0TVTRYtfNdg0GKbx7sGwuLy/nt7e3iWEYz1imspf9p5fvYTyMjAqMCQGANJf85m7aaJr2M9YYni2kIYuCVYGRaS5ztg7V2u/368U8nNvZ2fnm4uq6QWn/wHGcg1ar9bbf7//med6v3W73d/wXBMEeYkpp3XXdg3a7/dY0Tc113b1er3fabDZfFwO7mNafF8MC23EG49Sen8Gls7Ozuz27u7uIcWo9Kg6Qra0tzHaJCWXBXJH9tbW1cqVSqS4vLz8ul8tr1Wq1srq6WtE0bT7fM9fpdApc+gc0WAWZVrhbCQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/d878eef0f4b726da8c48e1f411322ba2/d9ecf/output_4_0.png\"\n        srcset=\"/static/d878eef0f4b726da8c48e1f411322ba2/e9ff0/output_4_0.png 180w,\n/static/d878eef0f4b726da8c48e1f411322ba2/d9ecf/output_4_0.png 330w\"\n        sizes=\"(max-width: 330px) 100vw, 330px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>linear_model <span class=\"token keyword\">import</span> LinearRegression\n<span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np \n\nX <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">)</span>\nY <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span>Y<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Iris Datasetì„ Linear Regressionìœ¼ë¡œ í•™ìŠµí•©ë‹ˆë‹¤. </span>\nlinear<span class=\"token operator\">=</span> LinearRegression<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nlinear<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> Y<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Linear Regressionì˜ ê¸°ìš¸ê¸°ì™€ ì ˆí¸ì„ í™•ì¸í•©ë‹ˆë‹¤. </span>\na<span class=\"token punctuation\">,</span> b<span class=\"token operator\">=</span>linear<span class=\"token punctuation\">.</span>coef_<span class=\"token punctuation\">,</span> linear<span class=\"token punctuation\">.</span>intercept_\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"ê¸°ìš¸ê¸° : %0.2f, ì ˆí¸ : %0.2f\"</span> <span class=\"token operator\">%</span><span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">,</span>b<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">ê¸°ìš¸ê¸° : 1.00, ì ˆí¸ : 1.06</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">plt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>scatter<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span>Y<span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span>linear<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token string\">'-b'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'petal-sepal scatter with linear regression'</span><span class=\"token punctuation\">)</span> \nplt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">'petal length (cm)'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'sepal length (cm)'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>grid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 336px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 98.88888888888889%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAAsTAAALEwEAmpwYAAAD5UlEQVQ4y4VUS28bVRQ+tSseUgUVJEoARzJIoPyG7FixZJMNC7yBfdRKiKLCjh+DWqBpJVCSWnmI0ipRbJPMuKkdJ/Y8Etfxa2LPeObOfRx07thWKEhc6Wq++/B3z3e+cwyICDQMw6DPGwDwPgC8CwAfAMA745kBgJsAMAcAswAwDwBvA8B7V9bX7MYxQKlUSgHAjc3NzS8sy9qp1+sbtm2vVyqVLdu2NyzLelyr1fKO46w5jrPeaDTWXNt6THjvr/LW6elJ/mXTXm/Um/m93Wefgud5aYrStu27Sin8v0F3RnFyrzti+lu3EZ0mx6OK+TUgYooIK5XKN1EUoRCCcc55FEVcCKEnYRoT7HZ9jig4GwmefzLkhzWfdYY+Pt0rfTklNAzjLmOMCGmoKNIYhZRI+5xzVFKiiGPsBD423BgLRYbegClEKQTnaJpGThPW63U4Ozu7HccxKRBKKSUEn8qUQiAqxPPLEZ5ceLj2bID7hzGGjO5LygIFgaZp5mBlZeV1ALheKBR+IMlxHNNryhsGOAgiDCKGXc9HIRm67QDXdwZYbxCR0JGHYaSIjfDBwUEOMplMhiRThCRL30RUQciwNYhwxARaPQ+LVR8f5H08cYOxOYhCSJRSkkNCSonlcjkH8/PzHxJhtVr9liRLKQUmIrD68hKZ5GgcRbjxxMeS1ccRC1FJpa9QAJxzTTiVPDMz8wkApMvl8p0wJJe58PxQnbS6WGp0Mf9ngA932njgXCDjHC/6QwzCSOc1YoxkTyUfHh7mYG5u7iOKsNls3tJOKhTGeU/tvuhjoaTQbQl0+wOstYZaat8PMYxFYpb8D8mzs7MfU6cUS6XvGYtQqlhs7vfU71sedrxQp9QbjLB9GegyYlE0kapxFL1iyvLy8puJKe5txmKsN5RwHVSVZg+Pmp6OJDEr6Y4kzwnWdSrEP3M4Kezj4+ffWVaMXk+JThCoWrOvSeSVwp5g+jFhIo/jWJctnRuGkYNut6t7uVx+fofqkB6LY67iJNkq6ZpIkZuvYjKEJlUGkWtTvH5fE7quc0tJnewoUal18glWSv0LSyn1RERGEZumqXs5TZ2yt1/48cLzkScyKNla5gST1AmmrzYlKZspNk3zKzBfHKe2/ngKu/uFz4vl6mav17vX6XR+OT09/a3dbv/qed59x3Eedbvdn4fD4U+O4zxstVoP+v3+fdd1H9GZ53n3zs/P11ZXVz+DyRj/c6cdx4EgCAi/Rnvj/ZtX8FsAkNre3obJXrFYnJzdmG4i4jWalFPfD9LjdWpxcXEum81mstnswsLCQpbWS0tL9EB6XCEpy7Kuj1MHfwOMqArQb760ogAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/2fc7c4278cbcf1ba6b256f6e838832b6/d99f2/output_6_0.png\"\n        srcset=\"/static/2fc7c4278cbcf1ba6b256f6e838832b6/e9ff0/output_6_0.png 180w,\n/static/2fc7c4278cbcf1ba6b256f6e838832b6/d99f2/output_6_0.png 336w\"\n        sizes=\"(max-width: 336px) 100vw, 336px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\">#L1 regularizationì€ Lassoë¡œ import í•©ë‹ˆë‹¤.</span>\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>linear_model <span class=\"token keyword\">import</span> Lasso\n\nL1 <span class=\"token operator\">=</span> Lasso<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nL1<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> Y<span class=\"token punctuation\">)</span>\na<span class=\"token punctuation\">,</span> b<span class=\"token operator\">=</span>L1<span class=\"token punctuation\">.</span>coef_<span class=\"token punctuation\">,</span> L1<span class=\"token punctuation\">.</span>intercept_\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"ê¸°ìš¸ê¸° : %0.2f, ì ˆí¸ : %0.2f\"</span> <span class=\"token operator\">%</span><span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">,</span>b<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nplt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>scatter<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span>Y<span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span>L1<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token string\">'-b'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'petal-sepal scatter with L1 regularization(Lasso)'</span><span class=\"token punctuation\">)</span> \nplt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">'petal length (cm)'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'sepal length (cm)'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>grid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">ê¸°ìš¸ê¸° : 0.00, ì ˆí¸ : 6.59</code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 336px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 98.88888888888889%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAAsTAAALEwEAmpwYAAAD/ElEQVQ4y3VUW28bVRCexBUIgQCphIBIwCCB8hvyB+CNl7ziB+A9ah+ASognHvJTopZLqGiVJlUbqRVqi+s0ydqJY3sv3nidxPZ6413be66D5ngdcRFHGs3nOWe/c2bmG8Pa2hrYtj0DAO8BwDsA8AYAvA8ArwPAuwDwFgDMZf5lALgKAB9ksbezM3OZXQXXdWeJZH19/Wvbth81m83NWq320HGce47j3Pc8b8t13U3yvu/fazQa206jvtNsNreevKjcd113q+V7203XeXz3zu+fged5uSAIoNPpfKO1xun6P0wrZsr4XsJRasSEa4xTiXtW5UtAxFlEBMuyvkvTFKWUTAgh0jQVUkpjhDnnl7jdT4RWSiBKUQ1C4XVj1omG+KRY+uKSsFwu32CMESEtnZGjVAopzoVApRRKzrHZjbE7GGMySlEKQc+XWgosWwcFQ9hoNCAIguucczSbWmspxWWKSkrjne4QD/wQq+0B9kccx8xcYgjpcsuyCrC6ukqdu1IsFn9gjF7FpVJCR3GCg9EYR4xhJ4oxZQz7wzF2ogEqukxLFJwhY6lWSkrKYm9vrwALCwsLlPLpafvaeCyQsmYM9UXM0TsfY5RIPPQvsOREWLQv0DsbIvExjjgeKzLNOVVCYaVSLsD8/PyHADBTrZZvtFop1utCeq7Uns3xwZ8RVqoM98pDfFwa4PbTCI+qY3QdgbYjsV5n2Ggw3WhI2W4zPDzcL8Dc3NwnRHh8fPytlFRDLZOU6eN2iOUgxLPBCF80O7jb7FI1sRcnyCbnUGtBpukbavrBwYF54UeUchAE14SgAyif2T191IoIY5JKdM9jtDuJaUyUpDjmkyZJqchMU0gB5XLZvPBjAHh1d3f3e2pKyristSNdC0LsDkaolcR4OMLeYGhkxNIU6WIyakSapppafNmUlZWVV8IwhFarZWRDiqF8qkHfyIMWfYzZtNCZiVJwolMp/ymbqbArlYoRNtUj6A91/bRv6qQyYYtM2Jn4DSZyzrmRLe2bGjLGchnhdPQkF0JzxigVnU2NFkL8BzPGjCmlJJHv7+8XIOx1DeHJiX+d6oWI6SRLyhPFFGtq6b+wUsoYIjJ6sWVZZpZzNCnPis9/PI8SFJM0qNgmzSk285xh8tOmTMtB3rKsr8A6qs0+fPQHPC0+/7xUPn4QhuHNbrf7s23bdzqdzi9RFN3yff92r9f7KY7jdd/3fzs7O/u13+/fOjk5uU17URTdDIJgc2Nj41OYLkobAHK+78NwOCT8EsWy+Jt/w/RPPruzswPTWKlUmu69dhlExBmyqN/PJckwl/2eXVpams/n8wv5fH5xcXExT7+Xl5fpglymkFnP865kpYO/AHq4BOl4qIQaAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/c1c3d0dc2cedc5cab88e3cfd8fca76c0/d99f2/output_7_1.png\"\n        srcset=\"/static/c1c3d0dc2cedc5cab88e3cfd8fca76c0/e9ff0/output_7_1.png 180w,\n/static/c1c3d0dc2cedc5cab88e3cfd8fca76c0/d99f2/output_7_1.png 336w\"\n        sizes=\"(max-width: 336px) 100vw, 336px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>ì´ê²Œ Lasso ë°©ì‹ì´ê³ </p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\">#L2 regularizationì€ Ridgeë¡œ import í•©ë‹ˆë‹¤. </span>\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>linear_model <span class=\"token keyword\">import</span> Ridge\n\nL2 <span class=\"token operator\">=</span> Ridge<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nL2<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> Y<span class=\"token punctuation\">)</span>\na<span class=\"token punctuation\">,</span> b <span class=\"token operator\">=</span> L2<span class=\"token punctuation\">.</span>coef_<span class=\"token punctuation\">,</span> L2<span class=\"token punctuation\">.</span>intercept_\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"ê¸°ìš¸ê¸° : %0.2f, ì ˆí¸ : %0.2f\"</span> <span class=\"token operator\">%</span><span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">,</span>b<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nplt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>scatter<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span>Y<span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span>L2<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token string\">'-b'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'petal-sepal scatter with L2 regularization(Ridge)'</span><span class=\"token punctuation\">)</span> \nplt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">'petal length (cm)'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'sepal length (cm)'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>grid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">ê¸°ìš¸ê¸° : 0.93, ì ˆí¸ : 1.41</code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 336px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 98.88888888888889%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAAsTAAALEwEAmpwYAAAD60lEQVQ4y3VUTW8bVRS9sStQBQIkMAaRgEEC9TfkD7BgwSZbsgD2UbOAVkKsWOSnRC2koRIlSSNqqdCEynHjZJwmcTzjsZ2xnYlnJvbYnnlfF93nsQUFnvR0z1zPO3PPvecZVlZWwDTNGQB4DwDeAYDXAeB9AHgNAN4FgLcAIJPE6wDwJgB8kOTeTs7Q2Q91rlarpYhkdXX1a9M0H9fr9Y1KpfLIsqxNy7K2bdveqtVqmxTr9fpWtVp9aFXP8oR39o+2Lcvaci+aG2a1snNvbe0zsG077TgOuK77jVIKJ+v/MK1+LHXsDpiOjTaidS7x5Oz4S0DEFCKCYRi3oihCIUTMOedRFHEhhN6EGWNT7HRDjig4CsHzu31eej6KO36Iu4XiF1PCcrl8O45jIqSlEnIUUiLlGafzEjlj2Or18bwT496zGF2XK0QllORoHB4uasJqtQqO4ywzpiUIpZSSgk8lSil0tL0BPm95+PDpFRZLAocjnryu60DDMBZhaWnpZQC4VigUvqeqGGNCcK68XohBOMJwFGPb6yMXEba9Ieb/CLFWIyKOjMU4GkWK2EhFqVRahNnZ2VmS3Gq1bnKuq6Jy1Chm6PgjHDKJtneFT4werm728LQejgdFL0qJUsoESiyXy4uQzWbJPzPUQ6qQcy6kEEqwGE03wP4owr3SEPO7fTxxAozYCAXnyIXQvY3jeFrhwcHBImQymU+I8PT09NuYMbKI8MNYnXU83D3xMb8T4YMdF/ebrq6IpjmMmK6RFHHOqeWC8CENJZvNfkSSHce5ydlY8n6zq/LFAA8OEP2eROeqh+bFWOrVIMKIi2RY/yE5k8l8DACvFIvPvhMiwlHExK+/X6ntHR+9cKhb2guH2O0NtI3icVv0JplR9MJQFhYWroehB+32+bLnMaxUlAh7qEzXx+NWT1eih5XcFrLWuCgc+1QINYaJbSbGPjk5ut1qMxRMCbc/UBXH132SibGJdILpMGEiZ4z9s4dxHKeJ8Ojo6BbnEZlYMMYVG09PJbdGUfNfxDRh2lJKQeR6yl73UhM2m41lKXSzo7FKPnZvgpVS/8JSSr0RMaaKDcPQdzlNN+VpYe+HiyDUd5W+lnhyivV9TjDFyVAm7aBoGMZXYBxXUo8eP4E/C3ufF8unv3med+fy8vIn0zR/cV13LQiCu41G43632/2x3++vNhqNnzudzj3f9+82m8379FsQBHccx9lYX1//FCaLZANAutFowGAwIPwS5ZL8G3/D9E+eyufzMMkVi8XJb69Ok4g4Qzvw/XQYDtLJc+rGjRvZXC43m8vl5ubm5nL0PD8/Tx9IJw5J2bZ9LWkd/AUa/wOfIeMgQQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/6ffbbbf6f87c1e36c5b43fd3ea8ac4d5/d99f2/output_9_1.png\"\n        srcset=\"/static/6ffbbbf6f87c1e36c5b43fd3ea8ac4d5/e9ff0/output_9_1.png 180w,\n/static/6ffbbbf6f87c1e36c5b43fd3ea8ac4d5/d99f2/output_9_1.png 336w\"\n        sizes=\"(max-width: 336px) 100vw, 336px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>ì´ê²Œ Ridge ë°©ë²•<br>\nê¸°ì¡´ ë°©ë²•ë³´ë‹¤ ì¶•ì€ ìœ„ë¡œ ì«Œ ì´ë™í–ˆì§€ë§Œ</p>\n<p>ê¸°ìš¸ê¸°ê°€ ì¢€ ì¤„ì—ˆë‹¤</p>\n<p>ì´ ë‘ ë°©ì‹ì€ Regularization\në‹¤ì‹œë§í•´ ì˜¤ë²„í”¼íŒ…ì„ ë°©ì§€í•œ ê²ƒì´ë‹¤</p>\n<hr>\n<p>, L1 Regularizationì„ ì‚¬ìš©í•  ë•ŒëŠ” Xê°€ 2ì°¨ì› ì´ìƒì¸ ì—¬ëŸ¬ ì»¬ëŸ¼ ê°’ì´ ìˆëŠ” ë°ì´í„°ì¼ ë•Œ ì‹¤ì œ íš¨ê³¼ë¥¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>\n<p>xê°€ 1ì°¨ì›ì´ì—ˆë˜ iris ê½ƒìê¸¸ì´ë°ì´í„°ê°™ì€ ë”°ë¶„í•œê±° ì“°ì§€ë§ê³ </p>\n<p>ì–´ë¥¸ì˜ ë°ì´í„°ì¸ wine datasetì„ ë³¼ê¹Œ?</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>datasets <span class=\"token keyword\">import</span> load_wine\n\nwine <span class=\"token operator\">=</span> load_wine<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nwine_df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span>data<span class=\"token operator\">=</span>wine<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">,</span> columns<span class=\"token operator\">=</span>wine<span class=\"token punctuation\">.</span>feature_names<span class=\"token punctuation\">)</span>\ntarget_df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span>data<span class=\"token operator\">=</span>wine<span class=\"token punctuation\">.</span>target<span class=\"token punctuation\">,</span> columns<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'Y'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">wine_df<span class=\"token punctuation\">.</span>head<span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}</code></pre></div>\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>alcohol</th>\n      <th>malic_acid</th>\n      <th>ash</th>\n      <th>alcalinity_of_ash</th>\n      <th>magnesium</th>\n      <th>total_phenols</th>\n      <th>flavanoids</th>\n      <th>nonflavanoid_phenols</th>\n      <th>proanthocyanins</th>\n      <th>color_intensity</th>\n      <th>hue</th>\n      <th>od280/od315_of_diluted_wines</th>\n      <th>proline</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>14.23</td>\n      <td>1.71</td>\n      <td>2.43</td>\n      <td>15.6</td>\n      <td>127.0</td>\n      <td>2.80</td>\n      <td>3.06</td>\n      <td>0.28</td>\n      <td>2.29</td>\n      <td>5.64</td>\n      <td>1.04</td>\n      <td>3.92</td>\n      <td>1065.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>13.20</td>\n      <td>1.78</td>\n      <td>2.14</td>\n      <td>11.2</td>\n      <td>100.0</td>\n      <td>2.65</td>\n      <td>2.76</td>\n      <td>0.26</td>\n      <td>1.28</td>\n      <td>4.38</td>\n      <td>1.05</td>\n      <td>3.40</td>\n      <td>1050.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13.16</td>\n      <td>2.36</td>\n      <td>2.67</td>\n      <td>18.6</td>\n      <td>101.0</td>\n      <td>2.80</td>\n      <td>3.24</td>\n      <td>0.30</td>\n      <td>2.81</td>\n      <td>5.68</td>\n      <td>1.03</td>\n      <td>3.17</td>\n      <td>1185.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>14.37</td>\n      <td>1.95</td>\n      <td>2.50</td>\n      <td>16.8</td>\n      <td>113.0</td>\n      <td>3.85</td>\n      <td>3.49</td>\n      <td>0.24</td>\n      <td>2.18</td>\n      <td>7.80</td>\n      <td>0.86</td>\n      <td>3.45</td>\n      <td>1480.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>13.24</td>\n      <td>2.59</td>\n      <td>2.87</td>\n      <td>21.0</td>\n      <td>118.0</td>\n      <td>2.80</td>\n      <td>2.69</td>\n      <td>0.39</td>\n      <td>1.82</td>\n      <td>4.32</td>\n      <td>1.04</td>\n      <td>2.93</td>\n      <td>735.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">target_df<span class=\"token punctuation\">.</span>head<span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}</code></pre></div>\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>model_selection <span class=\"token keyword\">import</span> train_test_split\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>linear_model <span class=\"token keyword\">import</span> LinearRegression\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>metrics <span class=\"token keyword\">import</span> mean_absolute_error<span class=\"token punctuation\">,</span> mean_squared_error\n\n<span class=\"token comment\"># ë°ì´í„°ë¥¼ ì¤€ë¹„í•˜ê³ </span>\nX_train<span class=\"token punctuation\">,</span> X_test<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> y_test <span class=\"token operator\">=</span> train_test_split<span class=\"token punctuation\">(</span>wine_df<span class=\"token punctuation\">,</span> target_df<span class=\"token punctuation\">,</span> test_size<span class=\"token operator\">=</span><span class=\"token number\">0.3</span><span class=\"token punctuation\">,</span> random_state<span class=\"token operator\">=</span><span class=\"token number\">101</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚µë‹ˆë‹¤.</span>\nmodel <span class=\"token operator\">=</span> LinearRegression<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># í…ŒìŠ¤íŠ¸ë¥¼ í•´ë³¼ê¹Œìš”?</span>\nmodel<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>X_test<span class=\"token punctuation\">)</span>\npred <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>X_test<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># í…ŒìŠ¤íŠ¸ ê²°ê³¼ëŠ” ì´ë ‡ìŠµë‹ˆë‹¤!</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"result of linear regression\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Mean Absolute Error:'</span><span class=\"token punctuation\">,</span> mean_absolute_error<span class=\"token punctuation\">(</span>y_test<span class=\"token punctuation\">,</span> pred<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Mean Squared Error:'</span><span class=\"token punctuation\">,</span> mean_squared_error<span class=\"token punctuation\">(</span>y_test<span class=\"token punctuation\">,</span> pred<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Mean Root Squared Error:'</span><span class=\"token punctuation\">,</span> np<span class=\"token punctuation\">.</span>sqrt<span class=\"token punctuation\">(</span>mean_squared_error<span class=\"token punctuation\">(</span>y_test<span class=\"token punctuation\">,</span> pred<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\n\\n coefficient linear regression\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">.</span>coef_<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">result of linear regression\nMean Absolute Error: 0.25128973939722626\nMean Squared Error: 0.1062458740952556\nMean Root Squared Error: 0.32595379134971814\n\n\n coefficient linear regression\n[[-8.09017190e-02  4.34817880e-02 -1.18857931e-01  3.65705449e-02\n  -4.68014203e-04  1.41423581e-01 -4.54107854e-01 -5.13172664e-01\n   9.69318443e-02  5.34311136e-02 -1.27626604e-01 -2.91381844e-01\n  -5.72238959e-04]]</code></pre></div>\n<p>ì„ í˜•íšŒê·€ë¡œ ë¬¸ì œë¥¼ í’€ê³ </p>\n<p>ê³„ìˆ˜(coefficient)</p>\n<p>ì ˆëŒ€ ì˜¤ì°¨ ( mean absolute error)</p>\n<p>ì œê³± ì˜¤ì°¨ ( mean squared error)</p>\n<p>í‰ê·  ì œê³±ê°’ ì˜¤ì°¨ (root mean squared error)</p>\n<p>ë¥¼ ì¶œë ¥</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>model_selection <span class=\"token keyword\">import</span> train_test_split\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>linear_model <span class=\"token keyword\">import</span> LinearRegression\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>metrics <span class=\"token keyword\">import</span> mean_absolute_error<span class=\"token punctuation\">,</span> mean_squared_error\n\n<span class=\"token comment\"># ë°ì´í„°ë¥¼ ì¤€ë¹„í•˜ê³ </span>\nX_train<span class=\"token punctuation\">,</span> X_test<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> y_test <span class=\"token operator\">=</span> train_test_split<span class=\"token punctuation\">(</span>wine_df<span class=\"token punctuation\">,</span> target_df<span class=\"token punctuation\">,</span> test_size<span class=\"token operator\">=</span><span class=\"token number\">0.3</span><span class=\"token punctuation\">,</span> random_state<span class=\"token operator\">=</span><span class=\"token number\">101</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚µë‹ˆë‹¤.</span>\nmodel <span class=\"token operator\">=</span> LinearRegression<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># í…ŒìŠ¤íŠ¸ë¥¼ í•´ë³¼ê¹Œìš”?</span>\nmodel<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>X_test<span class=\"token punctuation\">)</span>\npred <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>X_test<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># í…ŒìŠ¤íŠ¸ ê²°ê³¼ëŠ” ì´ë ‡ìŠµë‹ˆë‹¤!</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"result of linear regression\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Mean Absolute Error:'</span><span class=\"token punctuation\">,</span> mean_absolute_error<span class=\"token punctuation\">(</span>y_test<span class=\"token punctuation\">,</span> pred<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Mean Squared Error:'</span><span class=\"token punctuation\">,</span> mean_squared_error<span class=\"token punctuation\">(</span>y_test<span class=\"token punctuation\">,</span> pred<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Mean Root Squared Error:'</span><span class=\"token punctuation\">,</span> np<span class=\"token punctuation\">.</span>sqrt<span class=\"token punctuation\">(</span>mean_squared_error<span class=\"token punctuation\">(</span>y_test<span class=\"token punctuation\">,</span> pred<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\n\\n coefficient linear regression\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">.</span>coef_<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">result of linear regression\nMean Absolute Error: 0.25128973939722626\nMean Squared Error: 0.1062458740952556\nMean Root Squared Error: 0.32595379134971814\n\n\n coefficient linear regression\n[[-8.09017190e-02  4.34817880e-02 -1.18857931e-01  3.65705449e-02\n  -4.68014203e-04  1.41423581e-01 -4.54107854e-01 -5.13172664e-01\n   9.69318443e-02  5.34311136e-02 -1.27626604e-01 -2.91381844e-01\n  -5.72238959e-04]]</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>linear_model <span class=\"token keyword\">import</span> Lasso\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>metrics <span class=\"token keyword\">import</span> mean_absolute_error<span class=\"token punctuation\">,</span> mean_squared_error\n\n<span class=\"token comment\"># ëª¨ë¸ì„ ì¤€ë¹„í•˜ê³  í›ˆë ¨ì‹œí‚µë‹ˆë‹¤.</span>\nL1 <span class=\"token operator\">=</span> Lasso<span class=\"token punctuation\">(</span>alpha<span class=\"token operator\">=</span><span class=\"token number\">0.05</span><span class=\"token punctuation\">)</span>\nL1<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># í…ŒìŠ¤íŠ¸ë¥¼ í•´ë´…ì‹œë‹¤.</span>\npred <span class=\"token operator\">=</span> L1<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>X_test<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># ëª¨ë¸ ì„±ëŠ¥ì€ ì–¼ë§ˆë‚˜ ì¢‹ì„ê¹Œìš”?</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"result of Lasso\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Mean Absolute Error:'</span><span class=\"token punctuation\">,</span> mean_absolute_error<span class=\"token punctuation\">(</span>y_test<span class=\"token punctuation\">,</span> pred<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Mean Squared Error:'</span><span class=\"token punctuation\">,</span> mean_squared_error<span class=\"token punctuation\">(</span>y_test<span class=\"token punctuation\">,</span> pred<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Mean Root Squared Error:'</span><span class=\"token punctuation\">,</span> np<span class=\"token punctuation\">.</span>sqrt<span class=\"token punctuation\">(</span>mean_squared_error<span class=\"token punctuation\">(</span>y_test<span class=\"token punctuation\">,</span> pred<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\n\\n coefficient of Lasso\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>L1<span class=\"token punctuation\">.</span>coef_<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">result of Lasso\nMean Absolute Error: 0.24233731936122138\nMean Squared Error: 0.0955956894578189\nMean Root Squared Error: 0.3091855259513597\n\n\n coefficient of Lasso\n[-0.          0.01373795 -0.          0.03065716  0.00154719 -0.\n -0.34143614 -0.          0.          0.06755943 -0.         -0.14558153\n -0.00089635]</code></pre></div>\n<p>coefficient ë¶€ë¶„ì„ ë³´ì‹œë©´ Linear Regressionê³¼ L1 Regularizationì˜ ì°¨ì´ê°€ ì¢€ ë” ë‘ë“œëŸ¬ì§</p>\n<p>inear Regressionì—ì„œëŠ” ëª¨ë“  ì»¬ëŸ¼ì˜ ê°€ì¤‘ì¹˜ë¥¼ íƒìƒ‰í•˜ì—¬ êµ¬í•˜ëŠ” ë°˜ë©´, L1 Regularizationì—ì„œëŠ” ì´ 13ê°œ ì¤‘ 7ê°œë¥¼ ì œì™¸í•œ ë‚˜ë¨¸ì§€ì˜ ê°’ë“¤ì´ ëª¨ë‘ 0ì„</p>\n<h2 id=\"l2-norm--ridge\" style=\"position:relative;\"><a href=\"#l2-norm--ridge\" aria-label=\"l2 norm  ridge permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>L2 norm  Ridge</h2>\n<p><img src=\"attachment:image.png\" alt=\"image.png\"></p>\n<p>ë³´ë©´ L1 ì€ ê± ì ˆëŒ“ê°’ë§Œ ì”Œìš°ê³ </p>\n<p>L2 ëŠ” ì œê³±ì„ í•´,,! ê·¸ ì°¨ì´ì•¼,,!!</p>\n<p><img src=\"attachment:image-2.png\" alt=\"image-2.png\"></p>\n<p>L2 ëŠ” ì œê³±ì„ í•˜ê¸° ë•Œë¬¸ì— ì €ë ‡ê²Œ ì›ì˜ í˜•íƒœê°€ ë‚˜ì™€</p>\n<p>í•˜ì§€ë§Œ L1 ì€ ì‚¬ê°í˜•ì´ì§€</p>\n<p>ì œê³±ì´ë¼ ìˆ˜ë ´ ì†ë„ë„ ë¹ ë¦„ ë” ê°€ê¹Œìš´ ê¸¸ì„ ì°¾ì„ ìˆ˜ ìˆì–ì•„</p>\n<p>ì •ë¦¬í•˜ë©´, L1 Regularizationì€ ê°€ì¤‘ì¹˜ê°€ ì ì€ ë²¡í„°ì— í•´ë‹¹í•˜ëŠ” ê³„ìˆ˜ë¥¼ 0ìœ¼ë¡œ ë³´ë‚´ë©´ì„œ ì°¨ì› ì¶•ì†Œì™€ ë¹„ìŠ·í•œ ì—­í• ì„ í•˜ëŠ” ê²ƒì´ íŠ¹ì§•ì´ë©°, L2 Regularizationì€ 0ì´ ì•„ë‹Œ 0ì— ê°€ê¹ê²Œ ë³´ë‚´ì§€ë§Œ ì œê³± í…€ì´ ìˆê¸° ë•Œë¬¸ì— L1 Regularizationë³´ë‹¤ëŠ” ìˆ˜ë ´ ì†ë„ê°€ ë¹ ë¥´ë‹¤ëŠ” ì¥ì </p>\n<p>ì˜ˆë¥¼ ë“¤ì–´, A=[1,1,1,1,1]A=[1,1,1,1,1] , B=[5,0,0,0,0]B=[5,0,0,0,0] ì˜ ê²½ìš°<br>\nL1-normì€ ê°™ì§€ë§Œ, L2-normì€ ê°™ì§€ ì•ŠìŠµë‹ˆë‹¤.<br>\nì¦‰, ì œê³± í…€ì—ì„œ ê²°ê³¼ì— í° ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ê°’ì€ ë” í¬ê²Œ,<br>\nê²°ê³¼ì— ì˜í–¥ì´ ì ì€ ê°’ë“¤ì€ ë” ì‘ê²Œ ë³´ë‚´ë©´ì„œ ìˆ˜ë ´ ì†ë„ê°€ ë¹¨ë¼ì§€ëŠ” ê²ƒì…ë‹ˆë‹¤.</p>\n<h4 id=\"ê·¸ëŸ¬ë¯€ë¡œ-ë°ì´í„°ì—-ë”°ë¼-ì ì ˆí•œ-regularization-ë°©ë²•ì„-í™œìš©í•˜ëŠ”-ê²ƒì´-ì¢‹ìŠµë‹ˆë‹¤\" style=\"position:relative;\"><a href=\"#%EA%B7%B8%EB%9F%AC%EB%AF%80%EB%A1%9C-%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%97%90-%EB%94%B0%EB%9D%BC-%EC%A0%81%EC%A0%88%ED%95%9C-regularization-%EB%B0%A9%EB%B2%95%EC%9D%84-%ED%99%9C%EC%9A%A9%ED%95%98%EB%8A%94-%EA%B2%83%EC%9D%B4-%EC%A2%8B%EC%8A%B5%EB%8B%88%EB%8B%A4\" aria-label=\"ê·¸ëŸ¬ë¯€ë¡œ ë°ì´í„°ì— ë”°ë¼ ì ì ˆí•œ regularization ë°©ë²•ì„ í™œìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤ permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>ê·¸ëŸ¬ë¯€ë¡œ, ë°ì´í„°ì— ë”°ë¼ ì ì ˆí•œ Regularization ë°©ë²•ì„ í™œìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.</h4>\n<h2 id=\"ê·¼ë°-ê·¸ë˜ì„œ-norm-ì´ë€ê²Œ-ë­˜ê¹Œ\" style=\"position:relative;\"><a href=\"#%EA%B7%BC%EB%8D%B0-%EA%B7%B8%EB%9E%98%EC%84%9C-norm-%EC%9D%B4%EB%9E%80%EA%B2%8C-%EB%AD%98%EA%B9%8C\" aria-label=\"ê·¼ë° ê·¸ë˜ì„œ norm ì´ë€ê²Œ ë­˜ê¹Œ permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>ê·¼ë° ê·¸ë˜ì„œ Norm ì´ë€ê²Œ ë­˜ê¹Œâ€¦?</h2>\n<ol>\n<li>vector norm</li>\n<li>matrix norm</li>\n</ol>\n<p>Normì´ë¼ëŠ” ê°œë…ì€ ë²¡í„°ë¿ë§Œ ì•„ë‹ˆë¼ í•¨ìˆ˜, í–‰ë ¬ì— ëŒ€í•´ì„œ í¬ê¸°ë¥¼ êµ¬í•˜ëŠ” ê²ƒìœ¼ë¡œ, ë”¥ëŸ¬ë‹ì„ ë°°ìš°ëŠ” ê³¼ì •ì—ì„œëŠ” ì£¼ë¡œ ë²¡í„°, ì¢€ ë” ì–´ë µê²ŒëŠ” í–‰ë ¬ì˜ Norm ì •ë„ë§Œ ì•Œë©´ ë©ë‹ˆë‹¤.</p>\n<p><img src=\"attachment:image.png\" alt=\"image.png\"></p>\n<ol>\n<li>vector</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">x<span class=\"token operator\">=</span>np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\np<span class=\"token operator\">=</span><span class=\"token number\">5</span>\n\nnorm_x<span class=\"token operator\">=</span>np<span class=\"token punctuation\">.</span>linalg<span class=\"token punctuation\">.</span>norm<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> <span class=\"token builtin\">ord</span><span class=\"token operator\">=</span>p<span class=\"token punctuation\">)</span>\n\nmaking_norm <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>x<span class=\"token operator\">**</span>p<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token operator\">**</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token operator\">/</span>p<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"result of numpy package norm function : %0.5f \"</span><span class=\"token operator\">%</span>norm_x<span class=\"token punctuation\">)</span> \n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"result of making norm : %0.5f \"</span><span class=\"token operator\">%</span>making_norm<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">result of numpy package norm function : 10.00008 \nresult of making norm : 10.00008 </code></pre></div>\n<ol start=\"2\">\n<li>matrix</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">A<span class=\"token operator\">=</span>np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">[</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span><span class=\"token number\">6</span><span class=\"token punctuation\">,</span><span class=\"token number\">8</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\ninf_norm_A<span class=\"token operator\">=</span>np<span class=\"token punctuation\">.</span>linalg<span class=\"token punctuation\">.</span>norm<span class=\"token punctuation\">(</span>A<span class=\"token punctuation\">,</span> <span class=\"token builtin\">ord</span><span class=\"token operator\">=</span>np<span class=\"token punctuation\">.</span>inf<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"result inf norm of A :\"</span><span class=\"token punctuation\">,</span> inf_norm_A<span class=\"token punctuation\">)</span>\none_norm_A<span class=\"token operator\">=</span>np<span class=\"token punctuation\">.</span>linalg<span class=\"token punctuation\">.</span>norm<span class=\"token punctuation\">(</span>A<span class=\"token punctuation\">,</span> <span class=\"token builtin\">ord</span><span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"result one norm of A :\"</span><span class=\"token punctuation\">,</span> one_norm_A<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">result inf norm of A : 18.0\nresult one norm of A : 14.0</code></pre></div>\n<h2 id=\"dropout-ì€-ë­”ë°\" style=\"position:relative;\"><a href=\"#dropout-%EC%9D%80-%EB%AD%94%EB%8D%B0\" aria-label=\"dropout ì€ ë­”ë° permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Dropout ì€ ë­”ë°?</h2>\n<p><a href=\"https://jmlr.org/papers/v15/srivastava14a.html\">Dropout ë…¼ë¬¸</a></p>\n<p>Dropout ì€ Regularization ìœ¼ë¡œ ì˜¤ë²„í”¼íŒ…ì„ ë§‰ëŠ” ì •ì¹™í™” ì´ë‹¤.</p>\n<p>fully connected layerì—ì„œ ì˜¤ë²„í”¼íŒ…ì´ ìƒê¸°ëŠ” ê²½ìš°ì— ì£¼ë¡œ Dropout layerë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n<span class=\"token keyword\">from</span> tensorflow <span class=\"token keyword\">import</span> keras\n<span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n<span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>model_selection <span class=\"token keyword\">import</span> train_test_split\n\nfashion_mnist <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>datasets<span class=\"token punctuation\">.</span>fashion_mnist\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'=3'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">=3</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token punctuation\">(</span>train_images<span class=\"token punctuation\">,</span> train_labels<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>test_images<span class=\"token punctuation\">,</span> test_labels<span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> fashion_mnist<span class=\"token punctuation\">.</span>load_data<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nclass_names <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'T-shirt/top'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Trouser'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Pullover'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Dress'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Coat'</span><span class=\"token punctuation\">,</span>\n               <span class=\"token string\">'Sandal'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Shirt'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Sneaker'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Bag'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Ankle boot'</span><span class=\"token punctuation\">]</span>\n\ntrain_images <span class=\"token operator\">=</span> train_images <span class=\"token operator\">/</span> <span class=\"token number\">255.0</span>\ntest_images <span class=\"token operator\">=</span> test_images <span class=\"token operator\">/</span> <span class=\"token number\">255.0</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">model <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n    keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span>input_shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">28</span><span class=\"token punctuation\">,</span> <span class=\"token number\">28</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">128</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token comment\"># ì—¬ê¸°ì— dropout layerë¥¼ ì¶”ê°€í•´ë³´ì•˜ìŠµë‹ˆë‹¤. ë‚˜ë¨¸ì§€ layerëŠ” ì•„ë˜ì˜ ì‹¤ìŠµê³¼ ê°™ìŠµë‹ˆë‹¤.</span>\n    keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dropout<span class=\"token punctuation\">(</span><span class=\"token number\">0.9</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span><span class=\"token string\">'adam'</span><span class=\"token punctuation\">,</span>loss<span class=\"token operator\">=</span><span class=\"token string\">'sparse_categorical_crossentropy'</span><span class=\"token punctuation\">,</span>\n              metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nhistory<span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>train_images<span class=\"token punctuation\">,</span> train_labels<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Epoch 1/5\n1875/1875 [==============================] - 5s 2ms/step - loss: 1.4060 - accuracy: 0.4571\nEpoch 2/5\n1875/1875 [==============================] - 4s 2ms/step - loss: 1.1796 - accuracy: 0.5296\nEpoch 3/5\n1875/1875 [==============================] - 4s 2ms/step - loss: 1.1358 - accuracy: 0.5459\nEpoch 4/5\n1875/1875 [==============================] - 4s 2ms/step - loss: 1.1104 - accuracy: 0.5530\nEpoch 5/5\n1875/1875 [==============================] - 4s 2ms/step - loss: 1.0902 - accuracy: 0.5628</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">model <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n    keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span>input_shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">28</span><span class=\"token punctuation\">,</span> <span class=\"token number\">28</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token comment\"># ì´ë²ˆì—ëŠ” dropout layerê°€ ì—†ìŠµë‹ˆë‹¤. </span>\n    keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">128</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span><span class=\"token string\">'adam'</span><span class=\"token punctuation\">,</span>loss<span class=\"token operator\">=</span><span class=\"token string\">'sparse_categorical_crossentropy'</span><span class=\"token punctuation\">,</span>\n              metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nhistory <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>train_images<span class=\"token punctuation\">,</span> train_labels<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Epoch 1/5\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.5047 - accuracy: 0.8254\nEpoch 2/5\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.3759 - accuracy: 0.8648\nEpoch 3/5\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.3370 - accuracy: 0.8777\nEpoch 4/5\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.3138 - accuracy: 0.8853\nEpoch 5/5\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.2967 - accuracy: 0.8910</code></pre></div>\n<p>ë³´ë©´ ë“œëì•„ì›ƒì„ 0.9ë¡œ ì£¼ë©´ ì •í™•ë„ê°€ 56% ì´ë‹¤</p>\n<p>ì•„ë¬´ê²ƒë„ ì•ˆí•œê²Œ 89% ì¸ë° ã…‹ ì–´ì´ì—†ì–´ ì €ë ‡ê² ì“°ì§€ë§ˆ</p>\n<p>ê·¼ë° ì˜¤ë²„í”¼íŒ… ì¤„ì¼ë•Œ ì¨ë´</p>\n<h3 id=\"overfitting-ì¤„ì´ëŠ”-ë²•\" style=\"position:relative;\"><a href=\"#overfitting-%EC%A4%84%EC%9D%B4%EB%8A%94-%EB%B2%95\" aria-label=\"overfitting ì¤„ì´ëŠ” ë²• permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>overfitting ì¤„ì´ëŠ” ë²•</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">X_train<span class=\"token punctuation\">,</span> X_valid<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> y_valid <span class=\"token operator\">=</span> train_test_split<span class=\"token punctuation\">(</span>train_images<span class=\"token punctuation\">,</span> train_labels<span class=\"token punctuation\">,</span> test_size<span class=\"token operator\">=</span><span class=\"token number\">0.01</span><span class=\"token punctuation\">,</span> random_state<span class=\"token operator\">=</span><span class=\"token number\">101</span><span class=\"token punctuation\">)</span>\nX_train <span class=\"token operator\">=</span> X_train <span class=\"token operator\">/</span> <span class=\"token number\">255.0</span>\nX_valid <span class=\"token operator\">=</span> X_valid <span class=\"token operator\">/</span> <span class=\"token number\">255.0</span>\n\n<span class=\"token comment\">#Dense layerë§Œìœ¼ë¡œ ë§Œë“¤ì–´ ë‚¸ classification ëª¨ë¸ì…ë‹ˆë‹¤.</span>\nmodel <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n    keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span>input_shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">28</span><span class=\"token punctuation\">,</span> <span class=\"token number\">28</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">256</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span><span class=\"token string\">'adam'</span><span class=\"token punctuation\">,</span>loss<span class=\"token operator\">=</span><span class=\"token string\">'sparse_categorical_crossentropy'</span><span class=\"token punctuation\">,</span>\n              metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nhistory<span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">200</span><span class=\"token punctuation\">,</span> batch_size<span class=\"token operator\">=</span><span class=\"token number\">512</span><span class=\"token punctuation\">,</span> validation_data<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>X_valid<span class=\"token punctuation\">,</span> y_valid<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Epoch 1/200\n117/117 [==============================] - 1s 5ms/step - loss: 2.0499 - accuracy: 0.5479 - val_loss: 1.6354 - val_accuracy: 0.5983\nEpoch 2/200\n117/117 [==============================] - 0s 4ms/step - loss: 1.3857 - accuracy: 0.6154 - val_loss: 1.1556 - val_accuracy: 0.6817\nEpoch 3/200\n117/117 [==============================] - 0s 4ms/step - loss: 1.0562 - accuracy: 0.6812 - val_loss: 0.9326 - val_accuracy: 0.7333\nEpoch 4/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.8842 - accuracy: 0.7192 - val_loss: 0.8094 - val_accuracy: 0.7483\nEpoch 5/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.7847 - accuracy: 0.7343 - val_loss: 0.7366 - val_accuracy: 0.7650\nEpoch 6/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.7235 - accuracy: 0.7471 - val_loss: 0.6882 - val_accuracy: 0.7717\nEpoch 7/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.6827 - accuracy: 0.7565 - val_loss: 0.6565 - val_accuracy: 0.7850\nEpoch 8/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.6518 - accuracy: 0.7663 - val_loss: 0.6299 - val_accuracy: 0.7917\nEpoch 9/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.6271 - accuracy: 0.7739 - val_loss: 0.6132 - val_accuracy: 0.7933\nEpoch 10/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.6065 - accuracy: 0.7824 - val_loss: 0.5906 - val_accuracy: 0.7950\nEpoch 11/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.5883 - accuracy: 0.7897 - val_loss: 0.5751 - val_accuracy: 0.7967\nEpoch 12/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.5725 - accuracy: 0.7971 - val_loss: 0.5648 - val_accuracy: 0.8017\nEpoch 13/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.5597 - accuracy: 0.8016 - val_loss: 0.5587 - val_accuracy: 0.8000\nEpoch 14/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.5459 - accuracy: 0.8068 - val_loss: 0.5408 - val_accuracy: 0.8033\nEpoch 15/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.5356 - accuracy: 0.8118 - val_loss: 0.5273 - val_accuracy: 0.8000\nEpoch 16/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.5256 - accuracy: 0.8148 - val_loss: 0.5238 - val_accuracy: 0.8117\nEpoch 17/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.5163 - accuracy: 0.8192 - val_loss: 0.5124 - val_accuracy: 0.8117\nEpoch 18/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.8216 - val_loss: 0.5084 - val_accuracy: 0.8117\nEpoch 19/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.8243 - val_loss: 0.5048 - val_accuracy: 0.8133\nEpoch 20/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4931 - accuracy: 0.8270 - val_loss: 0.4947 - val_accuracy: 0.8183\nEpoch 21/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4868 - accuracy: 0.8289 - val_loss: 0.4901 - val_accuracy: 0.8167\nEpoch 22/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4807 - accuracy: 0.8313 - val_loss: 0.4836 - val_accuracy: 0.8233\nEpoch 23/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4756 - accuracy: 0.8335 - val_loss: 0.4753 - val_accuracy: 0.8250\nEpoch 24/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.8356 - val_loss: 0.4692 - val_accuracy: 0.8267\nEpoch 25/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.8366 - val_loss: 0.4710 - val_accuracy: 0.8283\nEpoch 26/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.8384 - val_loss: 0.4609 - val_accuracy: 0.8267\nEpoch 27/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.8388 - val_loss: 0.4640 - val_accuracy: 0.8250\nEpoch 28/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.8412 - val_loss: 0.4571 - val_accuracy: 0.8333\nEpoch 29/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.8428 - val_loss: 0.4522 - val_accuracy: 0.8333\nEpoch 30/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.8435 - val_loss: 0.4497 - val_accuracy: 0.8317\nEpoch 31/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.8450 - val_loss: 0.4491 - val_accuracy: 0.8317\nEpoch 32/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.8456 - val_loss: 0.4417 - val_accuracy: 0.8333\nEpoch 33/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.8473 - val_loss: 0.4395 - val_accuracy: 0.8367\nEpoch 34/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.8474 - val_loss: 0.4377 - val_accuracy: 0.8333\nEpoch 35/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.8487 - val_loss: 0.4360 - val_accuracy: 0.8317\nEpoch 36/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.8485 - val_loss: 0.4331 - val_accuracy: 0.8367\nEpoch 37/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8499 - val_loss: 0.4331 - val_accuracy: 0.8350\nEpoch 38/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.8499 - val_loss: 0.4268 - val_accuracy: 0.8333\nEpoch 39/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.8517 - val_loss: 0.4282 - val_accuracy: 0.8367\nEpoch 40/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.8526 - val_loss: 0.4243 - val_accuracy: 0.8400\nEpoch 41/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.8534 - val_loss: 0.4206 - val_accuracy: 0.8350\nEpoch 42/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4177 - accuracy: 0.8538 - val_loss: 0.4232 - val_accuracy: 0.8333\nEpoch 43/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4164 - accuracy: 0.8543 - val_loss: 0.4232 - val_accuracy: 0.8383\nEpoch 44/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4138 - accuracy: 0.8559 - val_loss: 0.4183 - val_accuracy: 0.8317\nEpoch 45/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4125 - accuracy: 0.8556 - val_loss: 0.4137 - val_accuracy: 0.8300\nEpoch 46/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4106 - accuracy: 0.8564 - val_loss: 0.4153 - val_accuracy: 0.8317\nEpoch 47/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4095 - accuracy: 0.8566 - val_loss: 0.4131 - val_accuracy: 0.8350\nEpoch 48/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.8581 - val_loss: 0.4158 - val_accuracy: 0.8400\nEpoch 49/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4059 - accuracy: 0.8577 - val_loss: 0.4130 - val_accuracy: 0.8333\nEpoch 50/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4032 - accuracy: 0.8588 - val_loss: 0.4109 - val_accuracy: 0.8367\nEpoch 51/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4019 - accuracy: 0.8594 - val_loss: 0.4092 - val_accuracy: 0.8317\nEpoch 52/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4010 - accuracy: 0.8599 - val_loss: 0.4081 - val_accuracy: 0.8350\nEpoch 53/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3985 - accuracy: 0.8603 - val_loss: 0.4027 - val_accuracy: 0.8333\nEpoch 54/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3972 - accuracy: 0.8607 - val_loss: 0.4011 - val_accuracy: 0.8367\nEpoch 55/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3959 - accuracy: 0.8609 - val_loss: 0.4045 - val_accuracy: 0.8367\nEpoch 56/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3946 - accuracy: 0.8608 - val_loss: 0.3998 - val_accuracy: 0.8383\nEpoch 57/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3925 - accuracy: 0.8622 - val_loss: 0.3959 - val_accuracy: 0.8367\nEpoch 58/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3920 - accuracy: 0.8624 - val_loss: 0.3958 - val_accuracy: 0.8383\nEpoch 59/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3905 - accuracy: 0.8628 - val_loss: 0.3966 - val_accuracy: 0.8350\nEpoch 60/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3898 - accuracy: 0.8634 - val_loss: 0.3964 - val_accuracy: 0.8417\nEpoch 61/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3877 - accuracy: 0.8642 - val_loss: 0.3943 - val_accuracy: 0.8333\nEpoch 62/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3858 - accuracy: 0.8643 - val_loss: 0.3931 - val_accuracy: 0.8450\nEpoch 63/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3848 - accuracy: 0.8643 - val_loss: 0.3928 - val_accuracy: 0.8433\nEpoch 64/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3840 - accuracy: 0.8642 - val_loss: 0.3893 - val_accuracy: 0.8350\nEpoch 65/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3822 - accuracy: 0.8652 - val_loss: 0.3940 - val_accuracy: 0.8367\nEpoch 66/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3828 - accuracy: 0.8659 - val_loss: 0.3843 - val_accuracy: 0.8367\nEpoch 67/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3800 - accuracy: 0.8664 - val_loss: 0.3837 - val_accuracy: 0.8383\nEpoch 68/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3787 - accuracy: 0.8665 - val_loss: 0.3838 - val_accuracy: 0.8367\nEpoch 69/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3773 - accuracy: 0.8672 - val_loss: 0.3854 - val_accuracy: 0.8367\nEpoch 70/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3774 - accuracy: 0.8673 - val_loss: 0.3827 - val_accuracy: 0.8383\nEpoch 71/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3752 - accuracy: 0.8684 - val_loss: 0.3791 - val_accuracy: 0.8367\nEpoch 72/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3738 - accuracy: 0.8686 - val_loss: 0.3844 - val_accuracy: 0.8467\nEpoch 73/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3740 - accuracy: 0.8677 - val_loss: 0.3817 - val_accuracy: 0.8467\nEpoch 74/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3729 - accuracy: 0.8684 - val_loss: 0.3797 - val_accuracy: 0.8417\nEpoch 75/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3706 - accuracy: 0.8687 - val_loss: 0.3812 - val_accuracy: 0.8467\nEpoch 76/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3701 - accuracy: 0.8693 - val_loss: 0.3757 - val_accuracy: 0.8483\nEpoch 77/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3689 - accuracy: 0.8693 - val_loss: 0.3788 - val_accuracy: 0.8450\nEpoch 78/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3684 - accuracy: 0.8705 - val_loss: 0.3774 - val_accuracy: 0.8483\nEpoch 79/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3680 - accuracy: 0.8703 - val_loss: 0.3738 - val_accuracy: 0.8433\nEpoch 80/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3657 - accuracy: 0.8711 - val_loss: 0.3756 - val_accuracy: 0.8450\nEpoch 81/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3648 - accuracy: 0.8716 - val_loss: 0.3760 - val_accuracy: 0.8450\nEpoch 82/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3656 - accuracy: 0.8708 - val_loss: 0.3768 - val_accuracy: 0.8467\nEpoch 83/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3628 - accuracy: 0.8719 - val_loss: 0.3718 - val_accuracy: 0.8467\nEpoch 84/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3612 - accuracy: 0.8729 - val_loss: 0.3743 - val_accuracy: 0.8450\nEpoch 85/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3608 - accuracy: 0.8727 - val_loss: 0.3700 - val_accuracy: 0.8417\nEpoch 86/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3602 - accuracy: 0.8727 - val_loss: 0.3771 - val_accuracy: 0.8467\nEpoch 87/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3612 - accuracy: 0.8727 - val_loss: 0.3671 - val_accuracy: 0.8450\nEpoch 88/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3577 - accuracy: 0.8743 - val_loss: 0.3657 - val_accuracy: 0.8450\nEpoch 89/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3569 - accuracy: 0.8745 - val_loss: 0.3677 - val_accuracy: 0.8500\nEpoch 90/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3559 - accuracy: 0.8743 - val_loss: 0.3750 - val_accuracy: 0.8483\nEpoch 91/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3563 - accuracy: 0.8748 - val_loss: 0.3626 - val_accuracy: 0.8400\nEpoch 92/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3541 - accuracy: 0.8749 - val_loss: 0.3644 - val_accuracy: 0.8433\nEpoch 93/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3536 - accuracy: 0.8752 - val_loss: 0.3652 - val_accuracy: 0.8467\nEpoch 94/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3527 - accuracy: 0.8754 - val_loss: 0.3644 - val_accuracy: 0.8483\nEpoch 95/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3514 - accuracy: 0.8757 - val_loss: 0.3615 - val_accuracy: 0.8500\nEpoch 96/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3521 - accuracy: 0.8755 - val_loss: 0.3620 - val_accuracy: 0.8550\nEpoch 97/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3505 - accuracy: 0.8756 - val_loss: 0.3613 - val_accuracy: 0.8467\nEpoch 98/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3501 - accuracy: 0.8766 - val_loss: 0.3613 - val_accuracy: 0.8483\nEpoch 99/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3491 - accuracy: 0.8769 - val_loss: 0.3630 - val_accuracy: 0.8533\nEpoch 100/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3472 - accuracy: 0.8775 - val_loss: 0.3580 - val_accuracy: 0.8483\nEpoch 101/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3466 - accuracy: 0.8775 - val_loss: 0.3561 - val_accuracy: 0.8433\nEpoch 102/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3466 - accuracy: 0.8774 - val_loss: 0.3581 - val_accuracy: 0.8533\nEpoch 103/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3458 - accuracy: 0.8783 - val_loss: 0.3562 - val_accuracy: 0.8467\nEpoch 104/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3452 - accuracy: 0.8774 - val_loss: 0.3581 - val_accuracy: 0.8417\nEpoch 105/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3444 - accuracy: 0.8783 - val_loss: 0.3597 - val_accuracy: 0.8517\nEpoch 106/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3435 - accuracy: 0.8784 - val_loss: 0.3579 - val_accuracy: 0.8567\nEpoch 107/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3440 - accuracy: 0.8782 - val_loss: 0.3545 - val_accuracy: 0.8550\nEpoch 108/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3414 - accuracy: 0.8794 - val_loss: 0.3543 - val_accuracy: 0.8467\nEpoch 109/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3405 - accuracy: 0.8798 - val_loss: 0.3526 - val_accuracy: 0.8533\nEpoch 110/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3414 - accuracy: 0.8797 - val_loss: 0.3543 - val_accuracy: 0.8483\nEpoch 111/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3400 - accuracy: 0.8797 - val_loss: 0.3533 - val_accuracy: 0.8517\nEpoch 112/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3379 - accuracy: 0.8805 - val_loss: 0.3552 - val_accuracy: 0.8533\nEpoch 113/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3375 - accuracy: 0.8809 - val_loss: 0.3574 - val_accuracy: 0.8533\nEpoch 114/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3399 - accuracy: 0.8790 - val_loss: 0.3517 - val_accuracy: 0.8550\nEpoch 115/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3369 - accuracy: 0.8805 - val_loss: 0.3508 - val_accuracy: 0.8583\nEpoch 116/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3371 - accuracy: 0.8808 - val_loss: 0.3524 - val_accuracy: 0.8533\nEpoch 117/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3347 - accuracy: 0.8813 - val_loss: 0.3503 - val_accuracy: 0.8500\nEpoch 118/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3349 - accuracy: 0.8811 - val_loss: 0.3475 - val_accuracy: 0.8517\nEpoch 119/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3335 - accuracy: 0.8820 - val_loss: 0.3498 - val_accuracy: 0.8517\nEpoch 120/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3327 - accuracy: 0.8825 - val_loss: 0.3527 - val_accuracy: 0.8567\nEpoch 121/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3320 - accuracy: 0.8834 - val_loss: 0.3501 - val_accuracy: 0.8567\nEpoch 122/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3321 - accuracy: 0.8826 - val_loss: 0.3531 - val_accuracy: 0.8550\nEpoch 123/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3318 - accuracy: 0.8824 - val_loss: 0.3479 - val_accuracy: 0.8533\nEpoch 124/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3311 - accuracy: 0.8824 - val_loss: 0.3496 - val_accuracy: 0.8583\nEpoch 125/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3293 - accuracy: 0.8831 - val_loss: 0.3545 - val_accuracy: 0.8550\nEpoch 126/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3290 - accuracy: 0.8835 - val_loss: 0.3524 - val_accuracy: 0.8533\nEpoch 127/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3283 - accuracy: 0.8837 - val_loss: 0.3505 - val_accuracy: 0.8583\nEpoch 128/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3272 - accuracy: 0.8839 - val_loss: 0.3498 - val_accuracy: 0.8583\nEpoch 129/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3272 - accuracy: 0.8844 - val_loss: 0.3493 - val_accuracy: 0.8550\nEpoch 130/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3264 - accuracy: 0.8839 - val_loss: 0.3470 - val_accuracy: 0.8583\nEpoch 131/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3256 - accuracy: 0.8845 - val_loss: 0.3463 - val_accuracy: 0.8583\nEpoch 132/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3251 - accuracy: 0.8844 - val_loss: 0.3508 - val_accuracy: 0.8567\nEpoch 133/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3260 - accuracy: 0.8839 - val_loss: 0.3498 - val_accuracy: 0.8617\nEpoch 134/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3241 - accuracy: 0.8850 - val_loss: 0.3430 - val_accuracy: 0.8600\nEpoch 135/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3235 - accuracy: 0.8855 - val_loss: 0.3427 - val_accuracy: 0.8600\nEpoch 136/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3233 - accuracy: 0.8852 - val_loss: 0.3445 - val_accuracy: 0.8650\nEpoch 137/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3215 - accuracy: 0.8857 - val_loss: 0.3410 - val_accuracy: 0.8600\nEpoch 138/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3216 - accuracy: 0.8857 - val_loss: 0.3469 - val_accuracy: 0.8633\nEpoch 139/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3208 - accuracy: 0.8859 - val_loss: 0.3421 - val_accuracy: 0.8583\nEpoch 140/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3204 - accuracy: 0.8858 - val_loss: 0.3437 - val_accuracy: 0.8583\nEpoch 141/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3201 - accuracy: 0.8862 - val_loss: 0.3454 - val_accuracy: 0.8633\nEpoch 142/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3190 - accuracy: 0.8865 - val_loss: 0.3467 - val_accuracy: 0.8617\nEpoch 143/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3192 - accuracy: 0.8865 - val_loss: 0.3463 - val_accuracy: 0.8667\nEpoch 144/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3196 - accuracy: 0.8865 - val_loss: 0.3384 - val_accuracy: 0.8667\nEpoch 145/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3172 - accuracy: 0.8873 - val_loss: 0.3429 - val_accuracy: 0.8683\nEpoch 146/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3168 - accuracy: 0.8885 - val_loss: 0.3391 - val_accuracy: 0.8583\nEpoch 147/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3158 - accuracy: 0.8880 - val_loss: 0.3397 - val_accuracy: 0.8617\nEpoch 148/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3147 - accuracy: 0.8887 - val_loss: 0.3447 - val_accuracy: 0.8617\nEpoch 149/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3145 - accuracy: 0.8885 - val_loss: 0.3387 - val_accuracy: 0.8633\nEpoch 150/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3140 - accuracy: 0.8889 - val_loss: 0.3411 - val_accuracy: 0.8633\nEpoch 151/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3132 - accuracy: 0.8884 - val_loss: 0.3403 - val_accuracy: 0.8667\nEpoch 152/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3125 - accuracy: 0.8894 - val_loss: 0.3358 - val_accuracy: 0.8617\nEpoch 153/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3122 - accuracy: 0.8892 - val_loss: 0.3364 - val_accuracy: 0.8667\nEpoch 154/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3114 - accuracy: 0.8899 - val_loss: 0.3369 - val_accuracy: 0.8683\nEpoch 155/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3114 - accuracy: 0.8893 - val_loss: 0.3444 - val_accuracy: 0.8683\nEpoch 156/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3112 - accuracy: 0.8894 - val_loss: 0.3356 - val_accuracy: 0.8667\nEpoch 157/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3100 - accuracy: 0.8895 - val_loss: 0.3314 - val_accuracy: 0.8650\nEpoch 158/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3097 - accuracy: 0.8901 - val_loss: 0.3373 - val_accuracy: 0.8650\nEpoch 159/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3094 - accuracy: 0.8899 - val_loss: 0.3380 - val_accuracy: 0.8633\nEpoch 160/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3099 - accuracy: 0.8893 - val_loss: 0.3372 - val_accuracy: 0.8633\nEpoch 161/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3090 - accuracy: 0.8902 - val_loss: 0.3355 - val_accuracy: 0.8633\nEpoch 162/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3077 - accuracy: 0.8906 - val_loss: 0.3374 - val_accuracy: 0.8567\nEpoch 163/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3084 - accuracy: 0.8902 - val_loss: 0.3312 - val_accuracy: 0.8667\nEpoch 164/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3075 - accuracy: 0.8908 - val_loss: 0.3356 - val_accuracy: 0.8717\nEpoch 165/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3059 - accuracy: 0.8901 - val_loss: 0.3358 - val_accuracy: 0.8683\nEpoch 166/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3060 - accuracy: 0.8913 - val_loss: 0.3341 - val_accuracy: 0.8667\nEpoch 167/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3043 - accuracy: 0.8917 - val_loss: 0.3319 - val_accuracy: 0.8617\nEpoch 168/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3042 - accuracy: 0.8916 - val_loss: 0.3283 - val_accuracy: 0.8617\nEpoch 169/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3039 - accuracy: 0.8924 - val_loss: 0.3327 - val_accuracy: 0.8667\nEpoch 170/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3034 - accuracy: 0.8919 - val_loss: 0.3290 - val_accuracy: 0.8733\nEpoch 171/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3031 - accuracy: 0.8923 - val_loss: 0.3332 - val_accuracy: 0.8717\nEpoch 172/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3019 - accuracy: 0.8930 - val_loss: 0.3301 - val_accuracy: 0.8683\nEpoch 173/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3019 - accuracy: 0.8924 - val_loss: 0.3324 - val_accuracy: 0.8650\nEpoch 174/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3011 - accuracy: 0.8934 - val_loss: 0.3306 - val_accuracy: 0.8667\nEpoch 175/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3009 - accuracy: 0.8930 - val_loss: 0.3310 - val_accuracy: 0.8617\nEpoch 176/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.2996 - accuracy: 0.8929 - val_loss: 0.3307 - val_accuracy: 0.8650\nEpoch 177/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.2995 - accuracy: 0.8933 - val_loss: 0.3284 - val_accuracy: 0.8650\nEpoch 178/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.2993 - accuracy: 0.8935 - val_loss: 0.3299 - val_accuracy: 0.8633\nEpoch 179/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.2994 - accuracy: 0.8937 - val_loss: 0.3336 - val_accuracy: 0.8700\nEpoch 180/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.2975 - accuracy: 0.8942 - val_loss: 0.3276 - val_accuracy: 0.8650\nEpoch 181/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.2981 - accuracy: 0.8940 - val_loss: 0.3343 - val_accuracy: 0.8683\nEpoch 182/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.2969 - accuracy: 0.8949 - val_loss: 0.3326 - val_accuracy: 0.8683\nEpoch 183/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.2970 - accuracy: 0.8946 - val_loss: 0.3276 - val_accuracy: 0.8600\nEpoch 184/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.2963 - accuracy: 0.8944 - val_loss: 0.3316 - val_accuracy: 0.8750\nEpoch 185/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.2952 - accuracy: 0.8941 - val_loss: 0.3219 - val_accuracy: 0.8700\nEpoch 186/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.2958 - accuracy: 0.8951 - val_loss: 0.3301 - val_accuracy: 0.8650\nEpoch 187/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.2956 - accuracy: 0.8948 - val_loss: 0.3262 - val_accuracy: 0.8700\nEpoch 188/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.2939 - accuracy: 0.8950 - val_loss: 0.3255 - val_accuracy: 0.8667\nEpoch 189/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.2932 - accuracy: 0.8961 - val_loss: 0.3340 - val_accuracy: 0.8667\nEpoch 190/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.2948 - accuracy: 0.8954 - val_loss: 0.3298 - val_accuracy: 0.8667\nEpoch 191/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.2950 - accuracy: 0.8945 - val_loss: 0.3254 - val_accuracy: 0.8600\nEpoch 192/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.2919 - accuracy: 0.8964 - val_loss: 0.3252 - val_accuracy: 0.8650\nEpoch 193/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.2915 - accuracy: 0.8963 - val_loss: 0.3253 - val_accuracy: 0.8700\nEpoch 194/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.2908 - accuracy: 0.8963 - val_loss: 0.3237 - val_accuracy: 0.8700\nEpoch 195/200\n117/117 [==============================] - 0s 2ms/step - loss: 0.2913 - accuracy: 0.8959 - val_loss: 0.3282 - val_accuracy: 0.8667\nEpoch 196/200\n117/117 [==============================] - 0s 2ms/step - loss: 0.2914 - accuracy: 0.8960 - val_loss: 0.3261 - val_accuracy: 0.8683\nEpoch 197/200\n117/117 [==============================] - 0s 2ms/step - loss: 0.2895 - accuracy: 0.8966 - val_loss: 0.3250 - val_accuracy: 0.8750\nEpoch 198/200\n117/117 [==============================] - 0s 2ms/step - loss: 0.2899 - accuracy: 0.8969 - val_loss: 0.3268 - val_accuracy: 0.8717\nEpoch 199/200\n117/117 [==============================] - 0s 2ms/step - loss: 0.2881 - accuracy: 0.8974 - val_loss: 0.3265 - val_accuracy: 0.8700\nEpoch 200/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.2900 - accuracy: 0.8965 - val_loss: 0.3265 - val_accuracy: 0.8633</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># loss ê°’ì„ plot í•´ë³´ê² ìŠµë‹ˆë‹¤.</span>\ny_vloss <span class=\"token operator\">=</span> history<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'val_loss'</span><span class=\"token punctuation\">]</span>\ny_loss <span class=\"token operator\">=</span> history<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'loss'</span><span class=\"token punctuation\">]</span>\nx_len <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>arange<span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>y_loss<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>x_len<span class=\"token punctuation\">,</span> y_vloss<span class=\"token punctuation\">,</span> marker<span class=\"token operator\">=</span><span class=\"token string\">'.'</span><span class=\"token punctuation\">,</span> c<span class=\"token operator\">=</span><span class=\"token string\">'red'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">\"Validation-set Loss\"</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>x_len<span class=\"token punctuation\">,</span> y_loss<span class=\"token punctuation\">,</span> marker<span class=\"token operator\">=</span><span class=\"token string\">'.'</span><span class=\"token punctuation\">,</span> c<span class=\"token operator\">=</span><span class=\"token string\">'blue'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">\"Train-set Loss\"</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>legend<span class=\"token punctuation\">(</span>loc<span class=\"token operator\">=</span><span class=\"token string\">'upper right'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>grid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'Loss graph without dropout layer'</span><span class=\"token punctuation\">)</span> \nplt<span class=\"token punctuation\">.</span>ylim<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">'epoch'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'loss'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 386px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 72.22222222222221%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsTAAALEwEAmpwYAAAC7klEQVQ4y32Uz28TVxDHn6ASEkW9IXHoLRwQEvQMhxxStUDVgIAL/0FQfnBIlL+jaitV6oFLxAou9IKURGuTYJw4dSqL4liV4gbbDZs0trPL2l7vvt9fNOsk5ACs9NHMm519b958R8suXfzmBGPsy2d/LHz9IrN6YaNSPu84zuXp6elvJycnr42Pj9+Ympr6fuz+2A9pbGry2sSDiRuzs7PfzczMXM/lchc3NzfPl8vlC8vLy+dYWKmdBMB2q/Vne/UQieBhkiQ9IUS33+9H5HPOuzxJupxi78Jer/G212g0euWNcm9ra6tXq9XC7e1t1Ov1hwzACdqw02o///9NH8Zaa42FtRbGmCNLABZxpNDeVfA8D9VqFbVajXzLOUez2XzM5ufnv2CMnd7f9zM7//gQUkgppSGEEPbApqS+FEYbaZRSKQe5UmuNVqv16KjCbqebabwKYKxR5hMVHo8djxtjFAAEQeCwOI5PUoVRHGT/LQXYaUQK0BBCgnMxIOEQnEMKAcEFpJQpgtYDlFKKKnTY0NDQOaowTiI3iQ1eLnRUe5cDoJ5pHH9sGrWpbyygtIUyliwZ+L7vsJGRkTOMsVNB8C5D6Z2Aqz9zEVbmA2zkfVRWfWwVdhBWPcStAJHfA+/GMEkfUBFg+oQCONrtlkM9TAnDMGu0gbFK0cZ0+s62RL3SxWZxH8WFNgqPayj89heKP6+i9MtL/P3rMsq/5/Hqp4yqPn2N5m7TYaVSiVRmVCEpRf2QQlmllAWkHVzuUAZr0yMBG0aw3p61b/dg//O03GsaNJtth3melw52p9Nx6ROttTQHj1LaaDWwA18bJZWxdBUQ6sBqSR32/f0PYxMEwQtSigb0IyqmHMYO39MEHE7DQOX2EzY8PExj85Xrulcrlcro2traj4VCYZTI5/M3i8Vius5ms7dzudwt13XvrKys3FxcXLxL66Wlpdv5fH7Udd17c3NzV9j6+jq18Eicj6G1ppSz9BP5XB7xHjFQo2rcvFL8AAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/7659e0a64c70ee324e2c8cf47f322541/7bc0b/output_37_0.png\"\n        srcset=\"/static/7659e0a64c70ee324e2c8cf47f322541/e9ff0/output_37_0.png 180w,\n/static/7659e0a64c70ee324e2c8cf47f322541/f21e7/output_37_0.png 360w,\n/static/7659e0a64c70ee324e2c8cf47f322541/7bc0b/output_37_0.png 386w\"\n        sizes=\"(max-width: 386px) 100vw, 386px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># accuracy ê°’ì„ plot í•´ë³´ê² ìŠµë‹ˆë‹¤.</span>\ny_vacc <span class=\"token operator\">=</span> history<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'val_accuracy'</span><span class=\"token punctuation\">]</span>\ny_acc <span class=\"token operator\">=</span> history<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span>\nx_len <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>arange<span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>y_acc<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>x_len<span class=\"token punctuation\">,</span> y_vacc<span class=\"token punctuation\">,</span> marker<span class=\"token operator\">=</span><span class=\"token string\">'.'</span><span class=\"token punctuation\">,</span> c<span class=\"token operator\">=</span><span class=\"token string\">'red'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">\"Validation-set accuracy\"</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>x_len<span class=\"token punctuation\">,</span> y_acc<span class=\"token punctuation\">,</span> marker<span class=\"token operator\">=</span><span class=\"token string\">'.'</span><span class=\"token punctuation\">,</span> c<span class=\"token operator\">=</span><span class=\"token string\">'blue'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">\"Train-set accuracy\"</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>legend<span class=\"token punctuation\">(</span>loc<span class=\"token operator\">=</span><span class=\"token string\">'lower right'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>grid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylim<span class=\"token punctuation\">(</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span> \nplt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'Accuracy graph without dropout layer'</span><span class=\"token punctuation\">)</span> \nplt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">'epoch'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 386px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 72.22222222222221%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsTAAALEwEAmpwYAAAC/klEQVQ4y32U32sUVxTHL5FCS7HQh4JgEARBfAvkSSgItraFGiX2pX9BXrIlJOgfYV98Kn0SIrjYYl62GtzMTJK1kZ1sW8lq0tWa7HZ1dxnd3dkfk5nZmXvvuV+5k2QNRXrhw/fMzOGcc8+ce9n4+PgIY+xj0zRHi8Xi6Ww2e2ZmZubC7Ozsl1qnp6e/SaVSX2vVzM3NfTE1NfVtKvXDV5qrV6+d39h4csq2C2csyzrGOOdHALBWq3UvjmOEYdiLosiLotjz/cAP/NAPg4GXEGoNvUE42I2jgRdHwS7XxEFX8AEcx7nJAIzogJ7nLQOAEFKBJACNAKDwvsUB7HKgHwO9CMoXgOt27rB0Ov0BY+wj13VNwXUAyQMJcrqgWhPq7y2u1nMe5R+0yP6tQXamToXMKyrceU72rS1a/7lA9k8FvrVQglNzbusKE7y+Z+rMzx61hP3jQ2xcz2LzhoFaOofO/TX07i6ht2Cgt2QjePgH5J+PgdIm8M9T4MWmQLOOTquVZmNjY58yxj4Jop5V+b2Kv359JqjbBsIO4LtA7INkBIIE7TeC9psR7TMARAyg2Wym2ejx4yd0hX7HNUqLFe2sffc6qACpIYKUEiQkJOdQB7YQoMQWQhHBdd00Ozl64hhj7MM3z6tG/YUHQVLwmEMIAc7f6WFb63++C52wpbeM/t5frj6tmX3HB+ncOruUifOBDm3Oh+8OBU8CttvtNMvfLR5hjI1UijWr5/iQSgjOudK7OKyJLaXiUiqovUVEB3Cl1F6Fj1YbOiCrVvqG11fJ2JCkZEkphyqVorjXp9h5Q9WXL+nfSoXq9To1Gg2tvNFo6MG+PRxs53U3F4YCcRwNe6ZPzgFCcHTbAV7XA5TLO9jZ3kG5XMb29jaq1ao+YTrgL+zcuc91hUdXVoyzpdLmRD5vX8zn8xOatbW1S4VCIXm2LGtyeTV3+X526UpudfVSJpP5zjTNy4uLi5OWZU0YhvH9/Pz8Wba+vqx3PBzw9yGl1C6f6Uvk//w0bwHIlJYIkoZ5JQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/14349f49de542fb4d16446c01a574836/7bc0b/output_38_0.png\"\n        srcset=\"/static/14349f49de542fb4d16446c01a574836/e9ff0/output_38_0.png 180w,\n/static/14349f49de542fb4d16446c01a574836/f21e7/output_38_0.png 360w,\n/static/14349f49de542fb4d16446c01a574836/7bc0b/output_38_0.png 386w\"\n        sizes=\"(max-width: 386px) 100vw, 386px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>ì´ë ‡ê²Œ 200ë²ˆ epochs í•˜ë©´ ì–´ëŠìˆœê°„(loss í•œ 100ë¶€í„° accuracy í•œ 25ë¶€í„°,,)ë¶€í„° train loss ëŠ” ê³„ì† ë–¨ì–´ì§€ì§€ë§Œ val loss ëŠ” ë”ì´ìƒ ì›€ì§ì´ì§€ ì•ŠëŠ”ë‹¤â€¦</p>\n<p>ã…œã…œ ë„˜í•´</p>\n<p>ì´ëŸ´ë•Œ ë“œëì•„ì›ƒìœ¼ë¡œ ì˜¤ë²„í”¼íŒ… ë°©ì§€</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">model <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n    keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span>input_shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">28</span><span class=\"token punctuation\">,</span> <span class=\"token number\">28</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">256</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token comment\"># ì—¬ê¸°ì— dropout layerë¥¼ ì¶”ê°€í•´ë³´ì•˜ìŠµë‹ˆë‹¤. ë‚˜ë¨¸ì§€ layerëŠ” ìœ„ì˜ ì‹¤ìŠµê³¼ ê°™ìŠµë‹ˆë‹¤. </span>\n    keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dropout<span class=\"token punctuation\">(</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span><span class=\"token string\">'adam'</span><span class=\"token punctuation\">,</span>loss<span class=\"token operator\">=</span><span class=\"token string\">'sparse_categorical_crossentropy'</span><span class=\"token punctuation\">,</span>\n              metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nhistory<span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">200</span><span class=\"token punctuation\">,</span> batch_size<span class=\"token operator\">=</span><span class=\"token number\">512</span><span class=\"token punctuation\">,</span> validation_data<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>X_valid<span class=\"token punctuation\">,</span> y_valid<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Epoch 1/200\n117/117 [==============================] - 1s 7ms/step - loss: 2.0802 - accuracy: 0.4763 - val_loss: 1.7029 - val_accuracy: 0.5300\nEpoch 2/200\n117/117 [==============================] - 0s 3ms/step - loss: 1.4692 - accuracy: 0.5660 - val_loss: 1.2217 - val_accuracy: 0.6350\nEpoch 3/200\n117/117 [==============================] - 0s 4ms/step - loss: 1.1566 - accuracy: 0.6223 - val_loss: 1.0075 - val_accuracy: 0.7083\nEpoch 4/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.9942 - accuracy: 0.6671 - val_loss: 0.8747 - val_accuracy: 0.7533\nEpoch 5/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.8909 - accuracy: 0.6978 - val_loss: 0.7917 - val_accuracy: 0.7600\nEpoch 6/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.8228 - accuracy: 0.7125 - val_loss: 0.7359 - val_accuracy: 0.7567\nEpoch 7/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.7727 - accuracy: 0.7269 - val_loss: 0.6952 - val_accuracy: 0.7767\nEpoch 8/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.7379 - accuracy: 0.7364 - val_loss: 0.6664 - val_accuracy: 0.7833\nEpoch 9/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.7098 - accuracy: 0.7456 - val_loss: 0.6425 - val_accuracy: 0.7917\nEpoch 10/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.6862 - accuracy: 0.7520 - val_loss: 0.6225 - val_accuracy: 0.7917\nEpoch 11/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.6682 - accuracy: 0.7576 - val_loss: 0.6038 - val_accuracy: 0.7967\nEpoch 12/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.6491 - accuracy: 0.7655 - val_loss: 0.5924 - val_accuracy: 0.7967\nEpoch 13/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.6348 - accuracy: 0.7712 - val_loss: 0.5801 - val_accuracy: 0.7933\nEpoch 14/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.6212 - accuracy: 0.7761 - val_loss: 0.5685 - val_accuracy: 0.7950\nEpoch 15/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.6077 - accuracy: 0.7821 - val_loss: 0.5560 - val_accuracy: 0.7967\nEpoch 16/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.5986 - accuracy: 0.7863 - val_loss: 0.5497 - val_accuracy: 0.8050\nEpoch 17/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.5861 - accuracy: 0.7915 - val_loss: 0.5371 - val_accuracy: 0.8017\nEpoch 18/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.5760 - accuracy: 0.7923 - val_loss: 0.5313 - val_accuracy: 0.8033\nEpoch 19/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.5669 - accuracy: 0.7980 - val_loss: 0.5252 - val_accuracy: 0.7983\nEpoch 20/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.5606 - accuracy: 0.7998 - val_loss: 0.5152 - val_accuracy: 0.8067\nEpoch 21/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.5500 - accuracy: 0.8034 - val_loss: 0.5098 - val_accuracy: 0.8117\nEpoch 22/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.5430 - accuracy: 0.8059 - val_loss: 0.5044 - val_accuracy: 0.8133\nEpoch 23/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.5370 - accuracy: 0.8086 - val_loss: 0.4973 - val_accuracy: 0.8117\nEpoch 24/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.5300 - accuracy: 0.8109 - val_loss: 0.4926 - val_accuracy: 0.8133\nEpoch 25/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.5257 - accuracy: 0.8133 - val_loss: 0.4880 - val_accuracy: 0.8167\nEpoch 26/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.5208 - accuracy: 0.8151 - val_loss: 0.4803 - val_accuracy: 0.8217\nEpoch 27/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.5144 - accuracy: 0.8182 - val_loss: 0.4767 - val_accuracy: 0.8183\nEpoch 28/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.5101 - accuracy: 0.8194 - val_loss: 0.4730 - val_accuracy: 0.8200\nEpoch 29/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.8202 - val_loss: 0.4692 - val_accuracy: 0.8267\nEpoch 30/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.5016 - accuracy: 0.8223 - val_loss: 0.4649 - val_accuracy: 0.8250\nEpoch 31/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4949 - accuracy: 0.8246 - val_loss: 0.4627 - val_accuracy: 0.8217\nEpoch 32/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4908 - accuracy: 0.8260 - val_loss: 0.4581 - val_accuracy: 0.8200\nEpoch 33/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4880 - accuracy: 0.8282 - val_loss: 0.4540 - val_accuracy: 0.8267\nEpoch 34/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4853 - accuracy: 0.8270 - val_loss: 0.4477 - val_accuracy: 0.8250\nEpoch 35/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4800 - accuracy: 0.8301 - val_loss: 0.4479 - val_accuracy: 0.8267\nEpoch 36/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4784 - accuracy: 0.8317 - val_loss: 0.4423 - val_accuracy: 0.8317\nEpoch 37/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4746 - accuracy: 0.8326 - val_loss: 0.4429 - val_accuracy: 0.8283\nEpoch 38/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.8336 - val_loss: 0.4392 - val_accuracy: 0.8350\nEpoch 39/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.8346 - val_loss: 0.4364 - val_accuracy: 0.8333\nEpoch 40/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.8361 - val_loss: 0.4352 - val_accuracy: 0.8333\nEpoch 41/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.8360 - val_loss: 0.4318 - val_accuracy: 0.8367\nEpoch 42/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.8378 - val_loss: 0.4305 - val_accuracy: 0.8317\nEpoch 43/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.8379 - val_loss: 0.4267 - val_accuracy: 0.8317\nEpoch 44/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.8400 - val_loss: 0.4250 - val_accuracy: 0.8317\nEpoch 45/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4527 - accuracy: 0.8407 - val_loss: 0.4234 - val_accuracy: 0.8350\nEpoch 46/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.8398 - val_loss: 0.4185 - val_accuracy: 0.8350\nEpoch 47/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.8415 - val_loss: 0.4165 - val_accuracy: 0.8333\nEpoch 48/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.8418 - val_loss: 0.4174 - val_accuracy: 0.8367\nEpoch 49/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.8442 - val_loss: 0.4194 - val_accuracy: 0.8317\nEpoch 50/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4414 - accuracy: 0.8431 - val_loss: 0.4114 - val_accuracy: 0.8383\nEpoch 51/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.8454 - val_loss: 0.4127 - val_accuracy: 0.8350\nEpoch 52/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.8446 - val_loss: 0.4082 - val_accuracy: 0.8400\nEpoch 53/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.8454 - val_loss: 0.4059 - val_accuracy: 0.8383\nEpoch 54/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.8479 - val_loss: 0.4040 - val_accuracy: 0.8367\nEpoch 55/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.8481 - val_loss: 0.4016 - val_accuracy: 0.8367\nEpoch 56/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4268 - accuracy: 0.8489 - val_loss: 0.4070 - val_accuracy: 0.8400\nEpoch 57/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.8487 - val_loss: 0.4012 - val_accuracy: 0.8367\nEpoch 58/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.8498 - val_loss: 0.3998 - val_accuracy: 0.8383\nEpoch 59/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.8508 - val_loss: 0.3976 - val_accuracy: 0.8333\nEpoch 60/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.8501 - val_loss: 0.3967 - val_accuracy: 0.8383\nEpoch 61/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.8499 - val_loss: 0.3960 - val_accuracy: 0.8350\nEpoch 62/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.8510 - val_loss: 0.3976 - val_accuracy: 0.8367\nEpoch 63/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.8520 - val_loss: 0.3940 - val_accuracy: 0.8400\nEpoch 64/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4154 - accuracy: 0.8527 - val_loss: 0.3922 - val_accuracy: 0.8350\nEpoch 65/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4156 - accuracy: 0.8531 - val_loss: 0.3937 - val_accuracy: 0.8383\nEpoch 66/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4129 - accuracy: 0.8537 - val_loss: 0.3896 - val_accuracy: 0.8400\nEpoch 67/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4136 - accuracy: 0.8532 - val_loss: 0.3890 - val_accuracy: 0.8417\nEpoch 68/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4104 - accuracy: 0.8547 - val_loss: 0.3869 - val_accuracy: 0.8383\nEpoch 69/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8564 - val_loss: 0.3861 - val_accuracy: 0.8467\nEpoch 70/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4075 - accuracy: 0.8553 - val_loss: 0.3848 - val_accuracy: 0.8417\nEpoch 71/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4047 - accuracy: 0.8579 - val_loss: 0.3820 - val_accuracy: 0.8433\nEpoch 72/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4054 - accuracy: 0.8558 - val_loss: 0.3827 - val_accuracy: 0.8400\nEpoch 73/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4042 - accuracy: 0.8575 - val_loss: 0.3828 - val_accuracy: 0.8400\nEpoch 74/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4020 - accuracy: 0.8579 - val_loss: 0.3800 - val_accuracy: 0.8433\nEpoch 75/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4001 - accuracy: 0.8583 - val_loss: 0.3794 - val_accuracy: 0.8450\nEpoch 76/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4005 - accuracy: 0.8568 - val_loss: 0.3768 - val_accuracy: 0.8450\nEpoch 77/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4001 - accuracy: 0.8576 - val_loss: 0.3765 - val_accuracy: 0.8467\nEpoch 78/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3980 - accuracy: 0.8592 - val_loss: 0.3773 - val_accuracy: 0.8467\nEpoch 79/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3976 - accuracy: 0.8593 - val_loss: 0.3762 - val_accuracy: 0.8517\nEpoch 80/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3961 - accuracy: 0.8594 - val_loss: 0.3729 - val_accuracy: 0.8450\nEpoch 81/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3945 - accuracy: 0.8586 - val_loss: 0.3714 - val_accuracy: 0.8433\nEpoch 82/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3916 - accuracy: 0.8619 - val_loss: 0.3736 - val_accuracy: 0.8467\nEpoch 83/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3925 - accuracy: 0.8623 - val_loss: 0.3728 - val_accuracy: 0.8433\nEpoch 84/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3913 - accuracy: 0.8614 - val_loss: 0.3716 - val_accuracy: 0.8483\nEpoch 85/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3890 - accuracy: 0.8621 - val_loss: 0.3704 - val_accuracy: 0.8433\nEpoch 86/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3872 - accuracy: 0.8621 - val_loss: 0.3699 - val_accuracy: 0.8450\nEpoch 87/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3875 - accuracy: 0.8614 - val_loss: 0.3710 - val_accuracy: 0.8483\nEpoch 88/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3863 - accuracy: 0.8630 - val_loss: 0.3666 - val_accuracy: 0.8417\nEpoch 89/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3847 - accuracy: 0.8626 - val_loss: 0.3684 - val_accuracy: 0.8467\nEpoch 90/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3837 - accuracy: 0.8634 - val_loss: 0.3681 - val_accuracy: 0.8450\nEpoch 91/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3835 - accuracy: 0.8646 - val_loss: 0.3655 - val_accuracy: 0.8517\nEpoch 92/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3840 - accuracy: 0.8640 - val_loss: 0.3673 - val_accuracy: 0.8467\nEpoch 93/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3825 - accuracy: 0.8646 - val_loss: 0.3628 - val_accuracy: 0.8500\nEpoch 94/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3796 - accuracy: 0.8639 - val_loss: 0.3630 - val_accuracy: 0.8450\nEpoch 95/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3789 - accuracy: 0.8657 - val_loss: 0.3628 - val_accuracy: 0.8517\nEpoch 96/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3788 - accuracy: 0.8660 - val_loss: 0.3638 - val_accuracy: 0.8517\nEpoch 97/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3784 - accuracy: 0.8671 - val_loss: 0.3629 - val_accuracy: 0.8533\nEpoch 98/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3768 - accuracy: 0.8661 - val_loss: 0.3609 - val_accuracy: 0.8567\nEpoch 99/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3752 - accuracy: 0.8662 - val_loss: 0.3623 - val_accuracy: 0.8550\nEpoch 100/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3743 - accuracy: 0.8666 - val_loss: 0.3586 - val_accuracy: 0.8550\nEpoch 101/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3751 - accuracy: 0.8674 - val_loss: 0.3573 - val_accuracy: 0.8417\nEpoch 102/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3748 - accuracy: 0.8675 - val_loss: 0.3605 - val_accuracy: 0.8550\nEpoch 103/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3722 - accuracy: 0.8695 - val_loss: 0.3577 - val_accuracy: 0.8533\nEpoch 104/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3718 - accuracy: 0.8669 - val_loss: 0.3558 - val_accuracy: 0.8517\nEpoch 105/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3714 - accuracy: 0.8672 - val_loss: 0.3577 - val_accuracy: 0.8550\nEpoch 106/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3703 - accuracy: 0.8689 - val_loss: 0.3540 - val_accuracy: 0.8533\nEpoch 107/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3681 - accuracy: 0.8686 - val_loss: 0.3565 - val_accuracy: 0.8533\nEpoch 108/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3705 - accuracy: 0.8687 - val_loss: 0.3529 - val_accuracy: 0.8500\nEpoch 109/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3668 - accuracy: 0.8696 - val_loss: 0.3523 - val_accuracy: 0.8533\nEpoch 110/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3671 - accuracy: 0.8700 - val_loss: 0.3537 - val_accuracy: 0.8550\nEpoch 111/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3668 - accuracy: 0.8699 - val_loss: 0.3520 - val_accuracy: 0.8550\nEpoch 112/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3648 - accuracy: 0.8715 - val_loss: 0.3499 - val_accuracy: 0.8583\nEpoch 113/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3622 - accuracy: 0.8721 - val_loss: 0.3496 - val_accuracy: 0.8600\nEpoch 114/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3636 - accuracy: 0.8721 - val_loss: 0.3508 - val_accuracy: 0.8467\nEpoch 115/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3637 - accuracy: 0.8709 - val_loss: 0.3480 - val_accuracy: 0.8550\nEpoch 116/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3616 - accuracy: 0.8717 - val_loss: 0.3514 - val_accuracy: 0.8583\nEpoch 117/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3602 - accuracy: 0.8720 - val_loss: 0.3462 - val_accuracy: 0.8533\nEpoch 118/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3616 - accuracy: 0.8716 - val_loss: 0.3518 - val_accuracy: 0.8567\nEpoch 119/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3597 - accuracy: 0.8719 - val_loss: 0.3479 - val_accuracy: 0.8583\nEpoch 120/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3584 - accuracy: 0.8726 - val_loss: 0.3491 - val_accuracy: 0.8583\nEpoch 121/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3588 - accuracy: 0.8727 - val_loss: 0.3466 - val_accuracy: 0.8583\nEpoch 122/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3576 - accuracy: 0.8732 - val_loss: 0.3459 - val_accuracy: 0.8517\nEpoch 123/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3544 - accuracy: 0.8743 - val_loss: 0.3451 - val_accuracy: 0.8583\nEpoch 124/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3557 - accuracy: 0.8739 - val_loss: 0.3430 - val_accuracy: 0.8550\nEpoch 125/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3555 - accuracy: 0.8745 - val_loss: 0.3430 - val_accuracy: 0.8600\nEpoch 126/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3546 - accuracy: 0.8729 - val_loss: 0.3442 - val_accuracy: 0.8583\nEpoch 127/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3545 - accuracy: 0.8746 - val_loss: 0.3435 - val_accuracy: 0.8600\nEpoch 128/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3551 - accuracy: 0.8736 - val_loss: 0.3405 - val_accuracy: 0.8550\nEpoch 129/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3532 - accuracy: 0.8750 - val_loss: 0.3415 - val_accuracy: 0.8567\nEpoch 130/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3521 - accuracy: 0.8753 - val_loss: 0.3397 - val_accuracy: 0.8583\nEpoch 131/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3499 - accuracy: 0.8756 - val_loss: 0.3405 - val_accuracy: 0.8550\nEpoch 132/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3513 - accuracy: 0.8753 - val_loss: 0.3395 - val_accuracy: 0.8617\nEpoch 133/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3489 - accuracy: 0.8758 - val_loss: 0.3397 - val_accuracy: 0.8600\nEpoch 134/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3509 - accuracy: 0.8758 - val_loss: 0.3412 - val_accuracy: 0.8567\nEpoch 135/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3483 - accuracy: 0.8770 - val_loss: 0.3386 - val_accuracy: 0.8583\nEpoch 136/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3483 - accuracy: 0.8758 - val_loss: 0.3384 - val_accuracy: 0.8583\nEpoch 137/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3462 - accuracy: 0.8777 - val_loss: 0.3378 - val_accuracy: 0.8583\nEpoch 138/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3465 - accuracy: 0.8774 - val_loss: 0.3392 - val_accuracy: 0.8617\nEpoch 139/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3469 - accuracy: 0.8769 - val_loss: 0.3361 - val_accuracy: 0.8583\nEpoch 140/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3464 - accuracy: 0.8778 - val_loss: 0.3370 - val_accuracy: 0.8567\nEpoch 141/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3433 - accuracy: 0.8785 - val_loss: 0.3343 - val_accuracy: 0.8600\nEpoch 142/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3455 - accuracy: 0.8782 - val_loss: 0.3373 - val_accuracy: 0.8600\nEpoch 143/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3445 - accuracy: 0.8778 - val_loss: 0.3357 - val_accuracy: 0.8583\nEpoch 144/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3435 - accuracy: 0.8786 - val_loss: 0.3356 - val_accuracy: 0.8617\nEpoch 145/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3420 - accuracy: 0.8781 - val_loss: 0.3364 - val_accuracy: 0.8650\nEpoch 146/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3446 - accuracy: 0.8782 - val_loss: 0.3342 - val_accuracy: 0.8600\nEpoch 147/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3422 - accuracy: 0.8781 - val_loss: 0.3342 - val_accuracy: 0.8650\nEpoch 148/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3424 - accuracy: 0.8787 - val_loss: 0.3343 - val_accuracy: 0.8550\nEpoch 149/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3397 - accuracy: 0.8788 - val_loss: 0.3328 - val_accuracy: 0.8600\nEpoch 150/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3378 - accuracy: 0.8798 - val_loss: 0.3332 - val_accuracy: 0.8633\nEpoch 151/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3398 - accuracy: 0.8788 - val_loss: 0.3333 - val_accuracy: 0.8567\nEpoch 152/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3389 - accuracy: 0.8793 - val_loss: 0.3336 - val_accuracy: 0.8650\nEpoch 153/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3384 - accuracy: 0.8806 - val_loss: 0.3335 - val_accuracy: 0.8600\nEpoch 154/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3365 - accuracy: 0.8803 - val_loss: 0.3319 - val_accuracy: 0.8567\nEpoch 155/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3381 - accuracy: 0.8811 - val_loss: 0.3323 - val_accuracy: 0.8617\nEpoch 156/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3382 - accuracy: 0.8801 - val_loss: 0.3308 - val_accuracy: 0.8617\nEpoch 157/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3364 - accuracy: 0.8808 - val_loss: 0.3269 - val_accuracy: 0.8617\nEpoch 158/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3374 - accuracy: 0.8804 - val_loss: 0.3304 - val_accuracy: 0.8683\nEpoch 159/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3361 - accuracy: 0.8809 - val_loss: 0.3298 - val_accuracy: 0.8583\nEpoch 160/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3343 - accuracy: 0.8813 - val_loss: 0.3296 - val_accuracy: 0.8650\nEpoch 161/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3336 - accuracy: 0.8816 - val_loss: 0.3282 - val_accuracy: 0.8700\nEpoch 162/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3335 - accuracy: 0.8817 - val_loss: 0.3293 - val_accuracy: 0.8600\nEpoch 163/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3334 - accuracy: 0.8810 - val_loss: 0.3317 - val_accuracy: 0.8650\nEpoch 164/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3312 - accuracy: 0.8828 - val_loss: 0.3252 - val_accuracy: 0.8633\nEpoch 165/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3315 - accuracy: 0.8819 - val_loss: 0.3271 - val_accuracy: 0.8700\nEpoch 166/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3320 - accuracy: 0.8823 - val_loss: 0.3270 - val_accuracy: 0.8633\nEpoch 167/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3322 - accuracy: 0.8825 - val_loss: 0.3263 - val_accuracy: 0.8650\nEpoch 168/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3315 - accuracy: 0.8830 - val_loss: 0.3270 - val_accuracy: 0.8600\nEpoch 169/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3307 - accuracy: 0.8824 - val_loss: 0.3241 - val_accuracy: 0.8617\nEpoch 170/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3296 - accuracy: 0.8829 - val_loss: 0.3249 - val_accuracy: 0.8650\nEpoch 171/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3314 - accuracy: 0.8823 - val_loss: 0.3261 - val_accuracy: 0.8650\nEpoch 172/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3277 - accuracy: 0.8836 - val_loss: 0.3255 - val_accuracy: 0.8650\nEpoch 173/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3312 - accuracy: 0.8824 - val_loss: 0.3264 - val_accuracy: 0.8633\nEpoch 174/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3284 - accuracy: 0.8830 - val_loss: 0.3247 - val_accuracy: 0.8650\nEpoch 175/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3266 - accuracy: 0.8836 - val_loss: 0.3226 - val_accuracy: 0.8683\nEpoch 176/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3266 - accuracy: 0.8835 - val_loss: 0.3229 - val_accuracy: 0.8633\nEpoch 177/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3261 - accuracy: 0.8841 - val_loss: 0.3252 - val_accuracy: 0.8633\nEpoch 178/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3229 - accuracy: 0.8872 - val_loss: 0.3233 - val_accuracy: 0.8650\nEpoch 179/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3282 - accuracy: 0.8845 - val_loss: 0.3215 - val_accuracy: 0.8667\nEpoch 180/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3264 - accuracy: 0.8844 - val_loss: 0.3245 - val_accuracy: 0.8617\nEpoch 181/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3247 - accuracy: 0.8846 - val_loss: 0.3210 - val_accuracy: 0.8633\nEpoch 182/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3253 - accuracy: 0.8843 - val_loss: 0.3230 - val_accuracy: 0.8667\nEpoch 183/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3243 - accuracy: 0.8842 - val_loss: 0.3240 - val_accuracy: 0.8650\nEpoch 184/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3248 - accuracy: 0.8845 - val_loss: 0.3199 - val_accuracy: 0.8700\nEpoch 185/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3242 - accuracy: 0.8856 - val_loss: 0.3225 - val_accuracy: 0.8733\nEpoch 186/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3236 - accuracy: 0.8844 - val_loss: 0.3208 - val_accuracy: 0.8650\nEpoch 187/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3223 - accuracy: 0.8859 - val_loss: 0.3167 - val_accuracy: 0.8667\nEpoch 188/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3214 - accuracy: 0.8849 - val_loss: 0.3201 - val_accuracy: 0.8633\nEpoch 189/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3260 - accuracy: 0.8848 - val_loss: 0.3202 - val_accuracy: 0.8717\nEpoch 190/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3214 - accuracy: 0.8855 - val_loss: 0.3192 - val_accuracy: 0.8633\nEpoch 191/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3205 - accuracy: 0.8861 - val_loss: 0.3214 - val_accuracy: 0.8650\nEpoch 192/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3213 - accuracy: 0.8857 - val_loss: 0.3180 - val_accuracy: 0.8700\nEpoch 193/200\n117/117 [==============================] - 0s 2ms/step - loss: 0.3203 - accuracy: 0.8859 - val_loss: 0.3191 - val_accuracy: 0.8617\nEpoch 194/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3223 - accuracy: 0.8858 - val_loss: 0.3170 - val_accuracy: 0.8683\nEpoch 195/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3216 - accuracy: 0.8862 - val_loss: 0.3222 - val_accuracy: 0.8667\nEpoch 196/200\n117/117 [==============================] - 0s 2ms/step - loss: 0.3196 - accuracy: 0.8860 - val_loss: 0.3167 - val_accuracy: 0.8700\nEpoch 197/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3179 - accuracy: 0.8880 - val_loss: 0.3194 - val_accuracy: 0.8700\nEpoch 198/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3185 - accuracy: 0.8865 - val_loss: 0.3178 - val_accuracy: 0.8633\nEpoch 199/200\n117/117 [==============================] - 0s 2ms/step - loss: 0.3152 - accuracy: 0.8877 - val_loss: 0.3137 - val_accuracy: 0.8667\nEpoch 200/200\n117/117 [==============================] - 0s 2ms/step - loss: 0.3166 - accuracy: 0.8876 - val_loss: 0.3202 - val_accuracy: 0.8650</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># loss ê°’ì„ plot í•´ë³´ê² ìŠµë‹ˆë‹¤. </span>\ny_vloss <span class=\"token operator\">=</span> history<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'val_loss'</span><span class=\"token punctuation\">]</span>\ny_loss <span class=\"token operator\">=</span> history<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'loss'</span><span class=\"token punctuation\">]</span>\nx_len <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>arange<span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>y_loss<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>x_len<span class=\"token punctuation\">,</span> y_vloss<span class=\"token punctuation\">,</span> marker<span class=\"token operator\">=</span><span class=\"token string\">'.'</span><span class=\"token punctuation\">,</span> c<span class=\"token operator\">=</span><span class=\"token string\">'red'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">\"Validation-set Loss\"</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>x_len<span class=\"token punctuation\">,</span> y_loss<span class=\"token punctuation\">,</span> marker<span class=\"token operator\">=</span><span class=\"token string\">'.'</span><span class=\"token punctuation\">,</span> c<span class=\"token operator\">=</span><span class=\"token string\">'blue'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">\"Train-set Loss\"</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>legend<span class=\"token punctuation\">(</span>loc<span class=\"token operator\">=</span><span class=\"token string\">'upper right'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>grid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylim<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'Loss graph with dropout layer'</span><span class=\"token punctuation\">)</span> \nplt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">'epoch'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'loss'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 386px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 72.22222222222221%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsTAAALEwEAmpwYAAAC9UlEQVQ4y32US2sbVxTHL0mh0IbuCll05yYE0k2XKdQLp5S21ClpNv0AKV4YhMEQ6MYfwl1lEUJN1VdIQykxzkix60qWI8WGVHKaxjEzQp666DUaaaSZ+/6XM37ENKEXfpx7z5w78z8Phr17/p0TjLHX793+5a2fvls/V35YObOxsXFmbm7u/ZmZmQ+mpqY+yWQyH05PT380Ozt78eqXVyevfXVtIpPJfDw/P3/Bdd23q9Xq2Vqtdm5lZeU0E83WSQCstev/uvukg4QnYZIkEed8EMdxFMfxMEmSASeEGIx6YTSs+wPP86JarRbt7OxEruuGjUYDnufdYABO0Av7YXh/r9qBscZaa0EYY44sAVjEQ4XWnoTv+9je3obrurS3nHM0m83v2eLi4iuMsdc67U6u/sCHkFJKIY2U0gghyFqyB3sjpDDaKKPUPuSjK1prtFqtb48UCjHIeat1BD2jAAOtX1R4XPVxvzF0BwiCIMviOD5JCvtylA8euVjLbitKDpAQgkNyDp4cwCU4F5BSpgghDlFKKVKYZWNjY6fTGg6GDtWofuuBKt58ioanwDV5/rv2a0lYa1KM0YoUd7vdLJuYmDjFGHu11+vllKZgpcLKY9Su/461rx+i/M2fqP78F2r3fTz5Y4S93QTDPkccCQwjgThWSIRW2mi02+0s1TAlDMO8NQZSKnUkph9APKtjt9yAt/wM7t0tPLr9FKUf6yjd+RtrdztYyw1QzEXq8eYIzX9aWba5uUldZqSQOiWFUFJISwhtrDrML8VaQFvApNZCWqO4FcORHA0Ems12lvm+nw52v993qA5aa2kOllbKGK2NkiqFEkutJrc2ihKlQGskfa/b7TwfmyAIfqNO0YC+pIsph77jzw/tfpfbP7Dx8XEamzccx3lva2trcn19/dNSqTRJFAqFS+VyOT3n8/nLq6urnzmO83mxWLy0tLR0hc7Ly8uXC4XCpOM4XywsLFxglUqFSnjUnJehtaaQN+kn8n9xxL9MAaP24DqSKAAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/3c940df8a06089ad50c2fbe8c6ea158f/7bc0b/output_41_0.png\"\n        srcset=\"/static/3c940df8a06089ad50c2fbe8c6ea158f/e9ff0/output_41_0.png 180w,\n/static/3c940df8a06089ad50c2fbe8c6ea158f/f21e7/output_41_0.png 360w,\n/static/3c940df8a06089ad50c2fbe8c6ea158f/7bc0b/output_41_0.png 386w\"\n        sizes=\"(max-width: 386px) 100vw, 386px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># accuracy ê°’ì„ plot í•´ë³´ê² ìŠµë‹ˆë‹¤. </span>\ny_vacc <span class=\"token operator\">=</span> history<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'val_accuracy'</span><span class=\"token punctuation\">]</span>\ny_acc <span class=\"token operator\">=</span> history<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span>\nx_len <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>arange<span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>y_acc<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>x_len<span class=\"token punctuation\">,</span> y_vacc<span class=\"token punctuation\">,</span> marker<span class=\"token operator\">=</span><span class=\"token string\">'.'</span><span class=\"token punctuation\">,</span> c<span class=\"token operator\">=</span><span class=\"token string\">'red'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">\"Validation-set accuracy\"</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>x_len<span class=\"token punctuation\">,</span> y_acc<span class=\"token punctuation\">,</span> marker<span class=\"token operator\">=</span><span class=\"token string\">'.'</span><span class=\"token punctuation\">,</span> c<span class=\"token operator\">=</span><span class=\"token string\">'blue'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">\"Train-set accuracy\"</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>legend<span class=\"token punctuation\">(</span>loc<span class=\"token operator\">=</span><span class=\"token string\">'lower right'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>grid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylim<span class=\"token punctuation\">(</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span> \nplt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'Accuracy graph with dropout layer'</span><span class=\"token punctuation\">)</span> \nplt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">'epoch'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 386px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 72.22222222222221%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsTAAALEwEAmpwYAAADEElEQVQ4y41Uz2sbRxQeHAItJYUcCjkYH5pTbi6GkFx6aGlDwU5Ic8kfYIMPFj7Yf4Rv/XXpxcFQixoX0pjEppU2yNiyskqckjo2DWvJklP9sCWvvNrV7mrnzcxXZv2jaumhDx7fx7zZb99782bY0NBQH2PsPcMw+k3TvGZZ1oczMzM3JiYmbk1OTn42PT39yejo6PDU1NSniUTiViKR+HxsbGxYr4+Pj38xO/vgo+3tnav6W8MwrjDO+QUArNlsPo6iCEEQON1u142iyA2CwPM7vh/4gRcEoRsGXdfvBG7gh14YhG7H87041vGdKAxRr9dnGYA+Lei67lMAEEIoISSkkIAiAAr/w5QEYNutH1kymbzIGHu31bLTxAlcEAeEVFCy6ULW6qQqliOt5w35cuVPmfv5rTQf12T+YUmaD17JjR/eyOy3z/jW4jZqlcN5nWHs7bab1r/ijkdbWQe5+SI2v8vit68y2PxmDdb3Bg4XMzh+sgbHeI72ShbOShbus9fomL8TWXtoNZtJNjg4eJkx9r4TeEa4Y2H16xdkvfbQsT0ItwWQCyACIOPixWkT5CnXSABp3mg0kqy/v39AZ8i7TurNwx3UDuLGxUYKIAkQSRAJSCIIziH/wQmCiJSUsG07ya4ODFxhjL1zXNpPFV62ICAo6nIQETj/G3u5xn/FSQiBpi757JTtQilds1yQUiRI6NOON5/hOef8fK1HPBY8OjpKsvyieYEx1ld+VTLst+04Q8650lX0YsyFUFwIBXViUsoz50qpkwzXftrSgqy0fZByG13dZi6EjE2cEo1CKRk5bRnVD2V5f1+W9vZkpVKR1WpVI69Wq3qw589LLv1xsOo0QpCIEEUnPdM358yJOI6PfBxUfBSLBRR2CygWi9jd3UW5XNY3TAsusOvXP9YZXnr0yLi5ubkzYpq54Y2N3EgulxtZX1+/nc/nhzU3DOPu08zqnSe//PrlaiZze2lp6V46nb6zvLx81zCMkVQqdX9ubu4mW1hY0xXHw02E80HvdSGE3vKBfkT+K97rfwFv9ZYsQOGykwAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/07db8a2400447ea8b0cf8954c55862e6/7bc0b/output_42_0.png\"\n        srcset=\"/static/07db8a2400447ea8b0cf8954c55862e6/e9ff0/output_42_0.png 180w,\n/static/07db8a2400447ea8b0cf8954c55862e6/f21e7/output_42_0.png 360w,\n/static/07db8a2400447ea8b0cf8954c55862e6/7bc0b/output_42_0.png 386w\"\n        sizes=\"(max-width: 386px) 100vw, 386px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>ì§„ì§œ ì¡°ê¸ˆ ë°”ë€Œê¸´ í–ˆì§€ë§Œ ì°¨ì´ê°€ ìˆê¸´ ìˆë‹¤</p>\n<p>ì‚¬ì‹¤ ë” ë³µì¡í•œ ë„¤íŠ¸ì›Œí¬ë‚˜, ë” ì–´ë ¤ìš´ ë°ì´í„°ì˜ ê²½ìš°ì—ëŠ” ì´ëŸ¬í•œ ì˜¤ë²„í”¼íŒ…ì´ ë” ìì£¼ ìˆëŠ” ì¼ì´ë¯€ë¡œ, Dropout layerë¥¼ ì¶”ê°€í•˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì´ ë˜í•œ í™•ë¥  ê°’ì´ íŒŒë¼ë¯¸í„°ë¡œ ë“¤ì–´ê°€ë¯€ë¡œ, ì–´ë– í•œ ê°’ì„ ì„ íƒí•˜ëŠëƒëŠ” ë°ì´í„°ì™€ ë„¤íŠ¸ì›Œí¬ì— ë”°ë¼ ë‹¬ë¦° ì¼ì…ë‹ˆë‹¤.</p>\n<h2 id=\"batch-normalization\" style=\"position:relative;\"><a href=\"#batch-normalization\" aria-label=\"batch normalization permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Batch Normalization</h2>\n<h3 id=\"ìš”ê±´-ê¸°ìš¸ê¸°ì†Œì‹¤-ì´ë‘-ê¸°ìš¸ê¸°í¬í™”-ë¬¸ì œë¥¼-í•´ê²°í•œë‹¤\" style=\"position:relative;\"><a href=\"#%EC%9A%94%EA%B1%B4-%EA%B8%B0%EC%9A%B8%EA%B8%B0%EC%86%8C%EC%8B%A4-%EC%9D%B4%EB%9E%91-%EA%B8%B0%EC%9A%B8%EA%B8%B0%ED%8F%AC%ED%99%94-%EB%AC%B8%EC%A0%9C%EB%A5%BC-%ED%95%B4%EA%B2%B0%ED%95%9C%EB%8B%A4\" aria-label=\"ìš”ê±´ ê¸°ìš¸ê¸°ì†Œì‹¤ ì´ë‘ ê¸°ìš¸ê¸°í¬í™” ë¬¸ì œë¥¼ í•´ê²°í•œë‹¤ permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>ìš”ê±´ ê¸°ìš¸ê¸°ì†Œì‹¤ ì´ë‘ ê¸°ìš¸ê¸°í¬í™” ë¬¸ì œë¥¼ í•´ê²°í•œë‹¤.</h3>\n<p><a href=\"https://arxiv.org/pdf/1502.03167.pdf\">ë…¼ë¬¸</a></p>\n<p>ì‰½ê²Œ ë§í•˜ë©´ ë¯¸ë‹ˆë°°ì¹˜ì—ì„œ</p>\n<p>í‰ê· ì´ë‘ ë¶„ì‚°ì„ êµ¬í•´ê°€ì§€ê³ </p>\n<p>xì—ì„œ í‰ê· ëº€ê±°ë¥¼ ë¶„ì‚°ìœ¼ë¡œ ë‚˜ëˆˆ ê°’ìœ¼ë¡œ ì •ê·œí™” í•˜ëŠ”ê±°</p>\n<p>íŠ¹íˆ ì¤‘ìš”í•œ ë¶€ë¶„ì€ ë¶„ëª¨ì— ì—¡ì‹¤ë¡ (0.001)) ê°€ ì¶”ê°€ëœ ê²ƒì´ë‹¤ ì´ ë¶€ë¶„ìœ¼ë¡œ</p>\n<p>ê°€ì¤‘ì¹˜ ì†Œì‹¤, í¬í™”ë¥¼ ë§‰ì„ ìˆ˜ ìˆë‹¤. ê·¸ë˜ì„œ ì´ê±¸ë¡œ\nì˜¤ë²„í”¼íŒ…ìœ¼ë¡œ í•™ìŠµì´ ì˜ë˜ì§€ ì•ŠëŠ” ê²ƒì„ ë§‰ì„ ìˆ˜ ìˆë‹«.</p>\n<p>fashion_mnist ë°ì´í„°ë¡œ ê°€ì ¸ê°€ë³´ì</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n<span class=\"token keyword\">from</span> tensorflow <span class=\"token keyword\">import</span> keras\n<span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n<span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt\n\nfashion_mnist <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>datasets<span class=\"token punctuation\">.</span>fashion_mnist\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'=3'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">=3</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token punctuation\">(</span>train_images<span class=\"token punctuation\">,</span> train_labels<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>test_images<span class=\"token punctuation\">,</span> test_labels<span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> fashion_mnist<span class=\"token punctuation\">.</span>load_data<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nclass_names <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'T-shirt/top'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Trouser'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Pullover'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Dress'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Coat'</span><span class=\"token punctuation\">,</span>\n               <span class=\"token string\">'Sandal'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Shirt'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Sneaker'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Bag'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Ankle boot'</span><span class=\"token punctuation\">]</span>\n\ntrain_images <span class=\"token operator\">=</span> train_images <span class=\"token operator\">/</span> <span class=\"token number\">255.0</span>\ntest_images <span class=\"token operator\">=</span> test_images <span class=\"token operator\">/</span> <span class=\"token number\">255.0</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>model_selection <span class=\"token keyword\">import</span> train_test_split\n\nX_train<span class=\"token punctuation\">,</span> X_valid<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> y_valid <span class=\"token operator\">=</span> train_test_split<span class=\"token punctuation\">(</span>train_images<span class=\"token punctuation\">,</span> train_labels<span class=\"token punctuation\">,</span> test_size<span class=\"token operator\">=</span><span class=\"token number\">0.3</span><span class=\"token punctuation\">,</span> random_state<span class=\"token operator\">=</span><span class=\"token number\">101</span><span class=\"token punctuation\">)</span>\n\nmodel <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n    keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span>input_shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">28</span><span class=\"token punctuation\">,</span> <span class=\"token number\">28</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">128</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span><span class=\"token string\">'adam'</span><span class=\"token punctuation\">,</span>loss<span class=\"token operator\">=</span><span class=\"token string\">'sparse_categorical_crossentropy'</span><span class=\"token punctuation\">,</span>\n              metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nhistory<span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">20</span><span class=\"token punctuation\">,</span> batch_size<span class=\"token operator\">=</span><span class=\"token number\">2048</span><span class=\"token punctuation\">,</span> validation_data<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>X_valid<span class=\"token punctuation\">,</span> y_valid<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Epoch 1/20\n21/21 [==============================] - 1s 23ms/step - loss: 1.2103 - accuracy: 0.6096 - val_loss: 0.7485 - val_accuracy: 0.7401\nEpoch 2/20\n21/21 [==============================] - 0s 10ms/step - loss: 0.6556 - accuracy: 0.7789 - val_loss: 0.5983 - val_accuracy: 0.8006\nEpoch 3/20\n21/21 [==============================] - 0s 10ms/step - loss: 0.5541 - accuracy: 0.8160 - val_loss: 0.5364 - val_accuracy: 0.8184\nEpoch 4/20\n21/21 [==============================] - 0s 9ms/step - loss: 0.5061 - accuracy: 0.8299 - val_loss: 0.5008 - val_accuracy: 0.8274\nEpoch 5/20\n21/21 [==============================] - 0s 9ms/step - loss: 0.4775 - accuracy: 0.8394 - val_loss: 0.4801 - val_accuracy: 0.8369\nEpoch 6/20\n21/21 [==============================] - 0s 9ms/step - loss: 0.4555 - accuracy: 0.8452 - val_loss: 0.4612 - val_accuracy: 0.8456\nEpoch 7/20\n21/21 [==============================] - 0s 9ms/step - loss: 0.4391 - accuracy: 0.8502 - val_loss: 0.4470 - val_accuracy: 0.8479\nEpoch 8/20\n21/21 [==============================] - 0s 8ms/step - loss: 0.4251 - accuracy: 0.8559 - val_loss: 0.4369 - val_accuracy: 0.8503\nEpoch 9/20\n21/21 [==============================] - 0s 6ms/step - loss: 0.4144 - accuracy: 0.8578 - val_loss: 0.4295 - val_accuracy: 0.8530\nEpoch 10/20\n21/21 [==============================] - 0s 6ms/step - loss: 0.4059 - accuracy: 0.8595 - val_loss: 0.4182 - val_accuracy: 0.8566\nEpoch 11/20\n21/21 [==============================] - 0s 7ms/step - loss: 0.3950 - accuracy: 0.8646 - val_loss: 0.4125 - val_accuracy: 0.8588\nEpoch 12/20\n21/21 [==============================] - 0s 6ms/step - loss: 0.3900 - accuracy: 0.8662 - val_loss: 0.4139 - val_accuracy: 0.8543\nEpoch 13/20\n21/21 [==============================] - 0s 6ms/step - loss: 0.3826 - accuracy: 0.8678 - val_loss: 0.4036 - val_accuracy: 0.8598\nEpoch 14/20\n21/21 [==============================] - 0s 6ms/step - loss: 0.3731 - accuracy: 0.8719 - val_loss: 0.3979 - val_accuracy: 0.8619\nEpoch 15/20\n21/21 [==============================] - 0s 6ms/step - loss: 0.3696 - accuracy: 0.8723 - val_loss: 0.3929 - val_accuracy: 0.8624\nEpoch 16/20\n21/21 [==============================] - 0s 6ms/step - loss: 0.3614 - accuracy: 0.8761 - val_loss: 0.3878 - val_accuracy: 0.8650\nEpoch 17/20\n21/21 [==============================] - 0s 6ms/step - loss: 0.3560 - accuracy: 0.8774 - val_loss: 0.3865 - val_accuracy: 0.8647\nEpoch 18/20\n21/21 [==============================] - 0s 6ms/step - loss: 0.3514 - accuracy: 0.8776 - val_loss: 0.3858 - val_accuracy: 0.8644\nEpoch 19/20\n21/21 [==============================] - 0s 6ms/step - loss: 0.3476 - accuracy: 0.8803 - val_loss: 0.3774 - val_accuracy: 0.8686\nEpoch 20/20\n21/21 [==============================] - 0s 6ms/step - loss: 0.3385 - accuracy: 0.8828 - val_loss: 0.3780 - val_accuracy: 0.8672</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># loss ê°’ì„ plot í•´ë³´ê² ìŠµë‹ˆë‹¤. </span>\ny_vloss <span class=\"token operator\">=</span> history<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'val_loss'</span><span class=\"token punctuation\">]</span>\ny_loss <span class=\"token operator\">=</span> history<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'loss'</span><span class=\"token punctuation\">]</span>\nx_len <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>arange<span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>y_loss<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>x_len<span class=\"token punctuation\">,</span> y_vloss<span class=\"token punctuation\">,</span> marker<span class=\"token operator\">=</span><span class=\"token string\">'.'</span><span class=\"token punctuation\">,</span> c<span class=\"token operator\">=</span><span class=\"token string\">'red'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">\"Validation-set Loss\"</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>x_len<span class=\"token punctuation\">,</span> y_loss<span class=\"token punctuation\">,</span> marker<span class=\"token operator\">=</span><span class=\"token string\">'.'</span><span class=\"token punctuation\">,</span> c<span class=\"token operator\">=</span><span class=\"token string\">'blue'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">\"Train-set Loss\"</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>legend<span class=\"token punctuation\">(</span>loc<span class=\"token operator\">=</span><span class=\"token string\">'upper right'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>grid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylim<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'Loss graph without batch normalization'</span><span class=\"token punctuation\">)</span> \nplt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">'epoch'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'loss'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 386px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 72.22222222222221%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsTAAALEwEAmpwYAAADBklEQVQ4y3WSS28TVxTHrwAJqQVV6qpddBWpLKCrrLNoSguBLAqi9BtEWXhhrCzoh+muVugmD2XRyDbJhiBFURIXN1aaJrZjj03sGXvG4/jOff+rMxYgVfRIR//7ODP3dx5senr6CmPs00Kh8NWrV399vby8/E0mk7mXzWbvLiwsPMzlct+RZrPZ7xcXF+ee//L822dLz+7mcrl7mUxmfmlp6YfNzc3bp6ent7a3t79kSsqrAJjv+xudtoCUIuKcx5zzS875SAgRJ0kSSynjRIiYR8N4VG/FjfPzuFKpxGdnZ3GtVgubzSYajcavDMAV+uEwHr30AwBwzhhDC1hr4ZzDh70BH2v0Ogqe5+Hk5AS1Wg2tVstJKdHr9ZbZHy9eXGOMfRJ22sWgPQZPjJJSWKUUBZFaUq21FUKkqrSwZHRnjKFzRQ8HQfDbe0Ix6hcHf/cwvIQGLKydkFEgkZJN9oDRE2Kt9TtNF1EU5RkX4ioRDkbDUvI2QHPP05xLOGgYp6GMBqVD3yRCQCmNJBHQqSZQSpFqawwR5tnU1NQXRBjHowK9Mm4PdP0wgN8WCL0Y+pJPiJyDcwRCtBNCh4kZICUMiXB2dvYGY+x6GIZFrQ0cnFZaIfQTdOsRmm981F+fo73fRrfcQq/cxMWfHoJ/+vBPLsBbXfBWR5tggKDby1MNU4+iqES1MsZoSoNIHNUSVEsNY4FoaBBGFv0LjrgzQlAfoHMcovEm0N3aJXoXQZ7t7+9TlxkRUtGpwFJKwnRSkFK3FY2S01pQAs5YRdnSinrklDVEgH6/n2ee56WDPRwOCy6tk1M0Gs65dCTISGlP59Y6qxXdIx2bdHxkmhLCMPwwNoPBYJs6SS7Sbqq0u++czj+mFEfxlJ3v+7+zmZkZGpubq6urMzs7O48PDg7mtra2fiyXyw+KxeKjo6Oj+6VS6VGlUplbW1t7uru7O7+xsfFTtVq9v7Ky8vPh4eGD9fX1J8fHx/PVavUOC4KASvi+Of/18XicKmPsc8bYZ/8XR763t8f+BXp2qO3PX9GyAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/6a1f7c39ee994f85d98d4d22baf532e5/7bc0b/output_50_0.png\"\n        srcset=\"/static/6a1f7c39ee994f85d98d4d22baf532e5/e9ff0/output_50_0.png 180w,\n/static/6a1f7c39ee994f85d98d4d22baf532e5/f21e7/output_50_0.png 360w,\n/static/6a1f7c39ee994f85d98d4d22baf532e5/7bc0b/output_50_0.png 386w\"\n        sizes=\"(max-width: 386px) 100vw, 386px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>ì¼ë°˜ì ì¸ Dense FC layer ë¥¼ ì“°ë©´ ì €ë ‡ê²Œ val lossê°€ 7.5 ì¯¤ì—ì„œ ë©ˆì¶˜ë‹¤</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># accuracy ê°’ì„ plot í•´ë³´ê² ìŠµë‹ˆë‹¤. </span>\ny_vacc <span class=\"token operator\">=</span> history<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'val_accuracy'</span><span class=\"token punctuation\">]</span>\ny_acc <span class=\"token operator\">=</span> history<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span>\nx_len <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>arange<span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>y_acc<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>x_len<span class=\"token punctuation\">,</span> y_vacc<span class=\"token punctuation\">,</span> marker<span class=\"token operator\">=</span><span class=\"token string\">'.'</span><span class=\"token punctuation\">,</span> c<span class=\"token operator\">=</span><span class=\"token string\">'red'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">\"Validation-set accuracy\"</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>x_len<span class=\"token punctuation\">,</span> y_acc<span class=\"token punctuation\">,</span> marker<span class=\"token operator\">=</span><span class=\"token string\">'.'</span><span class=\"token punctuation\">,</span> c<span class=\"token operator\">=</span><span class=\"token string\">'blue'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">\"Train-set accuracy\"</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>legend<span class=\"token punctuation\">(</span>loc<span class=\"token operator\">=</span><span class=\"token string\">'lower right'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>grid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylim<span class=\"token punctuation\">(</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'Accuracy graph without batch normalization'</span><span class=\"token punctuation\">)</span> \nplt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">'epoch'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 386px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 72.22222222222221%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsTAAALEwEAmpwYAAADCklEQVQ4y32TS2sbVxTHDw6BloaUdhXSkkWyCmRh8NaFQBOITQJJyeMLeCG8sWywv013EXVxqRZd2XJtMHZtk+AYFJWoUjS2HuMZzVOjGc3cx7mn3LEtki56hzu/++LM+f/vGZiampoAgK92dna+W19fv7e0tPTjwsLCQ81CoTAzPz8/UywWH2guLi4+KBQKsysrK/eLxeJDvT83N/dkeXn5/uHh4d3t7e0bwDm/QkTgOM4fWZYRYyxI0zRK0zSO4zjJ0kyPI8ZYNBqNoixjUZKMIsZ4znweJwFnnGzb/hmIaEIHjKLoTyIipZQSQmqSIqTzpi7e6rP5J8wHYRj+AqVS6SoAfOn7XkUIQVJJLpEhKqmGg1QN+jGGdoRDN0GnM0CzFeHphxB7zSG2ay52ah4ab7rc/rtPlmm/1hnCeYbDiv4KGzLRbQzJbMR01s7I+uDT2XuH+nWfvLpFccuixDgj1nVoZLqUnfmU2KGQiaDA9UowOTn5DQBcD+PBZty2yXhriUGQUppkxAUjRTJ/tDyhBCEp4ihzM5gUJEkRk1xoO1zPLcH3N2/e0hmmXn/D/celESdB+TFFUkpCiSS1p6hIcEEKkbQ12j7Ni3Wh1QVBUII7t2/fAIAvQs/bsC1JiFKwjOWHOedj6uCMsTER8dO50JfoeV5pfMuuN6g4DuoMxGWA/JIuqAPodfyfgL7vl2B/37oCABOGEVTCUJeLEIwxJYRQl+ScKymlYpwroTAfa1P13nmZCa4l5xm22z0dEMJwsIGodP1xIQQqpVBKibppKiLM/AC51Ufj9BQNw8BOp4O9Xg+73S43TZMsy3o9lhwE/va5X4L0H6PlaUmXXaIg34nJ6ib08WOTGo0GtVqtnCcnJ5QkCZmm+StMT0/rDK+Vy+Ufdnd3f3r37mhma2vr6fHx8WylUnlWq9UebW5uPntfrc789nv55c5f+4/L5fKLo6OjR6urq6/29vZm19bWntfr9cfVavUeNJtNrXhc4P/tSZLkBIBvAeDry/UwDD87h4hwcHAA/wLoLKAxXQohggAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/3efbcc1914c76a9b1265a4d0a9e655c9/7bc0b/output_52_0.png\"\n        srcset=\"/static/3efbcc1914c76a9b1265a4d0a9e655c9/e9ff0/output_52_0.png 180w,\n/static/3efbcc1914c76a9b1265a4d0a9e655c9/f21e7/output_52_0.png 360w,\n/static/3efbcc1914c76a9b1265a4d0a9e655c9/7bc0b/output_52_0.png 386w\"\n        sizes=\"(max-width: 386px) 100vw, 386px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<h3 id=\"ë°°ì¹˜-ë…¸ë§ë¼ì´ì œì´ì…˜-ì“°ë©´\" style=\"position:relative;\"><a href=\"#%EB%B0%B0%EC%B9%98-%EB%85%B8%EB%A7%90%EB%9D%BC%EC%9D%B4%EC%A0%9C%EC%9D%B4%EC%85%98-%EC%93%B0%EB%A9%B4\" aria-label=\"ë°°ì¹˜ ë…¸ë§ë¼ì´ì œì´ì…˜ ì“°ë©´ permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>ë°°ì¹˜ ë…¸ë§ë¼ì´ì œì´ì…˜ ì“°ë©´</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">model <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n    keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span>input_shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">28</span><span class=\"token punctuation\">,</span> <span class=\"token number\">28</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">128</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token comment\">#ì—¬ê¸°ì— batchnormalization layerë¥¼ ì¶”ê°€í•´ë³´ì•˜ìŠµë‹ˆë‹¤. ë‚˜ë¨¸ì§€ layerëŠ” ìœ„ì˜ ì‹¤ìŠµê³¼ ê°™ìŠµë‹ˆë‹¤.</span>\n    keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>BatchNormalization<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span><span class=\"token string\">'adam'</span><span class=\"token punctuation\">,</span>loss<span class=\"token operator\">=</span><span class=\"token string\">'sparse_categorical_crossentropy'</span><span class=\"token punctuation\">,</span>\n              metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nhistory<span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">20</span><span class=\"token punctuation\">,</span> batch_size<span class=\"token operator\">=</span><span class=\"token number\">2048</span><span class=\"token punctuation\">,</span> validation_data<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>X_valid<span class=\"token punctuation\">,</span> y_valid<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Epoch 1/20\n21/21 [==============================] - 1s 25ms/step - loss: 0.8808 - accuracy: 0.7005 - val_loss: 1.0613 - val_accuracy: 0.6525\nEpoch 2/20\n21/21 [==============================] - 0s 9ms/step - loss: 0.5167 - accuracy: 0.8267 - val_loss: 0.8411 - val_accuracy: 0.7488\nEpoch 3/20\n21/21 [==============================] - 0s 10ms/step - loss: 0.4500 - accuracy: 0.8469 - val_loss: 0.7390 - val_accuracy: 0.7935\nEpoch 4/20\n21/21 [==============================] - 0s 9ms/step - loss: 0.4127 - accuracy: 0.8584 - val_loss: 0.6659 - val_accuracy: 0.8183\nEpoch 5/20\n21/21 [==============================] - 0s 10ms/step - loss: 0.3869 - accuracy: 0.8680 - val_loss: 0.6321 - val_accuracy: 0.8328\nEpoch 6/20\n21/21 [==============================] - 0s 9ms/step - loss: 0.3640 - accuracy: 0.8746 - val_loss: 0.5769 - val_accuracy: 0.8439\nEpoch 7/20\n21/21 [==============================] - 0s 10ms/step - loss: 0.3465 - accuracy: 0.8790 - val_loss: 0.5427 - val_accuracy: 0.8486\nEpoch 8/20\n21/21 [==============================] - 0s 6ms/step - loss: 0.3321 - accuracy: 0.8842 - val_loss: 0.5140 - val_accuracy: 0.8510\nEpoch 9/20\n21/21 [==============================] - 0s 7ms/step - loss: 0.3164 - accuracy: 0.8903 - val_loss: 0.4943 - val_accuracy: 0.8492\nEpoch 10/20\n21/21 [==============================] - 0s 7ms/step - loss: 0.3045 - accuracy: 0.8935 - val_loss: 0.4571 - val_accuracy: 0.8611\nEpoch 11/20\n21/21 [==============================] - 0s 7ms/step - loss: 0.2944 - accuracy: 0.8968 - val_loss: 0.4447 - val_accuracy: 0.8588\nEpoch 12/20\n21/21 [==============================] - 0s 6ms/step - loss: 0.2839 - accuracy: 0.9001 - val_loss: 0.4193 - val_accuracy: 0.8649\nEpoch 13/20\n21/21 [==============================] - 0s 7ms/step - loss: 0.2733 - accuracy: 0.9047 - val_loss: 0.4101 - val_accuracy: 0.8683\nEpoch 14/20\n21/21 [==============================] - 0s 6ms/step - loss: 0.2639 - accuracy: 0.9089 - val_loss: 0.4099 - val_accuracy: 0.8638\nEpoch 15/20\n21/21 [==============================] - 0s 6ms/step - loss: 0.2580 - accuracy: 0.9097 - val_loss: 0.3807 - val_accuracy: 0.8750\nEpoch 16/20\n21/21 [==============================] - 0s 6ms/step - loss: 0.2502 - accuracy: 0.9125 - val_loss: 0.3694 - val_accuracy: 0.8753\nEpoch 17/20\n21/21 [==============================] - 0s 6ms/step - loss: 0.2434 - accuracy: 0.9149 - val_loss: 0.3822 - val_accuracy: 0.8688\nEpoch 18/20\n21/21 [==============================] - 0s 7ms/step - loss: 0.2365 - accuracy: 0.9167 - val_loss: 0.3545 - val_accuracy: 0.8790\nEpoch 19/20\n21/21 [==============================] - 0s 6ms/step - loss: 0.2273 - accuracy: 0.9210 - val_loss: 0.3586 - val_accuracy: 0.8746\nEpoch 20/20\n21/21 [==============================] - 0s 7ms/step - loss: 0.2213 - accuracy: 0.9223 - val_loss: 0.3413 - val_accuracy: 0.8785</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># loss ê°’ì„ plot í•´ë³´ê² ìŠµë‹ˆë‹¤. </span>\ny_vloss <span class=\"token operator\">=</span> history<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'val_loss'</span><span class=\"token punctuation\">]</span>\ny_loss <span class=\"token operator\">=</span> history<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'loss'</span><span class=\"token punctuation\">]</span>\nx_len <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>arange<span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>y_loss<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>x_len<span class=\"token punctuation\">,</span> y_vloss<span class=\"token punctuation\">,</span> marker<span class=\"token operator\">=</span><span class=\"token string\">'.'</span><span class=\"token punctuation\">,</span> c<span class=\"token operator\">=</span><span class=\"token string\">'red'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">\"Validation-set Loss\"</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>x_len<span class=\"token punctuation\">,</span> y_loss<span class=\"token punctuation\">,</span> marker<span class=\"token operator\">=</span><span class=\"token string\">'.'</span><span class=\"token punctuation\">,</span> c<span class=\"token operator\">=</span><span class=\"token string\">'blue'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">\"Train-set Loss\"</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>legend<span class=\"token punctuation\">(</span>loc<span class=\"token operator\">=</span><span class=\"token string\">'upper right'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>grid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylim<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'Loss graph with batch normalization'</span><span class=\"token punctuation\">)</span> \nplt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">'epoch'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'loss'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 386px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 72.22222222222221%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsTAAALEwEAmpwYAAADI0lEQVQ4y3VSTUtkRxQtZgKBfBDIahbZOYsMZJVZZdEEJBhHXGTCJPkJImhrthMmP8F/kF2akI12ELKwW4MLFyLaQtMiKm2/fs+2+/X76tf93qvPe0K1M2MIzIXLqbpVVJ177mFPn375gDH24e5u/bOjnZ3PTxuNx69+fVVaX1//ZmlpaWF1dXVuZWXl27W1tbnl5eX5l7+8/Lr8c3muXC7bs8WNjY2vLi8vHzebzSf7+/uPmBDyIQA29Ifb/OYGXIgkz/O04HycZdmEcz4uiiIVQthamiejdHztpo7jpM1mM726uhq32+2k2+2i0+n8xgA8sA92e8XuxAmBYkIKABkDYwyICFpr2DBGI88U/J6E53m4uLhAu92G67okhIDv+3+wra2/32OMfdD345p/y6GdjuR5bqQxRnBOUkojhDBKKcM5n6JU3NiwZ1prW5f24yAIfn/LME3T2jAEUBRKX3dAWQZjmVpmrxlapkSAVnd7pdQbnC6SJKmwPM8fWoZxHNZ9X4FLo2SRQTpdiK4LOR5DSAVFBC4lpJTgnEMrBV4UUFKiKApl5QmCoMJmZmYeWYZFMd5JU4LnkdLGTH+mSQrq3cB0u6AwgppkMIbumb3uQBkzLcRxXGGzs7MfMcbej+O4RqQRRVq12xL9vsJorCEUQRQFkEYwfQ/wOlCda9DQhxz0YYIhRJJYYRGGYcVqOM0kSepmyswo21aSGNzeKjgdDdfV8EOg1zcYBgZZpiDjMfJBCD4IIT1XIfQR+YMKOz4+tlNmlqEV3QoshCAiRVoLMkZRUUgaJYriSFAUKXIcQd4tyLnR5PZAjqukHehgEFaY53lTY49Gox07eiKS1hrGkFFWzWloY51JpP6D1qbSWMhzKTkHoii+t00URf9YsW3aKdq2rVnf5F1dQMo7vN/bexxW/+Fw+CcrlUrWNh9vbW2VDg4Ovj85OXm2t7f33enp6UKtVnvearXm6/X682az+axarf54eHi4uL29/cPZ2dn85ubmT41GY6Fa/evF+fn5Yqt19gULgsBK+HY4/88sy6bIGPuUMfbJu+7ZPDo6Yv8CUj2pel0/ITIAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/baa29ed3f08a5d4b724717acc1de9ef2/7bc0b/output_55_0.png\"\n        srcset=\"/static/baa29ed3f08a5d4b724717acc1de9ef2/e9ff0/output_55_0.png 180w,\n/static/baa29ed3f08a5d4b724717acc1de9ef2/f21e7/output_55_0.png 360w,\n/static/baa29ed3f08a5d4b724717acc1de9ef2/7bc0b/output_55_0.png 386w\"\n        sizes=\"(max-width: 386px) 100vw, 386px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># accuracy ê°’ì„ plot í•´ë³´ê² ìŠµë‹ˆë‹¤. </span>\ny_vacc <span class=\"token operator\">=</span> history<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'val_accuracy'</span><span class=\"token punctuation\">]</span>\ny_acc <span class=\"token operator\">=</span> history<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span>\nx_len <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>arange<span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>y_acc<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>x_len<span class=\"token punctuation\">,</span> y_vacc<span class=\"token punctuation\">,</span> marker<span class=\"token operator\">=</span><span class=\"token string\">'.'</span><span class=\"token punctuation\">,</span> c<span class=\"token operator\">=</span><span class=\"token string\">'red'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">\"Validation-set accuracy\"</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>x_len<span class=\"token punctuation\">,</span> y_acc<span class=\"token punctuation\">,</span> marker<span class=\"token operator\">=</span><span class=\"token string\">'.'</span><span class=\"token punctuation\">,</span> c<span class=\"token operator\">=</span><span class=\"token string\">'blue'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">\"Train-set accuracy\"</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>legend<span class=\"token punctuation\">(</span>loc<span class=\"token operator\">=</span><span class=\"token string\">'lower right'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>grid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylim<span class=\"token punctuation\">(</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span> \nplt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'Accurcy graph with batch normalization'</span><span class=\"token punctuation\">)</span> \nplt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">'epoch'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 386px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 72.22222222222221%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsTAAALEwEAmpwYAAADGElEQVQ4y31Tz2skRRgtsgiKouhJIboHEQ96COYaDy64ZsIeXPHHX7C72Q0TWAzkb8nBm4Mj0Z2Dp6THCJJoTkNkjGScSSbzq9MzPf1jOtPd1VX11ZPq7ITVgx88XtfXxev3vq5ii4uLc4yxF3d2dt48OTl5Z2tr64P19fWPNzc3P1pbW1teXX1YKBaLt4vF9duPHq19srGxcevx469vPXjwsHDv3mrh/v3VlXL5x/dqtfq7llV9gwkhbgBgruv+xDkH5zxMkiRKU345nU6nSZJecp5GUmYR50kkBI8yHkeaskhkcUTKrKeBJoHRaPgNAzBnBKMo+llrmNJaS0NPAXABZBJIuEamAC8E3ABwXGA4BvoOdDABxl74HSuVSs8xxl7wPM8ikhBCCH8iyR5q6p7GutuYUOckpH7r8gp/DMk5tilq2RQ2uhT93aPgr7aIO0O4F863xmGOOI6sNAV6A0i7ESBuDpB2LsC7DvSFDXgjYGgDySUw8YEsheYJIDh0GkuQRBgEJbawsPAqY+zlMPSqzogwPetL7XSheAIhM0hocKUgNJBKBaEIXEhI0uBZBqEU0iyTpDXG43GJzc/Pv2UchjHfdZsB4LlS5IMElFIgRVBS5Q0lpRlwzqbk07WUV43AOLx58+3XGWPP93rRbthyoLWSWZblm4UQ12zETX/GRPTsWhphz/NK13857PUtCkIQIGcCRmzGRsD06X8Efd8vsYtu5wZjbC4Yjy0TRarcoZZS6hkLIbRSSmdCaKkpfzZTMe9MSZlP6cph37aNIJtE0a75itZaSGlmrEkpRaYMa4C4H5BwRtTudKjdblOv16PBYED9fl/Ytg3HuTo2eWTf938x0QzMjTHxTKQZFEn47hROP8bpaQvNZhNnZ2c5n5+fI45j2Lb9PVtaWjIOX6pUKh/u7+9/VqvVCnt7e58eHR2tWJZ19/j4eLlard79s14v/PCk8uWvv/1+p1KpfFGr1ZbL5fJXBwcHK9vb2583Go079Xr9fdZqtUzi6wP+X8RxnDNj7DXG2CuzfhiG/9pHROzw8JD9A/hQoR0ACR8rAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/d8558b14bc2e985dfb95c978261e3a12/7bc0b/output_56_0.png\"\n        srcset=\"/static/d8558b14bc2e985dfb95c978261e3a12/e9ff0/output_56_0.png 180w,\n/static/d8558b14bc2e985dfb95c978261e3a12/f21e7/output_56_0.png 360w,\n/static/d8558b14bc2e985dfb95c978261e3a12/7bc0b/output_56_0.png 386w\"\n        sizes=\"(max-width: 386px) 100vw, 386px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<div class=\"table-of-contents\">\n<ul>\n<li>\n<p><a href=\"#l2-norm--ridge\">L2 norm  Ridge</a></p>\n<ul>\n<li>\n<ul>\n<li><a href=\"#%EA%B7%B8%EB%9F%AC%EB%AF%80%EB%A1%9C-%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%97%90-%EB%94%B0%EB%9D%BC-%EC%A0%81%EC%A0%88%ED%95%9C-regularization-%EB%B0%A9%EB%B2%95%EC%9D%84-%ED%99%9C%EC%9A%A9%ED%95%98%EB%8A%94-%EA%B2%83%EC%9D%B4-%EC%A2%8B%EC%8A%B5%EB%8B%88%EB%8B%A4\">ê·¸ëŸ¬ë¯€ë¡œ, ë°ì´í„°ì— ë”°ë¼ ì ì ˆí•œ Regularization ë°©ë²•ì„ í™œìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><a href=\"#%EA%B7%BC%EB%8D%B0-%EA%B7%B8%EB%9E%98%EC%84%9C-norm-%EC%9D%B4%EB%9E%80%EA%B2%8C-%EB%AD%98%EA%B9%8C\">ê·¼ë° ê·¸ë˜ì„œ Norm ì´ë€ê²Œ ë­˜ê¹Œâ€¦?</a></p>\n</li>\n<li>\n<p><a href=\"#dropout-%EC%9D%80-%EB%AD%94%EB%8D%B0\">Dropout ì€ ë­”ë°?</a></p>\n<ul>\n<li><a href=\"#overfitting-%EC%A4%84%EC%9D%B4%EB%8A%94-%EB%B2%95\">overfitting ì¤„ì´ëŠ” ë²•</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#batch-normalization\">Batch Normalization</a></p>\n<ul>\n<li><a href=\"#%EC%9A%94%EA%B1%B4-%EA%B8%B0%EC%9A%B8%EA%B8%B0%EC%86%8C%EC%8B%A4-%EC%9D%B4%EB%9E%91-%EA%B8%B0%EC%9A%B8%EA%B8%B0%ED%8F%AC%ED%99%94-%EB%AC%B8%EC%A0%9C%EB%A5%BC-%ED%95%B4%EA%B2%B0%ED%95%9C%EB%8B%A4\">ìš”ê±´ ê¸°ìš¸ê¸°ì†Œì‹¤ ì´ë‘ ê¸°ìš¸ê¸°í¬í™” ë¬¸ì œë¥¼ í•´ê²°í•œë‹¤.</a></li>\n<li><a href=\"#%EB%B0%B0%EC%B9%98-%EB%85%B8%EB%A7%90%EB%9D%BC%EC%9D%B4%EC%A0%9C%EC%9D%B4%EC%85%98-%EC%93%B0%EB%A9%B4\">ë°°ì¹˜ ë…¸ë§ë¼ì´ì œì´ì…˜ ì“°ë©´</a></li>\n</ul>\n</li>\n</ul>\n</div>","frontmatter":{"date":"April 21, 2022","title":"ì •ê·œí™” ì •ì¹™í™” ì°¨ì´","categories":"STUDY","author":"í•˜ì„±ë¯¼","emoji":"ğŸ˜"},"fields":{"slug":"/DML_norm/"}},"site":{"siteMetadata":{"siteUrl":"https://xman227.github.io","comments":{"utterances":{"repo":"xman227/blog_comments"}}}}},"pageContext":{"slug":"/DML_AI4/","nextSlug":"/DML_keras3/","prevSlug":"/DML_norm/"}},
    "staticQueryHashes": ["1073350324","1956554647","2938748437"]}