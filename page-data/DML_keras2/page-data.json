{
    "componentChunkName": "component---src-templates-blog-template-js",
    "path": "/DML_keras2/",
    "result": {"data":{"cur":{"id":"797d644a-1f24-5817-8dd3-7489d8b62484","html":"<h1 id=\"span-stylebackground-color-fff5b1-tensor-flow-v2-ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼-ì´ìš©í•´-ë”¥ëŸ¬ë‹-ëª¨ë¸-ìƒì„±í•˜ê¸°span\" style=\"position:relative;\"><a href=\"#span-stylebackground-color-fff5b1-tensor-flow-v2-%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%B4-%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%AA%A8%EB%8D%B8-%EC%83%9D%EC%84%B1%ED%95%98%EA%B8%B0span\" aria-label=\"span stylebackground color fff5b1 tensor flow v2 ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ìš©í•´ ë”¥ëŸ¬ë‹ ëª¨ë¸ ìƒì„±í•˜ê¸°span permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><span style='background-color: #fff5b1'>ğŸŒ  Tensor flow V2 ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ìš©í•´ ë”¥ëŸ¬ë‹ ëª¨ë¸ ìƒì„±í•˜ê¸°</span></h1>\n<p>Tensor flow V2 ë²„ì „ì—ì„œ ë”¥ëŸ¬ë‹ ëª¨ë¸ ì‘ì„± ë°©ë²•ì—ëŠ” í¬ê²Œ 3ê°€ì§€ê°€ ìˆë‹¤.</p>\n<ul>\n<li>Sequential</li>\n<li>Functional : sequential ì˜ ì¼ë°˜í™”ëœ ê°œë…</li>\n<li>Model Subclassing : í´ë˜ìŠ¤ë¡œ êµ¬í˜„ëœ ê¸°ì¡´ ëª¨ë¸ì„ ìƒì†ë°›ì•„ ìê¸° ëª¨ë¸ ë§Œë“¤ê¸°</li>\n</ul>\n<p>ìˆœì°¨ì ìœ¼ë¡œ ì–´ë–¤ ì°¨ì´ê°€ ìˆê³ ,<br>\nì–´ë–¤ ì‹ìœ¼ë¡œ ì œì‘í•˜ëŠ”ì§€ ì•Œì•„ê°€ë³´ì.</p>\n<hr>\n<h2 id=\"1-sequential-model\" style=\"position:relative;\"><a href=\"#1-sequential-model\" aria-label=\"1 sequential model permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. Sequential Model</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n<span class=\"token keyword\">from</span> tensorflow <span class=\"token keyword\">import</span> keras\n\nmodel <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>__ë„£ê³ ì‹¶ì€ ë ˆì´ì–´__<span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>__ë„£ê³ ì‹¶ì€ ë ˆì´ì–´__<span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>__ë„£ê³ ì‹¶ì€ ë ˆì´ì–´__<span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">20</span><span class=\"token punctuation\">,</span> batch_size<span class=\"token operator\">=</span><span class=\"token number\">16</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>epochs : ëª¨ë¸ë¡œ ë°ì´í„°ë¥¼ í•™ìŠµí•  íšŸìˆ˜<br>\nbatch_size : ë°ì´í„°ë¥¼ ì†Œë¶„í•´ ë„£ì„ ì–‘</p>\n<p>model = keras.Sequential() ì„ í™œìš©í•˜ë©´<br>\në”¥ëŸ¬ë‹ ëª¨ë¸ì„ ìŒ“ì•„ ë‚˜ê°ˆ ìˆ˜ ìˆë‹¤.</p>\n<p>ì…ë ¥ë¶€í„° ì¶œë ¥ê¹Œì§€ ìˆœì°¨ì (ì‹œí€€ì…œ) ìœ¼ë¡œ add í•˜ë©´ ëœë‹¤.</p>\n<h4 id=\"but\" style=\"position:relative;\"><a href=\"#but\" aria-label=\"but permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>but,</h4>\n<p>ëª¨ë¸ì˜ ì…ë ¥ê³¼ ì¶œë ¥ì´ ì—¬ëŸ¬ê°œì¸ ê²½ìš°ì—ëŠ” ì í•©í•˜ì§€ ì•Šë‹¤.<br>\n(ë°˜ë“œì‹œ ì…ë ¥ 1ê°œ ì¶œë ¥ 1ê°€ì§€ ì—¬ì•¼ í•¨)</p>\n<h2 id=\"2-functional-api\" style=\"position:relative;\"><a href=\"#2-functional-api\" aria-label=\"2 functional api permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. Functional API</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n<span class=\"token keyword\">from</span> tensorflow <span class=\"token keyword\">import</span> keras\n\ninputs <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>Input<span class=\"token punctuation\">(</span>shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>__ì›í•˜ëŠ” ì…ë ¥ê°’ ëª¨ì–‘__<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nx <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>__ë„£ê³ ì‹¶ì€ ë ˆì´ì–´__<span class=\"token punctuation\">(</span>ê´€ë ¨ íŒŒë¼ë¯¸í„°<span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">input</span><span class=\"token punctuation\">)</span>\nx <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>__ë„£ê³ ì‹¶ì€ ë ˆì´ì–´__<span class=\"token punctuation\">(</span>ê´€ë ¨ íŒŒë¼ë¯¸í„°<span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\noutputs <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>__ë„£ê³ ì‹¶ì€ ë ˆì´ì–´__<span class=\"token punctuation\">(</span>ê´€ë ¨ íŒŒë¼ë¯¸í„°<span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n\nmodel <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>Model<span class=\"token punctuation\">(</span>inputs<span class=\"token operator\">=</span>inputs<span class=\"token punctuation\">,</span> outputs<span class=\"token operator\">=</span>outputs<span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span>y<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> batch_size<span class=\"token operator\">=</span><span class=\"token number\">32</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>model ì— ketas.Model ì´ ë“¤ì–´ê°„ë‹¤.<br>\nì´ê²ƒì€ ìš°ë¦¬ê°€ danse ë‚˜ Flatten ê°™ì€ ì§œì—¬ì ¸ ìˆëŠ” ì‹ ê²½ë§ì„ ì“°ëŠ” ê²Œ ì•„ë‹ˆë¼<br>\nì§ì ‘ input ê³¼ output ì„ êµ¬ì„±í•œë‹¤.</p>\n<p>ë•Œë¬¸ì— ì…ë ¥ê³¼ ì¶œë ¥ê°’ì´ ììœ ë¡­ë‹¤</p>\n<hr>\n<p>ë”¥ ëŸ¬ë‹ ëª¨ë¸ì€ ì¼ë°˜ì ìœ¼ë¡œ ë ˆì´ì–´ì˜ DAG Directed Acyclic graph ì´ë‹¤.<br>\në ˆì´ì–´ì˜ ê·¸ë˜í”„ë¥¼ bulid í•œë‹¤ëŠ” ëœ»ì´ë‹¤.</p>\n<h2 id=\"3-subclassing\" style=\"position:relative;\"><a href=\"#3-subclassing\" aria-label=\"3 subclassing permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. Subclassing</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n<span class=\"token keyword\">from</span> tensorflow <span class=\"token keyword\">import</span> keras\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">CustomModel</span><span class=\"token punctuation\">(</span>keras<span class=\"token punctuation\">.</span>Model<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span>CustomModel<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>__ì •ì˜í•˜ê³ ì í•˜ëŠ” ë ˆì´ì–´__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>__ì •ì˜í•˜ê³ ì í•˜ëŠ” ë ˆì´ì–´__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>__ì •ì˜í•˜ê³ ì í•˜ëŠ” ë ˆì´ì–´__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    \n    <span class=\"token keyword\">def</span> <span class=\"token function\">call</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>__ì •ì˜í•˜ê³ ì í•˜ëŠ” ë ˆì´ì–´__<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>__ì •ì˜í•˜ê³ ì í•˜ëŠ” ë ˆì´ì–´__<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>__ì •ì˜í•˜ê³ ì í•˜ëŠ” ë ˆì´ì–´__<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        \n        <span class=\"token keyword\">return</span> x\n    \nmodel <span class=\"token operator\">=</span> CustomModel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span>y<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> batch_size<span class=\"token operator\">=</span><span class=\"token number\">32</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>ì œì¼ ììœ ë¡œìš´ ëª¨ë¸ë§ì´ ê°€ëŠ¥í•œ subclassing</p>\n<h1 id=\"ì´ë¥¼-ë°”íƒ•ìœ¼ë¡œ-ì§ì ‘-êµ¬í˜„í•´ë³´ì\" style=\"position:relative;\"><a href=\"#%EC%9D%B4%EB%A5%BC-%EB%B0%94%ED%83%95%EC%9C%BC%EB%A1%9C-%EC%A7%81%EC%A0%91-%EA%B5%AC%ED%98%84%ED%95%B4%EB%B3%B4%EC%9E%90\" aria-label=\"ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ì ‘ êµ¬í˜„í•´ë³´ì permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ì ‘ êµ¬í˜„í•´ë³´ì</h1>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n<span class=\"token keyword\">from</span> tensorflow <span class=\"token keyword\">import</span> keras\n<span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># ë°ì´í„° êµ¬ì„±ë¶€ë¶„</span>\nmnist <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>datasets<span class=\"token punctuation\">.</span>mnist\n\n<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span> y_test<span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> mnist<span class=\"token punctuation\">.</span>load_data<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nx_train<span class=\"token punctuation\">,</span> x_test <span class=\"token operator\">=</span> x_train <span class=\"token operator\">/</span> <span class=\"token number\">255.0</span><span class=\"token punctuation\">,</span> x_test <span class=\"token operator\">/</span> <span class=\"token number\">255.0</span>\n\nx_train<span class=\"token operator\">=</span>x_train<span class=\"token punctuation\">[</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">,</span>np<span class=\"token punctuation\">.</span>newaxis<span class=\"token punctuation\">]</span>\nx_test<span class=\"token operator\">=</span>x_test<span class=\"token punctuation\">[</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">,</span>np<span class=\"token punctuation\">.</span>newaxis<span class=\"token punctuation\">]</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n11493376/11490434 [==============================] - 0s 0us/step\n11501568/11490434 [==============================] - 0s 0us/step\n60000 10000</code></pre></div>\n<h2 id=\"1-sequential-model-1\" style=\"position:relative;\"><a href=\"#1-sequential-model-1\" aria-label=\"1 sequential model 1 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. Sequential model</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># Sequential Modelì„ êµ¬ì„±í•´ì£¼ì„¸ìš”.</span>\n<span class=\"token triple-quoted-string string\">\"\"\"\nSpec:\n1. 32ê°œì˜ ì±„ë„ì„ ê°€ì§€ê³ , ì»¤ë„ì˜ í¬ê¸°ê°€ 3, activation functionì´ reluì¸ Conv2D ë ˆì´ì–´\n2. 64ê°œì˜ ì±„ë„ì„ ê°€ì§€ê³ , ì»¤ë„ì˜ í¬ê¸°ê°€ 3, activation functionì´ reluì¸ Conv2D ë ˆì´ì–´\n3. Flatten ë ˆì´ì–´\n4. 128ê°œì˜ ì•„ì›ƒí’‹ ë…¸ë“œë¥¼ ê°€ì§€ê³ , activation functionì´ reluì¸ Fully-Connected Layer(Dense)\n5. ë°ì´í„°ì…‹ì˜ í´ë˜ìŠ¤ ê°œìˆ˜ì— ë§ëŠ” ì•„ì›ƒí’‹ ë…¸ë“œë¥¼ ê°€ì§€ê³ , activation functionì´ softmaxì¸ Fully-Connected Layer(Dense)\n\"\"\"</span>\n\n\nmodel <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>models<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span>activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span>activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">128</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span>activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span>\n                           <span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n\n<span class=\"token triple-quoted-string string\">\"\"\"\nmodel.add.Conv2D(32, 3, activation=\"relu\")\nmodel.add.Conv2D(64, 3, activation=\"relu\")\nmodel.add.Flatten()\nmodel.add.Dense(128, activation='relu')\nmodel.add.Dense(10, activation='softmax')\n\"\"\"</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">'\\nmodel.add.Conv2D(32, 3, activation=\"relu\")\\nmodel.add.Conv2D(64, 3, activation=\"relu\")\\nmodel.add.Flatten()\\nmodel.add.Dense(128, activation=\\'relu\\')\\nmodel.add.Dense(10, activation=\\'softmax\\')\\n'</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># ëª¨ë¸ í•™ìŠµ ì„¤ì •</span>\n\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span><span class=\"token string\">'adam'</span><span class=\"token punctuation\">,</span>\n              loss<span class=\"token operator\">=</span><span class=\"token string\">'sparse_categorical_crossentropy'</span><span class=\"token punctuation\">,</span>\n              metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span>  y_test<span class=\"token punctuation\">,</span> verbose<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Epoch 1/5\n1875/1875 [==============================] - 31s 3ms/step - loss: 0.1118 - accuracy: 0.9654\nEpoch 2/5\n1875/1875 [==============================] - 5s 3ms/step - loss: 0.0368 - accuracy: 0.9882\nEpoch 3/5\n1875/1875 [==============================] - 5s 3ms/step - loss: 0.0211 - accuracy: 0.9933\nEpoch 4/5\n1875/1875 [==============================] - 5s 3ms/step - loss: 0.0131 - accuracy: 0.9956\nEpoch 5/5\n1875/1875 [==============================] - 5s 3ms/step - loss: 0.0100 - accuracy: 0.9968\n313/313 - 1s - loss: 0.0516 - accuracy: 0.9878\n\n\n\n\n\n[0.051644984632730484, 0.9878000020980835]</code></pre></div>\n<h2 id=\"2-functional-api-1\" style=\"position:relative;\"><a href=\"#2-functional-api-1\" aria-label=\"2 functional api 1 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. Functional API</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">mnist <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>datasets<span class=\"token punctuation\">.</span>mnist\n\n<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span> y_test<span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> mnist<span class=\"token punctuation\">.</span>load_data<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nx_train<span class=\"token punctuation\">,</span> x_test <span class=\"token operator\">=</span> x_train <span class=\"token operator\">/</span> <span class=\"token number\">255.0</span><span class=\"token punctuation\">,</span> x_test <span class=\"token operator\">/</span> <span class=\"token number\">255.0</span>\n\nx_train<span class=\"token operator\">=</span>x_train<span class=\"token punctuation\">[</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">,</span>np<span class=\"token punctuation\">.</span>newaxis<span class=\"token punctuation\">]</span>\nx_test<span class=\"token operator\">=</span>x_test<span class=\"token punctuation\">[</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">,</span>np<span class=\"token punctuation\">.</span>newaxis<span class=\"token punctuation\">]</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">60000 10000</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token triple-quoted-string string\">\"\"\"\nSpec:\n0. (28X28X1) ì°¨ì›ìœ¼ë¡œ ì •ì˜ëœ Input\n1. 32ê°œì˜ ì±„ë„ì„ ê°€ì§€ê³ , ì»¤ë„ì˜ í¬ê¸°ê°€ 3, activation functionì´ reluì¸ Conv2D ë ˆì´ì–´\n2. 64ê°œì˜ ì±„ë„ì„ ê°€ì§€ê³ , ì»¤ë„ì˜ í¬ê¸°ê°€ 3, activation functionì´ reluì¸ Conv2D ë ˆì´ì–´\n3. Flatten ë ˆì´ì–´\n4. 128ê°œì˜ ì•„ì›ƒí’‹ ë…¸ë“œë¥¼ ê°€ì§€ê³ , activation functionì´ reluì¸ Fully-Connected Layer(Dense)\n5. ë°ì´í„°ì…‹ì˜ í´ë˜ìŠ¤ ê°œìˆ˜ì— ë§ëŠ” ì•„ì›ƒí’‹ ë…¸ë“œë¥¼ ê°€ì§€ê³ , activation functionì´ softmaxì¸ Fully-Connected Layer(Dense)\n\"\"\"</span>\n\ninputs <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>Input<span class=\"token punctuation\">(</span>shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">28</span><span class=\"token punctuation\">,</span><span class=\"token number\">28</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nx <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span>activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>inputs<span class=\"token punctuation\">)</span>\nx <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span>activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\nx <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\nx <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">128</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\noutputs <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n\nmodel <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>Model<span class=\"token punctuation\">(</span>inputs<span class=\"token operator\">=</span>inputs<span class=\"token punctuation\">,</span> outputs<span class=\"token operator\">=</span>outputs<span class=\"token punctuation\">)</span>\n\n\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span><span class=\"token string\">'adam'</span><span class=\"token punctuation\">,</span>\n              loss<span class=\"token operator\">=</span><span class=\"token string\">'sparse_categorical_crossentropy'</span><span class=\"token punctuation\">,</span>\n              metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span>  y_test<span class=\"token punctuation\">,</span> verbose<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Epoch 1/5\n1875/1875 [==============================] - 7s 3ms/step - loss: 0.1039 - accuracy: 0.9679\nEpoch 2/5\n1875/1875 [==============================] - 6s 3ms/step - loss: 0.0339 - accuracy: 0.9895\nEpoch 3/5\n1875/1875 [==============================] - 6s 3ms/step - loss: 0.0204 - accuracy: 0.9931\nEpoch 4/5\n1875/1875 [==============================] - 6s 3ms/step - loss: 0.0130 - accuracy: 0.9959\nEpoch 5/5\n1875/1875 [==============================] - 6s 3ms/step - loss: 0.0093 - accuracy: 0.9972\n313/313 - 1s - loss: 0.0522 - accuracy: 0.9868\n\n\n\n\n\n[0.05223735421895981, 0.9868000149726868]</code></pre></div>\n<h2 id=\"3-subclassing-api\" style=\"position:relative;\"><a href=\"#3-subclassing-api\" aria-label=\"3 subclassing api permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. Subclassing API</h2>\n<p>keras.models ë¥¼ ìƒì†ë°›ëŠ” í´ë˜ìŠ¤ë¥¼ ë§Œë“œëŠ” ê²ƒ</p>\n<ol>\n<li><strong>init</strong> ë©”ì„œë“œì— ë ˆì´ì–´ ì„ ì–¸</li>\n<li>call() ë©”ì„œë“œì— forward propagation ë°©ì‹ ì²´ê³„ êµ¬í˜„</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token triple-quoted-string string\">\"\"\"\nSpec:\n0. keras.Model ì„ ìƒì†ë°›ì•˜ìœ¼ë©°, __init__()ì™€ call() ë©”ì„œë“œë¥¼ ê°€ì§„ ëª¨ë¸ í´ë˜ìŠ¤\n1. 32ê°œì˜ ì±„ë„ì„ ê°€ì§€ê³ , ì»¤ë„ì˜ í¬ê¸°ê°€ 3, activation functionì´ reluì¸ Conv2D ë ˆì´ì–´\n2. 64ê°œì˜ ì±„ë„ì„ ê°€ì§€ê³ , ì»¤ë„ì˜ í¬ê¸°ê°€ 3, activation functionì´ reluì¸ Conv2D ë ˆì´ì–´\n3. Flatten ë ˆì´ì–´\n4. 128ê°œì˜ ì•„ì›ƒí’‹ ë…¸ë“œë¥¼ ê°€ì§€ê³ , activation functionì´ reluì¸ Fully-Connected Layer(Dense)\n5. ë°ì´í„°ì…‹ì˜ í´ë˜ìŠ¤ ê°œìˆ˜ì— ë§ëŠ” ì•„ì›ƒí’‹ ë…¸ë“œë¥¼ ê°€ì§€ê³ , activation functionì´ softmaxì¸ Fully-Connected Layer(Dense)\n6. callì˜ ì…ë ¥ê°’ì´ ëª¨ë¸ì˜ Input, callì˜ ë¦¬í„´ê°’ì´ ëª¨ë¸ì˜ Output\n\"\"\"</span>\n\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">kerasModel</span><span class=\"token punctuation\">(</span>keras<span class=\"token punctuation\">.</span>Model<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        \n        self<span class=\"token punctuation\">.</span>Conv2D32 <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>Conv2D64 <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>Flatten <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>Dense128 <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">128</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>Dense <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span>\n    \n    <span class=\"token keyword\">def</span> <span class=\"token function\">call</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>Conv2D32<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>Conv2D64<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>Dense128<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        output <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        \n        <span class=\"token keyword\">return</span> output\n    \nmodel <span class=\"token operator\">=</span> kerasModel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span><span class=\"token string\">'adam'</span><span class=\"token punctuation\">,</span>\n              loss<span class=\"token operator\">=</span><span class=\"token string\">'sparse_categorical_crossentropy'</span><span class=\"token punctuation\">,</span>\n              metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span>  y_test<span class=\"token punctuation\">,</span> verbose<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Epoch 1/5\n1875/1875 [==============================] - 7s 3ms/step - loss: 0.1011 - accuracy: 0.9689\nEpoch 2/5\n1875/1875 [==============================] - 6s 3ms/step - loss: 0.0339 - accuracy: 0.9893\nEpoch 3/5\n1875/1875 [==============================] - 6s 3ms/step - loss: 0.0184 - accuracy: 0.9938\nEpoch 4/5\n1875/1875 [==============================] - 6s 3ms/step - loss: 0.0136 - accuracy: 0.9954\nEpoch 5/5\n1875/1875 [==============================] - 6s 3ms/step - loss: 0.0078 - accuracy: 0.9973\n313/313 - 1s - loss: 0.0581 - accuracy: 0.9853\n\n\n\n\n\n[0.05812956392765045, 0.9853000044822693]</code></pre></div>\n<p>ì´ê±´ ê²°ë¡ ì ìœ¼ë¡œëŠ” model ì„ ê°–ë‹¤ ì“°ëŠ”ê±°ë¼ì„œ<br>\ninput ì„ ë”°ë¡œ ì„¤ì •ì•ˆí•˜ê³ <br>\nê·¸ë¦¬ê³  call ë©”ì„œë“œë„ fit í• ë•Œ ìë™ìœ¼ë¡œ ì¨ì§€ëŠ” ë“¯ í•˜ë‹¤.</p>\n<hr>\n<h1 id=\"cifar--100-ë°ì´í„°-ì˜ˆì œë¡œ-ë³µìŠµ\" style=\"position:relative;\"><a href=\"#cifar--100-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%98%88%EC%A0%9C%EB%A1%9C-%EB%B3%B5%EC%8A%B5\" aria-label=\"cifar  100 ë°ì´í„° ì˜ˆì œë¡œ ë³µìŠµ permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>CIFAR -100 ë°ì´í„° ì˜ˆì œë¡œ ë³µìŠµ</h1>\n<h3 id=\"sequential\" style=\"position:relative;\"><a href=\"#sequential\" aria-label=\"sequential permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Sequential</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># ë°ì´í„° êµ¬ì„±ë¶€ë¶„</span>\ncifar100 <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>datasets<span class=\"token punctuation\">.</span>cifar100\n\n<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span> y_test<span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> cifar100<span class=\"token punctuation\">.</span>load_data<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nx_train<span class=\"token punctuation\">,</span> x_test <span class=\"token operator\">=</span> x_train <span class=\"token operator\">/</span> <span class=\"token number\">255.0</span><span class=\"token punctuation\">,</span> x_test <span class=\"token operator\">/</span> <span class=\"token number\">255.0</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">50000 10000</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># Sequential Modelì„ êµ¬ì„±í•´ì£¼ì„¸ìš”.</span>\n<span class=\"token triple-quoted-string string\">\"\"\"\nSpec:\n1. 16ê°œì˜ ì±„ë„ì„ ê°€ì§€ê³ , ì»¤ë„ì˜ í¬ê¸°ê°€ 3, activation functionì´ reluì¸ Conv2D ë ˆì´ì–´\n2. pool_sizeê°€ 2ì¸ MaxPool ë ˆì´ì–´\n3. 32ê°œì˜ ì±„ë„ì„ ê°€ì§€ê³ , ì»¤ë„ì˜ í¬ê¸°ê°€ 3, activation functionì´ reluì¸ Conv2D ë ˆì´ì–´\n4. pool_sizeê°€ 2ì¸ MaxPool ë ˆì´ì–´\n5. 256ê°œì˜ ì•„ì›ƒí’‹ ë…¸ë“œë¥¼ ê°€ì§€ê³ , activation functionì´ reluì¸ Fully-Connected Layer(Dense)\n6. ë°ì´í„°ì…‹ì˜ í´ë˜ìŠ¤ ê°œìˆ˜ì— ë§ëŠ” ì•„ì›ƒí’‹ ë…¸ë“œë¥¼ ê°€ì§€ê³ , activation functionì´ softmaxì¸ Fully-Connected Layer(Dense)\n\"\"\"</span>\n\nmodel <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>models<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span>activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>MaxPool2D<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span>activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>MaxPool2D<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">256</span><span class=\"token punctuation\">,</span>activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">100</span><span class=\"token punctuation\">,</span>activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">model<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span><span class=\"token string\">'adam'</span><span class=\"token punctuation\">,</span>\n              loss<span class=\"token operator\">=</span><span class=\"token string\">'sparse_categorical_crossentropy'</span><span class=\"token punctuation\">,</span>\n              metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span>  y_test<span class=\"token punctuation\">,</span> verbose<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Epoch 1/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\nEpoch 2/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\nEpoch 3/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\nEpoch 4/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\nEpoch 5/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\n313/313 - 1s - loss: nan - accuracy: 0.0100\n\n\n\n\n\n[nan, 0.009999999776482582]</code></pre></div>\n<h3 id=\"functional\" style=\"position:relative;\"><a href=\"#functional\" aria-label=\"functional permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Functional</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token triple-quoted-string string\">\"\"\"\nSpec:\n0. (32X32X3) ì°¨ì›ìœ¼ë¡œ ì •ì˜ëœ Input\n1. 16ê°œì˜ ì±„ë„ì„ ê°€ì§€ê³ , ì»¤ë„ì˜ í¬ê¸°ê°€ 3, activation functionì´ reluì¸ Conv2D ë ˆì´ì–´\n2. pool_sizeê°€ 2ì¸ MaxPool ë ˆì´ì–´\n3. 32ê°œì˜ ì±„ë„ì„ ê°€ì§€ê³ , ì»¤ë„ì˜ í¬ê¸°ê°€ 3, activation functionì´ reluì¸ Conv2D ë ˆì´ì–´\n4. pool_sizeê°€ 2ì¸ MaxPool ë ˆì´ì–´\n5. 256ê°œì˜ ì•„ì›ƒí’‹ ë…¸ë“œë¥¼ ê°€ì§€ê³ , activation functionì´ reluì¸ Fully-Connected Layer(Dense)\n6. ë°ì´í„°ì…‹ì˜ í´ë˜ìŠ¤ ê°œìˆ˜ì— ë§ëŠ” ì•„ì›ƒí’‹ ë…¸ë“œë¥¼ ê°€ì§€ê³ , activation functionì´ softmaxì¸ Fully-Connected Layer(Dense)\n\"\"\"</span>\n\ninputs <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>Input<span class=\"token punctuation\">(</span>shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nx <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span>activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>inputs<span class=\"token punctuation\">)</span>\nx <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>MaxPool2D<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\nx <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span>activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\nx <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>MaxPool2D<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\nx <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\nx <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">256</span><span class=\"token punctuation\">,</span>activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\noutputs <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">100</span><span class=\"token punctuation\">,</span>activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n\nmodel <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>Model<span class=\"token punctuation\">(</span>inputs<span class=\"token operator\">=</span>inputs<span class=\"token punctuation\">,</span> outputs<span class=\"token operator\">=</span>outputs<span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span><span class=\"token string\">'adam'</span><span class=\"token punctuation\">,</span>\n               loss<span class=\"token operator\">=</span><span class=\"token string\">'sparse_categorical_crossentropy'</span><span class=\"token punctuation\">,</span>\n               metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> epochs <span class=\"token operator\">=</span> <span class=\"token number\">5</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span> y_test<span class=\"token punctuation\">,</span> verbose <span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Epoch 1/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\nEpoch 2/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\nEpoch 3/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\nEpoch 4/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\nEpoch 5/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\n313/313 - 1s - loss: nan - accuracy: 0.0100\n\n\n\n\n\n[nan, 0.009999999776482582]</code></pre></div>\n<h3 id=\"subclass-api\" style=\"position:relative;\"><a href=\"#subclass-api\" aria-label=\"subclass api permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Subclass API</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token triple-quoted-string string\">\"\"\"\nSpec:\n0. keras.Model ì„ ìƒì†ë°›ì•˜ìœ¼ë©°, __init__()ì™€ call() ë©”ì„œë“œë¥¼ ê°€ì§„ ëª¨ë¸ í´ë˜ìŠ¤\n1. 16ê°œì˜ ì±„ë„ì„ ê°€ì§€ê³ , ì»¤ë„ì˜ í¬ê¸°ê°€ 3, activation functionì´ reluì¸ Conv2D ë ˆì´ì–´\n2. pool_sizeê°€ 2ì¸ MaxPool ë ˆì´ì–´\n3. 32ê°œì˜ ì±„ë„ì„ ê°€ì§€ê³ , ì»¤ë„ì˜ í¬ê¸°ê°€ 3, activation functionì´ reluì¸ Conv2D ë ˆì´ì–´\n4. pool_sizeê°€ 2ì¸ MaxPool ë ˆì´ì–´\n5. 256ê°œì˜ ì•„ì›ƒí’‹ ë…¸ë“œë¥¼ ê°€ì§€ê³ , activation functionì´ reluì¸ Fully-Connected Layer(Dense)\n6. ë°ì´í„°ì…‹ì˜ í´ë˜ìŠ¤ ê°œìˆ˜ì— ë§ëŠ” ì•„ì›ƒí’‹ ë…¸ë“œë¥¼ ê°€ì§€ê³ , activation functionì´ softmaxì¸ Fully-Connected Layer(Dense)\n7. callì˜ ì…ë ¥ê°’ì´ ëª¨ë¸ì˜ Input, callì˜ ë¦¬í„´ê°’ì´ ëª¨ë¸ì˜ Output\n\"\"\"</span>\n\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">kerasModel</span><span class=\"token punctuation\">(</span>keras<span class=\"token punctuation\">.</span>Model<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        \n        self<span class=\"token punctuation\">.</span>Conv2D16 <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>Conv2D32 <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>Maxpool <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>MaxPool2D<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>Flatten <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>Dense256 <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">256</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>Dense <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span>\n    \n    <span class=\"token keyword\">def</span> <span class=\"token function\">call</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>Conv2D16<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>Maxpool<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>Conv2D32<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>Maxpool<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>Dense256<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        output <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        \n        <span class=\"token keyword\">return</span> output\n    \nmodel <span class=\"token operator\">=</span> kerasModel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span><span class=\"token string\">'adam'</span><span class=\"token punctuation\">,</span>\n              loss<span class=\"token operator\">=</span><span class=\"token string\">'sparse_categorical_crossentropy'</span><span class=\"token punctuation\">,</span>\n              metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span>  y_test<span class=\"token punctuation\">,</span> verbose<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Epoch 1/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\nEpoch 2/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\nEpoch 3/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\nEpoch 4/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\nEpoch 5/5\n1563/1563 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0100\n313/313 - 1s - loss: nan - accuracy: 0.0100\n\n\n\n\n\n[nan, 0.009999999776482582]</code></pre></div>\n<hr>\n<p>ìš°ë¦¬ëŠ” model.compile ì— ìˆì–´ì„œ ê³„ì† ë™ì¼í•œ êµ¬ì„±ì„ ìœ ì§€í–ˆë‹¤.</p>\n<p>ì ì‹œ ì¸ê³µì§€ëŠ¥ í•™ìŠµ ê³¼ì •ì„ ë³µê¸°í•´ë³´ì.</p>\n<ol>\n<li>Forward Propagation</li>\n<li>Loss ê°’ ê³„ì‚°</li>\n<li>ì¤‘ê°„ ë ˆì´ì–´ ê°’ ë° loss ë¥¼ í™œìš©í•œ chain rule ë°©ì‹ì˜ Back propagation</li>\n<li>parameter update</li>\n<li>repeat</li>\n</ol>\n<p>ì´ëŸ° ê³¼ì •ì´ tf v2 ì—ì„œëŠ” fit ì— ë‹¤ ë‹´ê²¨ìˆë‹¤.</p>\n<p>tf.gredient tape ëŠ” propagation ë™ì•ˆ ì§„í–‰ë˜ëŠ” ëª¨ë“  ì—°ì‚°ì˜ ì¤‘ê°„ ë ˆì´ì–´ ê°’ì„<br>\ntape ì— ê¸°ë¡í•œë‹¤.</p>\n<p>ì´ë¥¼ ì´ìš©í•´ gredient ë¥¼ ê³„ì‚°í•˜ê³  tape ë¥¼ íê¸°í•œë‹¤.</p>\n<p>ìš°ë¦¬ëŠ” ì´ tape ê°’ì„ ì´ìš©í•´ ê³ ê¸‰ê¸°ë²•ì„ ì´ìš©í•  ìˆ˜ ìˆë‹¤.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n<span class=\"token keyword\">from</span> tensorflow <span class=\"token keyword\">import</span> keras\n\n<span class=\"token comment\"># ë°ì´í„° êµ¬ì„±ë¶€ë¶„</span>\ncifar100 <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>datasets<span class=\"token punctuation\">.</span>cifar100\n\n<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span> y_test<span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> cifar100<span class=\"token punctuation\">.</span>load_data<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nx_train<span class=\"token punctuation\">,</span> x_test <span class=\"token operator\">=</span> x_train <span class=\"token operator\">/</span> <span class=\"token number\">255.0</span><span class=\"token punctuation\">,</span> x_test <span class=\"token operator\">/</span> <span class=\"token number\">255.0</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># ëª¨ë¸ êµ¬ì„±ë¶€ë¶„</span>\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">CustomModel</span><span class=\"token punctuation\">(</span>keras<span class=\"token punctuation\">.</span>Model<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>conv1 <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>maxpool1 <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>MaxPool2D<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>conv2 <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>maxpool2 <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>MaxPool2D<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>flatten <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>fc1 <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">256</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>fc2 <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">100</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">call</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>conv1<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>maxpool1<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>conv2<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>maxpool2<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>flatten<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>fc1<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>fc2<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">return</span> x\n\nmodel <span class=\"token operator\">=</span> CustomModel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">50000 10000</code></pre></div>\n<p>ì§€ê¸ˆê¹Œì§€ëŠ”</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">model<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span><span class=\"token string\">'adam'</span><span class=\"token punctuation\">,</span>\n              loss<span class=\"token operator\">=</span><span class=\"token string\">'sparse_categorical_crossentropy'</span><span class=\"token punctuation\">,</span>\n              metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>ì—ì„œ ì•Œì•„ì„œ loss ë¥¼ í†µí•´ í•™ìŠµ íŒŒë¼ë¯¸í„°ë¥¼ ìˆ˜ì •í•  ìˆ˜ ìˆê²Œ í•´ì£¼ì—ˆë‹¤.</p>\n<p>ì´ë²ˆì—ëŠ” tape.gradient() ë¥¼ í†µí•´ì„œ<br>\në§¤ ìŠ¤í… ë§ˆë‹¤ ë°œìƒí•˜ëŠ” gredient ë¥¼ export,<br>\noptimizer.apply_grediens() ë¥¼ í†µí•´ ë°œìƒí•œ gredient ê°€<br>\nmodel.trainable_variables ë¥¼ í†µí•´ íŒŒë¼ë¯¸í„°ë¥¼ ì—…ë°ì´í„° í•˜ë„ë¡ í•œë‹¤.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">loss_func <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>losses<span class=\"token punctuation\">.</span>SparseCategoricalCrossentropy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\noptimizer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>optimizers<span class=\"token punctuation\">.</span>Adam<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># tf.GradientTape()ë¥¼ í™œìš©í•œ train_step</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">train_step</span><span class=\"token punctuation\">(</span>features<span class=\"token punctuation\">,</span> labels<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> tf<span class=\"token punctuation\">.</span>GradientTape<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> tape<span class=\"token punctuation\">:</span>\n        predictions <span class=\"token operator\">=</span> model<span class=\"token punctuation\">(</span>features<span class=\"token punctuation\">)</span>\n        loss <span class=\"token operator\">=</span> loss_func<span class=\"token punctuation\">(</span>labels<span class=\"token punctuation\">,</span> predictions<span class=\"token punctuation\">)</span>\n        gradients <span class=\"token operator\">=</span> tape<span class=\"token punctuation\">.</span>gradient<span class=\"token punctuation\">(</span>loss<span class=\"token punctuation\">,</span> model<span class=\"token punctuation\">.</span>trainable_variables<span class=\"token punctuation\">)</span>\n    optimizer<span class=\"token punctuation\">.</span>apply_gradients<span class=\"token punctuation\">(</span><span class=\"token builtin\">zip</span><span class=\"token punctuation\">(</span>gradients<span class=\"token punctuation\">,</span> model<span class=\"token punctuation\">.</span>trainable_variables<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> loss</code></pre></div>\n<p>ìœ„ì˜ train_step ë©”ì„œë“œê°€ ë°”ë¡œ<br>\nfit ì„ í†µí•´ 1ë²ˆ epoch í•˜ëŠ” ë™ì•ˆì˜ ì•ˆì—ì„œ ì´ë£¨ì–´ì§€ëŠ” steps ë“¤ì˜ ì§„í–‰ë°©ì‹ì„ ë‚˜íƒ€ë‚¸ê²ƒ.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> time\n<span class=\"token keyword\">def</span> <span class=\"token function\">train_model</span><span class=\"token punctuation\">(</span>batch_size<span class=\"token operator\">=</span><span class=\"token number\">32</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    start <span class=\"token operator\">=</span> time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">for</span> epoch <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        x_batch <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n        y_batch <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">for</span> step<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">)</span> <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">zip</span><span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            x_batch<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n            y_batch<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>y<span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">if</span> step <span class=\"token operator\">%</span> batch_size <span class=\"token operator\">==</span> batch_size<span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">:</span>\n                loss <span class=\"token operator\">=</span> train_step<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span>x_batch<span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>np<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span>y_batch<span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>np<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n                x_batch <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n                y_batch <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Epoch %d: last batch loss = %.4f'</span> <span class=\"token operator\">%</span> <span class=\"token punctuation\">(</span>epoch<span class=\"token punctuation\">,</span> <span class=\"token builtin\">float</span><span class=\"token punctuation\">(</span>loss<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"It took {} seconds\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> start<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\ntrain_model<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Epoch 0: last batch loss = 3.2522\nEpoch 1: last batch loss = 2.6932\nEpoch 2: last batch loss = 2.4441\nEpoch 3: last batch loss = 2.3071\nEpoch 4: last batch loss = 2.2136\nIt took 85.202951669693 seconds</code></pre></div>\n<p>ìœ„ ë‘ í•¨ìˆ˜ì˜ ì—°ê³„ì‚¬ìš©ì´\nfit ë©”ì„œë“œë¥¼ í’€ì–´ ì“´ ê²ƒì´ë‹¤.</p>\n<p>ì‰½ê²Œ ë§í•˜ë©´</p>\n<p>ë°ì´í„°ë“¤ì„ batch_size ë§Œí¼ ëŠì–´ì„œ<br>\nê·¸ ëŠì€ ë§Œí¼ì˜ x_train(feature) ë¥¼ ë„£ì–´ ëª¨ë¸ ì‹ ê²½ë§ì— ë„£ê³  ëŒë ¤\nì˜ˆì¸¡í•œ y_train ê°’ì„ ë°˜í™˜í•˜ê³ </p>\n<p>ì‹¤ì œ y_trian(label) ê°’ê³¼ ì˜ˆì¸¡í•œ y_trian ê°’ì„ ì†ì‹¤í•¨ìˆ˜(loss) ë¥¼ ëŒë ¤<br>\nê·¸ ì¶œë ¥ ê°’ìœ¼ë¡œ Back propagation ì„ í†µí•´ ëª¨ë¸ ë‚´ë¶€ ê°€ì¤‘ì¹˜ë¥¼ ìƒˆë¡œìš´ ê°€ì¤‘ì¹˜ë¡œ update</p>\n<p>ì ê·¸ëŸ¼ ì†ì‹¤ê°’ì€ í•œ 1epochs ì— ë°°ì¹˜ì‚¬ì´ì¦ˆ ëŒë¦°ë§Œí¼ ë‚˜ì˜¤ê² ì§€?<br>\n(ìœ„ì˜ ê²½ìš° 32ë°°ì¹˜ì‚¬ì´ì¦ˆ ì´ë¯€ë¡œ ë°ì´í„°ê°€ 100ê°œë©´ í•œ epochs ë‹¹ loss ê°€ 3ê°œ ë‚˜ì˜¤ì§€)\ní•˜ì§€ë§Œ ì¶œë ¥ë˜ëŠ” loss ëŠ” ë§¨ ë§ˆì§€ë§‰ ë°°ì¹˜ì˜ loss ì´ë‹¤.</p>\n<p>ì´ ê³¼ì •ì„ epoch íšŸìˆ˜ ë§Œí¼ ë°˜ë³µí•˜ëŠ” ê²ƒì´ë‹¤.</p>\n<p>ì´ê²Œ fit ë©”ì„œë“œê°€ í•˜ëŠ” ì¼.</p>\n<hr>\n<p>ì´ê±¸ êµ³ì´ ë„ì§‘ì–´ë‚´ì„œ ë³´ëŠ” ì´ìœ ëŠ”</p>\n<p>ìš°ë¦¬ê°€ ê°•í™”í•™ìŠµ ë˜ëŠ” GAN ì„ ì‹œí–‰í•  ë•Œ\nì´ ë‚´ë¶€ train_step ì˜ ì¬êµ¬ì„±ì„ í•´ì•¼ í•˜ë¯€ë¡œ!!!!!</p>\n<hr>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">prediction <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span> batch_size<span class=\"token operator\">=</span>x_test<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> verbose<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\ntemp <span class=\"token operator\">=</span> <span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>squeeze<span class=\"token punctuation\">(</span>y_test<span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> np<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>prediction<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\ntemp<span class=\"token operator\">/</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>y_test<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># Accuracy</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">1/1 [==============================] - 1s 822ms/step\n\n\n\n\n\n0.346</code></pre></div>\n<p>ì¼ë‹¨ epoch í•´ë´£ìœ¼ë‹ˆ ê²°ê³¼ê°’ë„ ì´ë ‡ê²Œ ë„ì¶œì´ ëœë‹¤.</p>\n<div class=\"table-of-contents\">\n<ul>\n<li>\n<p><a href=\"#1-sequential-model\">1. Sequential Model</a></p>\n<ul>\n<li>\n<ul>\n<li><a href=\"#but\">but,</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><a href=\"#2-functional-api\">2. Functional API</a></p>\n</li>\n<li>\n<p><a href=\"#3-subclassing\">3. Subclassing</a></p>\n</li>\n<li>\n<p><a href=\"#1-sequential-model-1\">1. Sequential model</a></p>\n</li>\n<li>\n<p><a href=\"#2-functional-api-1\">2. Functional API</a></p>\n</li>\n<li>\n<p><a href=\"#3-subclassing-api\">3. Subclassing API</a></p>\n<ul>\n<li><a href=\"#sequential\">Sequential</a></li>\n<li><a href=\"#functional\">Functional</a></li>\n<li><a href=\"#subclass-api\">Subclass API</a></li>\n</ul>\n</li>\n</ul>\n</div>","excerpt":"ğŸŒ  Tensor flow V2 ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ìš©í•´ ë”¥ëŸ¬ë‹ ëª¨ë¸ ìƒì„±í•˜ê¸° Tensor flow V2 ë²„ì „ì—ì„œ ë”¥ëŸ¬ë‹ ëª¨ë¸ ì‘ì„± ë°©ë²•ì—ëŠ” í¬ê²Œ 3ê°€ì§€ê°€ ìˆë‹¤. Sequential Functional : sequential ì˜ ì¼ë°˜í™”ëœ ê°œë… Model Subclassing : í´ë˜ìŠ¤ë¡œ êµ¬í˜„ëœ ê¸°ì¡´ ëª¨ë¸ì„ ìƒì†ë°›ì•„ ìê¸° ëª¨ë¸ ë§Œë“¤ê¸° ìˆœì°¨ì ìœ¼ë¡œ ì–´ë–¤ ì°¨ì´ê°€ ìˆê³ , ì–´ë–¤ ì‹ìœ¼ë¡œ ì œì‘í•˜ëŠ”ì§€ ì•Œì•„ê°€ë³´ì. 1. Sequential Model epochs : ëª¨ë¸ë¡œ ë°ì´í„°ë¥¼ í•™ìŠµí•  íšŸìˆ˜ batch_size : ë°ì´í„°ë¥¼ ì†Œë¶„í•´ ë„£ì„ ì–‘ model = keras.Sequential() ì„ í™œìš©í•˜ë©´ ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ìŒ“ì•„ ë‚˜ê°ˆ ìˆ˜ ìˆë‹¤. ì…ë ¥ë¶€í„° ì¶œë ¥ê¹Œì§€ ìˆœì°¨ì (ì‹œí€€ì…œ) ìœ¼ë¡œ add í•˜ë©´ ëœë‹¤. but, ëª¨ë¸ì˜ ì…ë ¥ê³¼ ì¶œë ¥ì´ ì—¬ëŸ¬ê°œì¸ ê²½ìš°ì—ëŠ” ì í•©í•˜ì§€ ì•Šë‹¤. (ë°˜ë“œì‹œ ì…ë ¥ 1ê°œ ì¶œë ¥ 1ê°€ì§€ ì—¬ì•¼ í•¨) 2. Functional API model ì— ketas.Model ì´ ë“¤ì–´ê°„ë‹¤. ì´ê²ƒì€ ìš°ë¦¬ê°€ danse â€¦","frontmatter":{"date":"April 21, 2022","title":"Keras ë”¥ëŸ¬ë‹ ëª¨ë¸","categories":"DeepML","author":"í•˜ì„±ë¯¼","emoji":"ğŸ˜"},"fields":{"slug":"/DML_keras2/"}},"next":{"id":"178ea2b3-2dfd-599d-86ad-b2669c612f60","html":"<h1 id=\"span-stylebackground-color-fff4f5ì¸ê³µì§€ëŠ¥-ê¸°ì´ˆ-ï¸-ì‚¬ì§„-ë¶„ë¥˜-í”„ë¡œê·¸ë¨-ë§›ë³´ê¸°span\" style=\"position:relative;\"><a href=\"#span-stylebackground-color-fff4f5%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-%EA%B8%B0%EC%B4%88-%EF%B8%8F-%EC%82%AC%EC%A7%84-%EB%B6%84%EB%A5%98-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%A8-%EB%A7%9B%EB%B3%B4%EA%B8%B0span\" aria-label=\"span stylebackground color fff4f5ì¸ê³µì§€ëŠ¥ ê¸°ì´ˆ ï¸ ì‚¬ì§„ ë¶„ë¥˜ í”„ë¡œê·¸ë¨ ë§›ë³´ê¸°span permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><span style='background-color: #fff4f5'>ì¸ê³µì§€ëŠ¥ ê¸°ì´ˆ ğŸš¶â€â™‚ï¸: ì‚¬ì§„ ë¶„ë¥˜ í”„ë¡œê·¸ë¨ ë§›ë³´ê¸°</span></h1>\n<h2 id=\"ê°•ì•„ì§€--ê³ ì–‘ì´-ë¶„ë¥˜-í”„ë¡œê·¸ë¨-ì œì‘-\" style=\"position:relative;\"><a href=\"#%EA%B0%95%EC%95%84%EC%A7%80--%EA%B3%A0%EC%96%91%EC%9D%B4-%EB%B6%84%EB%A5%98-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%A8-%EC%A0%9C%EC%9E%91-\" aria-label=\"ê°•ì•„ì§€  ê³ ì–‘ì´ ë¶„ë¥˜ í”„ë¡œê·¸ë¨ ì œì‘  permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>ê°•ì•„ì§€ &#x26; ê³ ì–‘ì´ ë¶„ë¥˜ í”„ë¡œê·¸ë¨ ì œì‘ !</h2>\n<h3 id=\"content\" style=\"position:relative;\"><a href=\"#content\" aria-label=\"content permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Content</h3>\n<ol>\n<li>ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° (Tensor Flow)</li>\n<li>ë°ì´í„° ì „ì²˜ë¦¬</li>\n<li>ëª¨ë¸ ìƒì„± (ìì²´ ìƒì„± ëª¨ë¸)</li>\n<li>í•™ìŠµ ë° í‰ê°€</li>\n</ol>\n<p><strong>ì‹œì‘í•˜ê¸°ì— ì•ì„œ, ì´ë²ˆ ê²Œì‹œê¸€ì€<br>\nì „ì²´ì ì¸ ì¸ê³µì§€ëŠ¥ ì ìš©ì— ëŒ€í•œ ë§¥ë½ì„ ì„¤ëª…í•˜ê¸° ìœ„í•œ ê¸€ì…ë‹ˆë‹¤.<br>\nì•„ì£¼ ê°„ë‹¨í•œ Deep Learning Layer ëª‡ ì¢…ë¥˜ë¥¼ ì´ìš©í–ˆìŠµë‹ˆë‹¤.</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>__version__ <span class=\"token punctuation\">,</span> <span class=\"token string\">'ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ì„ ë§Œë“¤ ë¼ì´ë¸ŒëŸ¬ë¦¬ tensor flow ì…ë‹ˆë‹¤'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">2.6.0 ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ì„ ë§Œë“¤ ë¼ì´ë¸ŒëŸ¬ë¦¬ tensor flow ì…ë‹ˆë‹¤</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow_datasets <span class=\"token keyword\">as</span> tfds\n\ntfds<span class=\"token punctuation\">.</span>__version__</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">'4.4.0'</code></pre></div>\n<p>tensor flow ì—ì„œëŠ” ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ì„ ì´ë¯¸ ì œê³µí•˜ê³  ìˆë‹¤.<br>\nê°•ì•„ì§€ê³ ì–‘ì´, ìŒì„±, ì´ë¯¸ì§€, í…ìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë³´ìœ í•˜ê³  ìˆìœ¼ë‹ˆ ì„¸ë¶€ ë‚´ìš© í™•ì¸í•´ë³´ê³  ì‹¶ìŒ í•´ë³´ê¸°</p>\n<p><a href=\"https://www.tensorflow.org/datasets/catalog/overview\">tensor flow link</a></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token punctuation\">(</span>raw_train<span class=\"token punctuation\">,</span> raw_validation<span class=\"token punctuation\">,</span> raw_test<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> metadata <span class=\"token operator\">=</span> tfds<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span>\n    <span class=\"token string\">'cats_vs_dogs'</span><span class=\"token punctuation\">,</span>\n    split<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'train[:80%]'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'train[80%:90%]'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'train[90%:]'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n    with_info<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n    as_supervised<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">\u001b[1mDownloading and preparing dataset 786.68 MiB (download: 786.68 MiB, generated: Unknown size, total: 786.68 MiB) to /aiffel/tensorflow_datasets/cats_vs_dogs/4.0.0...\u001b[0m\n\n\n\nDl Completed...: 0 url [00:00, ? url/s]\n\n\n\nDl Size...: 0 MiB [00:00, ? MiB/s]\n\n\n\nGenerating splits...:   0%|          | 0/1 [00:00&lt;?, ? splits/s]\n\n\n\nGenerating train examples...:   0%|          | 0/23262 [00:00&lt;?, ? examples/s]\n\n\nWARNING:absl:1738 images were corrupted and were skipped\n\n\n\nShuffling cats_vs_dogs-train.tfrecord...:   0%|          | 0/23262 [00:00&lt;?, ? examples/s]\n\n\n\u001b[1mDataset cats_vs_dogs downloaded and prepared to /aiffel/tensorflow_datasets/cats_vs_dogs/4.0.0. Subsequent calls will reuse this data.\u001b[0m</code></pre></div>\n<hr>\n<p>â€œWARNING:absl:1738 images were corrupted and were skippedâ€ë¼ëŠ” ê²½ê³ ê°€ ë‚˜íƒ€ë‚  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìš°ì„  ë¬´ì‹œí•˜ì‹œë©´ ë©ë‹ˆë‹¤.<br>\n1738 ì¥ì˜ ì‚¬ì§„ì€ ì“¸ ìˆ˜ ì—†ë‹¤ëŠ” ëœ»ì…ë‹ˆë‹¤.<br>\nì´ëŸ° ê²ƒë“¤ì€ tf ì‚¬ì´íŠ¸ ë°ì´í„°ì…‹ ì„¤ëª…ì—ì„œ í™•ì¸ ê°€ëŠ¥í•©ë‹ˆë‹¤</p>\n<p><img src=\"/a0b5d21d105e7623091003cd8f24e715/1.png\" alt=\"PNG\"></p>\n<p>1738ì´ currupted ë˜ì–´ìˆë‹¤ ë˜ì–´ìˆì ¸?<br>\nê·¸ë¦¬ê³  ë°‘ì— Splitì„ ë³´ë©´ 23262 ì¥ì˜ ì‚¬ì§„ì´ ìˆìŒì„ í™•ì¸ ê°€ëŠ¥í•©ë‹ˆë‹¤.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>raw_train<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>raw_validation<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>raw_test<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">&lt;PrefetchDataset shapes: ((None, None, 3), ()), types: (tf.uint8, tf.int64)>\n&lt;PrefetchDataset shapes: ((None, None, 3), ()), types: (tf.uint8, tf.int64)>\n&lt;PrefetchDataset shapes: ((None, None, 3), ()), types: (tf.uint8, tf.int64)></code></pre></div>\n<p>ì˜ ë³€ìˆ˜ë¡œ ì§€ì •ë˜ì–´ìˆìŒì„ ì•Œ ìˆ˜ ìˆë‹¤.</p>\n<p>ëª¨ë“  ë°ì´í„°ì…‹ì€ (image, label)ì˜ í˜•íƒœë¥¼ ê°€ì§‘ë‹ˆë‹¤.<br>\n((None, None, 3), ())ê°€ ì´ë¥¼ ë‚˜íƒ€ë‚´ì£ .</p>\n<p>ì—¬ê¸°ì—ì„œ ì•ì— ìˆëŠ” (None, None, 3)ì€ imageì˜ shapeë¥¼,<br>\në’¤ì˜ ()ëŠ” ì •ë‹µ ì¹´í…Œê³ ë¦¬ì¸ labelì˜ shapeë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.</p>\n<p>ì´ë¯¸ì§€ëŠ” (height, width, channel)ë¡œ 3ì°¨ì› ë°ì´í„°ì´ê¸° ë•Œë¬¸ì—<br>\n(None, None, 3)ê³¼ ê°™ì´ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.</p>\n<p>ì´ë•Œ heightì™€ widthê°€ Noneìœ¼ë¡œ ë‚˜íƒ€ë‚œ ì´ìœ ëŠ”<br>\nëª¨ë“  ì‚¬ì§„ë“¤ì˜ í¬ê¸°ê°€ ì œê°ê°ì´ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.<br>\ní•˜ë‚˜ì˜ ê°’ìœ¼ë¡œ ë‚˜íƒ€ë‚¼ ìˆ˜ ì—†ìœ¼ë‹ˆ None ìœ¼ë¡œ í‘œê¸°ë©ë‹ˆë‹¤.</p>\n<h2 id=\"1-ë°ì´í„°-ì „ì²˜ë¦¬\" style=\"position:relative;\"><a href=\"#1-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%84%EC%B2%98%EB%A6%AC\" aria-label=\"1 ë°ì´í„° ì „ì²˜ë¦¬ permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. ë°ì´í„° ì „ì²˜ë¦¬</h2>\n<p>ì ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™”ìœ¼ë‹ˆ ê¹”ë”í•˜ê²Œ ì²˜ë¦¬í•´ì•¼ì§€</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt\n<span class=\"token operator\">%</span>matplotlib inline\n<span class=\"token operator\">%</span>config InlineBackend<span class=\"token punctuation\">.</span>figure_format <span class=\"token operator\">=</span> <span class=\"token string\">'retina'</span></code></pre></div>\n<p>ë°ì´í„°ë¥¼ ì–´ë–»ê²Œ ì²˜ë¦¬í• ì§€ ê³ ë¯¼í•˜ê¸° ìœ„í•´ì„œ ìš°ë¦¬ê°€ ê°€ì ¸ì˜¨ ë°ì´í„°ë¥¼<br>\nìŠ¤ë¦¬ìŠ¬ì© ë“¤ì—¬ë‹¤ ë³´ì.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">plt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\">#ì „ì²´ ì¹¸ë°”ìŠ¤ í¬ê¸°</span>\n\nget_label_name <span class=\"token operator\">=</span> metadata<span class=\"token punctuation\">.</span>features<span class=\"token punctuation\">[</span><span class=\"token string\">'label'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>int2str \n\n<span class=\"token keyword\">for</span> idx<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> label<span class=\"token punctuation\">)</span> <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>raw_train<span class=\"token punctuation\">.</span>take<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>  <span class=\"token comment\"># 10ê°œì˜ ë°ì´í„°ë¥¼ ë”°ë¡œ ê°€ì ¸ ì˜µë‹ˆë‹¤.</span>\n    plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">,</span> idx<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token comment\">#10ê°œì˜ ì‚¬ì§„ì„ êº¼ë‚´ë³´ê² ìŒ íŒ êº¼ëƒ„</span>\n    plt<span class=\"token punctuation\">.</span>imshow<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'label </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>label<span class=\"token punctuation\">}</span></span><span class=\"token string\">: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>get_label_name<span class=\"token punctuation\">(</span>label<span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">'</span></span><span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>axis<span class=\"token punctuation\">(</span><span class=\"token string\">'off'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 52.222222222222214%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAABYlAAAWJQFJUiTwAAADNUlEQVQozwEqA9X8AIqJkgD//98A////AMO5kgB3WDdNSEEedTo8GXVNPhk/ZaBgEHmIfyydqbYmQ1NdExwaDgDtw1sA+tJ9AINtQwDq4d4A////APPr5AD+//8AAFRRVXZ3b1uhs6N3pberglF4UzK5Uz8l/084If9nSSKWfZBZlauFYPGwinHwXFdTjxsNAFlZSSOsdWE0qW1YK2GQjItZeXNvqm9rZ6WMi41yAH99cNVdUET/aFQ9/5eHYphRSiCoaDIj/2kxIP9URSCKfn9YrJh7Z/+WdWD/kXdknRgcHalJQC//gXRf/3RnVLJHRUGgOjs3/1FQSf9+cmfIAJGOd6pnWETjVlA16V1YP3hmWy66djUh/2w8Hv9BQxWWmqiFsoKQcP98gWz/vr22p2VQLoNrVTHpkH5k6W1lWY1xa2eBf3t365GKhOeWiIGhAFNcVgs1RDgPP15WEGeUaARIQiCARywXuXBNJrpdVSVojaKGNXuSWVxlc0hbqbCpOUAAAAeWdT0TemUwEkY3CQz///8B////Av///wH///8BAP///wAAAAACAAAAAf/h3wAHDjcdAA4wNgAJJC8NF0YZXmtnAKaqfQCZkWkApKqsAC8ZAwDm3M0Aq6SWAD88NgAREhYsV1NCWi8sGlcqKBk3AGJdTqPPo4nb166a4bl+bHNZUEKsiXZc/3BlVf86NDKUP0hXQntxaYKWf2d5goWQQhwXFEGPjo58amhneywsMz5PTDSRWFI0/1tTMP9EPya3AGhgVcqWemj/hnRq/7mUh5CegU2sqoxe/6KLaP+FZz2MQlBmtaejoP+2nYX/fIGIplZSUaSOhID/cmxo/0xKS6xeVzN/VFE//1ZSPP9KQyypAIh9bs+akob/l5KH/761qpSrmnezvJ9t/6mQav92bmOTW2h/p4OJlP+IhYL/dXyCm15XUZtwZ2H/d3Fq/2xmYaIrKBiEdXRs/3Jya/9CPSqvAIVxX22snYuRs6eWlcO2oUyFgnqOspRn156Se9ZtdHh8e36JEoSJkCuIk5gqp6mqGFZPSRlxb2csfXZtLq2clBBBQDKBmZmT+Lm2svZJRDOf3gpvCUkCLewAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/d16b019357261570c527d6ef9965d80a/37523/output_13_0.png\"\n        srcset=\"/static/d16b019357261570c527d6ef9965d80a/e9ff0/output_13_0.png 180w,\n/static/d16b019357261570c527d6ef9965d80a/f21e7/output_13_0.png 360w,\n/static/d16b019357261570c527d6ef9965d80a/37523/output_13_0.png 720w,\n/static/d16b019357261570c527d6ef9965d80a/302a4/output_13_0.png 1080w,\n/static/d16b019357261570c527d6ef9965d80a/ee3fb/output_13_0.png 1144w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>ì ë´ë¼, ì´ë¯¸ì§€ í¬ê¸°ê°€ ë‹¤ ì œê°ê°ì´ë„¤?</p>\n<p>ì˜¬ë°”ë¥¸ í•™ìŠµì„ ìœ„í•´ì„œëŠ” ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆë¶€í„° ì œëŒ€ë¡œ ë§ì¶°ì¤˜ì•¼ í•œë‹¤.</p>\n<p>format_example() í•¨ìˆ˜ë¡œ ì´ë¯¸ì§€ë¥¼ ê°™ì€ í¬ë©§ìœ¼ë¡œ ë§ì¶¥ë‹ˆë‹¤.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">IMG_SIZE <span class=\"token operator\">=</span> <span class=\"token number\">160</span> <span class=\"token comment\"># ë¦¬ì‚¬ì´ì§•í•  ì´ë¯¸ì§€ì˜ í¬ê¸°</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">format_example</span><span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> label<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    image <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>cast<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> tf<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># image=float(image)ê°™ì€ íƒ€ì…ìºìŠ¤íŒ…ì˜  í…ì„œí”Œë¡œìš° ë²„ì „ì…ë‹ˆë‹¤.</span>\n    image <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>image<span class=\"token operator\">/</span><span class=\"token number\">127.5</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> <span class=\"token number\">1</span> <span class=\"token comment\"># í”½ì…€ê°’ì˜ scale ìˆ˜ì •</span>\n    image <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>image<span class=\"token punctuation\">.</span>resize<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>IMG_SIZE<span class=\"token punctuation\">,</span> IMG_SIZE<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> image<span class=\"token punctuation\">,</span> label</code></pre></div>\n<p>í”½ì…€ê°’ì˜ scale ì„ ìˆ˜ì •í–‡ë‹¤ëŠ” ê²ƒì€ í”½ì…€ê°’ì„ ì •ê·œí™”í–‡ë‹¤ëŠ” ë§ê³¼ ê·¼ì‚¬í•˜ë‹¤.<br>\n0~ 255ì¸ í”½ì…€ê°’ì„ 127.5ë¡œ ë‚˜ëˆ„ë©´ 0~ 2ê°€ëœë‹¤. ê·¸ê±¸ 1ë¡œ ëºìœ¼ë‹ˆ<br>\n-1~1 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ ë³€í–ˆë‹¤.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">train <span class=\"token operator\">=</span> raw_train<span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span>format_example<span class=\"token punctuation\">)</span>\nvalidation <span class=\"token operator\">=</span> raw_validation<span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span>format_example<span class=\"token punctuation\">)</span>\ntest <span class=\"token operator\">=</span> raw_test<span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span>format_example<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>train<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>validation<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>test<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">&lt;MapDataset shapes: ((160, 160, 3), ()), types: (tf.float32, tf.int64)>\n&lt;MapDataset shapes: ((160, 160, 3), ()), types: (tf.float32, tf.int64)>\n&lt;MapDataset shapes: ((160, 160, 3), ()), types: (tf.float32, tf.int64)></code></pre></div>\n<p>map ë©”ì„œë“œë¡œ ëª¨ë“  raw_** ì˜ ì •ë³´ë¥¼ format_example ì˜ í•¨ìˆ˜ë¡œ ë³€í™˜ì‹œì¼œì£¼ì—ˆë‹¤.<br>\në³€í™˜ëœ í›„ì˜ ë‚´ìš©ë¬¼ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">plt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n\nget_label_name <span class=\"token operator\">=</span> metadata<span class=\"token punctuation\">.</span>features<span class=\"token punctuation\">[</span><span class=\"token string\">'label'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>int2str\n\n<span class=\"token keyword\">for</span> idx<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> label<span class=\"token punctuation\">)</span> <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>train<span class=\"token punctuation\">.</span>take<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">,</span> idx<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n    image <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>image <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> <span class=\"token number\">2</span>\n    plt<span class=\"token punctuation\">.</span>imshow<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'label </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>label<span class=\"token punctuation\">}</span></span><span class=\"token string\">: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>get_label_name<span class=\"token punctuation\">(</span>label<span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">'</span></span><span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>axis<span class=\"token punctuation\">(</span><span class=\"token string\">'off'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 47.77777777777777%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAABYlAAAWJQFJUiTwAAADNUlEQVQozwEqA9X8AFVQQz6LiGA8iYpjLaqATg9FOB5BLzYROS4uETd1hUwNboNbOLayrzyCiIw9NT09D11FEC1aSiFAXUsbO2dNDRdmZWghR0RBQVdRTzx/fX0uAGdgVf6smnL/uKV8xI1tS2pkSCr/OzQe9l8/IexxgURcioJW6ryGYveWe2j/NjUyZyIZA8toVy/8eWY//29dN4SNiIWhfHhz/29rZ/aVk5PkAF5VS/88Jx7/d2VMyW5vN25kQCP/ayoh/l09IPJgcTtgiHde8p1/b/+Nblf/hndsaxgdIdJPRjj/f3Zp/3FnV4kuLSimGx8Z/zM2Lf1yZFXrAHZnVf9hVTb/ZFtC1WZoNHRiPyX/fzQd/1NFHv9ueklllaKC/3iFaP+PkIL/xsK7cVJELN10Xz3/l4l3/2deUpFmYV2vendz/5GJhP+WiID4AFtURmpUWkFrQkc8UlBPJy48MBxsXDwgZ2lYL2NsdU8oj6N8Ymh/P2d2gWhryMa4LH1SD1WDYitpdmA4blpOMjjPxcJEw7m1brSsqmeqoqFhAP/60AD///cA28a0AElFKAD/4HcA//+xAKeMTgBFTj4A///lAP//kgDb3rYApqefANafTQD//9UA48OPAHRrVQD/+dkA////AP///wDEuKcAALOPdsLovqfCyJR/lkQ4OkxZUEbGbGVavDo2N7EhJTRBZGZtsqOMdr6Xh3m/aHKGSjo0MJqvrq7BW1lWxz4+QWNHRTh4Xlg8yVBJLLxCPSerAJ9/a/+PeW3/uJCB04RsTnSef1D/n4ts/4tzUP8vLTBlbniF/cazoP+oloT/ZHCAcW1nZNyUiYb/Z2Jf/0xLS5BbVTOvT0s0/1tUOP9IQir3AJqQg/94dW//t6uey6OXgW+5nm3/sZNl/52JbPVDRlJganiO9KGbmP+IgXz/X2lxbGVcVtN3bWj/cGtl/19cWYo4NCGofn53/2xtZ/9IQi/tAK+gjuWqoJLmy72nsHl+gGChjnHprZNq3oSGgtReZm1UeX+P032Dit+AhYjlgoWHXVxVT7d1cGnke3Rs7HFqY3hBQjaRmpqV7cvIw91GQTHOUnqDylKzWK4AAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/1271a3703b5b224b0557b0d74541dd9c/37523/output_19_0.png\"\n        srcset=\"/static/1271a3703b5b224b0557b0d74541dd9c/e9ff0/output_19_0.png 180w,\n/static/1271a3703b5b224b0557b0d74541dd9c/f21e7/output_19_0.png 360w,\n/static/1271a3703b5b224b0557b0d74541dd9c/37523/output_19_0.png 720w,\n/static/1271a3703b5b224b0557b0d74541dd9c/302a4/output_19_0.png 1080w,\n/static/1271a3703b5b224b0557b0d74541dd9c/ee3fb/output_19_0.png 1144w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>ë°ì´í„° ì „ì²˜ë¦¬ ë~</p>\n<hr>\n<h2 id=\"2-ëª¨ë¸-ìƒì„±-ë°-í•™ìŠµ\" style=\"position:relative;\"><a href=\"#2-%EB%AA%A8%EB%8D%B8-%EC%83%9D%EC%84%B1-%EB%B0%8F-%ED%95%99%EC%8A%B5\" aria-label=\"2 ëª¨ë¸ ìƒì„± ë° í•™ìŠµ permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2 ëª¨ë¸ ìƒì„± ë° í•™ìŠµ</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>models <span class=\"token keyword\">import</span> Sequential\n<span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers <span class=\"token keyword\">import</span> Dense<span class=\"token punctuation\">,</span> Conv2D<span class=\"token punctuation\">,</span> Flatten<span class=\"token punctuation\">,</span> MaxPooling2D\n</code></pre></div>\n<p>models ì—ëŠ” ëª¨ë¸ ìì²´ë¥¼ êµ¬ì¶•í•˜ê¸° ìœ„í•œ í•¨ìˆ˜ê°€ ìˆê³   ê·¸ ì•ˆì˜ Sequential í•¨ìˆ˜ ì•ˆì— ì—¬ëŸ¬ê°€ì§€ layer ë“¤ì´ ë“¤ì–´ê°ˆ ìˆ˜ ìˆë‹¤.<br>\nlayers ì—ëŠ” ëª¨ë¸ì˜ êµ¬ì„± ìš”ì†Œì¸ ì—¬ëŸ¬ê°€ì§€ ì¢…ë¥˜ì˜ layer(ì¸µ) í•¨ìˆ˜ë“¤ì„ ê°€ì§€ê³  ìˆë‹¤.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">model <span class=\"token operator\">=</span> Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n    Conv2D<span class=\"token punctuation\">(</span>filters<span class=\"token operator\">=</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token string\">'same'</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">,</span> input_shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">160</span><span class=\"token punctuation\">,</span> <span class=\"token number\">160</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    MaxPooling2D<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    Conv2D<span class=\"token punctuation\">(</span>filters<span class=\"token operator\">=</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token string\">'same'</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    MaxPooling2D<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    Conv2D<span class=\"token punctuation\">(</span>filters<span class=\"token operator\">=</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token string\">'same'</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    MaxPooling2D<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    Flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    Dense<span class=\"token punctuation\">(</span>units<span class=\"token operator\">=</span><span class=\"token number\">512</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    Dense<span class=\"token punctuation\">(</span>units<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>ë”¥ëŸ¬ë‹ì—ì„œëŠ” <strong>ë ˆì´ì–´</strong> ë¼ëŠ” ê°œë…ì„ ìì„¸í•˜ê²Œ ê³µë¶€í•œë‹¤.<br>\nì—¬ê¸°ì„œëŠ”</p>\n<ul>\n<li>Conv2D</li>\n<li>MaxPooling2D</li>\n<li>Flatten</li>\n<li>Dense</li>\n</ul>\n<p>ë¼ëŠ” ë„¤ ë ˆì´ì–´ë¥¼ ì‚¬ìš©í–ˆë‹¤.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">model<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_3 (Conv2D)            (None, 160, 160, 16)      448       \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 80, 80, 16)        0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 80, 80, 32)        4640      \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 40, 40, 32)        0         \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 40, 40, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_5 (MaxPooling2 (None, 20, 20, 64)        0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 25600)             0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 512)               13107712  \n_________________________________________________________________\ndense_3 (Dense)              (None, 2)                 1026      \n=================================================================\nTotal params: 13,132,322\nTrainable params: 13,132,322\nNon-trainable params: 0\n_________________________________________________________________</code></pre></div>\n<p>ëª¨ë¸ì„ ë§Œë“¤ì—ˆìœ¼ë‹ˆ í•™ìŠµì‹œì¼œë³´ì.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">learning_rate <span class=\"token operator\">=</span> <span class=\"token number\">0.0001</span>\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span>tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>optimizers<span class=\"token punctuation\">.</span>RMSprop<span class=\"token punctuation\">(</span>lr<span class=\"token operator\">=</span>learning_rate<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n              loss<span class=\"token operator\">=</span>tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>losses<span class=\"token punctuation\">.</span>sparse_categorical_crossentropy<span class=\"token punctuation\">,</span>\n              metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n</code></pre></div>\n<p>í•™ìŠµì‹œí‚¤ê¸° ìœ„í•´ì„œëŠ” Optimer , Loss, Metrics ê°€ í•„ìš”í•˜ë‹¤.</p>\n<p>opt : í•™ìŠµì„ ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ ì‹œí‚¬ ê²ƒì¸ì§€<br>\nloss : ëª¨ë¸ì´ í•™ìŠµí•´ë‚˜ê°€ì•¼ í•  ë°©í–¥ (ì´ ê²½ìš°ëŠ” í™•ë¥ ë¶„í¬)<br>\nmetrics : [accuracy, precision, recall]</p>\n<p>ì•„ì§ì€ ì‹¤í–‰í•˜ê¸° ì „ì´ë‹¤. ì§€ê¸ˆì€ ì‚¬ì „ ì‘ì—…ë§Œ ê±°ì¹œ ìƒíƒœ</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">BATCH_SIZE <span class=\"token operator\">=</span> <span class=\"token number\">32</span>\nSHUFFLE_BUFFER_SIZE <span class=\"token operator\">=</span> <span class=\"token number\">1000</span>\n\ntrain_batches <span class=\"token operator\">=</span> train<span class=\"token punctuation\">.</span>shuffle<span class=\"token punctuation\">(</span>SHUFFLE_BUFFER_SIZE<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>batch<span class=\"token punctuation\">(</span>BATCH_SIZE<span class=\"token punctuation\">)</span>\nvalidation_batches <span class=\"token operator\">=</span> validation<span class=\"token punctuation\">.</span>batch<span class=\"token punctuation\">(</span>BATCH_SIZE<span class=\"token punctuation\">)</span>\ntest_batches <span class=\"token operator\">=</span> test<span class=\"token punctuation\">.</span>batch<span class=\"token punctuation\">(</span>BATCH_SIZE<span class=\"token punctuation\">)</span></code></pre></div>\n<p>ì´ë ‡ê²Œ train ë°ì´í„°ë¥¼ í†µìœ¼ë¡œ ë„£ì§€ ì•Šê³  32ê°œì”© ëŠì–´ ë„£ëŠ” ì´ìœ ëŠ”\nëœë¤í•œ 32ê°œì˜ ì‚¬ì§„ë“¤ì„ ë¬¶ì–´ ì—¬ëŸ¬ê°œì˜ Decision Tree ë¥¼ ë§Œë“¤ì–´ ansamble í•˜ê¸° ìœ„í•¨</p>\n<p>train_batches ì˜ ë°ì´í„°ë¥¼ í™•ì¸í•´ë³´ì</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">for</span> image_batch<span class=\"token punctuation\">,</span> label_batch <span class=\"token keyword\">in</span> train_batches<span class=\"token punctuation\">.</span>take<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">pass</span>\n\nimage_batch<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">,</span> label_batch<span class=\"token punctuation\">.</span>shape</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">(TensorShape([32, 160, 160, 3]), TensorShape([32]))</code></pre></div>\n<p>ëª¨ë¸ í•™ìŠµ ì „ì— ì´ˆê¸° ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•´ë³¼ê¹Œ? validation data ë¡œ ëª¨ë¸ì„ í‰ê°€í•´ë³´ì<br>\n20ë²ˆì˜ ì˜ˆì¸¡ì„ í•´ë³´ê³  loss ì™€ accuracyë¥¼ êµ¬í•´ë³´ì</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">validation_steps <span class=\"token operator\">=</span> <span class=\"token number\">20</span>\nloss0<span class=\"token punctuation\">,</span> accuracy0 <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>validation_batches<span class=\"token punctuation\">,</span> steps<span class=\"token operator\">=</span>validation_steps<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"initial loss: {:.2f}\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>loss0<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"initial accuracy: {:.2f}\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>accuracy0<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">10/20 [==============>...............] - ETA: 0s - loss: 0.6924 - accuracy: 0.5156\n\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\n\n\n20/20 [==============================] - 3s 32ms/step - loss: 0.6919 - accuracy: 0.5172\ninitial loss: 0.69\ninitial accuracy: 0.52\n\n\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9</code></pre></div>\n<p>ë³´ë©´ ì•„ë¬´ê²ƒë„ í•˜ê¸° ì „ì— ëª¨ë¸ evaluate ëŠ” ê± ë­ ì•„ë¬´ê²ƒë„ ëª¨ë¥¸ë‹¤.\nì´ì œ ì´ê±¸ í•™ìŠµì‹œì¼œë³´ì</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">EPOCHS <span class=\"token operator\">=</span> <span class=\"token number\">10</span>\nhistory <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>train_batches<span class=\"token punctuation\">,</span>\n                    epochs<span class=\"token operator\">=</span>EPOCHS<span class=\"token punctuation\">,</span>\n                    validation_data<span class=\"token operator\">=</span>validation_batches<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Epoch 1/10\n170/582 [=======>......................] - ETA: 18s - loss: 0.5444 - accuracy: 0.7250\n\nCorrupt JPEG data: 99 extraneous bytes before marker 0xd9\n\n\n202/582 [=========>....................] - ETA: 17s - loss: 0.5408 - accuracy: 0.7274\n\nWarning: unknown JFIF revision number 0.00\n\n\n212/582 [=========>....................] - ETA: 16s - loss: 0.5427 - accuracy: 0.7258\n\nCorrupt JPEG data: 396 extraneous bytes before marker 0xd9\n\n\n284/582 [=============>................] - ETA: 13s - loss: 0.5408 - accuracy: 0.7272\n\nCorrupt JPEG data: 65 extraneous bytes before marker 0xd9\n\n\n492/582 [========================>.....] - ETA: 3s - loss: 0.5280 - accuracy: 0.7363\n\nCorrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n\n\n504/582 [========================>.....] - ETA: 3s - loss: 0.5277 - accuracy: 0.7360\n\nCorrupt JPEG data: 128 extraneous bytes before marker 0xd9\n\n\n516/582 [=========================>....] - ETA: 2s - loss: 0.5271 - accuracy: 0.7372\n\nCorrupt JPEG data: 239 extraneous bytes before marker 0xd9\n\n\n542/582 [==========================>...] - ETA: 1s - loss: 0.5269 - accuracy: 0.7374\n\nCorrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n\n\n550/582 [===========================>..] - ETA: 1s - loss: 0.5271 - accuracy: 0.7372\n\nCorrupt JPEG data: 228 extraneous bytes before marker 0xd9\n\n\n582/582 [==============================] - ETA: 0s - loss: 0.5259 - accuracy: 0.7389\n\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 214 extraneous bytes before marker 0xd9\n\n\n582/582 [==============================] - 29s 48ms/step - loss: 0.5259 - accuracy: 0.7389 - val_loss: 0.5102 - val_accuracy: 0.7502\nEpoch 2/10\n169/582 [=======>......................] - ETA: 18s - loss: 0.4561 - accuracy: 0.7898\n\nCorrupt JPEG data: 99 extraneous bytes before marker 0xd9\n\n\n201/582 [=========>....................] - ETA: 16s - loss: 0.4553 - accuracy: 0.7886\n\nWarning: unknown JFIF revision number 0.00\n\n\n213/582 [=========>....................] - ETA: 16s - loss: 0.4548 - accuracy: 0.7893\n\nCorrupt JPEG data: 396 extraneous bytes before marker 0xd9\n\n\n283/582 [=============>................] - ETA: 13s - loss: 0.4483 - accuracy: 0.7911\n\nCorrupt JPEG data: 65 extraneous bytes before marker 0xd9\n\n\n492/582 [========================>.....] - ETA: 3s - loss: 0.4446 - accuracy: 0.7943\n\nCorrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n\n\n506/582 [=========================>....] - ETA: 3s - loss: 0.4450 - accuracy: 0.7947\n\nCorrupt JPEG data: 128 extraneous bytes before marker 0xd9\n\n\n516/582 [=========================>....] - ETA: 2s - loss: 0.4445 - accuracy: 0.7951\n\nCorrupt JPEG data: 239 extraneous bytes before marker 0xd9\n\n\n542/582 [==========================>...] - ETA: 1s - loss: 0.4437 - accuracy: 0.7953\n\nCorrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n\n\n548/582 [===========================>..] - ETA: 1s - loss: 0.4433 - accuracy: 0.7952\n\nCorrupt JPEG data: 228 extraneous bytes before marker 0xd9\n\n\n580/582 [============================>.] - ETA: 0s - loss: 0.4425 - accuracy: 0.7956\n\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 214 extraneous bytes before marker 0xd9\n\n\n582/582 [==============================] - 28s 47ms/step - loss: 0.4422 - accuracy: 0.7958 - val_loss: 0.5503 - val_accuracy: 0.7386\nEpoch 3/10\n169/582 [=======>......................] - ETA: 18s - loss: 0.3937 - accuracy: 0.8229\n\nCorrupt JPEG data: 99 extraneous bytes before marker 0xd9\n\n\n201/582 [=========>....................] - ETA: 16s - loss: 0.3927 - accuracy: 0.8232\n\nWarning: unknown JFIF revision number 0.00\n\n\n213/582 [=========>....................] - ETA: 16s - loss: 0.3927 - accuracy: 0.8234\n\nCorrupt JPEG data: 396 extraneous bytes before marker 0xd9\n\n\n283/582 [=============>................] - ETA: 13s - loss: 0.3870 - accuracy: 0.8266\n\nCorrupt JPEG data: 65 extraneous bytes before marker 0xd9\n\n\n492/582 [========================>.....] - ETA: 3s - loss: 0.3836 - accuracy: 0.8281\n\nCorrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n\n\n506/582 [=========================>....] - ETA: 3s - loss: 0.3843 - accuracy: 0.8278\n\nCorrupt JPEG data: 128 extraneous bytes before marker 0xd9\n\n\n516/582 [=========================>....] - ETA: 2s - loss: 0.3836 - accuracy: 0.8281\n\nCorrupt JPEG data: 239 extraneous bytes before marker 0xd9\n\n\n543/582 [==========================>...] - ETA: 1s - loss: 0.3820 - accuracy: 0.8288\n\nCorrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n\n\n549/582 [===========================>..] - ETA: 1s - loss: 0.3814 - accuracy: 0.8292\n\nCorrupt JPEG data: 228 extraneous bytes before marker 0xd9\n\n\n581/582 [============================>.] - ETA: 0s - loss: 0.3800 - accuracy: 0.8289\n\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 214 extraneous bytes before marker 0xd9\n\n\n582/582 [==============================] - 28s 47ms/step - loss: 0.3799 - accuracy: 0.8290 - val_loss: 0.4954 - val_accuracy: 0.7674\nEpoch 4/10\n169/582 [=======>......................] - ETA: 18s - loss: 0.3449 - accuracy: 0.8460\n\nCorrupt JPEG data: 99 extraneous bytes before marker 0xd9\n\n\n201/582 [=========>....................] - ETA: 16s - loss: 0.3404 - accuracy: 0.8469\n\nWarning: unknown JFIF revision number 0.00\n\n\n213/582 [=========>....................] - ETA: 16s - loss: 0.3395 - accuracy: 0.8480\n\nCorrupt JPEG data: 396 extraneous bytes before marker 0xd9\n\n\n283/582 [=============>................] - ETA: 12s - loss: 0.3357 - accuracy: 0.8520\n\nCorrupt JPEG data: 65 extraneous bytes before marker 0xd9\n\n\n492/582 [========================>.....] - ETA: 3s - loss: 0.3270 - accuracy: 0.8581\n\nCorrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n\n\n506/582 [=========================>....] - ETA: 3s - loss: 0.3273 - accuracy: 0.8581\n\nCorrupt JPEG data: 128 extraneous bytes before marker 0xd9\n\n\n516/582 [=========================>....] - ETA: 2s - loss: 0.3260 - accuracy: 0.8586\n\nCorrupt JPEG data: 239 extraneous bytes before marker 0xd9\n\n\n542/582 [==========================>...] - ETA: 1s - loss: 0.3256 - accuracy: 0.8590\n\nCorrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n\n\n550/582 [===========================>..] - ETA: 1s - loss: 0.3252 - accuracy: 0.8593\n\nCorrupt JPEG data: 228 extraneous bytes before marker 0xd9\n\n\n580/582 [============================>.] - ETA: 0s - loss: 0.3244 - accuracy: 0.8602\n\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 214 extraneous bytes before marker 0xd9\n\n\n582/582 [==============================] - 28s 47ms/step - loss: 0.3244 - accuracy: 0.8602 - val_loss: 0.4858 - val_accuracy: 0.7825\nEpoch 5/10\n170/582 [=======>......................] - ETA: 18s - loss: 0.2913 - accuracy: 0.8765\n\nCorrupt JPEG data: 99 extraneous bytes before marker 0xd9\n\n\n202/582 [=========>....................] - ETA: 16s - loss: 0.2866 - accuracy: 0.8790\n\nWarning: unknown JFIF revision number 0.00\n\n\n212/582 [=========>....................] - ETA: 16s - loss: 0.2868 - accuracy: 0.8791\n\nCorrupt JPEG data: 396 extraneous bytes before marker 0xd9\n\n\n284/582 [=============>................] - ETA: 12s - loss: 0.2804 - accuracy: 0.8825\n\nCorrupt JPEG data: 65 extraneous bytes before marker 0xd9\n\n\n493/582 [========================>.....] - ETA: 3s - loss: 0.2756 - accuracy: 0.8869\n\nCorrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n\n\n505/582 [=========================>....] - ETA: 3s - loss: 0.2740 - accuracy: 0.8876\n\nCorrupt JPEG data: 128 extraneous bytes before marker 0xd9\n\n\n515/582 [=========================>....] - ETA: 2s - loss: 0.2733 - accuracy: 0.8877\n\nCorrupt JPEG data: 239 extraneous bytes before marker 0xd9\n\n\n543/582 [==========================>...] - ETA: 1s - loss: 0.2732 - accuracy: 0.8886\n\nCorrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n\n\n549/582 [===========================>..] - ETA: 1s - loss: 0.2727 - accuracy: 0.8889\n\nCorrupt JPEG data: 228 extraneous bytes before marker 0xd9\n\n\n581/582 [============================>.] - ETA: 0s - loss: 0.2720 - accuracy: 0.8886\n\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 214 extraneous bytes before marker 0xd9\n\n\n582/582 [==============================] - 28s 46ms/step - loss: 0.2721 - accuracy: 0.8885 - val_loss: 0.4933 - val_accuracy: 0.7919\nEpoch 6/10\n169/582 [=======>......................] - ETA: 18s - loss: 0.2373 - accuracy: 0.9051\n\nCorrupt JPEG data: 99 extraneous bytes before marker 0xd9\n\n\n201/582 [=========>....................] - ETA: 16s - loss: 0.2335 - accuracy: 0.9083\n\nWarning: unknown JFIF revision number 0.00\n\n\n211/582 [=========>....................] - ETA: 16s - loss: 0.2331 - accuracy: 0.9083\n\nCorrupt JPEG data: 396 extraneous bytes before marker 0xd9\n\n\n283/582 [=============>................] - ETA: 13s - loss: 0.2268 - accuracy: 0.9110\n\nCorrupt JPEG data: 65 extraneous bytes before marker 0xd9\n\n\n493/582 [========================>.....] - ETA: 3s - loss: 0.2216 - accuracy: 0.9123\n\nCorrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n\n\n505/582 [=========================>....] - ETA: 3s - loss: 0.2209 - accuracy: 0.9127\n\nCorrupt JPEG data: 128 extraneous bytes before marker 0xd9\n\n\n516/582 [=========================>....] - ETA: 2s - loss: 0.2196 - accuracy: 0.9133\n\nCorrupt JPEG data: 239 extraneous bytes before marker 0xd9\n\n\n542/582 [==========================>...] - ETA: 1s - loss: 0.2178 - accuracy: 0.9147\n\nCorrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n\n\n548/582 [===========================>..] - ETA: 1s - loss: 0.2171 - accuracy: 0.9150\n\nCorrupt JPEG data: 228 extraneous bytes before marker 0xd9\n\n\n580/582 [============================>.] - ETA: 0s - loss: 0.2163 - accuracy: 0.9152\n\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 214 extraneous bytes before marker 0xd9\n\n\n582/582 [==============================] - 29s 47ms/step - loss: 0.2162 - accuracy: 0.9153 - val_loss: 0.6168 - val_accuracy: 0.7601\nEpoch 7/10\n169/582 [=======>......................] - ETA: 18s - loss: 0.1858 - accuracy: 0.9310\n\nCorrupt JPEG data: 99 extraneous bytes before marker 0xd9\n\n\n201/582 [=========>....................] - ETA: 16s - loss: 0.1836 - accuracy: 0.9331\n\nWarning: unknown JFIF revision number 0.00\n\n\n213/582 [=========>....................] - ETA: 16s - loss: 0.1820 - accuracy: 0.9341\n\nCorrupt JPEG data: 396 extraneous bytes before marker 0xd9\n\n\n283/582 [=============>................] - ETA: 13s - loss: 0.1783 - accuracy: 0.9361\n\nCorrupt JPEG data: 65 extraneous bytes before marker 0xd9\n\n\n493/582 [========================>.....] - ETA: 3s - loss: 0.1724 - accuracy: 0.9365\n\nCorrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n\n\n505/582 [=========================>....] - ETA: 3s - loss: 0.1717 - accuracy: 0.9369\n\nCorrupt JPEG data: 128 extraneous bytes before marker 0xd9\n\n\n515/582 [=========================>....] - ETA: 2s - loss: 0.1709 - accuracy: 0.9374\n\nCorrupt JPEG data: 239 extraneous bytes before marker 0xd9\n\n\n543/582 [==========================>...] - ETA: 1s - loss: 0.1699 - accuracy: 0.9378\n\nCorrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n\n\n549/582 [===========================>..] - ETA: 1s - loss: 0.1698 - accuracy: 0.9378\n\nCorrupt JPEG data: 228 extraneous bytes before marker 0xd9\n\n\n581/582 [============================>.] - ETA: 0s - loss: 0.1678 - accuracy: 0.9382\n\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 214 extraneous bytes before marker 0xd9\n\n\n582/582 [==============================] - 28s 47ms/step - loss: 0.1677 - accuracy: 0.9382 - val_loss: 0.6220 - val_accuracy: 0.7627\nEpoch 8/10\n170/582 [=======>......................] - ETA: 18s - loss: 0.1322 - accuracy: 0.9537\n\nCorrupt JPEG data: 99 extraneous bytes before marker 0xd9\n\n\n202/582 [=========>....................] - ETA: 16s - loss: 0.1317 - accuracy: 0.9547\n\nWarning: unknown JFIF revision number 0.00\n\n\n212/582 [=========>....................] - ETA: 16s - loss: 0.1293 - accuracy: 0.9558\n\nCorrupt JPEG data: 396 extraneous bytes before marker 0xd9\n\n\n284/582 [=============>................] - ETA: 13s - loss: 0.1267 - accuracy: 0.9558\n\nCorrupt JPEG data: 65 extraneous bytes before marker 0xd9\n\n\n493/582 [========================>.....] - ETA: 3s - loss: 0.1241 - accuracy: 0.9564\n\nCorrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n\n\n505/582 [=========================>....] - ETA: 3s - loss: 0.1237 - accuracy: 0.9566\n\nCorrupt JPEG data: 128 extraneous bytes before marker 0xd9\n\n\n515/582 [=========================>....] - ETA: 2s - loss: 0.1235 - accuracy: 0.9567\n\nCorrupt JPEG data: 239 extraneous bytes before marker 0xd9\n\n\n542/582 [==========================>...] - ETA: 1s - loss: 0.1223 - accuracy: 0.9574\n\nCorrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n\n\n550/582 [===========================>..] - ETA: 1s - loss: 0.1219 - accuracy: 0.9577\n\nCorrupt JPEG data: 228 extraneous bytes before marker 0xd9\n\n\n580/582 [============================>.] - ETA: 0s - loss: 0.1210 - accuracy: 0.9580\n\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 214 extraneous bytes before marker 0xd9\n\n\n582/582 [==============================] - 28s 47ms/step - loss: 0.1209 - accuracy: 0.9581 - val_loss: 0.6818 - val_accuracy: 0.7623\nEpoch 9/10\n170/582 [=======>......................] - ETA: 18s - loss: 0.0973 - accuracy: 0.9688\n\nCorrupt JPEG data: 99 extraneous bytes before marker 0xd9\n\n\n202/582 [=========>....................] - ETA: 16s - loss: 0.0932 - accuracy: 0.9711\n\nWarning: unknown JFIF revision number 0.00\n\n\n212/582 [=========>....................] - ETA: 16s - loss: 0.0942 - accuracy: 0.9704\n\nCorrupt JPEG data: 396 extraneous bytes before marker 0xd9\n\n\n284/582 [=============>................] - ETA: 13s - loss: 0.0915 - accuracy: 0.9712\n\nCorrupt JPEG data: 65 extraneous bytes before marker 0xd9\n\n\n492/582 [========================>.....] - ETA: 3s - loss: 0.0893 - accuracy: 0.9715\n\nCorrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n\n\n506/582 [=========================>....] - ETA: 3s - loss: 0.0888 - accuracy: 0.9719\n\nCorrupt JPEG data: 128 extraneous bytes before marker 0xd9\n\n\n516/582 [=========================>....] - ETA: 2s - loss: 0.0883 - accuracy: 0.9721\n\nCorrupt JPEG data: 239 extraneous bytes before marker 0xd9\n\n\n542/582 [==========================>...] - ETA: 1s - loss: 0.0880 - accuracy: 0.9722\n\nCorrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n\n\n550/582 [===========================>..] - ETA: 1s - loss: 0.0874 - accuracy: 0.9725\n\nCorrupt JPEG data: 228 extraneous bytes before marker 0xd9\n\n\n580/582 [============================>.] - ETA: 0s - loss: 0.0875 - accuracy: 0.9725\n\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 214 extraneous bytes before marker 0xd9\n\n\n582/582 [==============================] - 28s 47ms/step - loss: 0.0874 - accuracy: 0.9725 - val_loss: 0.6500 - val_accuracy: 0.7863\nEpoch 10/10\n170/582 [=======>......................] - ETA: 18s - loss: 0.0692 - accuracy: 0.9783\n\nCorrupt JPEG data: 99 extraneous bytes before marker 0xd9\n\n\n202/582 [=========>....................] - ETA: 17s - loss: 0.0681 - accuracy: 0.9785\n\nWarning: unknown JFIF revision number 0.00\n\n\n212/582 [=========>....................] - ETA: 16s - loss: 0.0674 - accuracy: 0.9788\n\nCorrupt JPEG data: 396 extraneous bytes before marker 0xd9\n\n\n284/582 [=============>................] - ETA: 13s - loss: 0.0648 - accuracy: 0.9798\n\nCorrupt JPEG data: 65 extraneous bytes before marker 0xd9\n\n\n493/582 [========================>.....] - ETA: 3s - loss: 0.0626 - accuracy: 0.9816\n\nCorrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n\n\n505/582 [=========================>....] - ETA: 3s - loss: 0.0624 - accuracy: 0.9817\n\nCorrupt JPEG data: 128 extraneous bytes before marker 0xd9\n\n\n515/582 [=========================>....] - ETA: 2s - loss: 0.0621 - accuracy: 0.9820\n\nCorrupt JPEG data: 239 extraneous bytes before marker 0xd9\n\n\n543/582 [==========================>...] - ETA: 1s - loss: 0.0610 - accuracy: 0.9826\n\nCorrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n\n\n549/582 [===========================>..] - ETA: 1s - loss: 0.0615 - accuracy: 0.9825\n\nCorrupt JPEG data: 228 extraneous bytes before marker 0xd9\n\n\n581/582 [============================>.] - ETA: 0s - loss: 0.0614 - accuracy: 0.9827\n\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 214 extraneous bytes before marker 0xd9\n\n\n582/582 [==============================] - 29s 47ms/step - loss: 0.0613 - accuracy: 0.9827 - val_loss: 0.6904 - val_accuracy: 0.7889</code></pre></div>\n<p>ë‹¤ìŒì€ í•™ìŠµì‹œí‚¨ ëª¨ë¸ì— ëŒ€í•œ ê·¸ë˜í”„ ë³´ê³ ì´ë‹¤</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">for</span> image_batch<span class=\"token punctuation\">,</span> label_batch <span class=\"token keyword\">in</span> test_batches<span class=\"token punctuation\">.</span>take<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    images <span class=\"token operator\">=</span> image_batch\n    labels <span class=\"token operator\">=</span> label_batch\n    predictions <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>image_batch<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">pass</span>\n\npredictions</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">array([[9.9999702e-01, 2.9417115e-06],\n       [8.3842850e-01, 1.6157144e-01],\n       [7.4218982e-01, 2.5781012e-01],\n       [9.9970847e-01, 2.9155653e-04],\n       [9.9640131e-01, 3.5986665e-03],\n       [7.8427315e-02, 9.2157269e-01],\n       [1.8649189e-02, 9.8135078e-01],\n       [9.1933328e-01, 8.0666728e-02],\n       [9.4125561e-02, 9.0587437e-01],\n       [7.8091651e-02, 9.2190832e-01],\n       [1.1057696e-01, 8.8942307e-01],\n       [9.2630666e-01, 7.3693395e-02],\n       [9.9996006e-01, 3.9985713e-05],\n       [4.6824862e-05, 9.9995315e-01],\n       [9.9207205e-01, 7.9279514e-03],\n       [9.9890709e-01, 1.0929310e-03],\n       [3.1051392e-02, 9.6894866e-01],\n       [5.8752208e-09, 1.0000000e+00],\n       [8.3172768e-01, 1.6827232e-01],\n       [9.9952376e-01, 4.7630019e-04],\n       [7.9531687e-01, 2.0468311e-01],\n       [9.9072027e-01, 9.2797335e-03],\n       [9.9999344e-01, 6.5057743e-06],\n       [9.1565454e-01, 8.4345400e-02],\n       [9.9570221e-01, 4.2977203e-03],\n       [1.0600092e-02, 9.8939985e-01],\n       [9.9997663e-01, 2.3377719e-05],\n       [1.0107538e-01, 8.9892459e-01],\n       [9.9934202e-01, 6.5792818e-04],\n       [9.9927968e-01, 7.2028313e-04],\n       [9.9999619e-01, 3.7975171e-06],\n       [2.8957015e-01, 7.1042985e-01]], dtype=float32)</code></pre></div>\n<p>ì´ê²ƒì´ ë°”ë¡œ ìš°ë¦¬ì˜ ì •í™•ë„ì´ë‹¤.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n\npredictions <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>predictions<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\npredictions</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">array([0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n       0, 0, 0, 1, 0, 1, 0, 0, 0, 1])</code></pre></div>\n<p>ì´ì œ 32ì¥ì˜ image ì™€ 32ê°œì˜ label , 32ê°œì˜ prediction ì„ ì–»ì—ˆë‹¤\nìµœì¢… í™•ì¸ì„ í•´ë³´ì</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">plt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">20</span><span class=\"token punctuation\">,</span> <span class=\"token number\">12</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">for</span> idx<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> label<span class=\"token punctuation\">,</span> prediction<span class=\"token punctuation\">)</span> <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">zip</span><span class=\"token punctuation\">(</span>images<span class=\"token punctuation\">,</span> labels<span class=\"token punctuation\">,</span> predictions<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span> <span class=\"token number\">8</span><span class=\"token punctuation\">,</span> idx<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n    image <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>image <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> <span class=\"token number\">2</span>\n    plt<span class=\"token punctuation\">.</span>imshow<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">)</span>\n    correct <span class=\"token operator\">=</span> label <span class=\"token operator\">==</span> prediction\n    title <span class=\"token operator\">=</span> <span class=\"token string-interpolation\"><span class=\"token string\">f'real: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>label<span class=\"token punctuation\">}</span></span><span class=\"token string\"> / pred :</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>prediction<span class=\"token punctuation\">}</span></span><span class=\"token string\">\\n </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>correct<span class=\"token punctuation\">}</span></span><span class=\"token string\">!'</span></span>\n    <span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> correct<span class=\"token punctuation\">:</span>\n        plt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span>title<span class=\"token punctuation\">,</span> fontdict<span class=\"token operator\">=</span><span class=\"token punctuation\">{</span><span class=\"token string\">'color'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'red'</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n        plt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span>title<span class=\"token punctuation\">,</span> fontdict<span class=\"token operator\">=</span><span class=\"token punctuation\">{</span><span class=\"token string\">'color'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'blue'</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>axis<span class=\"token punctuation\">(</span><span class=\"token string\">'off'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 59.44444444444444%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAABYlAAAWJQFJUiTwAAAD10lEQVQozwHMAzP8AHt+llZbXIBmh4aHNreNhmuldGpKSx8VSGoxKmxJOzQ3YmGAZYF9j1FwbX5CbWyGbipGQzheU1NhdG1wWFVfaTtmZ3xxZF1iOL+HhVq/dmlmAG9va/SAfnn/a2Zeq4Z5Zf+di3nUhnZo0IZ5bf9oY1yqiYJ4/6ihl+Wdnp6/mZCM/2hRSapweWH/aXp29lxjW69zcmL/cGVbqpx4VPiZcUv/AG1iVpyKhH+vLyQXbGZON7dkVECHv7mqhcnCu7iRk5FsdXFzsH94cpKijH56ZFNav1AgHWxzZk6pWWZonV1oa29oZmPGbmVSbG1PJp9GOyO2AM6tpk/WsK9co5OFMWgtH2FqMxlDfXybQUJDb2BTVFIymZmxXMbH3kkTDBQ8JChGZBwpNTOHgjxXtZE5T0E3RjUyLE9na219M////1GOjJ5dALKhm/Kqkor/q6OaqE0+Lv9eVUjSpJmXzm9oav96enmoh4eA/7e3s+OFhX+9nJmS/3NvV6iUiRH/o3kY80k/N60fIBz/UlRQqKCioPUyNzn/AOfUz6TCo5y21L2ucY15Zr+ek4eOm4aGi19UXsGLhItxY2FiuEhEQZqgoKSA4uLqyOXoxnGBcgCxZ1QBpXByXnVVVU3PNC8ucSQkJqcvMDq/AEgrKUhaMzNVZW1eLLi2yViFhYk9el5TO3FSWVm0sKktkKTHVHaInEMoFhg2NCY+XFFDQC5fWHhQlpGqSQ4QHzEAAAxfHB8uL4WGoEtaXHVVADIrI+41LSX/WF5MpZKSff9vcV3OZ1E2ykExGv+Cc16leHhq/5eflN9ORDW6Vk9B/2JcT6WQhn//hnZp7319d6lraWj/Ky0spF9jW/FtcWf/AD80Kq1MQTfAT1M9eGlqS8lZVz2Wc1tFk11MOsunjXF4gHpswpWUh6J6dWaHcnFp03h5d3jb0sm6kG1ercrKw3va4ePaSEtReFZYUK9oamHJAEA/WURdXolRZGZfKqN+aFW3qJI6VFhpOMS63FXLzdQreoGsUKqz0D8yGBM0MxwsWEtDRixXQ1tNOiA2Rmtmbi6XkLRar7LOLK5/b0ilblZRADEzMuVpbG//f3hqn76yif+dk2/HMC8pw1ROSv+trK6fbGxr/4iMjtdIOy2zTjsm/zkrGp9ubWr4TlBW535pXaS7q5H/wK+fn5iMe+m5r57/AH5sW8iBd2nfXlU+i5R9VulzWjeue3h3q2VfYeuVlqCLoKiw4Jqgp7xodnqdXmhm9CQjIYujn5XYiISDyWckMY+IWkz8lGlai4iEb8uklXrpdIjI2btfkaMAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/ec1ce97527379951f010a8c71cac03f3/37523/output_42_0.png\"\n        srcset=\"/static/ec1ce97527379951f010a8c71cac03f3/e9ff0/output_42_0.png 180w,\n/static/ec1ce97527379951f010a8c71cac03f3/f21e7/output_42_0.png 360w,\n/static/ec1ce97527379951f010a8c71cac03f3/37523/output_42_0.png 720w,\n/static/ec1ce97527379951f010a8c71cac03f3/302a4/output_42_0.png 1080w,\n/static/ec1ce97527379951f010a8c71cac03f3/07a9c/output_42_0.png 1440w,\n/static/ec1ce97527379951f010a8c71cac03f3/fbae3/output_42_0.png 2260w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">count <span class=\"token operator\">=</span> <span class=\"token number\">0</span>   <span class=\"token comment\"># ì •ë‹µì„ ë§ì¶˜ ê°œìˆ˜</span>\n<span class=\"token keyword\">for</span> image<span class=\"token punctuation\">,</span> label<span class=\"token punctuation\">,</span> prediction <span class=\"token keyword\">in</span> <span class=\"token builtin\">zip</span><span class=\"token punctuation\">(</span>images<span class=\"token punctuation\">,</span> labels<span class=\"token punctuation\">,</span> predictions<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    correct <span class=\"token operator\">=</span> label <span class=\"token operator\">==</span> prediction\n    <span class=\"token keyword\">if</span> correct<span class=\"token punctuation\">:</span>\n        count <span class=\"token operator\">=</span> count <span class=\"token operator\">+</span> <span class=\"token number\">1</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>count <span class=\"token operator\">/</span> <span class=\"token number\">32</span> <span class=\"token operator\">*</span> <span class=\"token number\">100</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">71.875</code></pre></div>\n<p>ì¤‘ê°„ì— ë“¤ì–´ê°€ìˆëŠ” ë”¥ëŸ¬ë‹ ëª¨ë¸ì´ ë‹¨ìˆœí•œ êµ¬ì¡°ì´ê¸° ë•Œë¬¸ì—<br>\nì¢‹ì€ ê²°ê³¼ê°€ ë‚˜ì˜¤ê³  ìˆì§€ëŠ” ì•Šë‹¤.</p>\n<p>ë‹¤ë§Œ ì¤‘ê°„ì˜ ëª¨ë¸êµ¬ì¡°ë¥¼ ë³€ê²½í•œë‹¤ë©´ ë” ì¢‹ì€ ê²°ê³¼ë¥¼<br>\nëŒì–´ë‚¼ ìˆ˜ ìˆì„ ê²ƒì´ë‹¤.</p>\n<div class=\"table-of-contents\">\n<ul>\n<li>\n<p><a href=\"#%EA%B0%95%EC%95%84%EC%A7%80--%EA%B3%A0%EC%96%91%EC%9D%B4-%EB%B6%84%EB%A5%98-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%A8-%EC%A0%9C%EC%9E%91-\">ê°•ì•„ì§€ &#x26; ê³ ì–‘ì´ ë¶„ë¥˜ í”„ë¡œê·¸ë¨ ì œì‘ !</a></p>\n<ul>\n<li><a href=\"#content\">Content</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#1-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%84%EC%B2%98%EB%A6%AC\">1. ë°ì´í„° ì „ì²˜ë¦¬</a></p>\n</li>\n<li>\n<p><a href=\"#2-%EB%AA%A8%EB%8D%B8-%EC%83%9D%EC%84%B1-%EB%B0%8F-%ED%95%99%EC%8A%B5\">2 ëª¨ë¸ ìƒì„± ë° í•™ìŠµ</a></p>\n</li>\n</ul>\n</div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"></code></pre></div>","frontmatter":{"date":"April 21, 2022","title":"ì¸ê³µì§€ëŠ¥ ê¸°ì´ˆ ì‚¬ì§„ ë¶„ë¥˜ í”„ë¡œê·¸ë¨ ë§›ë³´ê¸°","categories":"beginner","author":"í•˜ì„±ë¯¼","emoji":"ğŸ˜"},"fields":{"slug":"/DML_AI1/"}},"prev":{"id":"83c7066c-e6f4-5149-8931-eec9799d05b9","html":"<h1 id=\"span-stylebackground-color-fff5b1ë¯¸ë¦¬-í•™ìŠµëœ-ë”¥ëŸ¬ë‹-pre-trained--deep-learning-ì‚¬ìš©ì²˜span\" style=\"position:relative;\"><a href=\"#span-stylebackground-color-fff5b1%EB%AF%B8%EB%A6%AC-%ED%95%99%EC%8A%B5%EB%90%9C-%EB%94%A5%EB%9F%AC%EB%8B%9D-pre-trained--deep-learning-%EC%82%AC%EC%9A%A9%EC%B2%98span\" aria-label=\"span stylebackground color fff5b1ë¯¸ë¦¬ í•™ìŠµëœ ë”¥ëŸ¬ë‹ pre trained  deep learning ì‚¬ìš©ì²˜span permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><span style='background-color: #fff5b1'>ë¯¸ë¦¬ í•™ìŠµëœ ë”¥ëŸ¬ë‹ Pre-trained  Deep Learning ì‚¬ìš©ì²˜</span></h1>\n<p>ìš”ì¦˜ í•«í•œ ë§Œí¼ ë‹¤ì–‘í•œ ì—°êµ¬ì™€ ê¸°ë²•ì´ ë°œì „ë˜ê³  ìˆë‹¤</p>\n<p>DNN\në”¥ ë‰´ëŸ´ ë„¤íŠ¸ì›Œí¬</p>\n<p>ë” ì¢‹ì€ ë”¥ ë„¤íŠ¸ì›Œí¬ë¥¼ ë§Œë“¤ê¸° ìœ„í•´ ë§ì€ ì¢…ë¥˜ì˜ ë„¤íŠ¸ì›Œí¬ê°€ ìƒê²¼ë‹¤.<br>\nê·¸ ì¤‘ ëª‡ ê°€ì§€ ì‚¬ì „í•™ìŠµëœ pre-trained Network ëŠ”\nTF ë‚˜ Pytorch ë“±ì˜ í”„ë ˆì„ì›Œí¬ ì°¨ì›ìœ¼ë¡œ ì§€ì›í•˜ê³  ìˆë‹¤.</p>\n<hr>\n<p>ìš°ë¦¬ëŠ” ê·¸ ë§ì€ ëª¨ë¸ë“¤ì„ í›‘ì–´ë³¼ ê±´ë°</p>\n<p>íŠ¹íˆ ResNet ê³¼ VGG ë¥¼ ì¤‘ì‹¬ì ìœ¼ë¡œ ë³¼ ê±°ë‹¤</p>\n<h2 id=\"image-net\" style=\"position:relative;\"><a href=\"#image-net\" aria-label=\"image net permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Image Net</h2>\n<p>2010ë…„ ILSVRC 2010 ì„ ì‹œì‘ìœ¼ë¡œ ëŒ€ëŸ‰ì˜ ì´ë¯¸ì§€ ë°ì´í„°ì…‹<br>\në§Œ ê°œê°€ ë„˜ëŠ” ì¹´í…Œê³ ë¦¬ì— 100ë§Œ ì¥ ê·œëª¨ì˜ ì‚¬ì§„ì„ ê°€ì§€ê³  ìˆë‹¤.</p>\n<p>ì´ê±¸ í†µí•´ ë§ì€ ì‚¬ëŒë“¤ì´ ì´ë¯¸ì§€ ë¶„ë¥˜ ì½˜í…ŒìŠ¤íŠ¸ì— ë‚˜ê°€ ë„¤íŠ¸ì›Œí¬ë¥¼ í˜•ì„±í–ˆë‹¤.</p>\n<ol>\n<li>AlexNet</li>\n</ol>\n<p>2011ë…„ ì´ë¯¸ì§€ë„· ì±Œë¦°ì§€ 1ë“± ëª¨ë¸. ë…¼ë¬¸ì €ìì˜ ì´ë¦„ì„ ë•„ë‹¤.<br>\nCNN êµ¬ì¡°ì˜ í™•ì¥íŒì´ë‹¤.<br>\n2ê°œì˜ GPU ë¡œ ë³‘ë ¬ì—°ì‚°ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ ë³‘ë ¬êµ¬ì¡°ë¡œ ì„¤ê³„ë˜ì—ˆë‹¤.</p>\n<p><a href=\"https://bskyvision.com/421\">ìì„¸í•œ ë‚´ìš©</a></p>\n<ul>\n<li>LeNet</li>\n</ul>\n<p>ì´ê±´ ì´ë•Œ ìƒê¸´ê±´ ì•„ë‹ˆì§€ë§Œ 1998ë…„ì— ê°œë°œí•œ CNN ì•Œê³ ë¦¬ì¦˜ ì´ë¦„ì´ë‹¤.</p>\n<p>LeNet-5ëŠ” ì¸í’‹, 3ê°œì˜ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´(C1, C3, C5), 2ê°œì˜ ì„œë¸Œìƒ˜í”Œë§ ë ˆì´ì–´(S2, S4), 1ì¸µì˜ full-connected ë ˆì´ì–´(F6), ì•„ì›ƒí’‹ ë ˆì´ì–´ë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤. ì°¸ê³ ë¡œ C1ë¶€í„° F6ê¹Œì§€ í™œì„±í™” í•¨ìˆ˜ë¡œ tanhì„ ì‚¬ìš©í•œë‹¤.</p>\n<ol start=\"2\">\n<li>VGG (VGG16, VGG19 ë“±)</li>\n</ol>\n<p>2014ë…„ ì´ë¯¸ì§€ë„· ì±Œë¦°ì§€ ì¤€ìš°ìŠ¹ ëª¨ë¸<br>\nì´ë¦„ì²˜ëŸ¼ 16, 19ê°œì˜ ì¸µì„ ì´ë£¸.<br>\në³‘ë ¬êµ¬ì¡°ê°€ ì•„ë‹ˆë‹¤.</p>\n<hr>\n<p>ê·¼ë° ì¶”ì„¸ë¥¼ ë³´ë©´ ê³„ì† ì¸µì´ ê¹Šì–´ì§€ëŠ”ê²Œ<br>\nì¢‹ë‹¤ê³  í•˜ëŠ”ë°,  ì´ê²Œ ë˜</p>\n<p>ë§‰ ì¸µì„í‚¤ìš´ë‹¤ê³ ë§Œ ì¢‹ì€ê²Œ ì•„ë‹ˆë‹¤.</p>\n<p>ë¶€ì‘ìš©ì´ ìˆë‹¤.</p>\n<ul>\n<li>vanishing gradient (ë˜ëŠ” Exoloding Gradient)</li>\n</ul>\n<p>ì™€ ê·¼ë° ì´ê±¸ í•´ê²°í•œ ê²ƒì´</p>\n<ol start=\"3\">\n<li>ResNet</li>\n</ol>\n<p>2015ë…„ ì´ë¯¸ì§€ë„· ì±Œë¦°ì§€ ìš°ìŠ¹ ëª¨ë¸\nSkip connection ì´ë¼ëŠ” êµ¬ì¡°ë¡œ í•´ê²°\n: ë ˆì´ì–´ì˜ ì…ë ¥ì„ ë‹¤ë¥¸ ê³³ì— ì´ì–´ì„œ Gradient ê°€ ê¹Šê²Œ ì´ì–´ì§€ë„ë¡ ë§Œë“œëŠ” êµ¬ì¡°</p>\n<hr>\n<h2 id=\"ì´ì œëŠ”-ì‹¤ìŠµìœ¼ë¡œ-ë§Œë“¤ì–´ë³´ì\" style=\"position:relative;\"><a href=\"#%EC%9D%B4%EC%A0%9C%EB%8A%94-%EC%8B%A4%EC%8A%B5%EC%9C%BC%EB%A1%9C-%EB%A7%8C%EB%93%A4%EC%96%B4%EB%B3%B4%EC%9E%90\" aria-label=\"ì´ì œëŠ” ì‹¤ìŠµìœ¼ë¡œ ë§Œë“¤ì–´ë³´ì permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>ì´ì œëŠ” ì‹¤ìŠµìœ¼ë¡œ ë§Œë“¤ì–´ë³´ì</h2>\n<p><a href=\"https://github.com/keras-team/keras-applications/tree/master/keras_applications\">https://github.com/keras-team/keras-applications/tree/master/keras_applications</a></p>\n<p>ê·¸ëƒ¥ ì—¬ê¸°ì— ë‹¤ ë‹´ê²¨ìˆë‹¤ê³  ë³´ë©´ ëœë‹¤</p>\n<p>keras ì—ì„œ ì§€ì›í•˜ëŠ” pre-trained model ì´ ë‹´ê²¨ìˆë‹¤.\nêµ¿êµ¿ í‚¹ì™•ì§± êµ¿êµ¿ ğŸš¶â€â™‚ï¸ğŸ§“ğŸ‘©ğŸ‘¨</p>\n<div class=\"table-of-contents\">\n<ul>\n<li><a href=\"#image-net\">Image Net</a></li>\n<li><a href=\"#%EC%9D%B4%EC%A0%9C%EB%8A%94-%EC%8B%A4%EC%8A%B5%EC%9C%BC%EB%A1%9C-%EB%A7%8C%EB%93%A4%EC%96%B4%EB%B3%B4%EC%9E%90\">ì´ì œëŠ” ì‹¤ìŠµìœ¼ë¡œ ë§Œë“¤ì–´ë³´ì</a></li>\n</ul>\n</div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"></code></pre></div>","frontmatter":{"date":"April 21, 2022","title":"pre-trained ëª¨ë¸ ê°€ì ¸ì˜¤ëŠ” ë§í¬","categories":"DeepML","author":"í•˜ì„±ë¯¼","emoji":"ğŸ˜"},"fields":{"slug":"/DML_keras3/"}},"site":{"siteMetadata":{"siteUrl":"https://xman227.github.io","comments":{"utterances":{"repo":"xman227/blog_comments"}}}}},"pageContext":{"slug":"/DML_keras2/","nextSlug":"/DML_AI1/","prevSlug":"/DML_keras3/"}},
    "staticQueryHashes": ["1073350324","1956554647","2938748437"]}