{
    "componentChunkName": "component---src-templates-blog-template-js",
    "path": "/NLP_1/",
    "result": {"data":{"cur":{"id":"6d79397e-6ce5-58cd-bb09-adcf492b30f0","html":"<h1 id=\"\" style=\"position:relative;\"><a href=\"#\" aria-label=\" permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h1>\n<p>우리는 많은 문장들 속에서 살아간다.<br>\n한국어, 영어, 일본어, 중국어,, 영어 배워라 배워라 스트레스 받는것도 다<br>\n언어가 존재하기 때문이다.</p>\n<p>이렇게 일상에서 사용하는 언어를 <strong>자연어(Natural Language)</strong> 라고 부른다.</p>\n<p>반면에 우리가 쓰는 프로그래밍 언어는 <strong>기계어 또는 인공어(Artificial Language)</strong> 라고 부른다.</p>\n<p>(엄연히 따지면 자연어 안에 인공어가 속한다)</p>\n<p>프로그래밍 언어는 자연어보다 훨씬 명료하고 처리하기에 용이하여야 하므로<br>\n자연어와 다르게 문맥과 상관없이 항상 동일한 의미를 가진다.</p>\n<hr>\n<p>우리는 자연어를 처리해야 하기 때문에<br>\n사람이 하는 방식대로는 즉, 문맥을 이해하는 방식으로는<br>\n기계를 학습시키기가 어렵다.</p>\n<p>때문에, 단어들을 숫자로 매핑해 표현하는 머신러닝 기법 을 사용한다.<br>\n그렇다면 각 단어들의 의미를 기계들도 이해하고 연산할 수 있을 것이다.</p>\n<p><a href=\"http://w.elnn.kr/search/\">해당 블로그</a>에서는 그렇게 수치화된 단어들간의<br>\n계산을 시도해 볼 수 있다.</p>\n<p>이와 함께 단어를 어떻게 구분할 것인지(형태소? 단어?) 결정하는<br>\n<code class=\"language-text\">Toknization</code> 기법을 사용한다.</p>\n<h2 id=\"1-잡음이-많은-자연어\" style=\"position:relative;\"><a href=\"#1-%EC%9E%A1%EC%9D%8C%EC%9D%B4-%EB%A7%8E%EC%9D%80-%EC%9E%90%EC%97%B0%EC%96%B4\" aria-label=\"1 잡음이 많은 자연어 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. 잡음이 많은 자연어</h2>\n<p><img src=\"/fe59587a4cc89abb453737e1622d75b5/image1.png\"></img></p>\n<p>우리의 일상언어는 문맥이 있어야만 이해가 가능하다<br>\n위는 내가 친구들과 게임 약속을 잡을 때 나눈 대화이다.</p>\n<p>우선 어느정도의 오타가 존재하고, 주어 동사는 밥먹듯이 빼먹고 있다.<br>\n디코는 음성채팅 어플리케이션인 Discord의 줄임말이다.</p>\n<p>이러한 변형들이 자연어처리 모델 입장에서는 Noise(잡음) 이 된다.<br>\n따라서 우리가 모델을 학습시키기 위해선 이러한 잡음이 최대한 없는 데이터를 사용한다.</p>\n<p>(예를 들어 소설책, 뉴스기사 등)</p>\n<h3 id=\"잡음의-종류\" style=\"position:relative;\"><a href=\"#%EC%9E%A1%EC%9D%8C%EC%9D%98-%EC%A2%85%EB%A5%98\" aria-label=\"잡음의 종류 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>잡음의 종류</h3>\n<ol>\n<li>혼자서 두 세 번 전송하는 경우</li>\n<li>문장길이가 너무 짧거나 긴 경우</li>\n<li>문장 간격이 너무 긴 경우</li>\n<li>욕설 / 오타 가 많은 경우</li>\n</ol>\n<p>너무나도 많지만, 우선 우리가 그나마 정제할 수 있는 노이즈만 뽑자면 다음과 같다.</p>\n<ol>\n<li>문장부호</li>\n<li>대소문자 (영어)</li>\n<li>특수문자</li>\n</ol>\n<p>때문에 NLP 에서는 이렇게 정제할 수 있는 Noise 를\npreprocessing 하는 작업을 거친다.</p>\n<h2 id=\"2-preprocessing\" style=\"position:relative;\"><a href=\"#2-preprocessing\" aria-label=\"2 preprocessing permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. Preprocessing</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 1. 문장부호 구분</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">pad_punctuation</span><span class=\"token punctuation\">(</span>sentence<span class=\"token punctuation\">,</span> punc<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">for</span> p <span class=\"token keyword\">in</span> punc<span class=\"token punctuation\">:</span>\n        sentence <span class=\"token operator\">=</span> sentence<span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span>p<span class=\"token punctuation\">,</span> <span class=\"token string\">\" \"</span> <span class=\"token operator\">+</span> p <span class=\"token operator\">+</span> <span class=\"token string\">\" \"</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">return</span> sentence\n\nsentence <span class=\"token operator\">=</span> <span class=\"token string\">\"안녕, 내 글 읽어줘서 땡큐.\"</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>pad_punctuation<span class=\"token punctuation\">(</span>sentence<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\".\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"?\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"!\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\",\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># , ? ! . 가 들어간 부분 양쪽에 띄어쓰기 처리</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">안녕 ,  내 글 읽어줘서 땡큐 . </code></pre></div>\n<p>문장부호를 제거하지 않는 이유는 쉼표나 마침표 또한 일정한 의미를 가지고 있다고 판단하기 때문이다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 2. 대소문자 처리</span>\n\nsentence <span class=\"token operator\">=</span> <span class=\"token string\">\"First, open the first chapter.\"</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>sentence<span class=\"token punctuation\">.</span>lower<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">first, open the first chapter.</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 3. 특수문자 제거</span>\n\n<span class=\"token keyword\">import</span> re <span class=\"token comment\">#단어 정규화 라이브러리</span>\n\nsentence <span class=\"token operator\">=</span> <span class=\"token string\">\"He is a ten-year-old boy.\"</span>\nsentence <span class=\"token operator\">=</span> re<span class=\"token punctuation\">.</span>sub<span class=\"token punctuation\">(</span><span class=\"token string\">\"([^a-zA-Z.,?!])\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\" \"</span><span class=\"token punctuation\">,</span> sentence<span class=\"token punctuation\">)</span> <span class=\"token comment\">#알파벳과 ! ? ,. 이 아닌 모든 문자는 공백으로 변환</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>sentence<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">He is a ten year old boy.</code></pre></div>\n<hr>\n<h2 id=\"3-embeddng\" style=\"position:relative;\"><a href=\"#3-embeddng\" aria-label=\"3 embeddng permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. Embeddng</h2>\n<p>text를 정제했다면,  임베딩레이어 (<code class=\"language-text\">Embedding layer</code>)를 통해 단어의 분산 표현 (<code class=\"language-text\">Distributed represntation</code>) 을 구현한다.<br>\n분산표현은 단어의 속성 차원(<code class=\"language-text\">dim</code>) 을 우리가 임의로 지정하고, 그 <code class=\"language-text\">dim</code> 에 맞게 추상적인 속성을 구분해 표현하는 것을 의미한다.</p>\n<p>때문에 적절한 차원 수와 합당한 속성 값들이 들어간다면, 각 단어마다 적절한 의미의 유사도가 나타날 것이다.</p>\n<p>의미의 유사도는 <code class=\"language-text\">코사인 유사도</code> 를 통해 나타낸다.</p>\n<blockquote>\n<p>코사인 유사도 ( Cosine similarity )</p>\n</blockquote>\n<p>두 벡터 간의 코사인 각도를 이용해 구할 수 있는 두 벡터의 유사도, 다시 말 해 두 벡터(방향과 속도) 가 어느정도 유사한 지 찾는 계산</p>\n<p><img src=\"/5c5d5b0bb99a8f9840f66c02c02e0903/image2.png\"></img></p>\n<p>위의 그림처럼 동일한 속력 하에 방향이 반대면 -1, 90도면 0, 같은 방향이면 1 의 값을 가진다.<br>\n코사인 유사도는 -1에서 1 사이의 값을 지닌다.</p>\n<p>A와 B 의 코사인 유사도 계산식은 다음과 같다.</p>\n<p><img src=\"/6f4e5bb15c88af9e0b691b048eb41c8a/image3.png\"></img></p>\n<hr>\n<p>이 때, <code class=\"language-text\">dim</code>설정 후 나온 속성 값들의 모음을 <code class=\"language-text\">단어 사전</code> 이라 칭하는데,<br>\n이 단어사전을 제대로 작성하기 위해선 단어를 어떻게 쪼갤 것인지도 판단해야 한다.</p>\n<p>예를 들어보자</p>\n<p>나는 드디어 그녀와 사귀기로 했다</p>\n<p>라는 말이 있을 때, 어떻게 분리해야 할까?</p>\n<ol>\n<li>나, 는, 드디어, 그녀, 와, 사귀기로, 했다. # 조사 나눔</li>\n<li>나는, 드디어, 그녀와, 사귀기로, 했다. #띄어쓰기 나눔</li>\n<li>나,는, 드디어, 그녀, 와, 사귀기,로, 했,다. #형태소별 나눔</li>\n</ol>\n<p>문장을 나누었을 때 쪼개진 조각조각을 <code class=\"language-text\">Token</code> 이라 부른다.\n이것을 결정하는 방식이 <code class=\"language-text\">Tokenization</code> 이다.</p>\n<p>토큰화를 위한 여러가지 분석기들이 이미 개발되어 있다.</p>\n<p>그 종류별 차이점을 <a href=\"https://iostream.tistory.com/144\">해당 블로그</a> 에서 잘 설명해주고 있다.</p>\n<p>우리도 한 번 써보도록 하겠다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> konlpy<span class=\"token punctuation\">.</span>tag <span class=\"token keyword\">import</span> Hannanum<span class=\"token punctuation\">,</span>Kkma<span class=\"token punctuation\">,</span>Komoran<span class=\"token punctuation\">,</span>Mecab<span class=\"token punctuation\">,</span>Okt\n\ntokenizer_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>Hannanum<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>Kkma<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>Komoran<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>Mecab<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>Okt<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\n\nkor_text <span class=\"token operator\">=</span> <span class=\"token string\">'제 이름은 하성민입니다. 헬스 트레이닝과 NLP에 흥미가 있습니다. 세상의 우울을 해결하고 싶습니다.'</span>\n\n<span class=\"token keyword\">for</span> tokenizer <span class=\"token keyword\">in</span> tokenizer_list<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'[{}] \\n{}'</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>tokenizer<span class=\"token punctuation\">.</span>__class__<span class=\"token punctuation\">.</span>__name__<span class=\"token punctuation\">,</span> tokenizer<span class=\"token punctuation\">.</span>pos<span class=\"token punctuation\">(</span>kor_text<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">[Hannanum] \n[('저', 'N'), ('의', 'J'), ('이름', 'N'), ('은', 'J'), ('하성민입니', 'N'), ('이', 'J'), ('다', 'E'), ('.', 'S'), ('헬스', 'N'), ('트레이닝', 'N'), ('과', 'J'), ('NLP', 'F'), ('에', 'J'), ('흥미', 'N'), ('가', 'J'), ('있', 'P'), ('습니다', 'E'), ('.', 'S'), ('세상', 'N'), ('의', 'J'), ('우울', 'N'), ('을', 'J'), ('해결', 'N'), ('하고', 'J'), ('싶', 'P'), ('습니다', 'E'), ('.', 'S')]\n[Kkma] \n[('저', 'NP'), ('의', 'JKG'), ('이름', 'NNG'), ('은', 'JX'), ('하성', 'NNG'), ('민', 'NNG'), ('이', 'VCP'), ('ㅂ니다', 'EFN'), ('.', 'SF'), ('헬스', 'NNG'), ('트레이닝', 'NNG'), ('과', 'JC'), ('NLP', 'OL'), ('에', 'JKM'), ('흥미', 'NNG'), ('가', 'JKS'), ('있', 'VV'), ('습니다', 'EFN'), ('.', 'SF'), ('세상', 'NNG'), ('의', 'JKG'), ('우울', 'NNG'), ('을', 'JKO'), ('해결', 'NNG'), ('하', 'XSV'), ('고', 'ECE'), ('싶', 'VXA'), ('습니다', 'EFN'), ('.', 'SF')]\n[Komoran] \n[('제', 'XPN'), ('이름', 'NNG'), ('은', 'JX'), ('하성민', 'NNP'), ('이', 'VCP'), ('ㅂ니다', 'EF'), ('.', 'SF'), ('헬스', 'NNG'), ('트레이닝', 'NNG'), ('과', 'JC'), ('NLP', 'SL'), ('에', 'JKB'), ('흥미', 'NNG'), ('가', 'JKS'), ('있', 'VX'), ('습니다', 'EF'), ('.', 'SF'), ('세상', 'NNG'), ('의', 'JKG'), ('우울', 'NNG'), ('을', 'JKO'), ('해결', 'NNG'), ('하', 'XSV'), ('고', 'EC'), ('싶', 'VX'), ('습니다', 'EF'), ('.', 'SF')]\n[Mecab] \n[('제', 'NP+JKG'), ('이름', 'NNG'), ('은', 'JX'), ('하성민', 'NNP'), ('입니다', 'VCP+EF'), ('.', 'SF'), ('헬스', 'NNG'), ('트레이닝', 'NNG'), ('과', 'JC'), ('NLP', 'SL'), ('에', 'JKB'), ('흥미', 'NNG'), ('가', 'JKS'), ('있', 'VA'), ('습니다', 'EF'), ('.', 'SF'), ('세상', 'NNG'), ('의', 'JKG'), ('우울', 'NNG'), ('을', 'JKO'), ('해결', 'NNG'), ('하', 'XSV'), ('고', 'EC'), ('싶', 'VX'), ('습니다', 'EF'), ('.', 'SF')]\n[Okt] \n[('제', 'Noun'), ('이름', 'Noun'), ('은', 'Josa'), ('하성민', 'Noun'), ('입니다', 'Adjective'), ('.', 'Punctuation'), ('헬스', 'Noun'), ('트레이닝', 'Noun'), ('과', 'Josa'), ('NLP', 'Alpha'), ('에', 'Josa'), ('흥미', 'Noun'), ('가', 'Josa'), ('있습니다', 'Adjective'), ('.', 'Punctuation'), ('세상', 'Noun'), ('의', 'Josa'), ('우울', 'Noun'), ('을', 'Josa'), ('해결', 'Noun'), ('하고', 'Josa'), ('싶습니다', 'Verb'), ('.', 'Punctuation')]</code></pre></div>\n<p>뒤에 따라오는 알파벳은 해당 글자가 명사인지, 고유명사인지, 형용사인지 구분해주는 기호이다.</p>\n<p><a href=\"http://kkma.snu.ac.kr/documents/?doc=postag\">해당 블로그</a>에서 어떤 알파벳이 어떤 형태소를 나타내는지 표시해준다.<br>\n이 기호 또한 분석기마다 조금의 차이는 있지만 거의 비슷하다.</p>\n<p>내가 봤을 때는 Komoran 이 좀 정확한 것 같다.</p>\n<h3 id=\"이-외-embedding-방법\" style=\"position:relative;\"><a href=\"#%EC%9D%B4-%EC%99%B8-embedding-%EB%B0%A9%EB%B2%95\" aria-label=\"이 외 embedding 방법 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>이 외 Embedding 방법</h3>\n<ol>\n<li>BPE</li>\n</ol>\n<p>이처럼 Embedding layer 는 단어갯수 x 차원 수(n_dim) 의 가중치를 생성한다.</p>\n<p>단어갯수가 많을수록 사용되는 메모리가 많다고 볼 수 있다.<br>\n때문에 단어갯수를 줄여 저장하는 BPE (Byte Pair Encoding) 이나 그 응용 심화 단계인 WPM(Word Piece Model) 등이 사용되기도 한다.</p>\n<p>WPM 은 현재 공개되어 있지는 않고, 구글의 SentencePiece 라이브러리를 통해 전처리까지 해주는 고성능의 BPE 를 이용할 수 있다.<br>\n<a href=\"https://github.com/google/sentencepiece\">SentencePiece</a></p>\n<ol start=\"2\">\n<li>soynlp</li>\n</ol>\n<p>한국어 전용 라이브러리 이다. 토크나이저 외 추출, 형태소분석, 전처리도 가능하다.<br>\n특히 미등록단어(사전에 없는 신조어 등) 을 구분해낼 수 있는 능력을 갖추고 있다.</p>\n<p>예를 들어 <code class=\"language-text\">에스파</code> 라는 단어가 들어왔다면,\n에, 에스, 에스파 중 가장 쓰였을 확률이 높은 단어로 결정한다.</p>\n<hr>\n<h2 id=\"4-분산표현-임베딩의-학습종류\" style=\"position:relative;\"><a href=\"#4-%EB%B6%84%EC%82%B0%ED%91%9C%ED%98%84-%EC%9E%84%EB%B2%A0%EB%94%A9%EC%9D%98-%ED%95%99%EC%8A%B5%EC%A2%85%EB%A5%98\" aria-label=\"4 분산표현 임베딩의 학습종류 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>4. 분산표현 임베딩의 학습종류</h2>\n<h3 id=\"1-word2vec\" style=\"position:relative;\"><a href=\"#1-word2vec\" aria-label=\"1 word2vec permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. Word2Vec</h3>\n<p>한 문장 안에 있는 단어들끼리에는 유사성이 더 있다 라는 가정에서 시작한 방식이다.\n<code class=\"language-text\">word2Vec</code> 은 CBOW(주변단어로 중간단어 예측) 학습방식과 Skip-gram(중간단어로 주변단어 예측) 학습방식이 존재한다.</p>\n<h3 id=\"2-fasttext\" style=\"position:relative;\"><a href=\"#2-fasttext\" aria-label=\"2 fasttext permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. Fasttext</h3>\n<p>하나의 어휘를 n-gram 으로 더 쪼개어 더 정확한 예측을 한다.</p>\n<h3 id=\"3-elmo\" style=\"position:relative;\"><a href=\"#3-elmo\" aria-label=\"3 elmo permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. ELMo</h3>\n<p>동음이의어를 구분하지 못하는 word2Vec 의 단점을 보완했다.\n동음이의어를 구분하려면 그 주변의 문맥을 파악해야 하고, 이러한 특성이 반영된 임베딩을</p>\n<p>Contextualized Word Embedding 이라고 표현한다.</p>\n<p><img src=\"/14676ddd4510b651461ba8a936436cb2/image4.png\"></img></p>\n<p>이러한 방식은 임베딩값이 주변 단어에 따라 가변적인 속성을 띠게 되어\n배(boat, stomach) 가 쓰이는 맥락에 따라 다른 값을 표현한다.</p>\n<hr>\n<h2 id=\"5-정리\" style=\"position:relative;\"><a href=\"#5-%EC%A0%95%EB%A6%AC\" aria-label=\"5 정리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>5. 정리</h2>\n<p>NLP 에서 데이터 전처리와 토큰화는 큰 비중을 차지한다.</p>\n<p>문장에 Noise 를 제거 <code class=\"language-text\">preprocessing</code> 하고,<br>\n제거한 문장을 적절히 <code class=\"language-text\">Tokenize</code> 하고,<br>\n분리한 Token 을 <code class=\"language-text\">word Embedding</code> 한다.</p>\n<p>Tokenize 과정에는 일반적으로 형태소 분석기를 사용한다.<br>\n대표적으로는 koNLP, SentencePiece 라이브러리 등을 사용한다.</p>\n<p>word Embdding 은 대표적으로 Word2Vec, FastText, ELMo 모델을 사용한다.</p>\n<div class=\"table-of-contents\">\n<ul>\n<li>\n<p><a href=\"#1-%EC%9E%A1%EC%9D%8C%EC%9D%B4-%EB%A7%8E%EC%9D%80-%EC%9E%90%EC%97%B0%EC%96%B4\">1. 잡음이 많은 자연어</a></p>\n<ul>\n<li><a href=\"#%EC%9E%A1%EC%9D%8C%EC%9D%98-%EC%A2%85%EB%A5%98\">잡음의 종류</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#2-preprocessing\">2. Preprocessing</a></p>\n</li>\n<li>\n<p><a href=\"#3-embeddng\">3. Embeddng</a></p>\n<ul>\n<li><a href=\"#%EC%9D%B4-%EC%99%B8-embedding-%EB%B0%A9%EB%B2%95\">이 외 Embedding 방법</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#4-%EB%B6%84%EC%82%B0%ED%91%9C%ED%98%84-%EC%9E%84%EB%B2%A0%EB%94%A9%EC%9D%98-%ED%95%99%EC%8A%B5%EC%A2%85%EB%A5%98\">4. 분산표현 임베딩의 학습종류</a></p>\n<ul>\n<li><a href=\"#1-word2vec\">1. Word2Vec</a></li>\n<li><a href=\"#2-fasttext\">2. Fasttext</a></li>\n<li><a href=\"#3-elmo\">3. ELMo</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#5-%EC%A0%95%EB%A6%AC\">5. 정리</a></p>\n</li>\n</ul>\n</div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"></code></pre></div>","excerpt":"우리는 많은 문장들 속에서 살아간다. 한국어, 영어, 일본어, 중국어,, 영어 배워라 배워라 스트레스 받는것도 다 언어가 존재하기 때문이다. 이렇게 일상에서 사용하는 언어를 자연어(Natural Language) 라고 부른다. 반면에 우리가 쓰는 프로그래밍 언어는 기계어 또는 인공어(Artificial Language) 라고 부른다. (엄연히 따지면 자연어 안에 인공어가 속한다) 프로그래밍 언어는 자연어보다 훨씬 명료하고 처리하기에 용이하여야 하므로 자연어와 다르게 문맥과 상관없이 항상 동일한 의미를 가진다. 우리는 자연어를 처리해야 하기 때문에 사람이 하는 방식대로는 즉, 문맥을 이해하는 방식으로는 기계를 학습시키기가 어렵다. 때문에, 단어들을 숫자로 매핑해 표현하는 머신러닝 기법 을 사용한다. 그렇다면 각 단어들의 의미를 기계들도 이해하고 연산할 수 있을 것이다. 해당 블로그에서는 그렇게 수치화된 단어들간의 계산을 시도해 볼 수 있다. 이와 함께 단어를 어떻게 구분할 것인지(형…","frontmatter":{"date":"March 15, 2022","title":"NLP 에서 데이터 전처리 및 토큰화란","categories":"NLP","author":"하성민","emoji":"😁"},"fields":{"slug":"/NLP_1/"}},"next":{"id":"164e3337-bd6f-55fb-8feb-932bec92dc93","html":"<h1 id=\"빅데이터-핸들링의-필수-병렬-컴퓨팅\" style=\"position:relative;\"><a href=\"#%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%95%B8%EB%93%A4%EB%A7%81%EC%9D%98-%ED%95%84%EC%88%98-%EB%B3%91%EB%A0%AC-%EC%BB%B4%ED%93%A8%ED%8C%85\" aria-label=\"빅데이터 핸들링의 필수 병렬 컴퓨팅 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>빅데이터 핸들링의 필수, 병렬 컴퓨팅</h1>\n<h2 id=\"동시성과-병렬성\" style=\"position:relative;\"><a href=\"#%EB%8F%99%EC%8B%9C%EC%84%B1%EA%B3%BC-%EB%B3%91%EB%A0%AC%EC%84%B1\" aria-label=\"동시성과 병렬성 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>동시성과 병렬성</h2>\n<p>동시성 : Concurrency</p>\n<p>병렬성 : Parallelism</p>\n<p>멀티 태스킹에는 위의 2가지 방식있다.</p>\n<p>동시성 : 하나의 processor 가 남는 시간동안 다른 task 를 동시에 수행</p>\n<p>다시말해, 특정 순간에는 1가지 task 를 하겠지만, 다음 task 로 넘어가는데 시간이 걸리게 되면 다른 task 를 수행하도록 한다.</p>\n<p>병렬성 : 여러 processor 가 각자 task 를 동시에 수행</p>\n<blockquote>\n<p>다시 말해, 병렬성을 가진 processor 가 동시성을 가지고 일할 수 있다.</p>\n</blockquote>\n<p>예를 들어, 라면을 조리하려면 물을 끓여야 하는데.<br>\nprocessor 는 불을 켜고 물이 끓기를 기다려야 한다.</p>\n<p>이처럼 대기해야 하는 상황을 ‘bound’ 상태 라고 한다.</p>\n<p>bound 상태에 그저 대기만 하고 있는 방식을 Syncronzized, 동기 방식이라고 한다.<br>\nbound 상태에 다른 일을 처리하는 방식을 Asynchronous 비동기 방식이라고 한다.</p>\n<hr>\n<h2 id=\"process-thread--profiling\" style=\"position:relative;\"><a href=\"#process-thread--profiling\" aria-label=\"process thread  profiling permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>process, thread , profiling</h2>\n<h3 id=\"process\" style=\"position:relative;\"><a href=\"#process\" aria-label=\"process permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Process</h3>\n<p>하나의 프로그램을 생성할 때, 운영체제는 하나의 프로세스 를 생성한다.</p>\n<p>프로세스는 프로그램을 작동시키면서 일어나는 메모리상의 작업 단위를 의미한다.</p>\n<p>하나의 프로세스는 CPU , 메모리(Ram), 디스크 및 자료구조를 이용하는데,\n그 과정에서 메모리는 여러 번 쓰이게 된다.</p>\n<h3 id=\"thread\" style=\"position:relative;\"><a href=\"#thread\" aria-label=\"thread permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Thread</h3>\n<p>thread 는 process 내부에 있는 또 각각의 작업단위를 의미한다</p>\n<p>헬스를 하는 <code class=\"language-text\">program</code> 에서, 운동선수라는 <code class=\"language-text\">processor</code> 는 스쿼트, 레그프레스, 레그 컬 등의 <code class=\"language-text\">thread</code> 를 수행한다.</p>\n<p>헬스로 계속 비유를 들어 보겠다.</p>\n<p>운동선수들끼리 헬스장 자체를 공유할 수는 있지만, 하나의 렉 을 공유할 수는 없다.</p>\n<blockquote>\n<p>다시말해, <code class=\"language-text\">thraed</code> 마다 전용 메모리 공간 <code class=\"language-text\">head</code> 을 가진다.</p>\n</blockquote>\n<h3 id=\"profiling\" style=\"position:relative;\"><a href=\"#profiling\" aria-label=\"profiling permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>profiling</h3>\n<p>사건수사 프로파일링. 들어본적 있을 것이다.<br>\n그 사건의 일거수 일투족을 들여다보는 것을 의미한다.</p>\n<p>컴퓨터 내부의 프로파일링도 똑같다.</p>\n<p>프로그램 코드 내부에서</p>\n<ol>\n<li>어느 부분이 느린지</li>\n<li>어디서 RAM을 많이 사용하는지</li>\n</ol>\n<p>확인할 수 있다.</p>\n<p>파이썬에서도 구현할 수 있다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> timeit <span class=\"token comment\"># 프로파일링 라이브러리</span>\n        \n<span class=\"token keyword\">def</span> <span class=\"token function\">f1</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    s <span class=\"token operator\">=</span> <span class=\"token builtin\">set</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">100</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    \n<span class=\"token keyword\">def</span> <span class=\"token function\">f2</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    l <span class=\"token operator\">=</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">100</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    \n<span class=\"token keyword\">def</span> <span class=\"token function\">f3</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    t <span class=\"token operator\">=</span> <span class=\"token builtin\">tuple</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">100</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">f4</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    s <span class=\"token operator\">=</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">100</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    \n<span class=\"token keyword\">def</span> <span class=\"token function\">f5</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    s <span class=\"token operator\">=</span> <span class=\"token builtin\">set</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">100</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        s<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">f6</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    l <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n    <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">100</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        l<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">)</span>\n    \n<span class=\"token keyword\">def</span> <span class=\"token function\">f7</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    s_comp <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>i <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">100</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span>\n\n    \n<span class=\"token keyword\">def</span> <span class=\"token function\">f8</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    l_comp <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>i <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">100</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\n    \n\nt1 <span class=\"token operator\">=</span> timeit<span class=\"token punctuation\">.</span>Timer<span class=\"token punctuation\">(</span><span class=\"token string\">\"f1()\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"from __main__ import f1\"</span><span class=\"token punctuation\">)</span>\nt2 <span class=\"token operator\">=</span> timeit<span class=\"token punctuation\">.</span>Timer<span class=\"token punctuation\">(</span><span class=\"token string\">\"f2()\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"from __main__ import f2\"</span><span class=\"token punctuation\">)</span>\nt3 <span class=\"token operator\">=</span> timeit<span class=\"token punctuation\">.</span>Timer<span class=\"token punctuation\">(</span><span class=\"token string\">\"f3()\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"from __main__ import f3\"</span><span class=\"token punctuation\">)</span>\nt4 <span class=\"token operator\">=</span> timeit<span class=\"token punctuation\">.</span>Timer<span class=\"token punctuation\">(</span><span class=\"token string\">\"f4()\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"from __main__ import f4\"</span><span class=\"token punctuation\">)</span>\nt5 <span class=\"token operator\">=</span> timeit<span class=\"token punctuation\">.</span>Timer<span class=\"token punctuation\">(</span><span class=\"token string\">\"f5()\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"from __main__ import f5\"</span><span class=\"token punctuation\">)</span>\nt6 <span class=\"token operator\">=</span> timeit<span class=\"token punctuation\">.</span>Timer<span class=\"token punctuation\">(</span><span class=\"token string\">\"f6()\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"from __main__ import f6\"</span><span class=\"token punctuation\">)</span>\nt7 <span class=\"token operator\">=</span> timeit<span class=\"token punctuation\">.</span>Timer<span class=\"token punctuation\">(</span><span class=\"token string\">\"f7()\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"from __main__ import f7\"</span><span class=\"token punctuation\">)</span>\nt8 <span class=\"token operator\">=</span> timeit<span class=\"token punctuation\">.</span>Timer<span class=\"token punctuation\">(</span><span class=\"token string\">\"f8()\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"from __main__ import f8\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"set               :\"</span><span class=\"token punctuation\">,</span> t1<span class=\"token punctuation\">.</span>timeit<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"list              :\"</span><span class=\"token punctuation\">,</span> t2<span class=\"token punctuation\">.</span>timeit<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"tuple             :\"</span><span class=\"token punctuation\">,</span> t3<span class=\"token punctuation\">.</span>timeit<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"string            :\"</span><span class=\"token punctuation\">,</span> t4<span class=\"token punctuation\">.</span>timeit<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"set_add           :\"</span><span class=\"token punctuation\">,</span> t5<span class=\"token punctuation\">.</span>timeit<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"list_append       :\"</span><span class=\"token punctuation\">,</span> t6<span class=\"token punctuation\">.</span>timeit<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"set_comprehension :\"</span><span class=\"token punctuation\">,</span> t5<span class=\"token punctuation\">.</span>timeit<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"list_comprehension:\"</span><span class=\"token punctuation\">,</span> t6<span class=\"token punctuation\">.</span>timeit<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">set               : 1.690346003999366\nlist              : 0.7587415179996242\ntuple             : 0.7320455680001032\nstring            : 0.4020238100001734\nset_add           : 5.726110922999396\nlist_append       : 5.244985264999741\nset_comprehension : 5.7903866610004116\nlist_comprehension: 5.160655052999573</code></pre></div>\n<p>0부터 100까지의 수를 각 자료구조에 담는 시간을 세어 보았다.</p>\n<p>이렇게 함수의 성능을 측정할 수 있다.\n다만 이건 프로파일링을 최 단순화 한 것이다.</p>\n<p>원래는 코드별 들어가는 Ram 의 크기나 성능까지 측정한다.</p>\n<h2 id=\"multi-tasking\" style=\"position:relative;\"><a href=\"#multi-tasking\" aria-label=\"multi tasking permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Multi-tasking</h2>\n<p>단순히 말해 우리는 병렬화, 또는 동시화 하기 위해서 자원을 up 할 수도 있고,<br>\n자원을 out (확장) 할 수도 있다.</p>\n<p>Scale up - 한 대의 컴퓨터 성능 향상\nScale out - 한 대에서 여러대로 컴퓨터 개수를 늘려 한대처럼 사용</p>\n<h2 id=\"실습\" style=\"position:relative;\"><a href=\"#%EC%8B%A4%EC%8A%B5\" aria-label=\"실습 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>실습</h2>\n<h3 id=\"thread-1\" style=\"position:relative;\"><a href=\"#thread-1\" aria-label=\"thread 1 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>thread</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> threading <span class=\"token keyword\">import</span> <span class=\"token operator\">*</span>\n<span class=\"token keyword\">from</span> time <span class=\"token keyword\">import</span> sleep\n\nStopped <span class=\"token operator\">=</span> <span class=\"token boolean\">False</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">worker</span><span class=\"token punctuation\">(</span>work<span class=\"token punctuation\">,</span> sleep_sec<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span> \n    \n    <span class=\"token keyword\">while</span> <span class=\"token keyword\">not</span> Stopped<span class=\"token punctuation\">:</span>          \n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'do '</span><span class=\"token punctuation\">,</span> work<span class=\"token punctuation\">)</span>      \n        sleep<span class=\"token punctuation\">(</span>sleep_sec<span class=\"token punctuation\">)</span> \n        \n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'retired..'</span><span class=\"token punctuation\">)</span>         \n        \n        \nt <span class=\"token operator\">=</span> Thread<span class=\"token punctuation\">(</span>target<span class=\"token operator\">=</span>worker<span class=\"token punctuation\">,</span> args<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token string\">'work'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>    \nt<span class=\"token punctuation\">.</span>start<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>    </code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">do  work\ndo  work\ndo  work</code></pre></div>\n<p>원래는 하나의 코드가 있으면 작동중에 다른 것에 영향을 받지 않는다.<br>\n다만 현재 <code class=\"language-text\">Thread</code> 메서드를 통해 함수를 시작했다.</p>\n<p><code class=\"language-text\">Thread</code> 에서 worker 메서드를 시작시켰고, 함수의 인자는 work, 2 가 들어갔다.</p>\n<p>이 작업이 끝나려면 <code class=\"language-text\">Stopped = True</code> 가 되어야 한다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">Stopped <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span>    \n\nt<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>          \n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'finish'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">retired..\nfinish</code></pre></div>\n<p>이와 같이 <code class=\"language-text\">join</code> 메서드를 통해 같은 <code class=\"language-text\">thread</code> 에서 작업을 진행시켰고\n상단의 무한루프를 중단 시킬 수가 있다.</p>\n<h3 id=\"multi---process\" style=\"position:relative;\"><a href=\"#multi---process\" aria-label=\"multi   process permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>multi - process</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> multiprocessing <span class=\"token keyword\">as</span> mp\n\np <span class=\"token operator\">=</span> mp<span class=\"token punctuation\">.</span>Process<span class=\"token punctuation\">(</span>target<span class=\"token operator\">=</span><span class=\"token string\">'들어갈 프로그램/함수'</span><span class=\"token punctuation\">,</span> args<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token string\">'함수의 인자'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\np<span class=\"token punctuation\">.</span>start<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 프로세스 시작</span>\np<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 실제 종료까지 기다림 (필요시에만 사용)</span>\np<span class=\"token punctuation\">.</span>terminate<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 프로세스 종료</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">\n<span class=\"token keyword\">def</span> <span class=\"token function\">fitness</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'exercising...'</span><span class=\"token punctuation\">)</span>\n\np <span class=\"token operator\">=</span> mp<span class=\"token punctuation\">.</span>Process<span class=\"token punctuation\">(</span>target<span class=\"token operator\">=</span>fitness<span class=\"token punctuation\">,</span> args<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\np<span class=\"token punctuation\">.</span>start<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">delivering...</code></pre></div>\n<p>멀티 프로세스도 <code class=\"language-text\">thread</code> 와 동일하게 구현가능하다</p>\n<hr>\n<h2 id=\"실제-코딩-시-적용방법\" style=\"position:relative;\"><a href=\"#%EC%8B%A4%EC%A0%9C-%EC%BD%94%EB%94%A9-%EC%8B%9C-%EC%A0%81%EC%9A%A9%EB%B0%A9%EB%B2%95\" aria-label=\"실제 코딩 시 적용방법 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>실제 코딩 시 적용방법</h2>\n<p>결국 우리가 이런 걸 하는 이유는 더 효율적이고 빠른 프로그램을 만들 수 있기 때문이다.</p>\n<p>그런데 모든 함수마다 이렇게 병렬처리를 해주는 게 더 귀찮고 시간이 많이든다.</p>\n<p>때문에 파이썬에서는 이 병렬처리 및 multi-tasking 을 자동으로 해주는 모듈이 있다.</p>\n<p><code class=\"language-text\">concurrent.futures</code> 이것이다.</p>\n<p><a href=\"https://docs.python.org/ko/3.7/library/concurrent.futures.html\">공식문서</a></p>\n<p>만약 병렬로 처리하고 싶은 코드가 있다면 아래와 같은 코드에</p>\n<p>병렬을 원하는 함수를 <code class=\"language-text\">func</code> 에 넣어 사용하면 된다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> concurrent\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> concurrent<span class=\"token punctuation\">.</span>futures<span class=\"token punctuation\">.</span>ProcessPoolExecutor<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> executor<span class=\"token punctuation\">:</span>\n        \n        <span class=\"token keyword\">for</span> output <span class=\"token keyword\">in</span> executor<span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span> func <span class=\"token punctuation\">,</span> data <span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span> <span class=\"token comment\"># data 를 func 로 처리.</span>\n            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'%d is prime: %s'</span> <span class=\"token operator\">%</span> <span class=\"token punctuation\">(</span>output<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\">#모든 sequence 데이터가 동시처리됨</span>\n</code></pre></div>\n<div class=\"table-of-contents\">\n<ul>\n<li>\n<p><a href=\"#%EB%8F%99%EC%8B%9C%EC%84%B1%EA%B3%BC-%EB%B3%91%EB%A0%AC%EC%84%B1\">동시성과 병렬성</a></p>\n</li>\n<li>\n<p><a href=\"#process-thread--profiling\">process, thread , profiling</a></p>\n<ul>\n<li><a href=\"#process\">Process</a></li>\n<li><a href=\"#thread\">Thread</a></li>\n<li><a href=\"#profiling\">profiling</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#multi-tasking\">Multi-tasking</a></p>\n</li>\n<li>\n<p><a href=\"#%EC%8B%A4%EC%8A%B5\">실습</a></p>\n<ul>\n<li><a href=\"#thread-1\">thread</a></li>\n<li><a href=\"#multi---process\">multi - process</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#%EC%8B%A4%EC%A0%9C-%EC%BD%94%EB%94%A9-%EC%8B%9C-%EC%A0%81%EC%9A%A9%EB%B0%A9%EB%B2%95\">실제 코딩 시 적용방법</a></p>\n</li>\n</ul>\n</div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"></code></pre></div>","frontmatter":{"date":"February 23, 2022","title":"파이썬 함수 병렬 처리","categories":"Python","author":"하성민","emoji":"👩‍👩‍👦‍👦"},"fields":{"slug":"/python_tasking/"}},"prev":{"id":"a5f56b6d-f700-59e0-8291-651faebf1202","html":"<h1 id=\"-네이버-영화리뷰-감성분석에-sentencepiece-적용해보기span\" style=\"position:relative;\"><a href=\"#-%EB%84%A4%EC%9D%B4%EB%B2%84-%EC%98%81%ED%99%94%EB%A6%AC%EB%B7%B0-%EA%B0%90%EC%84%B1%EB%B6%84%EC%84%9D%EC%97%90-sentencepiece-%EC%A0%81%EC%9A%A9%ED%95%B4%EB%B3%B4%EA%B8%B0span\" aria-label=\" 네이버 영화리뷰 감성분석에 sentencepiece 적용해보기span permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>🙄 네이버 영화리뷰 감성분석에 SentencePiece 적용해보기</span></h1>\n<p>&#x3C;NLP기초></p>\n<h2 id=\"contexts\" style=\"position:relative;\"><a href=\"#contexts\" aria-label=\"contexts permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Contexts</h2>\n<h3 id=\"1-ready\" style=\"position:relative;\"><a href=\"#1-ready\" aria-label=\"1 ready permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. READY</h3>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">1-1 오늘의 Exp와 Rubric  \n1-2 사용하는 라이브러리  </code></pre></div>\n<h3 id=\"2-game\" style=\"position:relative;\"><a href=\"#2-game\" aria-label=\"2 game permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. GAME</h3>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">2-1. 데이터 읽어오기  \n2-2. 데이터 전처리  \n  -1. Tokenize (SentencePiece)\n  -2. 학습데이터 전처리\n  -3. Split Validation \n\n2-3. 모델 학습  \n2-4. 데이터 평가   </code></pre></div>\n<h3 id=\"3-potg-best-play-of-the-game\" style=\"position:relative;\"><a href=\"#3-potg-best-play-of-the-game\" aria-label=\"3 potg best play of the game permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. POTG (best Play Of The Game</h3>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">3-1. 소감(POTG)  \n3-2. 어려웠던 점과 극복방안  \n3-3. 추후  </code></pre></div>\n<hr>\n<h1 id=\"1-ready-1\" style=\"position:relative;\"><a href=\"#1-ready-1\" aria-label=\"1 ready 1 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. Ready</h1>\n<h2 id=\"1-1-오늘의-exp와-rubric\" style=\"position:relative;\"><a href=\"#1-1-%EC%98%A4%EB%8A%98%EC%9D%98-exp%EC%99%80-rubric\" aria-label=\"1 1 오늘의 exp와 rubric permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1-1. 오늘의 Exp와 Rubric</h2>\n<p><a href=\"https://github.com/google/sentencepiece\">SentencePiece</a> 는 Google 에서 제공하고 있는 Tokenizer / Detokenizer 이다.</p>\n<p>Tokenize 란 NLP 에서 중요한 부분인 ‘단어사전 제작’ 을 의미한다.</p>\n<p>직관적으로 생각했을 때, 단어사전은 단어별, 형태소별, 혹은 그 사이 어떤 경계를 나누어 만들 수 있다.</p>\n<p>Sentencepiece 는\nBPE 와 unigram 이라는 두 가지의 분리 방법을 통해 subword tokenizing model 을 제공하고 있다.</p>\n<p>최근 pretrained model 은 대부분 SentencePiece 를 Tokenizer 로 설정하는 추세이기에 NLP 분야 tokenizer 의 표준이라고 표현해도 과언이 아니다.</p>\n<p>오늘은 이러한 SentencePiece 를 끌어와 사용하는 것까지를 실습해보기로 한다.</p>\n<p>실습에 쓰이는 데이터는<br>\nSentencePiece 토크나이저를 학습시킬 <a href=\"https://github.com/jungyeul/korean-parallel-corpora\">한국어 corpus</a> 와<br>\n모델을 학습시킬  <a href=\"https://github.com/e9t/nsmc/blob/master/ratings_test.txt\">Naver_Moive txt data</a> 로 한다.</p>\n<p>오늘의 rubric</p>\n<table>\n<thead>\n<tr>\n<th>평가문항</th>\n<th>상세기준</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1. SentencePiece를 이용하여 모델을 만들기까지의 과정이 정상적으로 진행되었는가?</td>\n<td>코퍼스 분석, 전처리, SentencePiece 적용, 토크나이저 구현 및 동작이 빠짐없이 진행되었는가?</td>\n</tr>\n<tr>\n<td>2. SentencePiece를 통해 만든 Tokenizer가 자연어처리 모델과 결합하여 동작하는가?</td>\n<td>SentencePiece 토크나이저가 적용된 Text Classifier 모델이 정상적으로 수렴하여 80% 이상의 test accuracy가 확인되었다.</td>\n</tr>\n<tr>\n<td>3. SentencePiece의 성능을 다각도로 비교분석하였는가?</td>\n<td>SentencePiece 토크나이저를 활용했을 때의 성능을 다른 토크나이저 혹은 SentencePiece의 다른 옵션의 경우와 비교하여 분석을 체계적으로 진행하였다.</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"1-2-사용하는-라이브러리\" style=\"position:relative;\"><a href=\"#1-2-%EC%82%AC%EC%9A%A9%ED%95%98%EB%8A%94-%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC\" aria-label=\"1 2 사용하는 라이브러리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1-2. 사용하는 라이브러리</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">! python3 <span class=\"token operator\">-</span><span class=\"token operator\">-</span>version</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Python 3.7.12</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\">#import konlpy 단순 import 는 에러 발생</span></code></pre></div>\n<p>시작 하기전 Konlpy 라이브러리에 특이사항이 있다.<br>\ncolab에서는 Konlpy 를 install 할때 별도의 과정을 거쳐야 한다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">!apt<span class=\"token operator\">-</span>get update\n!apt<span class=\"token operator\">-</span>get install g<span class=\"token operator\">+</span><span class=\"token operator\">+</span> openjdk<span class=\"token operator\">-</span><span class=\"token number\">8</span><span class=\"token operator\">-</span>jdk \n!pip3 install konlpy JPype1<span class=\"token operator\">-</span>py3\n!bash <span class=\"token operator\">&lt;</span><span class=\"token punctuation\">(</span>curl <span class=\"token operator\">-</span>s https<span class=\"token punctuation\">:</span><span class=\"token operator\">//</span>raw<span class=\"token punctuation\">.</span>githubusercontent<span class=\"token punctuation\">.</span>com<span class=\"token operator\">/</span>konlpy<span class=\"token operator\">/</span>konlpy<span class=\"token operator\">/</span>master<span class=\"token operator\">/</span>scripts<span class=\"token operator\">/</span>mecab<span class=\"token punctuation\">.</span>sh<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">import</span> konlpy</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\nIgn:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\nGet:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [80.4 kB]\nHit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\nIgn:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\nGet:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\nGet:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\nGet:8 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\nHit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\nGet:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\nGet:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\nGet:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [934 kB]\nHit:14 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\nGet:15 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\nGet:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,098 kB]\nGet:17 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\nGet:18 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [860 kB]\nHit:19 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\nGet:20 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [29.9 kB]\nGet:21 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,262 kB]\nGet:22 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [893 kB]\nGet:23 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,829 kB]\nGet:24 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,484 kB]\nGet:25 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,660 kB]\nGet:26 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [937 kB]\nGet:27 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.2 kB]\nFetched 15.4 MB in 7s (2,158 kB/s)\nReading package lists... Done\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\ng++ is already the newest version (4:7.4.0-1ubuntu2.3).\ng++ set to manually installed.\nThe following additional packages will be installed:\n  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n  libatk-wrapper-java-jni libgail-common libgail18 libgtk2.0-0 libgtk2.0-bin\n  libgtk2.0-common libxxf86dga1 openjdk-8-jdk-headless openjdk-8-jre\n  openjdk-8-jre-headless x11-utils\nSuggested packages:\n  gvfs openjdk-8-demo openjdk-8-source visualvm icedtea-8-plugin libnss-mdns\n  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n  fonts-wqy-zenhei fonts-indic mesa-utils\nThe following NEW packages will be installed:\n  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n  libatk-wrapper-java-jni libgail-common libgail18 libgtk2.0-0 libgtk2.0-bin\n  libgtk2.0-common libxxf86dga1 openjdk-8-jdk openjdk-8-jdk-headless\n  openjdk-8-jre openjdk-8-jre-headless x11-utils\n0 upgraded, 15 newly installed, 0 to remove and 69 not upgraded.\nNeed to get 43.5 MB of archives.\nAfter this operation, 163 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxxf86dga1 amd64 2:1.1.4-1 [13.7 kB]\nGet:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-core all 2.37-1 [1,041 kB]\nGet:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-extra all 2.37-1 [1,953 kB]\nGet:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11-utils amd64 7.7+3build1 [196 kB]\nGet:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk-wrapper-java all 0.33.3-20ubuntu0.1 [34.7 kB]\nGet:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk-wrapper-java-jni amd64 0.33.3-20ubuntu0.1 [28.3 kB]\nGet:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-common all 2.24.32-1ubuntu1 [125 kB]\nGet:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-0 amd64 2.24.32-1ubuntu1 [1,769 kB]\nGet:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail18 amd64 2.24.32-1ubuntu1 [14.2 kB]\nGet:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail-common amd64 2.24.32-1ubuntu1 [112 kB]\nGet:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-bin amd64 2.24.32-1ubuntu1 [7,536 B]\nGet:12 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jre-headless amd64 8u312-b07-0ubuntu1~18.04 [28.2 MB]\nGet:13 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jre amd64 8u312-b07-0ubuntu1~18.04 [69.6 kB]\nGet:14 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jdk-headless amd64 8u312-b07-0ubuntu1~18.04 [8,298 kB]\nGet:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jdk amd64 8u312-b07-0ubuntu1~18.04 [1,625 kB]\nFetched 43.5 MB in 4s (10.1 MB/s)\nSelecting previously unselected package libxxf86dga1:amd64.\n(Reading database ... 155335 files and directories currently installed.)\nPreparing to unpack .../00-libxxf86dga1_2%3a1.1.4-1_amd64.deb ...\nUnpacking libxxf86dga1:amd64 (2:1.1.4-1) ...\nSelecting previously unselected package fonts-dejavu-core.\nPreparing to unpack .../01-fonts-dejavu-core_2.37-1_all.deb ...\nUnpacking fonts-dejavu-core (2.37-1) ...\nSelecting previously unselected package fonts-dejavu-extra.\nPreparing to unpack .../02-fonts-dejavu-extra_2.37-1_all.deb ...\nUnpacking fonts-dejavu-extra (2.37-1) ...\nSelecting previously unselected package x11-utils.\nPreparing to unpack .../03-x11-utils_7.7+3build1_amd64.deb ...\nUnpacking x11-utils (7.7+3build1) ...\nSelecting previously unselected package libatk-wrapper-java.\nPreparing to unpack .../04-libatk-wrapper-java_0.33.3-20ubuntu0.1_all.deb ...\nUnpacking libatk-wrapper-java (0.33.3-20ubuntu0.1) ...\nSelecting previously unselected package libatk-wrapper-java-jni:amd64.\nPreparing to unpack .../05-libatk-wrapper-java-jni_0.33.3-20ubuntu0.1_amd64.deb ...\nUnpacking libatk-wrapper-java-jni:amd64 (0.33.3-20ubuntu0.1) ...\nSelecting previously unselected package libgtk2.0-common.\nPreparing to unpack .../06-libgtk2.0-common_2.24.32-1ubuntu1_all.deb ...\nUnpacking libgtk2.0-common (2.24.32-1ubuntu1) ...\nSelecting previously unselected package libgtk2.0-0:amd64.\nPreparing to unpack .../07-libgtk2.0-0_2.24.32-1ubuntu1_amd64.deb ...\nUnpacking libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\nSelecting previously unselected package libgail18:amd64.\nPreparing to unpack .../08-libgail18_2.24.32-1ubuntu1_amd64.deb ...\nUnpacking libgail18:amd64 (2.24.32-1ubuntu1) ...\nSelecting previously unselected package libgail-common:amd64.\nPreparing to unpack .../09-libgail-common_2.24.32-1ubuntu1_amd64.deb ...\nUnpacking libgail-common:amd64 (2.24.32-1ubuntu1) ...\nSelecting previously unselected package libgtk2.0-bin.\nPreparing to unpack .../10-libgtk2.0-bin_2.24.32-1ubuntu1_amd64.deb ...\nUnpacking libgtk2.0-bin (2.24.32-1ubuntu1) ...\nSelecting previously unselected package openjdk-8-jre-headless:amd64.\nPreparing to unpack .../11-openjdk-8-jre-headless_8u312-b07-0ubuntu1~18.04_amd64.deb ...\nUnpacking openjdk-8-jre-headless:amd64 (8u312-b07-0ubuntu1~18.04) ...\nSelecting previously unselected package openjdk-8-jre:amd64.\nPreparing to unpack .../12-openjdk-8-jre_8u312-b07-0ubuntu1~18.04_amd64.deb ...\nUnpacking openjdk-8-jre:amd64 (8u312-b07-0ubuntu1~18.04) ...\nSelecting previously unselected package openjdk-8-jdk-headless:amd64.\nPreparing to unpack .../13-openjdk-8-jdk-headless_8u312-b07-0ubuntu1~18.04_amd64.deb ...\nUnpacking openjdk-8-jdk-headless:amd64 (8u312-b07-0ubuntu1~18.04) ...\nSelecting previously unselected package openjdk-8-jdk:amd64.\nPreparing to unpack .../14-openjdk-8-jdk_8u312-b07-0ubuntu1~18.04_amd64.deb ...\nUnpacking openjdk-8-jdk:amd64 (8u312-b07-0ubuntu1~18.04) ...\nSetting up libgtk2.0-common (2.24.32-1ubuntu1) ...\nSetting up fonts-dejavu-core (2.37-1) ...\nSetting up libxxf86dga1:amd64 (2:1.1.4-1) ...\nSetting up fonts-dejavu-extra (2.37-1) ...\nSetting up openjdk-8-jre-headless:amd64 (8u312-b07-0ubuntu1~18.04) ...\nupdate-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\nSetting up libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\nSetting up libgail18:amd64 (2.24.32-1ubuntu1) ...\nSetting up openjdk-8-jdk-headless:amd64 (8u312-b07-0ubuntu1~18.04) ...\nupdate-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\nSetting up x11-utils (7.7+3build1) ...\nSetting up libgail-common:amd64 (2.24.32-1ubuntu1) ...\nSetting up libatk-wrapper-java (0.33.3-20ubuntu0.1) ...\nSetting up libgtk2.0-bin (2.24.32-1ubuntu1) ...\nSetting up libatk-wrapper-java-jni:amd64 (0.33.3-20ubuntu0.1) ...\nSetting up openjdk-8-jre:amd64 (8u312-b07-0ubuntu1~18.04) ...\nupdate-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/policytool to provide /usr/bin/policytool (policytool) in auto mode\nSetting up openjdk-8-jdk:amd64 (8u312-b07-0ubuntu1~18.04) ...\nupdate-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/appletviewer to provide /usr/bin/appletviewer (appletviewer) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\nProcessing triggers for man-db (2.8.3-2ubuntu0.1) ...\nProcessing triggers for hicolor-icon-theme (0.17-2) ...\nProcessing triggers for fontconfig (2.12.6-0ubuntu2) ...\nProcessing triggers for mime-support (3.60ubuntu1) ...\nProcessing triggers for libc-bin (2.27-3ubuntu1.3) ...\n/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n\nCollecting konlpy\n  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n\u001b[K     |████████████████████████████████| 19.4 MB 516 kB/s \n\u001b[?25hCollecting JPype1-py3\n  Downloading JPype1-py3-0.5.5.4.tar.gz (88 kB)\n\u001b[K     |████████████████████████████████| 88 kB 7.6 MB/s \n\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\nCollecting JPype1>=0.7.0\n  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n\u001b[K     |████████████████████████████████| 448 kB 53.3 MB/s \n\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.5)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.10.0.2)\nBuilding wheels for collected packages: JPype1-py3\n  Building wheel for JPype1-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for JPype1-py3: filename=JPype1_py3-0.5.5.4-cp37-cp37m-linux_x86_64.whl size=2679864 sha256=06f1d436f3b329b086bc2b1f59e365e9853f59f6d0a60a7c75c2fd742e3ad1b8\n  Stored in directory: /root/.cache/pip/wheels/e7/d1/09/f55dca0203b0691945bdf0f63d486a0b4d4e5ec4bd78a2502e\nSuccessfully built JPype1-py3\nInstalling collected packages: JPype1, konlpy, JPype1-py3\nSuccessfully installed JPype1-1.3.0 JPype1-py3-0.5.5.4 konlpy-0.6.0\nInstalling automake (A dependency for mecab-ko)\nHit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\nIgn:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\nIgn:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\nHit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\nHit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\nHit:6 http://security.ubuntu.com/ubuntu bionic-security InRelease\nHit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\nHit:10 http://archive.ubuntu.com/ubuntu bionic InRelease\nHit:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\nHit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\nHit:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\nHit:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\nHit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\nReading package lists... Done\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nThe following additional packages will be installed:\n  autoconf autotools-dev libsigsegv2 m4\nSuggested packages:\n  autoconf-archive gnu-standards autoconf-doc libtool gettext m4-doc\nThe following NEW packages will be installed:\n  autoconf automake autotools-dev libsigsegv2 m4\n0 upgraded, 5 newly installed, 0 to remove and 69 not upgraded.\nNeed to get 1,082 kB of archives.\nAfter this operation, 3,994 kB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsigsegv2 amd64 2.12-1 [14.7 kB]\nGet:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 m4 amd64 1.4.18-1 [197 kB]\nGet:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 autoconf all 2.69-11 [322 kB]\nGet:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 autotools-dev all 20180224.1 [39.6 kB]\nGet:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 automake all 1:1.15.1-3ubuntu2 [509 kB]\nFetched 1,082 kB in 2s (500 kB/s)\ndebconf: unable to initialize frontend: Dialog\ndebconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, &lt;> line 5.)\ndebconf: falling back to frontend: Readline\ndebconf: unable to initialize frontend: Readline\ndebconf: (This frontend requires a controlling tty.)\ndebconf: falling back to frontend: Teletype\ndpkg-preconfigure: unable to re-open stdin: \nSelecting previously unselected package libsigsegv2:amd64.\n(Reading database ... 155911 files and directories currently installed.)\nPreparing to unpack .../libsigsegv2_2.12-1_amd64.deb ...\nUnpacking libsigsegv2:amd64 (2.12-1) ...\nSelecting previously unselected package m4.\nPreparing to unpack .../archives/m4_1.4.18-1_amd64.deb ...\nUnpacking m4 (1.4.18-1) ...\nSelecting previously unselected package autoconf.\nPreparing to unpack .../autoconf_2.69-11_all.deb ...\nUnpacking autoconf (2.69-11) ...\nSelecting previously unselected package autotools-dev.\nPreparing to unpack .../autotools-dev_20180224.1_all.deb ...\nUnpacking autotools-dev (20180224.1) ...\nSelecting previously unselected package automake.\nPreparing to unpack .../automake_1%3a1.15.1-3ubuntu2_all.deb ...\nUnpacking automake (1:1.15.1-3ubuntu2) ...\nSetting up libsigsegv2:amd64 (2.12-1) ...\nSetting up m4 (1.4.18-1) ...\nSetting up autotools-dev (20180224.1) ...\nSetting up autoconf (2.69-11) ...\nSetting up automake (1:1.15.1-3ubuntu2) ...\nupdate-alternatives: using /usr/bin/automake-1.15 to provide /usr/bin/automake (automake) in auto mode\nProcessing triggers for libc-bin (2.27-3ubuntu1.3) ...\n/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n\nProcessing triggers for man-db (2.8.3-2ubuntu0.1) ...\nInstall mecab-ko\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n100 1381k  100 1381k    0     0   496k      0  0:00:02  0:00:02 --:--:-- 1243k\nmecab-0.996-ko-0.9.2/\nmecab-0.996-ko-0.9.2/example/\nmecab-0.996-ko-0.9.2/example/example.cpp\nmecab-0.996-ko-0.9.2/example/example_lattice.cpp\nmecab-0.996-ko-0.9.2/example/example_lattice.c\nmecab-0.996-ko-0.9.2/example/example.c\nmecab-0.996-ko-0.9.2/example/thread_test.cpp\nmecab-0.996-ko-0.9.2/mecab-config.in\nmecab-0.996-ko-0.9.2/man/\nmecab-0.996-ko-0.9.2/man/Makefile.am\nmecab-0.996-ko-0.9.2/man/mecab.1\nmecab-0.996-ko-0.9.2/man/Makefile.in\nmecab-0.996-ko-0.9.2/mecab.iss.in\nmecab-0.996-ko-0.9.2/config.guess\nmecab-0.996-ko-0.9.2/README\nmecab-0.996-ko-0.9.2/COPYING\nmecab-0.996-ko-0.9.2/CHANGES.md\nmecab-0.996-ko-0.9.2/README.md\nmecab-0.996-ko-0.9.2/INSTALL\nmecab-0.996-ko-0.9.2/config.sub\nmecab-0.996-ko-0.9.2/configure.in\nmecab-0.996-ko-0.9.2/swig/\nmecab-0.996-ko-0.9.2/swig/Makefile\nmecab-0.996-ko-0.9.2/swig/version.h.in\nmecab-0.996-ko-0.9.2/swig/version.h\nmecab-0.996-ko-0.9.2/swig/MeCab.i\nmecab-0.996-ko-0.9.2/aclocal.m4\nmecab-0.996-ko-0.9.2/LGPL\nmecab-0.996-ko-0.9.2/Makefile.am\nmecab-0.996-ko-0.9.2/configure\nmecab-0.996-ko-0.9.2/tests/\nmecab-0.996-ko-0.9.2/tests/autolink/\nmecab-0.996-ko-0.9.2/tests/autolink/unk.def\nmecab-0.996-ko-0.9.2/tests/autolink/dicrc\nmecab-0.996-ko-0.9.2/tests/autolink/dic.csv\nmecab-0.996-ko-0.9.2/tests/autolink/test\nmecab-0.996-ko-0.9.2/tests/autolink/char.def\nmecab-0.996-ko-0.9.2/tests/autolink/matrix.def\nmecab-0.996-ko-0.9.2/tests/autolink/test.gld\nmecab-0.996-ko-0.9.2/tests/t9/\nmecab-0.996-ko-0.9.2/tests/t9/unk.def\nmecab-0.996-ko-0.9.2/tests/t9/ipadic.pl\nmecab-0.996-ko-0.9.2/tests/t9/dicrc\nmecab-0.996-ko-0.9.2/tests/t9/dic.csv\nmecab-0.996-ko-0.9.2/tests/t9/test\nmecab-0.996-ko-0.9.2/tests/t9/char.def\nmecab-0.996-ko-0.9.2/tests/t9/matrix.def\nmecab-0.996-ko-0.9.2/tests/t9/mkdic.pl\nmecab-0.996-ko-0.9.2/tests/t9/test.gld\nmecab-0.996-ko-0.9.2/tests/cost-train/\nmecab-0.996-ko-0.9.2/tests/cost-train/ipa.train\nmecab-0.996-ko-0.9.2/tests/cost-train/ipa.test\nmecab-0.996-ko-0.9.2/tests/cost-train/seed/\nmecab-0.996-ko-0.9.2/tests/cost-train/seed/rewrite.def\nmecab-0.996-ko-0.9.2/tests/cost-train/seed/feature.def\nmecab-0.996-ko-0.9.2/tests/cost-train/seed/unk.def\nmecab-0.996-ko-0.9.2/tests/cost-train/seed/dicrc\nmecab-0.996-ko-0.9.2/tests/cost-train/seed/dic.csv\nmecab-0.996-ko-0.9.2/tests/cost-train/seed/char.def\nmecab-0.996-ko-0.9.2/tests/cost-train/seed/matrix.def\nmecab-0.996-ko-0.9.2/tests/run-eval.sh\nmecab-0.996-ko-0.9.2/tests/run-cost-train.sh\nmecab-0.996-ko-0.9.2/tests/Makefile.am\nmecab-0.996-ko-0.9.2/tests/katakana/\nmecab-0.996-ko-0.9.2/tests/katakana/unk.def\nmecab-0.996-ko-0.9.2/tests/katakana/dicrc\nmecab-0.996-ko-0.9.2/tests/katakana/dic.csv\nmecab-0.996-ko-0.9.2/tests/katakana/test\nmecab-0.996-ko-0.9.2/tests/katakana/char.def\nmecab-0.996-ko-0.9.2/tests/katakana/matrix.def\nmecab-0.996-ko-0.9.2/tests/katakana/test.gld\nmecab-0.996-ko-0.9.2/tests/eval/\nmecab-0.996-ko-0.9.2/tests/eval/answer\nmecab-0.996-ko-0.9.2/tests/eval/system\nmecab-0.996-ko-0.9.2/tests/eval/test.gld\nmecab-0.996-ko-0.9.2/tests/shiin/\nmecab-0.996-ko-0.9.2/tests/shiin/unk.def\nmecab-0.996-ko-0.9.2/tests/shiin/dicrc\nmecab-0.996-ko-0.9.2/tests/shiin/dic.csv\nmecab-0.996-ko-0.9.2/tests/shiin/test\nmecab-0.996-ko-0.9.2/tests/shiin/char.def\nmecab-0.996-ko-0.9.2/tests/shiin/matrix.def\nmecab-0.996-ko-0.9.2/tests/shiin/mkdic.pl\nmecab-0.996-ko-0.9.2/tests/shiin/test.gld\nmecab-0.996-ko-0.9.2/tests/latin/\nmecab-0.996-ko-0.9.2/tests/latin/unk.def\nmecab-0.996-ko-0.9.2/tests/latin/dicrc\nmecab-0.996-ko-0.9.2/tests/latin/dic.csv\nmecab-0.996-ko-0.9.2/tests/latin/test\nmecab-0.996-ko-0.9.2/tests/latin/char.def\nmecab-0.996-ko-0.9.2/tests/latin/matrix.def\nmecab-0.996-ko-0.9.2/tests/latin/test.gld\nmecab-0.996-ko-0.9.2/tests/chartype/\nmecab-0.996-ko-0.9.2/tests/chartype/unk.def\nmecab-0.996-ko-0.9.2/tests/chartype/dicrc\nmecab-0.996-ko-0.9.2/tests/chartype/dic.csv\nmecab-0.996-ko-0.9.2/tests/chartype/test\nmecab-0.996-ko-0.9.2/tests/chartype/char.def\nmecab-0.996-ko-0.9.2/tests/chartype/matrix.def\nmecab-0.996-ko-0.9.2/tests/chartype/test.gld\nmecab-0.996-ko-0.9.2/tests/run-dics.sh\nmecab-0.996-ko-0.9.2/tests/ngram/\nmecab-0.996-ko-0.9.2/tests/ngram/unk.def\nmecab-0.996-ko-0.9.2/tests/ngram/dicrc\nmecab-0.996-ko-0.9.2/tests/ngram/dic.csv\nmecab-0.996-ko-0.9.2/tests/ngram/test\nmecab-0.996-ko-0.9.2/tests/ngram/char.def\nmecab-0.996-ko-0.9.2/tests/ngram/matrix.def\nmecab-0.996-ko-0.9.2/tests/ngram/test.gld\nmecab-0.996-ko-0.9.2/tests/Makefile.in\nmecab-0.996-ko-0.9.2/ltmain.sh\nmecab-0.996-ko-0.9.2/config.rpath\nmecab-0.996-ko-0.9.2/config.h.in\nmecab-0.996-ko-0.9.2/mecabrc.in\nmecab-0.996-ko-0.9.2/GPL\nmecab-0.996-ko-0.9.2/Makefile.train\nmecab-0.996-ko-0.9.2/ChangeLog\nmecab-0.996-ko-0.9.2/install-sh\nmecab-0.996-ko-0.9.2/AUTHORS\nmecab-0.996-ko-0.9.2/doc/\nmecab-0.996-ko-0.9.2/doc/bindings.html\nmecab-0.996-ko-0.9.2/doc/posid.html\nmecab-0.996-ko-0.9.2/doc/unk.html\nmecab-0.996-ko-0.9.2/doc/learn.html\nmecab-0.996-ko-0.9.2/doc/format.html\nmecab-0.996-ko-0.9.2/doc/libmecab.html\nmecab-0.996-ko-0.9.2/doc/mecab.css\nmecab-0.996-ko-0.9.2/doc/feature.html\nmecab-0.996-ko-0.9.2/doc/Makefile.am\nmecab-0.996-ko-0.9.2/doc/soft.html\nmecab-0.996-ko-0.9.2/doc/en/\nmecab-0.996-ko-0.9.2/doc/en/bindings.html\nmecab-0.996-ko-0.9.2/doc/dic-detail.html\nmecab-0.996-ko-0.9.2/doc/flow.png\nmecab-0.996-ko-0.9.2/doc/mecab.html\nmecab-0.996-ko-0.9.2/doc/index.html\nmecab-0.996-ko-0.9.2/doc/result.png\nmecab-0.996-ko-0.9.2/doc/doxygen/\nmecab-0.996-ko-0.9.2/doc/doxygen/tab_a.png\nmecab-0.996-ko-0.9.2/doc/doxygen/globals_eval.html\nmecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Tagger-members.html\nmecab-0.996-ko-0.9.2/doc/doxygen/functions_vars.html\nmecab-0.996-ko-0.9.2/doc/doxygen/doxygen.css\nmecab-0.996-ko-0.9.2/doc/doxygen/tab_r.gif\nmecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Lattice.html\nmecab-0.996-ko-0.9.2/doc/doxygen/functions.html\nmecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Tagger.html\nmecab-0.996-ko-0.9.2/doc/doxygen/mecab_8h_source.html\nmecab-0.996-ko-0.9.2/doc/doxygen/tabs.css\nmecab-0.996-ko-0.9.2/doc/doxygen/nav_f.png\nmecab-0.996-ko-0.9.2/doc/doxygen/tab_b.png\nmecab-0.996-ko-0.9.2/doc/doxygen/globals.html\nmecab-0.996-ko-0.9.2/doc/doxygen/nav_h.png\nmecab-0.996-ko-0.9.2/doc/doxygen/tab_h.png\nmecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Model.html\nmecab-0.996-ko-0.9.2/doc/doxygen/globals_func.html\nmecab-0.996-ko-0.9.2/doc/doxygen/closed.png\nmecab-0.996-ko-0.9.2/doc/doxygen/tab_l.gif\nmecab-0.996-ko-0.9.2/doc/doxygen/structmecab__path__t-members.html\nmecab-0.996-ko-0.9.2/doc/doxygen/functions_func.html\nmecab-0.996-ko-0.9.2/doc/doxygen/globals_type.html\nmecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Lattice-members.html\nmecab-0.996-ko-0.9.2/doc/doxygen/structmecab__node__t.html\nmecab-0.996-ko-0.9.2/doc/doxygen/namespacemembers_func.html\nmecab-0.996-ko-0.9.2/doc/doxygen/tab_s.png\nmecab-0.996-ko-0.9.2/doc/doxygen/structmecab__dictionary__info__t-members.html\nmecab-0.996-ko-0.9.2/doc/doxygen/namespacemembers_type.html\nmecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Model-members.html\nmecab-0.996-ko-0.9.2/doc/doxygen/structmecab__dictionary__info__t.html\nmecab-0.996-ko-0.9.2/doc/doxygen/namespaces.html\nmecab-0.996-ko-0.9.2/doc/doxygen/namespacemembers.html\nmecab-0.996-ko-0.9.2/doc/doxygen/namespaceMeCab.html\nmecab-0.996-ko-0.9.2/doc/doxygen/structmecab__path__t.html\nmecab-0.996-ko-0.9.2/doc/doxygen/files.html\nmecab-0.996-ko-0.9.2/doc/doxygen/structmecab__node__t-members.html\nmecab-0.996-ko-0.9.2/doc/doxygen/index.html\nmecab-0.996-ko-0.9.2/doc/doxygen/annotated.html\nmecab-0.996-ko-0.9.2/doc/doxygen/globals_defs.html\nmecab-0.996-ko-0.9.2/doc/doxygen/classes.html\nmecab-0.996-ko-0.9.2/doc/doxygen/mecab_8h-source.html\nmecab-0.996-ko-0.9.2/doc/doxygen/doxygen.png\nmecab-0.996-ko-0.9.2/doc/doxygen/tab_b.gif\nmecab-0.996-ko-0.9.2/doc/doxygen/bc_s.png\nmecab-0.996-ko-0.9.2/doc/doxygen/open.png\nmecab-0.996-ko-0.9.2/doc/doxygen/mecab_8h.html\nmecab-0.996-ko-0.9.2/doc/dic.html\nmecab-0.996-ko-0.9.2/doc/partial.html\nmecab-0.996-ko-0.9.2/doc/feature.png\nmecab-0.996-ko-0.9.2/doc/Makefile.in\nmecab-0.996-ko-0.9.2/missing\nmecab-0.996-ko-0.9.2/BSD\nmecab-0.996-ko-0.9.2/NEWS\nmecab-0.996-ko-0.9.2/mkinstalldirs\nmecab-0.996-ko-0.9.2/src/\nmecab-0.996-ko-0.9.2/src/dictionary.h\nmecab-0.996-ko-0.9.2/src/writer.h\nmecab-0.996-ko-0.9.2/src/utils.h\nmecab-0.996-ko-0.9.2/src/string_buffer.cpp\nmecab-0.996-ko-0.9.2/src/tokenizer.cpp\nmecab-0.996-ko-0.9.2/src/make.bat\nmecab-0.996-ko-0.9.2/src/mecab.h\nmecab-0.996-ko-0.9.2/src/freelist.h\nmecab-0.996-ko-0.9.2/src/string_buffer.h\nmecab-0.996-ko-0.9.2/src/learner_tagger.h\nmecab-0.996-ko-0.9.2/src/dictionary_compiler.cpp\nmecab-0.996-ko-0.9.2/src/eval.cpp\nmecab-0.996-ko-0.9.2/src/mecab-system-eval.cpp\nmecab-0.996-ko-0.9.2/src/darts.h\nmecab-0.996-ko-0.9.2/src/param.h\nmecab-0.996-ko-0.9.2/src/char_property.h\nmecab-0.996-ko-0.9.2/src/learner_node.h\nmecab-0.996-ko-0.9.2/src/mecab-dict-gen.cpp\nmecab-0.996-ko-0.9.2/src/mecab-dict-index.cpp\nmecab-0.996-ko-0.9.2/src/winmain.h\nmecab-0.996-ko-0.9.2/src/thread.h\nmecab-0.996-ko-0.9.2/src/context_id.cpp\nmecab-0.996-ko-0.9.2/src/Makefile.am\nmecab-0.996-ko-0.9.2/src/connector.h\nmecab-0.996-ko-0.9.2/src/common.h\nmecab-0.996-ko-0.9.2/src/dictionary_rewriter.cpp\nmecab-0.996-ko-0.9.2/src/Makefile.msvc.in\nmecab-0.996-ko-0.9.2/src/dictionary_rewriter.h\nmecab-0.996-ko-0.9.2/src/feature_index.h\nmecab-0.996-ko-0.9.2/src/iconv_utils.cpp\nmecab-0.996-ko-0.9.2/src/char_property.cpp\nmecab-0.996-ko-0.9.2/src/mecab-test-gen.cpp\nmecab-0.996-ko-0.9.2/src/tagger.cpp\nmecab-0.996-ko-0.9.2/src/mecab-cost-train.cpp\nmecab-0.996-ko-0.9.2/src/learner.cpp\nmecab-0.996-ko-0.9.2/src/dictionary.cpp\nmecab-0.996-ko-0.9.2/src/lbfgs.cpp\nmecab-0.996-ko-0.9.2/src/ucs.h\nmecab-0.996-ko-0.9.2/src/writer.cpp\nmecab-0.996-ko-0.9.2/src/learner_tagger.cpp\nmecab-0.996-ko-0.9.2/src/lbfgs.h\nmecab-0.996-ko-0.9.2/src/libmecab.cpp\nmecab-0.996-ko-0.9.2/src/tokenizer.h\nmecab-0.996-ko-0.9.2/src/mecab.cpp\nmecab-0.996-ko-0.9.2/src/utils.cpp\nmecab-0.996-ko-0.9.2/src/dictionary_generator.cpp\nmecab-0.996-ko-0.9.2/src/param.cpp\nmecab-0.996-ko-0.9.2/src/context_id.h\nmecab-0.996-ko-0.9.2/src/mmap.h\nmecab-0.996-ko-0.9.2/src/viterbi.h\nmecab-0.996-ko-0.9.2/src/viterbi.cpp\nmecab-0.996-ko-0.9.2/src/stream_wrapper.h\nmecab-0.996-ko-0.9.2/src/feature_index.cpp\nmecab-0.996-ko-0.9.2/src/nbest_generator.h\nmecab-0.996-ko-0.9.2/src/ucstable.h\nmecab-0.996-ko-0.9.2/src/nbest_generator.cpp\nmecab-0.996-ko-0.9.2/src/iconv_utils.h\nmecab-0.996-ko-0.9.2/src/connector.cpp\nmecab-0.996-ko-0.9.2/src/Makefile.in\nmecab-0.996-ko-0.9.2/src/scoped_ptr.h\nmecab-0.996-ko-0.9.2/Makefile.in\nchecking for a BSD-compatible install... /usr/bin/install -c\nchecking whether build environment is sane... yes\nchecking for a thread-safe mkdir -p... /bin/mkdir -p\nchecking for gawk... no\nchecking for mawk... mawk\nchecking whether make sets $(MAKE)... yes\nchecking for gcc... gcc\nchecking whether the C compiler works... yes\nchecking for C compiler default output file name... a.out\nchecking for suffix of executables... \nchecking whether we are cross compiling... no\nchecking for suffix of object files... o\nchecking whether we are using the GNU C compiler... yes\nchecking whether gcc accepts -g... yes\nchecking for gcc option to accept ISO C89... none needed\nchecking for style of include used by make... GNU\nchecking dependency style of gcc... none\nchecking for g++... g++\nchecking whether we are using the GNU C++ compiler... yes\nchecking whether g++ accepts -g... yes\nchecking dependency style of g++... none\nchecking how to run the C preprocessor... gcc -E\nchecking for grep that handles long lines and -e... /bin/grep\nchecking for egrep... /bin/grep -E\nchecking whether gcc needs -traditional... no\nchecking whether make sets $(MAKE)... (cached) yes\nchecking build system type... x86_64-unknown-linux-gnu\nchecking host system type... x86_64-unknown-linux-gnu\nchecking how to print strings... printf\nchecking for a sed that does not truncate output... /bin/sed\nchecking for fgrep... /bin/grep -F\nchecking for ld used by gcc... /usr/bin/ld\nchecking if the linker (/usr/bin/ld) is GNU ld... yes\nchecking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -B\nchecking the name lister (/usr/bin/nm -B) interface... BSD nm\nchecking whether ln -s works... yes\nchecking the maximum length of command line arguments... 1572864\nchecking whether the shell understands some XSI constructs... yes\nchecking whether the shell understands \"+=\"... yes\nchecking how to convert x86_64-unknown-linux-gnu file names to x86_64-unknown-linux-gnu format... func_convert_file_noop\nchecking how to convert x86_64-unknown-linux-gnu file names to toolchain format... func_convert_file_noop\nchecking for /usr/bin/ld option to reload object files... -r\nchecking for objdump... objdump\nchecking how to recognize dependent libraries... pass_all\nchecking for dlltool... dlltool\nchecking how to associate runtime and link libraries... printf %s\\n\nchecking for ar... ar\nchecking for archiver @FILE support... @\nchecking for strip... strip\nchecking for ranlib... ranlib\nchecking command to parse /usr/bin/nm -B output from gcc object... ok\nchecking for sysroot... no\n./configure: line 7378: /usr/bin/file: No such file or directory\nchecking for mt... no\nchecking if : is a manifest tool... no\nchecking for ANSI C header files... yes\nchecking for sys/types.h... yes\nchecking for sys/stat.h... yes\nchecking for stdlib.h... yes\nchecking for string.h... yes\nchecking for memory.h... yes\nchecking for strings.h... yes\nchecking for inttypes.h... yes\nchecking for stdint.h... yes\nchecking for unistd.h... yes\nchecking for dlfcn.h... yes\nchecking for objdir... .libs\nchecking if gcc supports -fno-rtti -fno-exceptions... no\nchecking for gcc option to produce PIC... -fPIC -DPIC\nchecking if gcc PIC flag -fPIC -DPIC works... yes\nchecking if gcc static flag -static works... yes\nchecking if gcc supports -c -o file.o... yes\nchecking if gcc supports -c -o file.o... (cached) yes\nchecking whether the gcc linker (/usr/bin/ld) supports shared libraries... yes\nchecking whether -lc should be explicitly linked in... no\nchecking dynamic linker characteristics... GNU/Linux ld.so\nchecking how to hardcode library paths into programs... immediate\nchecking whether stripping libraries is possible... yes\nchecking if libtool supports shared libraries... yes\nchecking whether to build shared libraries... yes\nchecking whether to build static libraries... yes\nchecking how to run the C++ preprocessor... g++ -E\nchecking for ld used by g++... /usr/bin/ld\nchecking if the linker (/usr/bin/ld) is GNU ld... yes\nchecking whether the g++ linker (/usr/bin/ld) supports shared libraries... yes\nchecking for g++ option to produce PIC... -fPIC -DPIC\nchecking if g++ PIC flag -fPIC -DPIC works... yes\nchecking if g++ static flag -static works... yes\nchecking if g++ supports -c -o file.o... yes\nchecking if g++ supports -c -o file.o... (cached) yes\nchecking whether the g++ linker (/usr/bin/ld) supports shared libraries... yes\nchecking dynamic linker characteristics... (cached) GNU/Linux ld.so\nchecking how to hardcode library paths into programs... immediate\nchecking for library containing strerror... none required\nchecking whether byte ordering is bigendian... no\nchecking for ld used by GCC... /usr/bin/ld\nchecking if the linker (/usr/bin/ld) is GNU ld... yes\nchecking for shared library run path origin... done\nchecking for iconv... yes\nchecking for working iconv... yes\nchecking for iconv declaration... \n         extern size_t iconv (iconv_t cd, char * *inbuf, size_t *inbytesleft, char * *outbuf, size_t *outbytesleft);\nchecking for ANSI C header files... (cached) yes\nchecking for an ANSI C-conforming const... yes\nchecking whether byte ordering is bigendian... (cached) no\nchecking for string.h... (cached) yes\nchecking for stdlib.h... (cached) yes\nchecking for unistd.h... (cached) yes\nchecking fcntl.h usability... yes\nchecking fcntl.h presence... yes\nchecking for fcntl.h... yes\nchecking for stdint.h... (cached) yes\nchecking for sys/stat.h... (cached) yes\nchecking sys/mman.h usability... yes\nchecking sys/mman.h presence... yes\nchecking for sys/mman.h... yes\nchecking sys/times.h usability... yes\nchecking sys/times.h presence... yes\nchecking for sys/times.h... yes\nchecking for sys/types.h... (cached) yes\nchecking dirent.h usability... yes\nchecking dirent.h presence... yes\nchecking for dirent.h... yes\nchecking ctype.h usability... yes\nchecking ctype.h presence... yes\nchecking for ctype.h... yes\nchecking for sys/types.h... (cached) yes\nchecking io.h usability... no\nchecking io.h presence... no\nchecking for io.h... no\nchecking windows.h usability... no\nchecking windows.h presence... no\nchecking for windows.h... no\nchecking pthread.h usability... yes\nchecking pthread.h presence... yes\nchecking for pthread.h... yes\nchecking for off_t... yes\nchecking for size_t... yes\nchecking size of char... 1\nchecking size of short... 2\nchecking size of int... 4\nchecking size of long... 8\nchecking size of long long... 8\nchecking size of size_t... 8\nchecking for size_t... (cached) yes\nchecking for unsigned long long int... yes\nchecking for stdlib.h... (cached) yes\nchecking for unistd.h... (cached) yes\nchecking for sys/param.h... yes\nchecking for getpagesize... yes\nchecking for working mmap... yes\nchecking for main in -lstdc++... yes\nchecking for pthread_create in -lpthread... yes\nchecking for pthread_join in -lpthread... yes\nchecking for getenv... yes\nchecking for opendir... yes\nchecking whether make is GNU Make... yes\nchecking if g++ supports stl &lt;vector> (required)... yes\nchecking if g++ supports stl &lt;list> (required)... yes\nchecking if g++ supports stl &lt;map> (required)... yes\nchecking if g++ supports stl &lt;set> (required)... yes\nchecking if g++ supports stl &lt;queue> (required)... yes\nchecking if g++ supports stl &lt;functional> (required)... yes\nchecking if g++ supports stl &lt;algorithm> (required)... yes\nchecking if g++ supports stl &lt;string> (required)... yes\nchecking if g++ supports stl &lt;iostream> (required)... yes\nchecking if g++ supports stl &lt;sstream> (required)... yes\nchecking if g++ supports stl &lt;fstream> (required)... yes\nchecking if g++ supports template &lt;class T> (required)... yes\nchecking if g++ supports const_cast&lt;> (required)... yes\nchecking if g++ supports static_cast&lt;> (required)... yes\nchecking if g++ supports reinterpret_cast&lt;> (required)... yes\nchecking if g++ supports namespaces (required) ... yes\nchecking if g++ supports __thread (optional)... yes\nchecking if g++ supports template &lt;class T> (required)... yes\nchecking if g++ supports GCC native atomic operations (optional)... yes\nchecking if g++ supports OSX native atomic operations (optional)... no\nchecking if g++ environment provides all required features... yes\nconfigure: creating ./config.status\nconfig.status: creating Makefile\nconfig.status: creating src/Makefile\nconfig.status: creating src/Makefile.msvc\nconfig.status: creating man/Makefile\nconfig.status: creating doc/Makefile\nconfig.status: creating tests/Makefile\nconfig.status: creating swig/version.h\nconfig.status: creating mecab.iss\nconfig.status: creating mecab-config\nconfig.status: creating mecabrc\nconfig.status: creating config.h\nconfig.status: executing depfiles commands\nconfig.status: executing libtool commands\nconfig.status: executing default commands\nmake  all-recursive\nmake[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\nMaking all in src\nmake[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o viterbi.lo viterbi.cpp\nlibtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c viterbi.cpp  -fPIC -DPIC -o .libs/viterbi.o\nIn file included from \u001b[01m\u001b[Kviterbi.cpp:14:0\u001b[m\u001b[K:\n\u001b[01m\u001b[Kparam.h:30:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K'\u001b[01m\u001b[KTarget {anonymous}::lexical_cast(Source) [with Target = std::__cxx11::basic_string&lt;char>; Source = std::__cxx11::basic_string&lt;char>]\u001b[m\u001b[K' defined but not used [\u001b[01;35m\u001b[K-Wunused-function\u001b[m\u001b[K]\n std::string \u001b[01;35m\u001b[Klexical_cast&lt;std::string, std::string>\u001b[m\u001b[K(std::string arg) {\n             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\nlibtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c viterbi.cpp -o viterbi.o >/dev/null 2>&amp;1\n/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o tagger.lo tagger.cpp\nlibtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c tagger.cpp  -fPIC -DPIC -o .libs/tagger.o\nlibtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c tagger.cpp -o tagger.o >/dev/null 2>&amp;1\n/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o utils.lo utils.cpp\nlibtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c utils.cpp  -fPIC -DPIC -o .libs/utils.o\nlibtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c utils.cpp -o utils.o >/dev/null 2>&amp;1\n/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o eval.lo eval.cpp\nlibtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c eval.cpp  -fPIC -DPIC -o .libs/eval.o\nlibtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c eval.cpp -o eval.o >/dev/null 2>&amp;1\n/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o iconv_utils.lo iconv_utils.cpp\nlibtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c iconv_utils.cpp  -fPIC -DPIC -o .libs/iconv_utils.o\nlibtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c iconv_utils.cpp -o iconv_utils.o >/dev/null 2>&amp;1\n/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o dictionary_rewriter.lo dictionary_rewriter.cpp\nlibtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_rewriter.cpp  -fPIC -DPIC -o .libs/dictionary_rewriter.o\nlibtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_rewriter.cpp -o dictionary_rewriter.o >/dev/null 2>&amp;1\n/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o dictionary_generator.lo dictionary_generator.cpp\nlibtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_generator.cpp  -fPIC -DPIC -o .libs/dictionary_generator.o\nlibtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_generator.cpp -o dictionary_generator.o >/dev/null 2>&amp;1\n/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o dictionary_compiler.lo dictionary_compiler.cpp\nlibtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_compiler.cpp  -fPIC -DPIC -o .libs/dictionary_compiler.o\nlibtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_compiler.cpp -o dictionary_compiler.o >/dev/null 2>&amp;1\n/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o context_id.lo context_id.cpp\nlibtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c context_id.cpp  -fPIC -DPIC -o .libs/context_id.o\nlibtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c context_id.cpp -o context_id.o >/dev/null 2>&amp;1\n/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o connector.lo connector.cpp\nlibtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c connector.cpp  -fPIC -DPIC -o .libs/connector.o\nlibtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c connector.cpp -o connector.o >/dev/null 2>&amp;1\n/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o nbest_generator.lo nbest_generator.cpp\nlibtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c nbest_generator.cpp  -fPIC -DPIC -o .libs/nbest_generator.o\nlibtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c nbest_generator.cpp -o nbest_generator.o >/dev/null 2>&amp;1\n/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o writer.lo writer.cpp\nlibtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c writer.cpp  -fPIC -DPIC -o .libs/writer.o\nlibtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c writer.cpp -o writer.o >/dev/null 2>&amp;1\n/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o string_buffer.lo string_buffer.cpp\nlibtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c string_buffer.cpp  -fPIC -DPIC -o .libs/string_buffer.o\nlibtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c string_buffer.cpp -o string_buffer.o >/dev/null 2>&amp;1\n/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o param.lo param.cpp\nlibtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c param.cpp  -fPIC -DPIC -o .libs/param.o\nlibtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c param.cpp -o param.o >/dev/null 2>&amp;1\n/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o tokenizer.lo tokenizer.cpp\nlibtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c tokenizer.cpp  -fPIC -DPIC -o .libs/tokenizer.o\nlibtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c tokenizer.cpp -o tokenizer.o >/dev/null 2>&amp;1\n/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o char_property.lo char_property.cpp\nlibtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c char_property.cpp  -fPIC -DPIC -o .libs/char_property.o\nlibtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c char_property.cpp -o char_property.o >/dev/null 2>&amp;1\n/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o dictionary.lo dictionary.cpp\nlibtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary.cpp  -fPIC -DPIC -o .libs/dictionary.o\nlibtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary.cpp -o dictionary.o >/dev/null 2>&amp;1\n/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o feature_index.lo feature_index.cpp\nlibtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c feature_index.cpp  -fPIC -DPIC -o .libs/feature_index.o\nlibtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c feature_index.cpp -o feature_index.o >/dev/null 2>&amp;1\n/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o lbfgs.lo lbfgs.cpp\nlibtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c lbfgs.cpp  -fPIC -DPIC -o .libs/lbfgs.o\nlibtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c lbfgs.cpp -o lbfgs.o >/dev/null 2>&amp;1\n/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o learner_tagger.lo learner_tagger.cpp\nlibtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c learner_tagger.cpp  -fPIC -DPIC -o .libs/learner_tagger.o\n\u001b[01m\u001b[Klearner_tagger.cpp:25:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K'\u001b[01m\u001b[Kchar* MeCab::{anonymous}::mystrdup(const string&amp;)\u001b[m\u001b[K' defined but not used [\u001b[01;35m\u001b[K-Wunused-function\u001b[m\u001b[K]\n char *\u001b[01;35m\u001b[Kmystrdup\u001b[m\u001b[K(const std::string &amp;str) {\n       \u001b[01;35m\u001b[K^~~~~~~~\u001b[m\u001b[K\nlibtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c learner_tagger.cpp -o learner_tagger.o >/dev/null 2>&amp;1\n/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o learner.lo learner.cpp\nlibtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c learner.cpp  -fPIC -DPIC -o .libs/learner.o\nlibtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c learner.cpp -o learner.o >/dev/null 2>&amp;1\n/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o libmecab.lo libmecab.cpp\nlibtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c libmecab.cpp  -fPIC -DPIC -o .libs/libmecab.o\nlibtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c libmecab.cpp -o libmecab.o >/dev/null 2>&amp;1\n/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall  -no-undefined -version-info 2:0:0  -o libmecab.la -rpath /usr/local/lib viterbi.lo tagger.lo utils.lo eval.lo iconv_utils.lo dictionary_rewriter.lo dictionary_generator.lo dictionary_compiler.lo context_id.lo connector.lo nbest_generator.lo writer.lo string_buffer.lo param.lo tokenizer.lo char_property.lo dictionary.lo feature_index.lo lbfgs.lo learner_tagger.lo learner.lo libmecab.lo  -lpthread -lpthread  -lstdc++ \nlibtool: link: g++  -fPIC -DPIC -shared -nostdlib /usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu/crti.o /usr/lib/gcc/x86_64-linux-gnu/7/crtbeginS.o  .libs/viterbi.o .libs/tagger.o .libs/utils.o .libs/eval.o .libs/iconv_utils.o .libs/dictionary_rewriter.o .libs/dictionary_generator.o .libs/dictionary_compiler.o .libs/context_id.o .libs/connector.o .libs/nbest_generator.o .libs/writer.o .libs/string_buffer.o .libs/param.o .libs/tokenizer.o .libs/char_property.o .libs/dictionary.o .libs/feature_index.o .libs/lbfgs.o .libs/learner_tagger.o .libs/learner.o .libs/libmecab.o   -lpthread -L/usr/lib/gcc/x86_64-linux-gnu/7 -L/usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu -L/usr/lib/gcc/x86_64-linux-gnu/7/../../../../lib -L/lib/x86_64-linux-gnu -L/lib/../lib -L/usr/lib/x86_64-linux-gnu -L/usr/lib/../lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/gcc/x86_64-linux-gnu/7/../../.. -lstdc++ -lm -lc -lgcc_s /usr/lib/gcc/x86_64-linux-gnu/7/crtendS.o /usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu/crtn.o  -O3   -Wl,-soname -Wl,libmecab.so.2 -o .libs/libmecab.so.2.0.0\nlibtool: link: (cd \".libs\" &amp;&amp; rm -f \"libmecab.so.2\" &amp;&amp; ln -s \"libmecab.so.2.0.0\" \"libmecab.so.2\")\nlibtool: link: (cd \".libs\" &amp;&amp; rm -f \"libmecab.so\" &amp;&amp; ln -s \"libmecab.so.2.0.0\" \"libmecab.so\")\nlibtool: link: ar cru .libs/libmecab.a  viterbi.o tagger.o utils.o eval.o iconv_utils.o dictionary_rewriter.o dictionary_generator.o dictionary_compiler.o context_id.o connector.o nbest_generator.o writer.o string_buffer.o param.o tokenizer.o char_property.o dictionary.o feature_index.o lbfgs.o learner_tagger.o learner.o libmecab.o\nar: `u' modifier ignored since `D' is the default (see `U')\nlibtool: link: ranlib .libs/libmecab.a\nlibtool: link: ( cd \".libs\" &amp;&amp; rm -f \"libmecab.la\" &amp;&amp; ln -s \"../libmecab.la\" \"libmecab.la\" )\ng++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab.o mecab.cpp\n/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab mecab.o libmecab.la -lpthread -lpthread  -lstdc++ \nlibtool: link: g++ -O3 -Wall -o .libs/mecab mecab.o  ./.libs/libmecab.so -lpthread -lstdc++\ng++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-dict-index.o mecab-dict-index.cpp\n/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-dict-index mecab-dict-index.o libmecab.la -lpthread -lpthread  -lstdc++ \nlibtool: link: g++ -O3 -Wall -o .libs/mecab-dict-index mecab-dict-index.o  ./.libs/libmecab.so -lpthread -lstdc++\ng++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-dict-gen.o mecab-dict-gen.cpp\n/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-dict-gen mecab-dict-gen.o libmecab.la -lpthread -lpthread  -lstdc++ \nlibtool: link: g++ -O3 -Wall -o .libs/mecab-dict-gen mecab-dict-gen.o  ./.libs/libmecab.so -lpthread -lstdc++\ng++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-cost-train.o mecab-cost-train.cpp\n/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-cost-train mecab-cost-train.o libmecab.la -lpthread -lpthread  -lstdc++ \nlibtool: link: g++ -O3 -Wall -o .libs/mecab-cost-train mecab-cost-train.o  ./.libs/libmecab.so -lpthread -lstdc++\ng++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-system-eval.o mecab-system-eval.cpp\n/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-system-eval mecab-system-eval.o libmecab.la -lpthread -lpthread  -lstdc++ \nlibtool: link: g++ -O3 -Wall -o .libs/mecab-system-eval mecab-system-eval.o  ./.libs/libmecab.so -lpthread -lstdc++\ng++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-test-gen.o mecab-test-gen.cpp\n/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-test-gen mecab-test-gen.o libmecab.la -lpthread -lpthread  -lstdc++ \nlibtool: link: g++ -O3 -Wall -o .libs/mecab-test-gen mecab-test-gen.o  ./.libs/libmecab.so -lpthread -lstdc++\nmake[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\nMaking all in man\nmake[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\nmake[2]: Nothing to be done for 'all'.\nmake[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\nMaking all in doc\nmake[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\nmake[2]: Nothing to be done for 'all'.\nmake[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\nMaking all in tests\nmake[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\nmake[2]: Nothing to be done for 'all'.\nmake[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\nmake[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\nmake[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\nmake[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\nMaking check in src\nmake[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\nmake[1]: Nothing to be done for 'check'.\nmake[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\nMaking check in man\nmake[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\nmake[1]: Nothing to be done for 'check'.\nmake[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\nMaking check in doc\nmake[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\nmake[1]: Nothing to be done for 'check'.\nmake[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\nMaking check in tests\nmake[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\nmake  check-TESTS\nmake[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n./pos-id.def is not found. minimum setting is used\nreading ./unk.def ... 2\nemitting double-array: 100% |###########################################| \n./model.def is not found. skipped.\n./pos-id.def is not found. minimum setting is used\nreading ./dic.csv ... 177\nemitting double-array: 100% |###########################################| \nreading ./matrix.def ... 178x178\nemitting matrix      : 100% |###########################################| \n\ndone!\n./pos-id.def is not found. minimum setting is used\nreading ./unk.def ... 2\nemitting double-array: 100% |###########################################| \n./model.def is not found. skipped.\n./pos-id.def is not found. minimum setting is used\nreading ./dic.csv ... 83\nemitting double-array: 100% |###########################################| \nreading ./matrix.def ... 84x84\nemitting matrix      : 100% |###########################################| \n\ndone!\n./pos-id.def is not found. minimum setting is used\nreading ./unk.def ... 2\nemitting double-array: 100% |###########################################| \n./model.def is not found. skipped.\n./pos-id.def is not found. minimum setting is used\nreading ./dic.csv ... 450\nemitting double-array: 100% |###########################################| \nreading ./matrix.def ... 1x1\n\ndone!\n./pos-id.def is not found. minimum setting is used\nreading ./unk.def ... 2\nemitting double-array: 100% |###########################################| \n./model.def is not found. skipped.\n./pos-id.def is not found. minimum setting is used\nreading ./dic.csv ... 162\nemitting double-array: 100% |###########################################| \nreading ./matrix.def ... 3x3\nemitting matrix      : 100% |###########################################| \n\ndone!\n./pos-id.def is not found. minimum setting is used\nreading ./unk.def ... 2\nemitting double-array: 100% |###########################################| \n./model.def is not found. skipped.\n./pos-id.def is not found. minimum setting is used\nreading ./dic.csv ... 4\nemitting double-array: 100% |###########################################| \nreading ./matrix.def ... 1x1\n\ndone!\n./pos-id.def is not found. minimum setting is used\nreading ./unk.def ... 11\nemitting double-array: 100% |###########################################| \n./model.def is not found. skipped.\n./pos-id.def is not found. minimum setting is used\nreading ./dic.csv ... 1\nreading ./matrix.def ... 1x1\n\ndone!\n./pos-id.def is not found. minimum setting is used\nreading ./unk.def ... 2\nemitting double-array: 100% |###########################################| \n./model.def is not found. skipped.\n./pos-id.def is not found. minimum setting is used\nreading ./dic.csv ... 1\nreading ./matrix.def ... 1x1\n\ndone!\nPASS: run-dics.sh\nPASS: run-eval.sh\nseed/pos-id.def is not found. minimum setting is used\nreading seed/unk.def ... 40\nemitting double-array: 100% |###########################################| \nseed/model.def is not found. skipped.\nseed/pos-id.def is not found. minimum setting is used\nreading seed/dic.csv ... 4335\nemitting double-array: 100% |###########################################| \nreading seed/matrix.def ... 1x1\n\ndone!\nreading corpus ...\nNumber of sentences: 34\nNumber of features:  64108\neta:                 0.00005\nfreq:                1\neval-size:           6\nunk-eval-size:       4\nthreads:             1\ncharset:             EUC-JP\nC(sigma^2):          1.00000\n\niter=0 err=1.00000 F=0.35771 target=2406.28355 diff=1.00000\niter=1 err=0.97059 F=0.65652 target=1484.25231 diff=0.38318\niter=2 err=0.91176 F=0.79331 target=863.32765 diff=0.41834\niter=3 err=0.85294 F=0.89213 target=596.72480 diff=0.30881\niter=4 err=0.61765 F=0.95467 target=336.30744 diff=0.43641\niter=5 err=0.50000 F=0.96702 target=246.53039 diff=0.26695\niter=6 err=0.35294 F=0.95472 target=188.93963 diff=0.23361\niter=7 err=0.20588 F=0.99106 target=168.62665 diff=0.10751\niter=8 err=0.05882 F=0.99777 target=158.64865 diff=0.05917\niter=9 err=0.08824 F=0.99665 target=154.14530 diff=0.02839\niter=10 err=0.08824 F=0.99665 target=151.94257 diff=0.01429\niter=11 err=0.02941 F=0.99888 target=147.20825 diff=0.03116\niter=12 err=0.00000 F=1.00000 target=147.34956 diff=0.00096\niter=13 err=0.02941 F=0.99888 target=146.32592 diff=0.00695\niter=14 err=0.00000 F=1.00000 target=145.77299 diff=0.00378\niter=15 err=0.02941 F=0.99888 target=145.24641 diff=0.00361\niter=16 err=0.00000 F=1.00000 target=144.96490 diff=0.00194\niter=17 err=0.02941 F=0.99888 target=144.90246 diff=0.00043\niter=18 err=0.00000 F=1.00000 target=144.75959 diff=0.00099\niter=19 err=0.00000 F=1.00000 target=144.71727 diff=0.00029\niter=20 err=0.00000 F=1.00000 target=144.66337 diff=0.00037\niter=21 err=0.00000 F=1.00000 target=144.61349 diff=0.00034\niter=22 err=0.00000 F=1.00000 target=144.62987 diff=0.00011\niter=23 err=0.00000 F=1.00000 target=144.60060 diff=0.00020\niter=24 err=0.00000 F=1.00000 target=144.59125 diff=0.00006\niter=25 err=0.00000 F=1.00000 target=144.58619 diff=0.00004\niter=26 err=0.00000 F=1.00000 target=144.58219 diff=0.00003\niter=27 err=0.00000 F=1.00000 target=144.58059 diff=0.00001\n\nDone! writing model file ... \nmodel-ipadic.c1.0.f1.model is not a binary model. reopen it as text mode...\nreading seed/unk.def ... 40\nreading seed/dic.csv ... 4335\nemitting model-ipadic.c1.0.f1.dic/left-id.def/ model-ipadic.c1.0.f1.dic/right-id.def\nemitting model-ipadic.c1.0.f1.dic/unk.def ... 40\nemitting model-ipadic.c1.0.f1.dic/dic.csv ... 4335\nemitting matrix      : 100% |###########################################| \ncopying seed/char.def to model-ipadic.c1.0.f1.dic/char.def\ncopying seed/rewrite.def to model-ipadic.c1.0.f1.dic/rewrite.def\ncopying seed/dicrc to model-ipadic.c1.0.f1.dic/dicrc\ncopying seed/feature.def to model-ipadic.c1.0.f1.dic/feature.def\ncopying model-ipadic.c1.0.f1.model to model-ipadic.c1.0.f1.dic/model.def\n\ndone!\nmodel-ipadic.c1.0.f1.dic/pos-id.def is not found. minimum setting is used\nreading model-ipadic.c1.0.f1.dic/unk.def ... 40\nemitting double-array: 100% |###########################################| \nmodel-ipadic.c1.0.f1.dic/pos-id.def is not found. minimum setting is used\nreading model-ipadic.c1.0.f1.dic/dic.csv ... 4335\nemitting double-array: 100% |###########################################| \nreading model-ipadic.c1.0.f1.dic/matrix.def ... 346x346\nemitting matrix      : 100% |###########################################| \n\ndone!\n              precision          recall         F\nLEVEL 0:    12.8959(57/442) 11.8998(57/479) 12.3779\nLEVEL 1:    12.2172(54/442) 11.2735(54/479) 11.7264\nLEVEL 2:    11.7647(52/442) 10.8559(52/479) 11.2921\nLEVEL 4:    11.7647(52/442) 10.8559(52/479) 11.2921\nPASS: run-cost-train.sh\n==================\nAll 3 tests passed\n==================\nmake[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\nmake[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\nmake[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\nmake[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\nMaking install in src\nmake[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\nmake[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\ntest -z \"/usr/local/lib\" || /bin/mkdir -p \"/usr/local/lib\"\n /bin/bash ../libtool   --mode=install /usr/bin/install -c   libmecab.la '/usr/local/lib'\nlibtool: install: /usr/bin/install -c .libs/libmecab.so.2.0.0 /usr/local/lib/libmecab.so.2.0.0\nlibtool: install: (cd /usr/local/lib &amp;&amp; { ln -s -f libmecab.so.2.0.0 libmecab.so.2 || { rm -f libmecab.so.2 &amp;&amp; ln -s libmecab.so.2.0.0 libmecab.so.2; }; })\nlibtool: install: (cd /usr/local/lib &amp;&amp; { ln -s -f libmecab.so.2.0.0 libmecab.so || { rm -f libmecab.so &amp;&amp; ln -s libmecab.so.2.0.0 libmecab.so; }; })\nlibtool: install: /usr/bin/install -c .libs/libmecab.lai /usr/local/lib/libmecab.la\nlibtool: install: /usr/bin/install -c .libs/libmecab.a /usr/local/lib/libmecab.a\nlibtool: install: chmod 644 /usr/local/lib/libmecab.a\nlibtool: install: ranlib /usr/local/lib/libmecab.a\nlibtool: finish: PATH=\"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin:/sbin\" ldconfig -n /usr/local/lib\n----------------------------------------------------------------------\nLibraries have been installed in:\n   /usr/local/lib\n\nIf you ever happen to want to link against installed libraries\nin a given directory, LIBDIR, you must either use libtool, and\nspecify the full pathname of the library, or use the `-LLIBDIR'\nflag during linking and do at least one of the following:\n   - add LIBDIR to the `LD_LIBRARY_PATH' environment variable\n     during execution\n   - add LIBDIR to the `LD_RUN_PATH' environment variable\n     during linking\n   - use the `-Wl,-rpath -Wl,LIBDIR' linker flag\n   - have your system administrator add LIBDIR to `/etc/ld.so.conf'\n\nSee any operating system documentation about shared libraries for\nmore information, such as the ld(1) and ld.so(8) manual pages.\n----------------------------------------------------------------------\ntest -z \"/usr/local/bin\" || /bin/mkdir -p \"/usr/local/bin\"\n  /bin/bash ../libtool   --mode=install /usr/bin/install -c mecab '/usr/local/bin'\nlibtool: install: /usr/bin/install -c .libs/mecab /usr/local/bin/mecab\ntest -z \"/usr/local/libexec/mecab\" || /bin/mkdir -p \"/usr/local/libexec/mecab\"\n  /bin/bash ../libtool   --mode=install /usr/bin/install -c mecab-dict-index mecab-dict-gen mecab-cost-train mecab-system-eval mecab-test-gen '/usr/local/libexec/mecab'\nlibtool: install: /usr/bin/install -c .libs/mecab-dict-index /usr/local/libexec/mecab/mecab-dict-index\nlibtool: install: /usr/bin/install -c .libs/mecab-dict-gen /usr/local/libexec/mecab/mecab-dict-gen\nlibtool: install: /usr/bin/install -c .libs/mecab-cost-train /usr/local/libexec/mecab/mecab-cost-train\nlibtool: install: /usr/bin/install -c .libs/mecab-system-eval /usr/local/libexec/mecab/mecab-system-eval\nlibtool: install: /usr/bin/install -c .libs/mecab-test-gen /usr/local/libexec/mecab/mecab-test-gen\ntest -z \"/usr/local/include\" || /bin/mkdir -p \"/usr/local/include\"\n /usr/bin/install -c -m 644 mecab.h '/usr/local/include'\nmake[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\nmake[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\nMaking install in man\nmake[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\nmake[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\nmake[2]: Nothing to be done for 'install-exec-am'.\ntest -z \"/usr/local/share/man/man1\" || /bin/mkdir -p \"/usr/local/share/man/man1\"\n /usr/bin/install -c -m 644 mecab.1 '/usr/local/share/man/man1'\nmake[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\nmake[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\nMaking install in doc\nmake[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\nmake[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\nmake[2]: Nothing to be done for 'install-exec-am'.\nmake[2]: Nothing to be done for 'install-data-am'.\nmake[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\nmake[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\nMaking install in tests\nmake[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\nmake[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\nmake[2]: Nothing to be done for 'install-exec-am'.\nmake[2]: Nothing to be done for 'install-data-am'.\nmake[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\nmake[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\nmake[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\nmake[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\ntest -z \"/usr/local/bin\" || /bin/mkdir -p \"/usr/local/bin\"\n /usr/bin/install -c mecab-config '/usr/local/bin'\ntest -z \"/usr/local/etc\" || /bin/mkdir -p \"/usr/local/etc\"\n /usr/bin/install -c -m 644 mecabrc '/usr/local/etc'\nmake[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\nmake[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\nInstall mecab-ko-dic\nInstall mecab-ko-dic\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n100 47.4M  100 47.4M    0     0  7757k      0  0:00:06  0:00:06 --:--:-- 10.1M\nmecab-ko-dic-2.1.1-20180720/\nmecab-ko-dic-2.1.1-20180720/configure\nmecab-ko-dic-2.1.1-20180720/COPYING\nmecab-ko-dic-2.1.1-20180720/autogen.sh\nmecab-ko-dic-2.1.1-20180720/Place-station.csv\nmecab-ko-dic-2.1.1-20180720/NNG.csv\nmecab-ko-dic-2.1.1-20180720/README\nmecab-ko-dic-2.1.1-20180720/EF.csv\nmecab-ko-dic-2.1.1-20180720/MAG.csv\nmecab-ko-dic-2.1.1-20180720/Preanalysis.csv\nmecab-ko-dic-2.1.1-20180720/NNB.csv\nmecab-ko-dic-2.1.1-20180720/Person-actor.csv\nmecab-ko-dic-2.1.1-20180720/VV.csv\nmecab-ko-dic-2.1.1-20180720/Makefile.in\nmecab-ko-dic-2.1.1-20180720/matrix.def\nmecab-ko-dic-2.1.1-20180720/EC.csv\nmecab-ko-dic-2.1.1-20180720/NNBC.csv\nmecab-ko-dic-2.1.1-20180720/clean\nmecab-ko-dic-2.1.1-20180720/ChangeLog\nmecab-ko-dic-2.1.1-20180720/J.csv\nmecab-ko-dic-2.1.1-20180720/.keep\nmecab-ko-dic-2.1.1-20180720/feature.def\nmecab-ko-dic-2.1.1-20180720/Foreign.csv\nmecab-ko-dic-2.1.1-20180720/XPN.csv\nmecab-ko-dic-2.1.1-20180720/EP.csv\nmecab-ko-dic-2.1.1-20180720/NR.csv\nmecab-ko-dic-2.1.1-20180720/left-id.def\nmecab-ko-dic-2.1.1-20180720/Place.csv\nmecab-ko-dic-2.1.1-20180720/Symbol.csv\nmecab-ko-dic-2.1.1-20180720/dicrc\nmecab-ko-dic-2.1.1-20180720/NP.csv\nmecab-ko-dic-2.1.1-20180720/ETM.csv\nmecab-ko-dic-2.1.1-20180720/IC.csv\nmecab-ko-dic-2.1.1-20180720/Place-address.csv\nmecab-ko-dic-2.1.1-20180720/Group.csv\nmecab-ko-dic-2.1.1-20180720/model.def\nmecab-ko-dic-2.1.1-20180720/XSN.csv\nmecab-ko-dic-2.1.1-20180720/INSTALL\nmecab-ko-dic-2.1.1-20180720/rewrite.def\nmecab-ko-dic-2.1.1-20180720/Inflect.csv\nmecab-ko-dic-2.1.1-20180720/configure.ac\nmecab-ko-dic-2.1.1-20180720/NNP.csv\nmecab-ko-dic-2.1.1-20180720/CoinedWord.csv\nmecab-ko-dic-2.1.1-20180720/XSV.csv\nmecab-ko-dic-2.1.1-20180720/pos-id.def\nmecab-ko-dic-2.1.1-20180720/Makefile.am\nmecab-ko-dic-2.1.1-20180720/unk.def\nmecab-ko-dic-2.1.1-20180720/missing\nmecab-ko-dic-2.1.1-20180720/VCP.csv\nmecab-ko-dic-2.1.1-20180720/install-sh\nmecab-ko-dic-2.1.1-20180720/Hanja.csv\nmecab-ko-dic-2.1.1-20180720/MAJ.csv\nmecab-ko-dic-2.1.1-20180720/XSA.csv\nmecab-ko-dic-2.1.1-20180720/Wikipedia.csv\nmecab-ko-dic-2.1.1-20180720/tools/\nmecab-ko-dic-2.1.1-20180720/tools/add-userdic.sh\nmecab-ko-dic-2.1.1-20180720/tools/mecab-bestn.sh\nmecab-ko-dic-2.1.1-20180720/tools/convert_for_using_store.sh\nmecab-ko-dic-2.1.1-20180720/user-dic/\nmecab-ko-dic-2.1.1-20180720/user-dic/nnp.csv\nmecab-ko-dic-2.1.1-20180720/user-dic/place.csv\nmecab-ko-dic-2.1.1-20180720/user-dic/person.csv\nmecab-ko-dic-2.1.1-20180720/user-dic/README.md\nmecab-ko-dic-2.1.1-20180720/NorthKorea.csv\nmecab-ko-dic-2.1.1-20180720/VX.csv\nmecab-ko-dic-2.1.1-20180720/right-id.def\nmecab-ko-dic-2.1.1-20180720/VA.csv\nmecab-ko-dic-2.1.1-20180720/char.def\nmecab-ko-dic-2.1.1-20180720/NEWS\nmecab-ko-dic-2.1.1-20180720/MM.csv\nmecab-ko-dic-2.1.1-20180720/ETN.csv\nmecab-ko-dic-2.1.1-20180720/AUTHORS\nmecab-ko-dic-2.1.1-20180720/Person.csv\nmecab-ko-dic-2.1.1-20180720/XR.csv\nmecab-ko-dic-2.1.1-20180720/VCN.csv\nLooking in current directory for macros.\nconfigure.ac:2: warning: AM_INIT_AUTOMAKE: two- and three-arguments forms are deprecated.  For more info, see:\nconfigure.ac:2: http://www.gnu.org/software/automake/manual/automake.html#Modernize-AM_005fINIT_005fAUTOMAKE-invocation\nchecking for a BSD-compatible install... /usr/bin/install -c\nchecking whether build environment is sane... yes\n/tmp/mecab-ko-dic-2.1.1-20180720/missing: Unknown `--is-lightweight' option\nTry `/tmp/mecab-ko-dic-2.1.1-20180720/missing --help' for more information\nconfigure: WARNING: 'missing' script is too old or missing\nchecking for a thread-safe mkdir -p... /bin/mkdir -p\nchecking for gawk... no\nchecking for mawk... mawk\nchecking whether make sets $(MAKE)... yes\nchecking whether make supports nested variables... yes\nchecking for mecab-config... /usr/local/bin/mecab-config\nchecking that generated files are newer than configure... done\nconfigure: creating ./config.status\nconfig.status: creating Makefile\n/usr/local/lib\n/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n\n/usr/local/libexec/mecab/mecab-dict-index -d . -o . -f UTF-8 -t UTF-8\nreading ./unk.def ... 13\nemitting double-array: 100% |###########################################| \nreading ./Inflect.csv ... 44820\nreading ./XSN.csv ... 124\nreading ./ETM.csv ... 133\nreading ./Hanja.csv ... 125750\nreading ./Place-address.csv ... 19301\nreading ./VX.csv ... 125\nreading ./Place.csv ... 30303\nreading ./Preanalysis.csv ... 5\nreading ./EC.csv ... 2547\nreading ./NR.csv ... 482\nreading ./MAJ.csv ... 240\nreading ./EF.csv ... 1820\nreading ./NNP.csv ... 2371\nreading ./Symbol.csv ... 16\nreading ./J.csv ... 416\nreading ./XPN.csv ... 83\nreading ./NNB.csv ... 140\nreading ./Place-station.csv ... 1145\nreading ./IC.csv ... 1305\nreading ./MAG.csv ... 14242\nreading ./Person-actor.csv ... 99230\nreading ./XSA.csv ... 19\nreading ./Wikipedia.csv ... 36762\nreading ./VV.csv ... 7331\nreading ./CoinedWord.csv ... 148\nreading ./Person.csv ... 196459\nreading ./Foreign.csv ... 11690\nreading ./NorthKorea.csv ... 3\nreading ./NNG.csv ... 208524\nreading ./XR.csv ... 3637\nreading ./MM.csv ... 453\nreading ./XSV.csv ... 23\nreading ./VCN.csv ... 7\nreading ./VA.csv ... 2360\nreading ./VCP.csv ... 9\nreading ./ETN.csv ... 14\nreading ./EP.csv ... 51\nreading ./NP.csv ... 342\nreading ./NNBC.csv ... 677\nreading ./Group.csv ... 3176\nemitting double-array: 100% |###########################################| \nreading ./matrix.def ... 3822x2693\nemitting matrix      : 100% |###########################################| \n\ndone!\necho To enable dictionary, rewrite /usr/local/etc/mecabrc as \\\"dicdir = /usr/local/lib/mecab/dic/mecab-ko-dic\\\"\nTo enable dictionary, rewrite /usr/local/etc/mecabrc as \"dicdir = /usr/local/lib/mecab/dic/mecab-ko-dic\"\nmake[1]: Entering directory '/tmp/mecab-ko-dic-2.1.1-20180720'\nmake[1]: Nothing to be done for 'install-exec-am'.\n /bin/mkdir -p '/usr/local/lib/mecab/dic/mecab-ko-dic'\n /usr/bin/install -c -m 644 model.bin matrix.bin char.bin sys.dic unk.dic left-id.def right-id.def rewrite.def pos-id.def dicrc '/usr/local/lib/mecab/dic/mecab-ko-dic'\nmake[1]: Leaving directory '/tmp/mecab-ko-dic-2.1.1-20180720'\nInstall mecab-python\n/tmp /tmp/mecab-ko-dic-2.1.1-20180720\nCloning into 'mecab-python-0.996'...\nUnpacking objects: 100% (17/17), done.\n/tmp/mecab-ko-dic-2.1.1-20180720\nProcessing /tmp/mecab-python-0.996\n\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\nBuilding wheels for collected packages: mecab-python\n  Building wheel for mecab-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for mecab-python: filename=mecab_python-0.996_ko_0.9.2-cp37-cp37m-linux_x86_64.whl size=141818 sha256=f8224281c456f08d8c3637aca638579c5ffafda3456d907e82f6ed0598c31843\n  Stored in directory: /root/.cache/pip/wheels/40/7b/9f/2922869bef86c3354ae7034f7a3647c573ee1997c2dad0290a\n\u001b[33m  WARNING: Built wheel for mecab-python is invalid: Metadata 1.2 mandates PEP 440 version, but '0.996-ko-0.9.2' is not\u001b[0m\nFailed to build mecab-python\nInstalling collected packages: mecab-python\n    Running setup.py install for mecab-python ... \u001b[?25l\u001b[?25hdone\n\u001b[33m  DEPRECATION: mecab-python was installed using the legacy 'setup.py install' method, because a wheel could not be built for it. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368.\u001b[0m\nSuccessfully installed mecab-python-0.996-ko-0.9.2\nDone.</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\">#주요 라이브러리 버전 확인</span>\n\n<span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf <span class=\"token comment\">#NLP 모델 생성</span>\n<span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np <span class=\"token comment\">#데이터 배열 처리</span>\n<span class=\"token keyword\">import</span> matplotlib <span class=\"token keyword\">as</span> plt <span class=\"token comment\">#시각화</span>\n<span class=\"token keyword\">import</span> konlpy\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>__version__<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>__version__<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>plt<span class=\"token punctuation\">.</span>__version__<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>konlpy<span class=\"token punctuation\">.</span>__version__<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">2.8.0\n1.21.5\n3.2.2\n0.6.0</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">!pip install sentencepiece</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Collecting sentencepiece\n  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n\u001b[K     |████████████████████████████████| 1.2 MB 4.3 MB/s \n\u001b[?25hInstalling collected packages: sentencepiece\nSuccessfully installed sentencepiece-0.1.96</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\">#이 외 라이브러리</span>\n\n<span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt <span class=\"token comment\">#시각화 라이브러리 pyplot</span>\n<span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd <span class=\"token comment\">#데이터 배열</span>\n<span class=\"token keyword\">import</span> sentencepiece <span class=\"token keyword\">as</span> spm <span class=\"token comment\">#우리가 사용할 Tokenizer</span>\n\n<span class=\"token keyword\">from</span> google<span class=\"token punctuation\">.</span>colab <span class=\"token keyword\">import</span> files \n<span class=\"token keyword\">import</span> io <span class=\"token comment\"># kolab 데이터 경로 라이브러리</span>\n</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># LSTM 라이브러리</span>\n\n<span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>models <span class=\"token keyword\">import</span> Sequential\n<span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers <span class=\"token keyword\">import</span> Embedding<span class=\"token punctuation\">,</span> Dense<span class=\"token punctuation\">,</span> LSTM</code></pre></div>\n<h1 id=\"2-game-1\" style=\"position:relative;\"><a href=\"#2-game-1\" aria-label=\"2 game 1 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. GAME</h1>\n<h2 id=\"2-1-데이터-읽어오기\" style=\"position:relative;\"><a href=\"#2-1-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%9D%BD%EC%96%B4%EC%98%A4%EA%B8%B0\" aria-label=\"2 1 데이터 읽어오기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2-1. 데이터 읽어오기</h2>\n<p>깃허브에서는 NLP 학습을 위해 일반 이용자들이 다양한 말뭉치를 제공해주고 있다.</p>\n<p>그 중 <a href=\"https://github.com/e9t/nsmc/\">여기</a> 에서는 네이버의 영화 리뷰에 대한 말뭉치를 제시한다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> google<span class=\"token punctuation\">.</span>colab <span class=\"token keyword\">import</span> drive\ndrive<span class=\"token punctuation\">.</span>mount<span class=\"token punctuation\">(</span><span class=\"token string\">'/content/drive'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Mounted at /content/drive</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> google<span class=\"token punctuation\">.</span>colab <span class=\"token keyword\">import</span> files\n\nuploaded <span class=\"token operator\">=</span> files<span class=\"token punctuation\">.</span>upload<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><input type=\"file\" id=\"files-c238279a-3be2-4583-a158-523e8391c9ce\" name=\"files[]\" multiple disabled\nstyle=\"border:none\" />\n<output id=\"result-c238279a-3be2-4583-a158-523e8391c9ce\">\nUpload widget is only available when the cell has been executed in the\ncurrent browser session. Please rerun this cell to enable.\n</output></p>\n <script src=\"/nbextensions/google.colab/files.js\"></script> \n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Saving ratings_train.txt to ratings_train.txt\nSaving ratings_test.txt to ratings_test.txt</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">train_data<span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>read_table<span class=\"token punctuation\">(</span>io<span class=\"token punctuation\">.</span>StringIO<span class=\"token punctuation\">(</span>uploaded<span class=\"token punctuation\">[</span><span class=\"token string\">'ratings_train.txt'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>decode<span class=\"token punctuation\">(</span><span class=\"token string\">'utf-8'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\ntrain_data<span class=\"token punctuation\">.</span>head<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n  <div id=\"df-f70194ae-0c56-4494-bfd2-e4f316891ca1\">\n    <div class=\"colab-df-container\">\n      <div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}</code></pre></div>\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>document</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9976970</td>\n      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3819312</td>\n      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10265843</td>\n      <td>너무재밓었다그래서보는것을추천한다</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9045019</td>\n      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6483659</td>\n      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f70194ae-0c56-4494-bfd2-e4f316891ca1')\"\n              title=\"Convert this dataframe to an interactive table.\"\n              style=\"display:none;\">\n<p>&#x3C;svg xmlns=”<a href=\"http://www.w3.org/2000/svg\">http://www.w3.org/2000/svg</a>” height=“24px”viewBox=“0 0 24 24”\nwidth=“24px”>\n<path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n<path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n</svg>\n</button></p>\n  <style>\n    .colab-df-container {\n      display:flex;\n      flex-wrap:wrap;\n      gap: 12px;\n    }\n\n    .colab-df-convert {\n      background-color: #E8F0FE;\n      border: none;\n      border-radius: 50%;\n      cursor: pointer;\n      display: none;\n      fill: #1967D2;\n      height: 32px;\n      padding: 0 0 0 0;\n      width: 32px;\n    }\n\n    .colab-df-convert:hover {\n      background-color: #E2EBFA;\n      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n      fill: #174EA6;\n    }\n\n    [theme=dark] .colab-df-convert {\n      background-color: #3B4455;\n      fill: #D2E3FC;\n    }\n\n    [theme=dark] .colab-df-convert:hover {\n      background-color: #434B5C;\n      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n      fill: #FFFFFF;\n    }\n  </style>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">  &lt;script>\n    const buttonEl =\n      document.querySelector('#df-f70194ae-0c56-4494-bfd2-e4f316891ca1 button.colab-df-convert');\n    buttonEl.style.display =\n      google.colab.kernel.accessAllowed ? 'block' : 'none';\n\n    async function convertToInteractive(key) {\n      const element = document.querySelector('#df-f70194ae-0c56-4494-bfd2-e4f316891ca1');\n      const dataTable =\n        await google.colab.kernel.invokeFunction('convertToInteractive',\n                                                 [key], {});\n      if (!dataTable) return;\n\n      const docLinkHtml = 'Like what you see? Visit the ' +\n        '&lt;a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook&lt;/a>'\n        + ' to learn more about interactive tables.';\n      element.innerHTML = '';\n      dataTable['output_type'] = 'display_data';\n      await google.colab.output.renderOutput(dataTable, element);\n      const docLink = document.createElement('div');\n      docLink.innerHTML = docLinkHtml;\n      element.appendChild(docLink);\n    }\n  &lt;/script>\n&lt;/div></code></pre></div>\n  </div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">test_data <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>read_table<span class=\"token punctuation\">(</span>io<span class=\"token punctuation\">.</span>StringIO<span class=\"token punctuation\">(</span>uploaded<span class=\"token punctuation\">[</span><span class=\"token string\">'ratings_test.txt'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>decode<span class=\"token punctuation\">(</span><span class=\"token string\">'utf-8'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\ntest_data<span class=\"token punctuation\">.</span>head<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n  <div id=\"df-a9a4f778-8733-4490-b8d0-1d8b358002c8\">\n    <div class=\"colab-df-container\">\n      <div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}</code></pre></div>\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>document</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6270596</td>\n      <td>굳 ㅋ</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9274899</td>\n      <td>GDNTOPCLASSINTHECLUB</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8544678</td>\n      <td>뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6825595</td>\n      <td>지루하지는 않은데 완전 막장임... 돈주고 보기에는....</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6723715</td>\n      <td>3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a9a4f778-8733-4490-b8d0-1d8b358002c8')\"\n              title=\"Convert this dataframe to an interactive table.\"\n              style=\"display:none;\">\n<p>&#x3C;svg xmlns=”<a href=\"http://www.w3.org/2000/svg\">http://www.w3.org/2000/svg</a>” height=“24px”viewBox=“0 0 24 24”\nwidth=“24px”>\n<path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n<path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n</svg>\n</button></p>\n  <style>\n    .colab-df-container {\n      display:flex;\n      flex-wrap:wrap;\n      gap: 12px;\n    }\n\n    .colab-df-convert {\n      background-color: #E8F0FE;\n      border: none;\n      border-radius: 50%;\n      cursor: pointer;\n      display: none;\n      fill: #1967D2;\n      height: 32px;\n      padding: 0 0 0 0;\n      width: 32px;\n    }\n\n    .colab-df-convert:hover {\n      background-color: #E2EBFA;\n      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n      fill: #174EA6;\n    }\n\n    [theme=dark] .colab-df-convert {\n      background-color: #3B4455;\n      fill: #D2E3FC;\n    }\n\n    [theme=dark] .colab-df-convert:hover {\n      background-color: #434B5C;\n      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n      fill: #FFFFFF;\n    }\n  </style>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">  &lt;script>\n    const buttonEl =\n      document.querySelector('#df-a9a4f778-8733-4490-b8d0-1d8b358002c8 button.colab-df-convert');\n    buttonEl.style.display =\n      google.colab.kernel.accessAllowed ? 'block' : 'none';\n\n    async function convertToInteractive(key) {\n      const element = document.querySelector('#df-a9a4f778-8733-4490-b8d0-1d8b358002c8');\n      const dataTable =\n        await google.colab.kernel.invokeFunction('convertToInteractive',\n                                                 [key], {});\n      if (!dataTable) return;\n\n      const docLinkHtml = 'Like what you see? Visit the ' +\n        '&lt;a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook&lt;/a>'\n        + ' to learn more about interactive tables.';\n      element.innerHTML = '';\n      dataTable['output_type'] = 'display_data';\n      await google.colab.output.renderOutput(dataTable, element);\n      const docLink = document.createElement('div');\n      docLink.innerHTML = docLinkHtml;\n      element.appendChild(docLink);\n    }\n  &lt;/script>\n&lt;/div></code></pre></div>\n  </div>\n<h2 id=\"2-2데이터-전처리\" style=\"position:relative;\"><a href=\"#2-2%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%84%EC%B2%98%EB%A6%AC\" aria-label=\"2 2데이터 전처리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2-2.데이터 전처리</h2>\n<h3 id=\"2-2-1-tokenizer-생성\" style=\"position:relative;\"><a href=\"#2-2-1-tokenizer-%EC%83%9D%EC%84%B1\" aria-label=\"2 2 1 tokenizer 생성 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2-2-1. Tokenizer 생성</h3>\n<p>우리가 단어사전을 만들기 위해 사용할<br>\n데이터는 따로 있다. 더 크고 방대한<br>\n한국어 자료를 사용해 더 명료하고 명확한<br>\n한국어 단어 사전을 만들 것이다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">corpus_path <span class=\"token operator\">=</span> <span class=\"token string\">'/content/drive/MyDrive/Colab_Notebooks/Aiffel/data/korean-english-park.train.ko'</span>\n\n<span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>corpus_path<span class=\"token punctuation\">,</span> <span class=\"token string\">\"r\"</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> f<span class=\"token punctuation\">:</span>\n    raw <span class=\"token operator\">=</span> f<span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>splitlines<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Data Size:\"</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>raw<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Example:\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">for</span> sen <span class=\"token keyword\">in</span> raw<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">:</span><span class=\"token number\">100</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">:</span><span class=\"token number\">20</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span> <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\">>\"</span><span class=\"token punctuation\">,</span> sen<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Data Size: 94123\nExample:\n>> 개인용 컴퓨터 사용의 상당 부분은 \"이것보다 뛰어날 수 있느냐?\"\n>> 북한의 핵무기 계획을 포기하도록 하려는 압력이 거세지고 있는 가운데, 일본과 북한의 외교관들이 외교 관계를 정상화하려는 회담을 재개했다.\n>> \"경호 로보트가 침입자나 화재를 탐지하기 위해서 개인적으로, 그리고 전문적으로 사용되고 있습니다.\"\n>> 수자원부 당국은 논란이 되고 있고, 막대한 비용이 드는 이 사업에 대해 내년에 건설을 시작할 계획이다.\n>> 또한 근력 운동은 활발하게 걷는 것이나 최소한 20분 동안 뛰는 것과 같은 유산소 활동에서 얻는 운동 효과를 심장과 폐에 주지 않기 때문에, 연구학자들은 근력 운동이 심장에 큰 영향을 미치는지 여부에 대해 논쟁을 해왔다.</code></pre></div>\n<p>이전에 이 자료를 탐색 및 분석했기 때문에 EDA 과정은 생략하고 바로 전처리에 들어가도록 하겠다.</p>\n<p>전처리 과정은</p>\n<blockquote>\n<ol>\n<li>중복데이터 삭제</li>\n</ol>\n</blockquote>\n<ol start=\"2\">\n<li><code class=\"language-text\">max_len</code> = 150</li>\n<li><code class=\"language-text\">min_len</code> = 10</li>\n<li><code class=\"language-text\">padding</code> 처리</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">cleaned_corpus <span class=\"token operator\">=</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">set</span><span class=\"token punctuation\">(</span>raw<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 1.중복제거</span>\n\nmax_len <span class=\"token operator\">=</span> <span class=\"token number\">150</span> <span class=\"token comment\"># 2번</span>\nmin_len <span class=\"token operator\">=</span> <span class=\"token number\">10</span> <span class=\"token comment\">#3번</span>\n\n<span class=\"token comment\"># 길이 조건에 맞는 문장 선택</span>\nfiltered_corpus <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>s <span class=\"token keyword\">for</span> s <span class=\"token keyword\">in</span> cleaned_corpus <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span> <span class=\"token operator\">&lt;</span> max_len<span class=\"token punctuation\">)</span> <span class=\"token operator\">&amp;</span> <span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span> <span class=\"token operator\">>=</span> min_len<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\n\n<span class=\"token comment\"># 분포도로 시각화.</span>\nsentence_length <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>max_len<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>np<span class=\"token punctuation\">.</span><span class=\"token builtin\">int</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">for</span> sen <span class=\"token keyword\">in</span> filtered_corpus<span class=\"token punctuation\">:</span>\n    sentence_length<span class=\"token punctuation\">[</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>sen<span class=\"token punctuation\">)</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+=</span> <span class=\"token number\">1</span>\n\nplt<span class=\"token punctuation\">.</span>bar<span class=\"token punctuation\">(</span><span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>max_len<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> sentence_length<span class=\"token punctuation\">,</span> width<span class=\"token operator\">=</span><span class=\"token number\">1.0</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">\"Sentence Length Distribution\"</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  # Remove the CWD from sys.path while we load stuff.</code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 381px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 69.44444444444444%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsSAAALEgHS3X78AAACtElEQVQ4y4WU20sUcRTHj9nFysJL3lr3ShJERH9B0KME4rtbDyWbQ+Cd3VUMiZ4iX3rqISJCg0TM1t3BNUhTMzKM9YpSOG67ju6klTu7O4vub+bEb3bWVl3oB4czc+acD99zfvP7AQCAxWIBRNxnAFAAAHoAOKc9GwGgGAB0AFCuWW6GOjhutVqLBEHoFkXx/fb2tjccDntDodAHv//HJ38gOBHk+TGOW5nieX58bW1tIhgMfgwEApOCIIyKouilNZFIZITn+WcUeKqmpsYcj8c3McN6OsYh88qHcYL/XdFodJUCc2pra8slSVqhQUVRdoms0HLyhdsiFe0sOX2vn3QNL6uxBJGJoigHbZfWiqI4rwJtNlt5LBbza0CZ+p2EjNe7RrG4yYUGuxsv3R9C/o+kKpEVBbVcTK8RRXGRAo9VVVVVSJKkAoksqx+n/b9R1zqIJocHLW0sFjQM4EP3IiZzFBWWEUh3pqOjoySlMAXsdC1gfv0AWpysCj3fOohXHwyjEI4fUnlQ4YnKysqLKSDNpUWXO717CmnLZqcHCxvf4t3u6T2VGYHpCrUc+fkEp7ZIIUbHP6Ngvd2NU9wvNTGRbObwDKurqy+kFO4kiHzt0QiWNLvQ5ExCjGkqi5tdeOPJ+N78tHnuAwJTV6cLi5FVGhxZCiXKWlyyyeEhRrtbNtjdxJDmLU4Pyat/Iz/2qr+RnBy7ktCAC5R31HrzlkmS4hs0yPR8xYJGF5rbWDQ6WK3ddM+iycliacsg3nk5jdxmLP3HXgGGYeA2U1+4JWy8Wwr8XDS39Pl0Db2zhqY+n76hd06/z7+e1/ycsblv5oytZ/ZK+8BsU/fkTP/n70v8+no/aCsbAE7SHadHMRsgj55xACgCgCMAUAoAWQBQpr3TiyHHdDaLXha5AJBPc78NvYC//kz3Mfiv3r4AAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/11ca6f3c58f745096e074987426920f1/2add2/output_25_1.png\"\n        srcset=\"/static/11ca6f3c58f745096e074987426920f1/e9ff0/output_25_1.png 180w,\n/static/11ca6f3c58f745096e074987426920f1/f21e7/output_25_1.png 360w,\n/static/11ca6f3c58f745096e074987426920f1/2add2/output_25_1.png 381w\"\n        sizes=\"(max-width: 381px) 100vw, 381px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>해당 데이터를 SentencePiece 라이브러리를 통해</p>\n<p>Tokenize 시킨다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">temp_file <span class=\"token operator\">=</span> <span class=\"token string\">'/content/drive/MyDrive/Colab_Notebooks/Aiffel/data/korean-english-park.train.ko.temp'</span>\n\nvocab_size <span class=\"token operator\">=</span> <span class=\"token number\">8000</span>\n\nmodel_type <span class=\"token operator\">=</span> <span class=\"token string\">'bpe'</span>\n<span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>temp_file<span class=\"token punctuation\">,</span> <span class=\"token string\">'w'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> f<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">for</span> row <span class=\"token keyword\">in</span> filtered_corpus<span class=\"token punctuation\">:</span>   <span class=\"token comment\"># 이전 스텝에서 정제했던 corpus를 활용합니다.</span>\n        f<span class=\"token punctuation\">.</span>write<span class=\"token punctuation\">(</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>row<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token string\">'\\n'</span><span class=\"token punctuation\">)</span>\n\nspm<span class=\"token punctuation\">.</span>SentencePieceTrainer<span class=\"token punctuation\">.</span>Train<span class=\"token punctuation\">(</span>\n    <span class=\"token string-interpolation\"><span class=\"token string\">f'--input=</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>temp_file<span class=\"token punctuation\">}</span></span><span class=\"token string\"> --model_prefix=korean_spm --vocab_size=</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>vocab_size<span class=\"token punctuation\">}</span></span><span class=\"token string\"> --model_type=</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>model_type<span class=\"token punctuation\">}</span></span><span class=\"token string\">'</span></span>    <span class=\"token comment\">#korean_spm 에 저장</span>\n<span class=\"token punctuation\">)</span>\n<span class=\"token comment\">#위 Train에서  --model_type = 'unigram'이 디폴트 적용되어 있습니다. --model_type = 'bpe' 로 옵션을 주어 변경할 수 있습니다.</span>\n\n\n!ls <span class=\"token operator\">-</span>l korean_spm<span class=\"token operator\">*</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">-rw-r--r-- 1 root root 371954 Mar 23 03:11 korean_spm.model\n-rw-r--r-- 1 root root 117142 Mar 23 03:11 korean_spm.vocab</code></pre></div>\n<p>위 코드를 실행하면 정상적으로 SentencePiece 모델 학습이 완료된다. 이후에는</p>\n<p>korean_spm.model 파일과<br>\nkorean_spm.vocab vocabulary 파일이 root에 생성된다.</p>\n<p>다음은 이렇게 학습한 model 데이터의 활용이다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">s <span class=\"token operator\">=</span> spm<span class=\"token punctuation\">.</span>SentencePieceProcessor<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\ns<span class=\"token punctuation\">.</span>Load<span class=\"token punctuation\">(</span><span class=\"token string\">'korean_spm.model'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># SentencePiece를 활용한 sentence -> encoding</span>\ntokensIDs <span class=\"token operator\">=</span> s<span class=\"token punctuation\">.</span>EncodeAsIds<span class=\"token punctuation\">(</span><span class=\"token string\">'아버지가방에들어가신다.'</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>tokensIDs<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># SentencePiece를 활용한 sentence -> encoded pieces</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">.</span>SampleEncodeAsPieces<span class=\"token punctuation\">(</span><span class=\"token string\">'아버지가방에들어가신다.'</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># SentencePiece를 활용한 encoding -> sentence 복원</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">.</span>DecodeIds<span class=\"token punctuation\">(</span>tokensIDs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">[1243, 11, 302, 7, 3608, 11, 287, 38, 3]\n['▁아버지', '가', '방', '에', '들어', '가', '신', '다', '.']\n아버지가방에들어가신다.</code></pre></div>\n<p><code class=\"language-text\">EncodeAsIds</code> = 글자를 벡터화 리스트로 반환</p>\n<p><code class=\"language-text\">SampleEncodeAsPieces</code> = 글자를 나눈 방법을 리스트로 반환</p>\n<p><code class=\"language-text\">DecodeIds</code> = 벡터화 리스트를 글자로 변환</p>\n<p>해당 SentencePiece 를 영화 리뷰 데이터로 Tokenize 하기 위한 코드는 다음과 같다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># s = spm.SentencePieceProcessor()</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">sp_tokenize</span><span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">,</span> corpus<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\n    tensor <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n\n    <span class=\"token keyword\">for</span> sen <span class=\"token keyword\">in</span> corpus<span class=\"token punctuation\">:</span>\n        tensor<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">.</span>EncodeAsIds<span class=\"token punctuation\">(</span>sen<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 문장이 벡터화된 리스트로 변환되어 tensor 에 입력</span>\n\n    <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"./korean_spm.vocab\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'r'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> f<span class=\"token punctuation\">:</span>\n        vocab <span class=\"token operator\">=</span> f<span class=\"token punctuation\">.</span>readlines<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    word_index <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token punctuation\">}</span>\n    index_word <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token punctuation\">}</span>\n\n    <span class=\"token keyword\">for</span> idx<span class=\"token punctuation\">,</span> line <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>vocab<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        word <span class=\"token operator\">=</span> line<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\n\n        word_index<span class=\"token punctuation\">.</span>update<span class=\"token punctuation\">(</span><span class=\"token punctuation\">{</span>idx<span class=\"token punctuation\">:</span>word<span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span> <span class=\"token comment\">#word_to_index 저장</span>\n        index_word<span class=\"token punctuation\">.</span>update<span class=\"token punctuation\">(</span><span class=\"token punctuation\">{</span>word<span class=\"token punctuation\">:</span>idx<span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span> <span class=\"token comment\">#index_to)word 저장</span>\n\n    tensor <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>preprocessing<span class=\"token punctuation\">.</span>sequence<span class=\"token punctuation\">.</span>pad_sequences<span class=\"token punctuation\">(</span>tensor<span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token string\">'post'</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># tensor 문장 중 가장 긴 문장을 기준으로 패딩</span>\n\n    <span class=\"token keyword\">return</span> tensor<span class=\"token punctuation\">,</span> word_index<span class=\"token punctuation\">,</span> index_word</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"></code></pre></div>\n<h3 id=\"2-2-2-학습-데이터-전처리\" style=\"position:relative;\"><a href=\"#2-2-2-%ED%95%99%EC%8A%B5-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%84%EC%B2%98%EB%A6%AC\" aria-label=\"2 2 2 학습 데이터 전처리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2-2-2. 학습 데이터 전처리</h3>\n<p>이제는 학습시키기 위해 영화리뷰 데이터를 전처리하도록 한다.</p>\n<ol>\n<li>오타 등 필요없는 문자 제거</li>\n<li>중복값 제거</li>\n<li>결측값 제거</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">\n<span class=\"token keyword\">def</span> <span class=\"token function\">preprocessing</span><span class=\"token punctuation\">(</span>train_data<span class=\"token punctuation\">,</span> test_data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    train_data<span class=\"token punctuation\">[</span><span class=\"token string\">'document'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> train_data<span class=\"token punctuation\">[</span><span class=\"token string\">'document'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"\"</span><span class=\"token punctuation\">)</span>\n    test_data<span class=\"token punctuation\">[</span><span class=\"token string\">'document'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> test_data<span class=\"token punctuation\">[</span><span class=\"token string\">'document'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"\"</span><span class=\"token punctuation\">)</span> <span class=\"token comment\">#한글이 아닌 문자를 공백으로 변환</span>\n\n    train_data<span class=\"token punctuation\">[</span><span class=\"token string\">'document'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> train_data<span class=\"token punctuation\">[</span><span class=\"token string\">'document'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">'^ +'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"\"</span><span class=\"token punctuation\">)</span>\n    train_data<span class=\"token punctuation\">[</span><span class=\"token string\">'document'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">''</span><span class=\"token punctuation\">,</span> np<span class=\"token punctuation\">.</span>nan<span class=\"token punctuation\">,</span> inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\n    test_data<span class=\"token punctuation\">[</span><span class=\"token string\">'document'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> test_data<span class=\"token punctuation\">[</span><span class=\"token string\">'document'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">'^ +'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"\"</span><span class=\"token punctuation\">)</span> <span class=\"token comment\">#긴 공백을 공백으로 변경</span>\n    test_data<span class=\"token punctuation\">[</span><span class=\"token string\">'document'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">''</span><span class=\"token punctuation\">,</span> np<span class=\"token punctuation\">.</span>nan<span class=\"token punctuation\">,</span> inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 공백을 NaN 으로 변경</span>\n\n    train_data<span class=\"token punctuation\">.</span>drop_duplicates<span class=\"token punctuation\">(</span>subset<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'document'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span> \n    test_data<span class=\"token punctuation\">.</span>drop_duplicates<span class=\"token punctuation\">(</span>subset<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'document'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span> <span class=\"token comment\">#중복값 제거</span>\n\n    train_data <span class=\"token operator\">=</span> train_data<span class=\"token punctuation\">.</span>dropna<span class=\"token punctuation\">(</span>how <span class=\"token operator\">=</span> <span class=\"token string\">'any'</span><span class=\"token punctuation\">)</span> \n    test_data <span class=\"token operator\">=</span> test_data<span class=\"token punctuation\">.</span>dropna<span class=\"token punctuation\">(</span>how <span class=\"token operator\">=</span> <span class=\"token string\">'any'</span><span class=\"token punctuation\">)</span> <span class=\"token comment\">#결측치 제거</span>\n\n    <span class=\"token keyword\">return</span> train_data<span class=\"token punctuation\">,</span> test_data\n  \ntrain<span class=\"token punctuation\">,</span> test <span class=\"token operator\">=</span> preprocessing<span class=\"token punctuation\">(</span>train_data<span class=\"token punctuation\">,</span> test_data<span class=\"token punctuation\">)</span>\n\ntrain<span class=\"token punctuation\">.</span>head<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n  This is separate from the ipykernel package so we can avoid doing imports until\n/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n  after removing the cwd from sys.path.\n/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n  \n/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: FutureWarning: The default value of regex will change from True to False in a future version.\n  if __name__ == '__main__':</code></pre></div>\n  <div id=\"df-c3f4c367-1db1-48cb-8ade-ac1bb06e3012\">\n    <div class=\"colab-df-container\">\n      <div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}</code></pre></div>\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>document</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9976970</td>\n      <td>아 더빙   진짜 짜증나네요 목소리</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3819312</td>\n      <td>흠   포스터보고 초딩영화줄    오버연기조차 가볍지 않구나</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10265843</td>\n      <td>너무재밓었다그래서보는것을추천한다</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9045019</td>\n      <td>교도소 이야기구먼   솔직히 재미는 없다  평점 조정</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6483659</td>\n      <td>사이몬페그의 익살스런 연기가 돋보였던 영화 스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c3f4c367-1db1-48cb-8ade-ac1bb06e3012')\"\n              title=\"Convert this dataframe to an interactive table.\"\n              style=\"display:none;\">\n<p>&#x3C;svg xmlns=”<a href=\"http://www.w3.org/2000/svg\">http://www.w3.org/2000/svg</a>” height=“24px”viewBox=“0 0 24 24”\nwidth=“24px”>\n<path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n<path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n</svg>\n</button></p>\n  <style>\n    .colab-df-container {\n      display:flex;\n      flex-wrap:wrap;\n      gap: 12px;\n    }\n\n    .colab-df-convert {\n      background-color: #E8F0FE;\n      border: none;\n      border-radius: 50%;\n      cursor: pointer;\n      display: none;\n      fill: #1967D2;\n      height: 32px;\n      padding: 0 0 0 0;\n      width: 32px;\n    }\n\n    .colab-df-convert:hover {\n      background-color: #E2EBFA;\n      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n      fill: #174EA6;\n    }\n\n    [theme=dark] .colab-df-convert {\n      background-color: #3B4455;\n      fill: #D2E3FC;\n    }\n\n    [theme=dark] .colab-df-convert:hover {\n      background-color: #434B5C;\n      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n      fill: #FFFFFF;\n    }\n  </style>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">  &lt;script>\n    const buttonEl =\n      document.querySelector('#df-c3f4c367-1db1-48cb-8ade-ac1bb06e3012 button.colab-df-convert');\n    buttonEl.style.display =\n      google.colab.kernel.accessAllowed ? 'block' : 'none';\n\n    async function convertToInteractive(key) {\n      const element = document.querySelector('#df-c3f4c367-1db1-48cb-8ade-ac1bb06e3012');\n      const dataTable =\n        await google.colab.kernel.invokeFunction('convertToInteractive',\n                                                 [key], {});\n      if (!dataTable) return;\n\n      const docLinkHtml = 'Like what you see? Visit the ' +\n        '&lt;a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook&lt;/a>'\n        + ' to learn more about interactive tables.';\n      element.innerHTML = '';\n      dataTable['output_type'] = 'display_data';\n      await google.colab.output.renderOutput(dataTable, element);\n      const docLink = document.createElement('div');\n      docLink.innerHTML = docLinkHtml;\n      element.appendChild(docLink);\n    }\n  &lt;/script>\n&lt;/div></code></pre></div>\n  </div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>train<span class=\"token punctuation\">.</span>isnull<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>values<span class=\"token punctuation\">.</span><span class=\"token builtin\">any</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>test<span class=\"token punctuation\">.</span>isnull<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>values<span class=\"token punctuation\">.</span><span class=\"token builtin\">any</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">False\nFalse</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>test<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">144975 48751</code></pre></div>\n<p>길이 분포를 확인하고 적절한 크기로 padding 한다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 데이터 길이 분포 확인하기</span>\n\nmin_len <span class=\"token operator\">=</span> <span class=\"token number\">999</span>\nmax_len <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\nsum_len <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n\n<span class=\"token keyword\">for</span> sen <span class=\"token keyword\">in</span> train<span class=\"token punctuation\">[</span><span class=\"token string\">'document'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n    length <span class=\"token operator\">=</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>sen<span class=\"token punctuation\">)</span>\n    \n    <span class=\"token comment\"># 문장 최소 길이 찾기</span>\n    <span class=\"token keyword\">if</span> min_len <span class=\"token operator\">></span> length<span class=\"token punctuation\">:</span> \n        min_len <span class=\"token operator\">=</span> length\n    \n    <span class=\"token comment\"># 문장 최대 길이 찾기</span>\n    <span class=\"token keyword\">if</span> max_len <span class=\"token operator\">&lt;</span> length<span class=\"token punctuation\">:</span> \n        max_len <span class=\"token operator\">=</span> length\n        \n    <span class=\"token comment\"># 전체 문장총 길이</span>\n    sum_len <span class=\"token operator\">+=</span> length\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"문장의 최단 길이:\"</span><span class=\"token punctuation\">,</span> min_len<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"문장의 최장 길이:\"</span><span class=\"token punctuation\">,</span> max_len<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"문장의 평균 길이:\"</span><span class=\"token punctuation\">,</span> sum_len <span class=\"token operator\">//</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>train_data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 전체 길이만큼 0벡터 ==> 길이에 따른 문장의 수를 저장하기 위해 먼저 0으로 이루어진 리스트를 만든다!!</span>\nsentence_length <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>max_len<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>np<span class=\"token punctuation\">.</span><span class=\"token builtin\">int</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">''</span><span class=\"token punctuation\">)</span>\n\n\n<span class=\"token keyword\">for</span> sen <span class=\"token keyword\">in</span> train<span class=\"token punctuation\">[</span><span class=\"token string\">'document'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n    sentence_length<span class=\"token punctuation\">[</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>sen<span class=\"token punctuation\">)</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+=</span> <span class=\"token number\">1</span> <span class=\"token comment\"># 0으로 이루어진 벡터에 문장 count를 더한 뒤 넣는다.</span>\n\nplt<span class=\"token punctuation\">.</span>bar<span class=\"token punctuation\">(</span><span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>max_len<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> sentence_length<span class=\"token punctuation\">,</span> width<span class=\"token operator\">=</span><span class=\"token number\">1.0</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 너비는 1.0씩 늘어나도록 설정</span>\nplt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">\"문장 길이별 분포\"</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">문장의 최단 길이: 1\n문장의 최장 길이: 145\n문장의 평균 길이: 36\n\n\n\n/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 47928 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51109 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44600 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51060 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 48324 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 48516 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 54252 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 47928 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51109 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44600 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51060 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 48324 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 48516 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 54252 missing from current font.\n  font.set_text(s, 0, flags=flags)</code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 381px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 69.44444444444444%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsSAAALEgHS3X78AAACiklEQVQ4y52UX0jTURTHzzLIShFz2lJztYgM33qoXkIiJAp7CKoXH3qqpBjMdKEPWSFF/7A/VhA9WmB/FN2aLkPDcBSkzU3NUtRttLbl0n6/ze33794T96eYmjPqwuHch3M+53vO5VzQ6/XADiImNABIBYD1AJAFAKuXjS0pKYFAMJgcDAbrOZ7vCIUn7RzHvZpn9kAg0OX1eh0+n88RCoXe8Dz/R0wkEun0+/2PWPW0g8WHtsmiMMELCnaPhPF/TzQaHWfAFUbTWZ0kxMemYhJeaOmXZIUolNJ/MYkBeZ7vV/uuuXpDK8Zj3mlRwZ2XX5O3w9/VijIhqqeULquMUkpmgYNqy4X7ivJlUfAwhQXVbeTw/W4U5YWw5aALgKWlpdAz7E+hkuD1/JjG7efbyJrTjVjb/mVGpUL+OrvFClMLiw5sRUX0jISimGu2kA3lFiy83onjE9E5dUsppAmASUePn8hGInmsrm+YYWomW6psqDU14/5bXRiXlITQeeP4DWSPYr72IB1R9lxpHcI0YxMxVNkw12zFgmo7hiOCmqQQOgddwhYozNi1Z28+UmnsVH0vA8qGypdEf86qsPaHAhyTyBLmeUoYhBCqEBVGZVEhGOH5AXh4swYQ4ylTfDRYXOfAzLIW3Fxlw02VNsw2W7Gotgsfv/fhgJ9DLi5jXCK4eJqT0yL2feVQFmKjMNHbBvculWf1fBpt31FtGdQZG5x5pmeujWXPnXmmp27tmQZn6sl6t6HihXP3RYv7WF1nX8WTd66axg+uOrvbeafV6T5yt+Pj7da+z7Gf4Sb1Y1gJkMSWHgBWaWb8OgDQAICO7XvOWo2ObRQAZAJAMgCkA4B29p4zG8t+maRf7HZNCc/hpT8AAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/491f77a7b6f65dce1bf58b96c199d6b4/2add2/output_40_2.png\"\n        srcset=\"/static/491f77a7b6f65dce1bf58b96c199d6b4/e9ff0/output_40_2.png 180w,\n/static/491f77a7b6f65dce1bf58b96c199d6b4/f21e7/output_40_2.png 360w,\n/static/491f77a7b6f65dce1bf58b96c199d6b4/2add2/output_40_2.png 381w\"\n        sizes=\"(max-width: 381px) 100vw, 381px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">min_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>s <span class=\"token keyword\">for</span> s <span class=\"token keyword\">in</span> train<span class=\"token punctuation\">[</span><span class=\"token string\">'document'</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span> <span class=\"token operator\">&lt;=</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\n\nmin_list<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token number\">10</span><span class=\"token punctuation\">]</span>\n</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">['최고', '졸작', '대박', '아', '점', '버려', '망함', '굳굳', '안습', '잼']</code></pre></div>\n<p>데이터 분포를 고려하여 45이하 데이터를 사용하도록 하겠다.</p>\n<p>원래는 2글자 이하 데이터도 제거하려 하였으나,<br>\n위 데이터를 보고 충분히 유의미하다고 느꼈다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">train_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>s <span class=\"token keyword\">for</span> s <span class=\"token keyword\">in</span> train<span class=\"token punctuation\">[</span><span class=\"token string\">'document'</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span> <span class=\"token operator\">&lt;=</span> <span class=\"token number\">35</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\ntest_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>s <span class=\"token keyword\">for</span> s <span class=\"token keyword\">in</span> test<span class=\"token punctuation\">[</span><span class=\"token string\">'document'</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span> <span class=\"token operator\">&lt;=</span> <span class=\"token number\">35</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\n\ntrain_df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span>train_list<span class=\"token punctuation\">)</span>\ntest_df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span>test_list<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 길이 40이하인 데이터를 기존 데이터와 병합.</span>\n\nnew_train_df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>merge<span class=\"token punctuation\">(</span>train_data<span class=\"token punctuation\">,</span> train_df<span class=\"token punctuation\">,</span> how<span class=\"token operator\">=</span><span class=\"token string\">'inner'</span><span class=\"token punctuation\">,</span> left_on<span class=\"token operator\">=</span><span class=\"token string\">'document'</span><span class=\"token punctuation\">,</span> right_on<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\nnew_test_df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>merge<span class=\"token punctuation\">(</span>test_data<span class=\"token punctuation\">,</span> test_df<span class=\"token punctuation\">,</span> how<span class=\"token operator\">=</span><span class=\"token string\">'inner'</span><span class=\"token punctuation\">,</span> left_on<span class=\"token operator\">=</span><span class=\"token string\">'document'</span><span class=\"token punctuation\">,</span> right_on<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n\ntrain_data <span class=\"token operator\">=</span> new_train_df<span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token string\">'id'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'document'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'label'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span>\ntest_data <span class=\"token operator\">=</span> new_test_df<span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token string\">'id'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'document'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'label'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">train_data</code></pre></div>\n  <div id=\"df-6b82ed66-34b6-44e2-bfa5-f1150a3e85f3\">\n    <div class=\"colab-df-container\">\n      <div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}</code></pre></div>\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>document</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9976970</td>\n      <td>아 더빙   진짜 짜증나네요 목소리</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3819312</td>\n      <td>흠   포스터보고 초딩영화줄    오버연기조차 가볍지 않구나</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10265843</td>\n      <td>너무재밓었다그래서보는것을추천한다</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9045019</td>\n      <td>교도소 이야기구먼   솔직히 재미는 없다  평점 조정</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7797314</td>\n      <td>원작의 긴장감을 제대로 살려내지못했다</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>93794</th>\n      <td>6222902</td>\n      <td>인간이 문제지   소는 뭔죄인가</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>93795</th>\n      <td>8549745</td>\n      <td>평점이 너무 낮아서</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>93796</th>\n      <td>9311800</td>\n      <td>이게 뭐요  한국인은 거들먹거리고 필리핀 혼혈은 착하다</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>93797</th>\n      <td>2376369</td>\n      <td>청춘 영화의 최고봉 방황과 우울했던 날들의 자화상</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>93798</th>\n      <td>9619869</td>\n      <td>한국 영화 최초로 수간하는 내용이 담긴 영화</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>93799 rows × 3 columns</p>\n</div>\n      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6b82ed66-34b6-44e2-bfa5-f1150a3e85f3')\"\n              title=\"Convert this dataframe to an interactive table.\"\n              style=\"display:none;\">\n<p>&#x3C;svg xmlns=”<a href=\"http://www.w3.org/2000/svg\">http://www.w3.org/2000/svg</a>” height=“24px”viewBox=“0 0 24 24”\nwidth=“24px”>\n<path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n<path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n</svg>\n</button></p>\n  <style>\n    .colab-df-container {\n      display:flex;\n      flex-wrap:wrap;\n      gap: 12px;\n    }\n\n    .colab-df-convert {\n      background-color: #E8F0FE;\n      border: none;\n      border-radius: 50%;\n      cursor: pointer;\n      display: none;\n      fill: #1967D2;\n      height: 32px;\n      padding: 0 0 0 0;\n      width: 32px;\n    }\n\n    .colab-df-convert:hover {\n      background-color: #E2EBFA;\n      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n      fill: #174EA6;\n    }\n\n    [theme=dark] .colab-df-convert {\n      background-color: #3B4455;\n      fill: #D2E3FC;\n    }\n\n    [theme=dark] .colab-df-convert:hover {\n      background-color: #434B5C;\n      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n      fill: #FFFFFF;\n    }\n  </style>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">  &lt;script>\n    const buttonEl =\n      document.querySelector('#df-6b82ed66-34b6-44e2-bfa5-f1150a3e85f3 button.colab-df-convert');\n    buttonEl.style.display =\n      google.colab.kernel.accessAllowed ? 'block' : 'none';\n\n    async function convertToInteractive(key) {\n      const element = document.querySelector('#df-6b82ed66-34b6-44e2-bfa5-f1150a3e85f3');\n      const dataTable =\n        await google.colab.kernel.invokeFunction('convertToInteractive',\n                                                 [key], {});\n      if (!dataTable) return;\n\n      const docLinkHtml = 'Like what you see? Visit the ' +\n        '&lt;a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook&lt;/a>'\n        + ' to learn more about interactive tables.';\n      element.innerHTML = '';\n      dataTable['output_type'] = 'display_data';\n      await google.colab.output.renderOutput(dataTable, element);\n      const docLink = document.createElement('div');\n      docLink.innerHTML = docLinkHtml;\n      element.appendChild(docLink);\n    }\n  &lt;/script>\n&lt;/div></code></pre></div>\n  </div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"훈련데이터 : \"</span><span class=\"token punctuation\">,</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>train_data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"테스트데이터 : \"</span><span class=\"token punctuation\">,</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>test_data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">훈련데이터 :  93799\n테스트데이터 :  31631</code></pre></div>\n<p>텍스트 정제 후엔 훈련된 tokenizer 를 이용해<br>\n문장을 vector 화 시킨다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># tensor 화 시킨다</span>\nX_train<span class=\"token punctuation\">,</span>X_train_word_index<span class=\"token punctuation\">,</span> X_train_index_word <span class=\"token operator\">=</span> sp_tokenize<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">,</span> train_data<span class=\"token punctuation\">[</span><span class=\"token string\">'document'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nX_test<span class=\"token punctuation\">,</span>X_test_word_index<span class=\"token punctuation\">,</span> X_test_index_word <span class=\"token operator\">=</span> sp_tokenize<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">,</span> test_data<span class=\"token punctuation\">[</span><span class=\"token string\">'document'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># label 데이터 분리</span>\n\ny_train <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>train_data<span class=\"token punctuation\">[</span><span class=\"token string\">'label'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\ny_test <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>test_data<span class=\"token punctuation\">[</span><span class=\"token string\">'label'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>train<span class=\"token punctuation\">[</span><span class=\"token string\">'document'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n  <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>X_train<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n  <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">아 더빙   진짜 짜증나네요 목소리\n[ 141  106 2611  912 4856    4 4856  752   69  554  514 2648    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0]\n\n흠   포스터보고 초딩영화줄    오버연기조차 가볍지 않구나\n[   4 7663  490 1756  146   14  439 3174 2766 1791  222  408  381   41\n 4189    4   11 7570   29 1311  230   69    0    0    0    0    0    0\n    0    0    0    0    0    0    0]\n\n너무재밓었다그래서보는것을추천한다\n[1328  437    0  266  254  591   95  146   10 1960    5 1011  703  249\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0]</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"학습데이터 :\"</span><span class=\"token punctuation\">,</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>X_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"타겟데이터 :\"</span><span class=\"token punctuation\">,</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>y_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">학습데이터 : 93799\n타겟데이터 : 93799</code></pre></div>\n<p>93799 개의 텍스트가 35개의 숫자 데이터로 정의되었다.<br>\npadding 까지 씌어졌음을 알 수 있다.</p>\n<h3 id=\"2-2-3-val-분리\" style=\"position:relative;\"><a href=\"#2-2-3-val-%EB%B6%84%EB%A6%AC\" aria-label=\"2 2 3 val 분리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2-2-3. val 분리</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>model_selection <span class=\"token keyword\">import</span> train_test_split\ntrain_input<span class=\"token punctuation\">,</span> val_input<span class=\"token punctuation\">,</span> train_target<span class=\"token punctuation\">,</span> val_target <span class=\"token operator\">=</span> train_test_split<span class=\"token punctuation\">(</span>X_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> test_size<span class=\"token operator\">=</span><span class=\"token number\">0.2</span><span class=\"token punctuation\">,</span> random_state<span class=\"token operator\">=</span><span class=\"token number\">64</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>train_input<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>val_input<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">75039\n18760</code></pre></div>\n<hr>\n<p>결과적으로, 총 데이터는 다음과 같다.</p>\n<p>train_input : 학습시킬 문장의 tensor<br>\ntrain_target :학습시킬 문장의 label</p>\n<p>val_input : 검증할 문장의 tensor<br>\nval_target : 검증할 문장의 label</p>\n<p>X_test : 측정할 문장의 tensor<br>\ny_test : 측정할 문장의 label</p>\n<h2 id=\"2-3모델-학습\" style=\"position:relative;\"><a href=\"#2-3%EB%AA%A8%EB%8D%B8-%ED%95%99%EC%8A%B5\" aria-label=\"2 3모델 학습 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2-3.모델 학습</h2>\n<p>훈련된 데이터를 통해 다양한 학습을 시킬 것이다.</p>\n<ol>\n<li>RNN 모델 사용</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">vocab_size <span class=\"token operator\">=</span> <span class=\"token number\">8000</span>  <span class=\"token comment\"># 어휘 사전의 크기입니다</span>\nword_vector_dim <span class=\"token operator\">=</span> <span class=\"token number\">100</span>  <span class=\"token comment\"># 단어 하나를 표현하는 임베딩 벡터의 차원수입니다. </span>\n\n<span class=\"token comment\"># RNN 방식</span>\n\nmodel <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Embedding<span class=\"token punctuation\">(</span>vocab_size<span class=\"token punctuation\">,</span> word_vector_dim<span class=\"token punctuation\">,</span> input_shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>LSTM<span class=\"token punctuation\">(</span><span class=\"token number\">8</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>   \nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">8</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'sigmoid'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 최종 출력은 긍정/부정을 나타내는 1dim 입니다.</span>\n\nmodel<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n embedding (Embedding)       (None, None, 100)         800000    \n                                                                 \n lstm (LSTM)                 (None, 8)                 3488      \n                                                                 \n dense (Dense)               (None, 8)                 72        \n                                                                 \n dense_1 (Dense)             (None, 1)                 9         \n                                                                 \n=================================================================\nTotal params: 803,569\nTrainable params: 803,569\nNon-trainable params: 0\n_________________________________________________________________</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">model<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span><span class=\"token string\">'adam'</span><span class=\"token punctuation\">,</span>\n              loss<span class=\"token operator\">=</span><span class=\"token string\">'binary_crossentropy'</span><span class=\"token punctuation\">,</span>\n              metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n              \nepochs<span class=\"token operator\">=</span><span class=\"token number\">20</span>  <span class=\"token comment\"># 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. </span>\n\nhistory <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>train_input<span class=\"token punctuation\">,</span>\n                    train_target<span class=\"token punctuation\">,</span>\n                    epochs<span class=\"token operator\">=</span>epochs<span class=\"token punctuation\">,</span>\n                    batch_size<span class=\"token operator\">=</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span>\n                    validation_data<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>val_input<span class=\"token punctuation\">,</span> val_target<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                    verbose<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Epoch 1/20\n1173/1173 [==============================] - 10s 7ms/step - loss: 0.3819 - accuracy: 0.8278 - val_loss: 0.4099 - val_accuracy: 0.8082\nEpoch 2/20\n1173/1173 [==============================] - 7s 6ms/step - loss: 0.3558 - accuracy: 0.8400 - val_loss: 0.4398 - val_accuracy: 0.8047\nEpoch 3/20\n1173/1173 [==============================] - 7s 6ms/step - loss: 0.3288 - accuracy: 0.8556 - val_loss: 0.4236 - val_accuracy: 0.8152\nEpoch 4/20\n1173/1173 [==============================] - 7s 6ms/step - loss: 0.3030 - accuracy: 0.8692 - val_loss: 0.4304 - val_accuracy: 0.8148\nEpoch 5/20\n1173/1173 [==============================] - 7s 6ms/step - loss: 0.2802 - accuracy: 0.8822 - val_loss: 0.4366 - val_accuracy: 0.8165\nEpoch 6/20\n1173/1173 [==============================] - 7s 6ms/step - loss: 0.2577 - accuracy: 0.8941 - val_loss: 0.4608 - val_accuracy: 0.8129\nEpoch 7/20\n1173/1173 [==============================] - 7s 6ms/step - loss: 0.2365 - accuracy: 0.9049 - val_loss: 0.4742 - val_accuracy: 0.8113\nEpoch 8/20\n1173/1173 [==============================] - 7s 6ms/step - loss: 0.2172 - accuracy: 0.9141 - val_loss: 0.4833 - val_accuracy: 0.8073\nEpoch 9/20\n1173/1173 [==============================] - 7s 6ms/step - loss: 0.2026 - accuracy: 0.9217 - val_loss: 0.5415 - val_accuracy: 0.8120\nEpoch 10/20\n1173/1173 [==============================] - 7s 6ms/step - loss: 0.1873 - accuracy: 0.9290 - val_loss: 0.5531 - val_accuracy: 0.8073\nEpoch 11/20\n1173/1173 [==============================] - 7s 6ms/step - loss: 0.1758 - accuracy: 0.9345 - val_loss: 0.5657 - val_accuracy: 0.8078\nEpoch 12/20\n1173/1173 [==============================] - 7s 6ms/step - loss: 0.1642 - accuracy: 0.9397 - val_loss: 0.5720 - val_accuracy: 0.8062\nEpoch 13/20\n1173/1173 [==============================] - 7s 6ms/step - loss: 0.1560 - accuracy: 0.9425 - val_loss: 0.5678 - val_accuracy: 0.8077\nEpoch 14/20\n1173/1173 [==============================] - 7s 6ms/step - loss: 0.1477 - accuracy: 0.9469 - val_loss: 0.6246 - val_accuracy: 0.8075\nEpoch 15/20\n1173/1173 [==============================] - 8s 6ms/step - loss: 0.1410 - accuracy: 0.9496 - val_loss: 0.6327 - val_accuracy: 0.8041\nEpoch 16/20\n1173/1173 [==============================] - 8s 7ms/step - loss: 0.1337 - accuracy: 0.9528 - val_loss: 0.6378 - val_accuracy: 0.8033\nEpoch 17/20\n1173/1173 [==============================] - 7s 6ms/step - loss: 0.1293 - accuracy: 0.9552 - val_loss: 0.6658 - val_accuracy: 0.8033\nEpoch 18/20\n1173/1173 [==============================] - 7s 6ms/step - loss: 0.1234 - accuracy: 0.9578 - val_loss: 0.6399 - val_accuracy: 0.8010\nEpoch 19/20\n1173/1173 [==============================] - 7s 6ms/step - loss: 0.1176 - accuracy: 0.9605 - val_loss: 0.7190 - val_accuracy: 0.8000\nEpoch 20/20\n1173/1173 [==============================] - 7s 6ms/step - loss: 0.1143 - accuracy: 0.9617 - val_loss: 0.6888 - val_accuracy: 0.8025</code></pre></div>\n<ol start=\"2\">\n<li>LSTM</li>\n</ol>\n<p>다음으로는 LSTM 모델을 이용해 학습을 진행했다.<br>\n손실함수와 최적화함수는 tensor flow 권장 사항을 따랐다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># LSTM</span>\n\nmodel <span class=\"token operator\">=</span> Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>Embedding<span class=\"token punctuation\">(</span>vocab_size<span class=\"token punctuation\">,</span> <span class=\"token number\">100</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 임베딩 레이어</span>\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>LSTM<span class=\"token punctuation\">(</span><span class=\"token number\">128</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># LSTM 레이어</span>\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'sigmoid'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 출력 레이어</span>\n\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span><span class=\"token string\">'rmsprop'</span><span class=\"token punctuation\">,</span> loss<span class=\"token operator\">=</span><span class=\"token string\">'binary_crossentropy'</span><span class=\"token punctuation\">,</span> metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'acc'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">epochs<span class=\"token operator\">=</span><span class=\"token number\">20</span>  <span class=\"token comment\"># 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. </span>\n\nhistory <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>train_input<span class=\"token punctuation\">,</span>\n                    train_target<span class=\"token punctuation\">,</span>\n                    epochs<span class=\"token operator\">=</span>epochs<span class=\"token punctuation\">,</span>\n                    batch_size<span class=\"token operator\">=</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span>\n                    validation_data<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>val_input<span class=\"token punctuation\">,</span> val_target<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                    verbose<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Epoch 1/20\n1173/1173 [==============================] - 11s 8ms/step - loss: 0.4747 - acc: 0.7743 - val_loss: 0.4453 - val_acc: 0.8026\nEpoch 2/20\n1173/1173 [==============================] - 8s 7ms/step - loss: 0.4123 - acc: 0.8123 - val_loss: 0.4038 - val_acc: 0.8118\nEpoch 3/20\n1173/1173 [==============================] - 8s 7ms/step - loss: 0.3873 - acc: 0.8236 - val_loss: 0.4068 - val_acc: 0.8171\nEpoch 4/20\n1173/1173 [==============================] - 8s 7ms/step - loss: 0.3695 - acc: 0.8326 - val_loss: 0.3877 - val_acc: 0.8201\nEpoch 5/20\n1173/1173 [==============================] - 8s 7ms/step - loss: 0.3545 - acc: 0.8420 - val_loss: 0.3878 - val_acc: 0.8239\nEpoch 6/20\n1173/1173 [==============================] - 8s 7ms/step - loss: 0.3404 - acc: 0.8503 - val_loss: 0.3892 - val_acc: 0.8233\nEpoch 7/20\n1173/1173 [==============================] - 8s 7ms/step - loss: 0.3272 - acc: 0.8582 - val_loss: 0.4038 - val_acc: 0.8201\nEpoch 8/20\n1173/1173 [==============================] - 8s 7ms/step - loss: 0.3160 - acc: 0.8649 - val_loss: 0.3799 - val_acc: 0.8292\nEpoch 9/20\n1173/1173 [==============================] - 8s 7ms/step - loss: 0.3042 - acc: 0.8701 - val_loss: 0.3780 - val_acc: 0.8266\nEpoch 10/20\n1173/1173 [==============================] - 8s 7ms/step - loss: 0.2929 - acc: 0.8774 - val_loss: 0.3885 - val_acc: 0.8285\nEpoch 11/20\n1173/1173 [==============================] - 8s 7ms/step - loss: 0.2812 - acc: 0.8827 - val_loss: 0.4003 - val_acc: 0.8289\nEpoch 12/20\n1173/1173 [==============================] - 8s 7ms/step - loss: 0.2688 - acc: 0.8889 - val_loss: 0.4134 - val_acc: 0.8292\nEpoch 13/20\n1173/1173 [==============================] - 8s 7ms/step - loss: 0.2533 - acc: 0.8970 - val_loss: 0.4477 - val_acc: 0.8150\nEpoch 14/20\n1173/1173 [==============================] - 8s 7ms/step - loss: 0.2401 - acc: 0.9041 - val_loss: 0.4366 - val_acc: 0.8217\nEpoch 15/20\n1173/1173 [==============================] - 8s 7ms/step - loss: 0.2265 - acc: 0.9101 - val_loss: 0.4455 - val_acc: 0.8181\nEpoch 16/20\n1173/1173 [==============================] - 8s 7ms/step - loss: 0.2133 - acc: 0.9178 - val_loss: 0.4690 - val_acc: 0.8197\nEpoch 17/20\n1173/1173 [==============================] - 9s 7ms/step - loss: 0.2002 - acc: 0.9237 - val_loss: 0.4750 - val_acc: 0.8135\nEpoch 18/20\n1173/1173 [==============================] - 8s 7ms/step - loss: 0.1866 - acc: 0.9295 - val_loss: 0.5083 - val_acc: 0.8131\nEpoch 19/20\n1173/1173 [==============================] - 8s 7ms/step - loss: 0.1741 - acc: 0.9356 - val_loss: 0.5606 - val_acc: 0.8115\nEpoch 20/20\n1173/1173 [==============================] - 8s 7ms/step - loss: 0.1614 - acc: 0.9406 - val_loss: 0.5704 - val_acc: 0.8082</code></pre></div>\n<h2 id=\"2-4데이터-평가\" style=\"position:relative;\"><a href=\"#2-4%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%8F%89%EA%B0%80\" aria-label=\"2 4데이터 평가 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2-4.데이터 평가</h2>\n<p>종합적으로 5번의 시도를 했으며,<br>\nbatch size = 64<br>\nepochs = 20 으로 통일하고</p>\n<p>tokenizer 와 학습 모델에 변화를 주었다.</p>\n<blockquote>\n<ol>\n<li>영화리뷰 데이터로 Sentencepiece Tokenize : RNN</li>\n</ol>\n</blockquote>\n<ol start=\"2\">\n<li>한국어 corpus 데이터로 Sentencepiece Tokenize : RNN (임베딩 차원 20)</li>\n<li>임베딩 차원 100</li>\n<li>LSTM 모델 설정 (임베딩 차원 100)</li>\n<li>SentencePiece 모델 타입 BPE 로 변경</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># tokenizer 를 영화 리뷰 데이터로 제작</span>\n\nresult <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>X_test<span class=\"token punctuation\">,</span>  y_test<span class=\"token punctuation\">,</span> verbose<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>result<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">1524/1524 - 6s - loss: 0.6932 - accuracy: 0.4982 - 6s/epoch - 4ms/step\n[0.6932055950164795, 0.4981846511363983]</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 한국어 corpus 사용</span>\n\nresult <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>X_test<span class=\"token punctuation\">,</span>  y_test<span class=\"token punctuation\">,</span> verbose<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>result<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">1524/1524 - 6s - loss: 0.6933 - acc: 0.4982 - 6s/epoch - 4ms/step\n[0.6933001279830933, 0.4981846511363983]</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 임베딩 차원 100</span>\n\nresults <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>X_test<span class=\"token punctuation\">,</span>  y_test<span class=\"token punctuation\">,</span> verbose<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>results<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">989/989 - 3s - loss: 0.6922 - accuracy: 0.8013 - 3s/epoch - 3ms/step\n[0.6921951770782471, 0.8012709021568298]</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># LSTM 모델 사용</span>\nresults <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>X_test<span class=\"token punctuation\">,</span>  y_test<span class=\"token punctuation\">,</span> verbose<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>results<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">989/989 - 4s - loss: 0.5414 - acc: 0.8038 - 4s/epoch - 4ms/step\n[0.5413879156112671, 0.8038316965103149]</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># SentencePiece 모델 타입 변경 BPE</span>\n\nresults <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>X_test<span class=\"token punctuation\">,</span>  y_test<span class=\"token punctuation\">,</span> verbose<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>results<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">989/989 - 5s - loss: 0.5565 - acc: 0.8088 - 5s/epoch - 5ms/step\n[0.5565109848976135, 0.8087635636329651]</code></pre></div>\n<p>결과적으로</p>\n<p>한국어 corpus 를 이용해 임베딩 차원 100 으로 두고\nLSTM 모델을 사용한 BPE 방식 Tokenizer 가 가장 큰 결과를 얻었다</p>\n<p>Accuracy = 0.808%</p>\n<p>다양한 시도를 통해 알 수 있었던 점</p>\n<ol>\n<li>임베딩차원의 크기가 정확도에 큰 영향을 미친다.</li>\n<li>RNN 보다 LSTM 이 Loss 를 대폭 줄인다.</li>\n</ol>\n<p>그 외의 차이는 미미한 것으로 보인다.<br>\n하지만 모델의 특성상 <code class=\"language-text\">batch_size</code> 나 임베딩차원, 전처리 방식에<br>\n변화를 주었을 때 또 다른 영향을 끼칠 수도 있음이 나의 결론이다.</p>\n<h1 id=\"3-potg\" style=\"position:relative;\"><a href=\"#3-potg\" aria-label=\"3 potg permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. POTG</h1>\n<h2 id=\"3-1-소감\" style=\"position:relative;\"><a href=\"#3-1-%EC%86%8C%EA%B0%90\" aria-label=\"3 1 소감 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3-1. 소감</h2>\n<h4 id=\"-nlp-뿌시기-1단계-통과\" style=\"position:relative;\"><a href=\"#-nlp-%EB%BF%8C%EC%8B%9C%EA%B8%B0-1%EB%8B%A8%EA%B3%84-%ED%86%B5%EA%B3%BC\" aria-label=\" nlp 뿌시기 1단계 통과 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>”👍 NLP 뿌시기 1단계 통과!”</h4>\n<p>드디어 Tokenizer 가 무엇인지 감을 잡은 것 같습니다.<br>\nTokenize 를 하기 위해선 tokenizer 에 들어갈 데이터도 전처리를 해주어야 합니다.  그리고 tokenizer 에 저장되어 있는 word_to_index 데이터로</p>\n<p>저희가 학습할 데이터를 tensor 화 해줍니다.</p>\n<p>tensor 라 함은 우리의 문장 데이터가 숫자로 변환된 리스트 데이터를 의미합니다.</p>\n<p>tensor 는 tokenizer 텍스트 데이터를 토대로 어떤 기준을 통해 글을 나눠야 할지 판별해주는 역할을 합니다.</p>\n<h2 id=\"3-2-어려웠던-점과-극복방안\" style=\"position:relative;\"><a href=\"#3-2-%EC%96%B4%EB%A0%A4%EC%9B%A0%EB%8D%98-%EC%A0%90%EA%B3%BC-%EA%B7%B9%EB%B3%B5%EB%B0%A9%EC%95%88\" aria-label=\"3 2 어려웠던 점과 극복방안 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3-2. 어려웠던 점과 극복방안</h2>\n<p>-1. 불용어 제거</p>\n<p>morphs 에서는 불용어를 제거하는데 (왜냐하면 그냥 단어를 분리만 해서 리턴해주니까)\nSentencepiece 는 모든 단어를 이미 tensor 화 해서 주기 때문에<br>\n불용어를 제거할 수가 없다.</p>\n<p>그렇다면 불용어를 제거하지 않아도 되는가?</p>\n<blockquote>\n<p>어차피 SentencePiece Train 을 하기 위해서 문장을 전처리 후에 넣게 되는데, 그러므로 불용어를 처리하고 넣을 수 잇다.</p>\n</blockquote>\n<p>-2 전처리 ” 데이터<br>\n결측치를 제거해도 min_len 이 0 이 나오는 상황이 생겼는데,\n” 데이터가 남아있기 때문이다. 때문에 판다스 메서드를 통해 이러한 부분을 제거해 주었다.</p>\n<p>-3. 오류<br>\n<code class=\"language-text\"> Another metric with the same name already exists.</code>\n라는 오류문이 <code class=\"language-text\">tp_tokenize</code> 과정에서 자꾸 났는데, stack over flow 검색 결과 keras 가 두 개 설치되어 있어 나타나는 현상이라고 한다. tensorflow 버전 문제라고 판단해 keras 버전을 2.6에서 2.8로 변경하고서는 오류가 나타나지 않았다.</p>\n<p>-4. 차이가 나는 indexing</p>\n<p><img src=\"/882fa8f89f03aadc3173362b70f0a756/image1.png\"></img></p>\n<p>어떤 부분에선가 train 데이터와 test 데이터가 동일하게 전처리되지 않았다. 다시 한번 꼼꼼히 진행하면서(한 코드씩 비교해가면서) 문제를 해결할 수 있었다.</p>\n<p>-5. 결과가 나오지 않는 모델</p>\n<p><img src=\"/67d16008f45d036c65f8239c1f647928/image2.png\"></img></p>\n<p>다양한 모델 변경을 해가면서 이전 test 타입과 이후 test 타입에 차이가 있어 나타난 현상이었다. 새로운 변수명을 주어 해결할 수 있었다.</p>\n<h2 id=\"3-3-추후\" style=\"position:relative;\"><a href=\"#3-3-%EC%B6%94%ED%9B%84\" aria-label=\"3 3 추후 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3-3. 추후</h2>\n<p>NLP 학습의 전체적인 큰 그림을 그려보고 싶다.</p>\n<p>tokenize 를 사용함과 사용하지 않을 때 padding 이나 임베딩에 차이가 있다.<br>\ntokenizer 를 통해 그런 부분이 해소되기 때문이다. 그래서 처음에<br>\n왜 padding 을 두번 해주는지 등 이해가 안되는 부분이 많았다.</p>\n<p>전체적인 그림을 그릴 수 있다면 이런 문제가 해소될 것이다.</p>\n<div class=\"table-of-contents\">\n<ul>\n<li>\n<p><a href=\"#contexts\">Contexts</a></p>\n<ul>\n<li><a href=\"#1-ready\">1. READY</a></li>\n<li><a href=\"#2-game\">2. GAME</a></li>\n<li><a href=\"#3-potg-best-play-of-the-game\">3. POTG (best Play Of The Game</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#1-1-%EC%98%A4%EB%8A%98%EC%9D%98-exp%EC%99%80-rubric\">1-1. 오늘의 Exp와 Rubric</a></p>\n</li>\n<li>\n<p><a href=\"#1-2-%EC%82%AC%EC%9A%A9%ED%95%98%EB%8A%94-%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC\">1-2. 사용하는 라이브러리</a></p>\n</li>\n<li>\n<p><a href=\"#2-1-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%9D%BD%EC%96%B4%EC%98%A4%EA%B8%B0\">2-1. 데이터 읽어오기</a></p>\n</li>\n<li>\n<p><a href=\"#2-2%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%84%EC%B2%98%EB%A6%AC\">2-2.데이터 전처리</a></p>\n<ul>\n<li><a href=\"#2-2-1-tokenizer-%EC%83%9D%EC%84%B1\">2-2-1. Tokenizer 생성</a></li>\n<li><a href=\"#2-2-2-%ED%95%99%EC%8A%B5-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%84%EC%B2%98%EB%A6%AC\">2-2-2. 학습 데이터 전처리</a></li>\n<li><a href=\"#2-2-3-val-%EB%B6%84%EB%A6%AC\">2-2-3. val 분리</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#2-3%EB%AA%A8%EB%8D%B8-%ED%95%99%EC%8A%B5\">2-3.모델 학습</a></p>\n</li>\n<li>\n<p><a href=\"#2-4%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%8F%89%EA%B0%80\">2-4.데이터 평가</a></p>\n</li>\n<li>\n<p><a href=\"#3-1-%EC%86%8C%EA%B0%90\">3-1. 소감</a></p>\n<ul>\n<li>\n<ul>\n<li><a href=\"#-nlp-%EB%BF%8C%EC%8B%9C%EA%B8%B0-1%EB%8B%A8%EA%B3%84-%ED%86%B5%EA%B3%BC\">”👍 NLP 뿌시기 1단계 통과!”</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><a href=\"#3-2-%EC%96%B4%EB%A0%A4%EC%9B%A0%EB%8D%98-%EC%A0%90%EA%B3%BC-%EA%B7%B9%EB%B3%B5%EB%B0%A9%EC%95%88\">3-2. 어려웠던 점과 극복방안</a></p>\n</li>\n<li>\n<p><a href=\"#3-3-%EC%B6%94%ED%9B%84\">3-3. 추후</a></p>\n</li>\n</ul>\n</div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"></code></pre></div>","frontmatter":{"date":"March 23, 2022","title":"SentencePiece Tokenizer 사용 방법","categories":"NLP","author":"하성민","emoji":"😁"},"fields":{"slug":"/NLP_2/"}},"site":{"siteMetadata":{"siteUrl":"https://xman227.github.io","comments":{"utterances":{"repo":"xman227/blog_comments"}}}}},"pageContext":{"slug":"/NLP_1/","nextSlug":"/python_tasking/","prevSlug":"/NLP_2/"}},
    "staticQueryHashes": ["1073350324","1956554647","2938748437"]}