{
    "componentChunkName": "component---src-templates-blog-template-js",
    "path": "/DML_norm/",
    "result": {"data":{"cur":{"id":"c23336a2-9dde-5998-a74d-897defbfb439","html":"<h1 id=\"span-stylebackground-color-fff5b1정규화라고-다같은-정규화가-아니다span\" style=\"position:relative;\"><a href=\"#span-stylebackground-color-fff5b1%EC%A0%95%EA%B7%9C%ED%99%94%EB%9D%BC%EA%B3%A0-%EB%8B%A4%EA%B0%99%EC%9D%80-%EC%A0%95%EA%B7%9C%ED%99%94%EA%B0%80-%EC%95%84%EB%8B%88%EB%8B%A4span\" aria-label=\"span stylebackground color fff5b1정규화라고 다같은 정규화가 아니다span permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><span style='background-color: #fff5b1'>정규화(라고 다같은 정규화가 아니다)</span></h1>\n<p>Regularization : 정칙화라고 불리며, 오버피팅을 해결하기 위한 방법 중의 하나</p>\n<p>Regularization 기법들은 모델이 train set의 정답을 맞히지 못하도록 오버피팅을 방해(train loss가 증가) 하는 역할을 합니다. 그래서 train loss는 약간 증가하지만 결과적으로, validation loss나 최종적인 test loss를 감소시키려는 목적</p>\n<p>(이건 오버피팅 방지)</p>\n<hr>\n<p>Normalization : 정규화라고 불리며, 이는 데이터의 형태를 좀 더 의미 있게, 혹은 트레이닝에 적합하게 전처리하는 과정</p>\n<p>(이건 전처리)</p>\n<p>예를 들어</p>\n<ol>\n<li>데이터를 z-socre 변환</li>\n<li>0 과 1 사이 값으로 분포 조정</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>datasets <span class=\"token keyword\">import</span> load_iris\n<span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd \n<span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt\n\niris <span class=\"token operator\">=</span> load_iris<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\niris_df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span>data<span class=\"token operator\">=</span>iris<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">,</span> columns<span class=\"token operator\">=</span>iris<span class=\"token punctuation\">.</span>feature_names<span class=\"token punctuation\">)</span>\ntarget_df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span>data<span class=\"token operator\">=</span>iris<span class=\"token punctuation\">.</span>target<span class=\"token punctuation\">,</span> columns<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'species'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 0, 1, 2로 되어있는 target 데이터를 </span>\n<span class=\"token comment\"># 알아보기 쉽게 'setosa', 'versicolor', 'virginica'로 바꿉니다 </span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">converter</span><span class=\"token punctuation\">(</span>species<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">if</span> species <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> <span class=\"token string\">'setosa'</span>\n    <span class=\"token keyword\">elif</span> species <span class=\"token operator\">==</span> <span class=\"token number\">1</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> <span class=\"token string\">'versicolor'</span>\n    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> <span class=\"token string\">'virginica'</span>\n\ntarget_df<span class=\"token punctuation\">[</span><span class=\"token string\">'species'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> target_df<span class=\"token punctuation\">[</span><span class=\"token string\">'species'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span>converter<span class=\"token punctuation\">)</span>\n\niris_df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>concat<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>iris_df<span class=\"token punctuation\">,</span> target_df<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\niris_df<span class=\"token punctuation\">.</span>head<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}</code></pre></div>\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal length (cm)</th>\n      <th>sepal width (cm)</th>\n      <th>petal length (cm)</th>\n      <th>petal width (cm)</th>\n      <th>species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">X <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>iris_df<span class=\"token punctuation\">[</span><span class=\"token string\">'petal length (cm)'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>a<span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> a <span class=\"token keyword\">in</span> iris_df<span class=\"token punctuation\">.</span>index <span class=\"token keyword\">if</span> iris_df<span class=\"token punctuation\">[</span><span class=\"token string\">'species'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>a<span class=\"token punctuation\">]</span><span class=\"token operator\">==</span><span class=\"token string\">'virginica'</span><span class=\"token punctuation\">]</span>\nY <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>iris_df<span class=\"token punctuation\">[</span><span class=\"token string\">'sepal length (cm)'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>a<span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> a <span class=\"token keyword\">in</span> iris_df<span class=\"token punctuation\">.</span>index <span class=\"token keyword\">if</span> iris_df<span class=\"token punctuation\">[</span><span class=\"token string\">'species'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>a<span class=\"token punctuation\">]</span><span class=\"token operator\">==</span><span class=\"token string\">'virginica'</span><span class=\"token punctuation\">]</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>Y<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">[6.0, 5.1, 5.9, 5.6, 5.8, 6.6, 4.5, 6.3, 5.8, 6.1, 5.1, 5.3, 5.5, 5.0, 5.1, 5.3, 5.5, 6.7, 6.9, 5.0, 5.7, 4.9, 6.7, 4.9, 5.7, 6.0, 4.8, 4.9, 5.6, 5.8, 6.1, 6.4, 5.6, 5.1, 5.6, 6.1, 5.6, 5.5, 4.8, 5.4, 5.6, 5.1, 5.1, 5.9, 5.7, 5.2, 5.0, 5.2, 5.4, 5.1]\n[6.3, 5.8, 7.1, 6.3, 6.5, 7.6, 4.9, 7.3, 6.7, 7.2, 6.5, 6.4, 6.8, 5.7, 5.8, 6.4, 6.5, 7.7, 7.7, 6.0, 6.9, 5.6, 7.7, 6.3, 6.7, 7.2, 6.2, 6.1, 6.4, 7.2, 7.4, 7.9, 6.4, 6.3, 6.1, 7.7, 6.3, 6.4, 6.0, 6.9, 6.7, 6.9, 5.8, 6.8, 6.7, 6.7, 6.3, 6.5, 6.2, 5.9]</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">plt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>scatter<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span>Y<span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'petal-sepal scatter before normalization'</span><span class=\"token punctuation\">)</span> \nplt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">'petal length (cm)'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'sepal length (cm)'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>grid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 336px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 98.88888888888889%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAAsTAAALEwEAmpwYAAADyElEQVQ4y4VUTW8jRRCt2CsQAq0QYCyEIxkkUH5Dbpw4csmFA77APWIv7EqIEz8GbfgIKyGRBC+JVmID68RyPI42cWLHHnvGie2ZsT1jT38WqvbYsCyIlkr9untc/erVa8PBwQFsbW2t9Ho9QEQAgDwAvAYAWQDIJDgHAK8DwFsA8Eay9yYAvJ3MOfrtTc8BKJfLKQC4XSwWP+52u8V6vV5st9s7NF9dXe21Wq3di4uLYqvV2mm327vNZnOn53R22ra9c1g53WtcXv7idOzdYf9m7/Dx4w/Atu2067rguu49pRT+79AaR7E0cBhyVBox5BpHM47HlepnVGaK6FqWdZcxhkIIJoQQcRwLKaUJwpzzJXb9UGilBKIUZ44n2oMJ648iPCyVP1kmrNVq9yihnA8dxzFhlEoh7XMhkCqQnGN7MMHBeIbhNEYphEZEqaXAmlUtmISXl5fgOM4dzjmaQ621kmJZpZLzEpuDCKu2h2fuGIMpxxkzl5iEdLllWQXY3Nx8EQBulUqlr4gV51zSrd44xCCcYTRjeO1PcBYz9CYzvPHHxAq1koZ5HMeashGuVCoFyOVypuWu634uhGFFdPSMcXSCGU65xIvrEVqdAE86I3T96C/mSi0ZEq7VagXIZrPvAMAKaUgMhRBSSamVYFh3A5xMGQ5HIbb6Y3zqBBhNZ0hyCDlnyBhbMjw5OSlAJpN5nxKen59/wUhDrWUQMX3a8bDS9tDxp3jU6OOTxgClVHgThDiNSWtNl1OQ5JJwtVo1DN+lkh3HMSVrRPmkOdTEhkbIJF71J9jsh2Y9imKMhfzvkjOZzHsA8HK5XP6SsRhjxmXdDXTd8XAwnhrxJ9EUh+PI2IjNZTHxr03Z2Nh4yfM86Ha7xjZEn+o5c3xjDxqmWVobTN/MSeHcp1I+a5uFsU9PT42xEbV0/Ehf9Hyjk0qMLRJjJ+Y3mJJzzp/VkDGWThLeTV6H5EJoPu+eTl6NJvH/ianDFEopSclNl73hwCTsdOw7pBcixvMqjSnFAmutn8NKKROIyIixZVnmLafppfxROvqaLCHmZWDiySU27znBNC+aspCDZsuyPgXraT3166Pf4PfS0UfHtfOHnufdHwwG3zUajZ/6/f73QRBs2bb9YDgcfjuZTL6xbfvH6+vrH3zf3+p0Og/oLAiC+47j/Ly9vf0hLEbyb522bRuiKCL8Au0l+6/+Dd8GgNT+/j4s9o6Pjxdnryw3EXGFIvD9dBhG6WSdWltby+bz+Vw+n19dXV3N03p9fZ0uSCcOSbVarVuJdPAn2XYUFtkpGdIAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/613dfaf87366d28da81864efc979bad9/d99f2/output_3_0.png\"\n        srcset=\"/static/613dfaf87366d28da81864efc979bad9/e9ff0/output_3_0.png 180w,\n/static/613dfaf87366d28da81864efc979bad9/d99f2/output_3_0.png 336w\"\n        sizes=\"(max-width: 336px) 100vw, 336px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>preprocessing <span class=\"token keyword\">import</span> minmax_scale\n\n<span class=\"token comment\">#sklearn 에서 지원하는 minmax_SCALE 로 0~ 1값으로 조정됨</span>\n\nX_scale <span class=\"token operator\">=</span> minmax_scale<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">)</span>\nY_scale <span class=\"token operator\">=</span> minmax_scale<span class=\"token punctuation\">(</span>Y<span class=\"token punctuation\">)</span>\n\nplt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>scatter<span class=\"token punctuation\">(</span>X_scale<span class=\"token punctuation\">,</span>Y_scale<span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'petal-sepal scatter after normalization'</span><span class=\"token punctuation\">)</span> \nplt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">'petal length (cm)'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'sepal length (cm)'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>grid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 330px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 101.11111111111111%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAAsTAAALEwEAmpwYAAADmklEQVQ4y21U2U4cRxStATkKkfI0MIIo9uCED0keYsOj7SzKLzk/wRPihSdreIAw6WDMNBiQmATJJALP1t01vc7S01stN7o13WRIaKlVp1tVt845dyEkf87PzwkAIPyCEPI4f78ihCwSQqqEkC9n/lcIIU9m9iAuqfMAUMKPWq32reM4OqX0FFfTNE8tyzpzXVc3DOPUtu0TxJTSk8BzG8PA1z/cdk7aPeP9MPAa4+HgvPXx9hcMOIeRj46OfkrTFIqHMfYgBinAG8eQcgnDSQIp4xBMMvWv3TPrRNf1+c3NTWJZ1rMkSdT5aQzGAUC9s1hKwf0w4SmX6tsZxfzGCdNRnEHHsN4ohmjc/v7+j3EcYyTJOZcYHJlxziGOpzjNGEjOoOuOgA4iCMYTvA1Zc8EZ9CmtqUTgW6/Xf8CAGEwIITOULwUIIYCzDLWCPYrh/Y0NzY4HzjiG8QT3q0tRBVgYcH19faFWqxFK6fNcssDTSZopb4QEoIMJcCEhTDn4YQJSytxOUWCOq+M4NbKysrJCCFnQNO1VFEVKMuNcRlEMVhAq428sH/7s+nDVC+Av04csS5UVSCDLMsUQV8uyamRpaQlr6JNGo/ECN3AhpLpWcGg5Y7AGkZLW9UK4tcfgDidKBG7Lg6EtGBMoSi6Xy1+jh57nfVdITpiQ19YAmr0B3DghfDAD2LuiwCWAM4pgGE3Li3F+T7Jt24ohdsGnx8fHLzEgJuTKGMiLjw4kGYM4Y9BxhvA3HanEhHECQRirgAVDKeW/DBcXF58SQj47evfuJXqYpJm8tUfy2vDA9MO8bGIYhKqkALPPWHbPQ6zTOw83NjYWdF0npmk+x06ReZZ7XggXbf9/ncL5tJSm+AHJ2MvooaZp3yMTkEKOolT+0XFVWeBhvCg3v2CkAqWKLVNJwVVJ9n1f9fLh4eGrSVE2jMk0TVTRYtfNdg0GKbx7sGwuLy/nt7e3iWEYz1imspf9p5fvYTyMjAqMCQGANJf85m7aaJr2M9YYni2kIYuCVYGRaS5ztg7V2u/368U8nNvZ2fnm4uq6QWn/wHGcg1ar9bbf7//med6v3W73d/wXBMEeYkpp3XXdg3a7/dY0Tc113b1er3fabDZfFwO7mNafF8MC23EG49Sen8Gls7Ozuz27u7uIcWo9Kg6Qra0tzHaJCWXBXJH9tbW1cqVSqS4vLz8ul8tr1Wq1srq6WtE0bT7fM9fpdApc+gc0WAWZVrhbCQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/d878eef0f4b726da8c48e1f411322ba2/d9ecf/output_4_0.png\"\n        srcset=\"/static/d878eef0f4b726da8c48e1f411322ba2/e9ff0/output_4_0.png 180w,\n/static/d878eef0f4b726da8c48e1f411322ba2/d9ecf/output_4_0.png 330w\"\n        sizes=\"(max-width: 330px) 100vw, 330px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>linear_model <span class=\"token keyword\">import</span> LinearRegression\n<span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np \n\nX <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">)</span>\nY <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span>Y<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Iris Dataset을 Linear Regression으로 학습합니다. </span>\nlinear<span class=\"token operator\">=</span> LinearRegression<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nlinear<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> Y<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Linear Regression의 기울기와 절편을 확인합니다. </span>\na<span class=\"token punctuation\">,</span> b<span class=\"token operator\">=</span>linear<span class=\"token punctuation\">.</span>coef_<span class=\"token punctuation\">,</span> linear<span class=\"token punctuation\">.</span>intercept_\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"기울기 : %0.2f, 절편 : %0.2f\"</span> <span class=\"token operator\">%</span><span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">,</span>b<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">기울기 : 1.00, 절편 : 1.06</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">plt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>scatter<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span>Y<span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span>linear<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token string\">'-b'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'petal-sepal scatter with linear regression'</span><span class=\"token punctuation\">)</span> \nplt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">'petal length (cm)'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'sepal length (cm)'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>grid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 336px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 98.88888888888889%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAAsTAAALEwEAmpwYAAAD5UlEQVQ4y4VUS28bVRQ+tSseUgUVJEoARzJIoPyG7FixZJMNC7yBfdRKiKLCjh+DWqBpJVCSWnmI0ipRbJPMuKkdJ/Y8Etfxa2LPeObOfRx07thWKEhc6Wq++/B3z3e+cwyICDQMw6DPGwDwPgC8CwAfAMA745kBgJsAMAcAswAwDwBvA8B7V9bX7MYxQKlUSgHAjc3NzS8sy9qp1+sbtm2vVyqVLdu2NyzLelyr1fKO46w5jrPeaDTWXNt6THjvr/LW6elJ/mXTXm/Um/m93Wefgud5aYrStu27Sin8v0F3RnFyrzti+lu3EZ0mx6OK+TUgYooIK5XKN1EUoRCCcc55FEVcCKEnYRoT7HZ9jig4GwmefzLkhzWfdYY+Pt0rfTklNAzjLmOMCGmoKNIYhZRI+5xzVFKiiGPsBD423BgLRYbegClEKQTnaJpGThPW63U4Ozu7HccxKRBKKSUEn8qUQiAqxPPLEZ5ceLj2bID7hzGGjO5LygIFgaZp5mBlZeV1ALheKBR+IMlxHNNryhsGOAgiDCKGXc9HIRm67QDXdwZYbxCR0JGHYaSIjfDBwUEOMplMhiRThCRL30RUQciwNYhwxARaPQ+LVR8f5H08cYOxOYhCSJRSkkNCSonlcjkH8/PzHxJhtVr9liRLKQUmIrD68hKZ5GgcRbjxxMeS1ccRC1FJpa9QAJxzTTiVPDMz8wkApMvl8p0wJJe58PxQnbS6WGp0Mf9ngA932njgXCDjHC/6QwzCSOc1YoxkTyUfHh7mYG5u7iOKsNls3tJOKhTGeU/tvuhjoaTQbQl0+wOstYZaat8PMYxFYpb8D8mzs7MfU6cUS6XvGYtQqlhs7vfU71sedrxQp9QbjLB9GegyYlE0kapxFL1iyvLy8puJKe5txmKsN5RwHVSVZg+Pmp6OJDEr6Y4kzwnWdSrEP3M4Kezj4+ffWVaMXk+JThCoWrOvSeSVwp5g+jFhIo/jWJctnRuGkYNut6t7uVx+fofqkB6LY67iJNkq6ZpIkZuvYjKEJlUGkWtTvH5fE7quc0tJnewoUal18glWSv0LSyn1RERGEZumqXs5TZ2yt1/48cLzkScyKNla5gST1AmmrzYlKZspNk3zKzBfHKe2/ngKu/uFz4vl6mav17vX6XR+OT09/a3dbv/qed59x3Eedbvdn4fD4U+O4zxstVoP+v3+fdd1H9GZ53n3zs/P11ZXVz+DyRj/c6cdx4EgCAi/Rnvj/ZtX8FsAkNre3obJXrFYnJzdmG4i4jWalFPfD9LjdWpxcXEum81mstnswsLCQpbWS0tL9EB6XCEpy7Kuj1MHfwOMqArQb760ogAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/2fc7c4278cbcf1ba6b256f6e838832b6/d99f2/output_6_0.png\"\n        srcset=\"/static/2fc7c4278cbcf1ba6b256f6e838832b6/e9ff0/output_6_0.png 180w,\n/static/2fc7c4278cbcf1ba6b256f6e838832b6/d99f2/output_6_0.png 336w\"\n        sizes=\"(max-width: 336px) 100vw, 336px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\">#L1 regularization은 Lasso로 import 합니다.</span>\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>linear_model <span class=\"token keyword\">import</span> Lasso\n\nL1 <span class=\"token operator\">=</span> Lasso<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nL1<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> Y<span class=\"token punctuation\">)</span>\na<span class=\"token punctuation\">,</span> b<span class=\"token operator\">=</span>L1<span class=\"token punctuation\">.</span>coef_<span class=\"token punctuation\">,</span> L1<span class=\"token punctuation\">.</span>intercept_\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"기울기 : %0.2f, 절편 : %0.2f\"</span> <span class=\"token operator\">%</span><span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">,</span>b<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nplt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>scatter<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span>Y<span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span>L1<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token string\">'-b'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'petal-sepal scatter with L1 regularization(Lasso)'</span><span class=\"token punctuation\">)</span> \nplt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">'petal length (cm)'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'sepal length (cm)'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>grid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">기울기 : 0.00, 절편 : 6.59</code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 336px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 98.88888888888889%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAAsTAAALEwEAmpwYAAAD/ElEQVQ4y3VUW28bVRCexBUIgQCphIBIwCCB8hvyB+CNl7ziB+A9ah+ASognHvJTopZLqGiVJlUbqRVqi+s0ydqJY3sv3nidxPZ6413be66D5ngdcRFHGs3nOWe/c2bmG8Pa2hrYtj0DAO8BwDsA8AYAvA8ArwPAuwDwFgDMZf5lALgKAB9ksbezM3OZXQXXdWeJZH19/Wvbth81m83NWq320HGce47j3Pc8b8t13U3yvu/fazQa206jvtNsNreevKjcd113q+V7203XeXz3zu+fged5uSAIoNPpfKO1xun6P0wrZsr4XsJRasSEa4xTiXtW5UtAxFlEBMuyvkvTFKWUTAgh0jQVUkpjhDnnl7jdT4RWSiBKUQ1C4XVj1omG+KRY+uKSsFwu32CMESEtnZGjVAopzoVApRRKzrHZjbE7GGMySlEKQc+XWgosWwcFQ9hoNCAIguucczSbWmspxWWKSkrjne4QD/wQq+0B9kccx8xcYgjpcsuyCrC6ukqdu1IsFn9gjF7FpVJCR3GCg9EYR4xhJ4oxZQz7wzF2ogEqukxLFJwhY6lWSkrKYm9vrwALCwsLlPLpafvaeCyQsmYM9UXM0TsfY5RIPPQvsOREWLQv0DsbIvExjjgeKzLNOVVCYaVSLsD8/PyHADBTrZZvtFop1utCeq7Uns3xwZ8RVqoM98pDfFwa4PbTCI+qY3QdgbYjsV5n2Ggw3WhI2W4zPDzcL8Dc3NwnRHh8fPytlFRDLZOU6eN2iOUgxLPBCF80O7jb7FI1sRcnyCbnUGtBpukbavrBwYF54UeUchAE14SgAyif2T191IoIY5JKdM9jtDuJaUyUpDjmkyZJqchMU0gB5XLZvPBjAHh1d3f3e2pKyristSNdC0LsDkaolcR4OMLeYGhkxNIU6WIyakSapppafNmUlZWVV8IwhFarZWRDiqF8qkHfyIMWfYzZtNCZiVJwolMp/ymbqbArlYoRNtUj6A91/bRv6qQyYYtM2Jn4DSZyzrmRLe2bGjLGchnhdPQkF0JzxigVnU2NFkL8BzPGjCmlJJHv7+8XIOx1DeHJiX+d6oWI6SRLyhPFFGtq6b+wUsoYIjJ6sWVZZpZzNCnPis9/PI8SFJM0qNgmzSk285xh8tOmTMtB3rKsr8A6qs0+fPQHPC0+/7xUPn4QhuHNbrf7s23bdzqdzi9RFN3yff92r9f7KY7jdd/3fzs7O/u13+/fOjk5uU17URTdDIJgc2Nj41OYLkobAHK+78NwOCT8EsWy+Jt/w/RPPruzswPTWKlUmu69dhlExBmyqN/PJckwl/2eXVpams/n8wv5fH5xcXExT7+Xl5fpglymkFnP865kpYO/AHq4BOl4qIQaAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/c1c3d0dc2cedc5cab88e3cfd8fca76c0/d99f2/output_7_1.png\"\n        srcset=\"/static/c1c3d0dc2cedc5cab88e3cfd8fca76c0/e9ff0/output_7_1.png 180w,\n/static/c1c3d0dc2cedc5cab88e3cfd8fca76c0/d99f2/output_7_1.png 336w\"\n        sizes=\"(max-width: 336px) 100vw, 336px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>이게 Lasso 방식이고</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\">#L2 regularization은 Ridge로 import 합니다. </span>\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>linear_model <span class=\"token keyword\">import</span> Ridge\n\nL2 <span class=\"token operator\">=</span> Ridge<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nL2<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> Y<span class=\"token punctuation\">)</span>\na<span class=\"token punctuation\">,</span> b <span class=\"token operator\">=</span> L2<span class=\"token punctuation\">.</span>coef_<span class=\"token punctuation\">,</span> L2<span class=\"token punctuation\">.</span>intercept_\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"기울기 : %0.2f, 절편 : %0.2f\"</span> <span class=\"token operator\">%</span><span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">,</span>b<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nplt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>scatter<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span>Y<span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span>L2<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token string\">'-b'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'petal-sepal scatter with L2 regularization(Ridge)'</span><span class=\"token punctuation\">)</span> \nplt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">'petal length (cm)'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'sepal length (cm)'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>grid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">기울기 : 0.93, 절편 : 1.41</code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 336px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 98.88888888888889%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAAsTAAALEwEAmpwYAAAD60lEQVQ4y3VUTW8bVRS9sStQBQIkMAaRgEEC9TfkD7BgwSZbsgD2UbOAVkKsWOSnRC2koRIlSSNqqdCEynHjZJwmcTzjsZ2xnYlnJvbYnnlfF93nsQUFnvR0z1zPO3PPvecZVlZWwDTNGQB4DwDeAYDXAeB9AHgNAN4FgLcAIJPE6wDwJgB8kOTeTs7Q2Q91rlarpYhkdXX1a9M0H9fr9Y1KpfLIsqxNy7K2bdveqtVqmxTr9fpWtVp9aFXP8oR39o+2Lcvaci+aG2a1snNvbe0zsG077TgOuK77jVIKJ+v/MK1+LHXsDpiOjTaidS7x5Oz4S0DEFCKCYRi3oihCIUTMOedRFHEhhN6EGWNT7HRDjig4CsHzu31eej6KO36Iu4XiF1PCcrl8O45jIqSlEnIUUiLlGafzEjlj2Or18bwT496zGF2XK0QllORoHB4uasJqtQqO4ywzpiUIpZSSgk8lSil0tL0BPm95+PDpFRZLAocjnryu60DDMBZhaWnpZQC4VigUvqeqGGNCcK68XohBOMJwFGPb6yMXEba9Ieb/CLFWIyKOjMU4GkWK2EhFqVRahNnZ2VmS3Gq1bnKuq6Jy1Chm6PgjHDKJtneFT4werm728LQejgdFL0qJUsoESiyXy4uQzWbJPzPUQ6qQcy6kEEqwGE03wP4owr3SEPO7fTxxAozYCAXnyIXQvY3jeFrhwcHBImQymU+I8PT09NuYMbKI8MNYnXU83D3xMb8T4YMdF/ebrq6IpjmMmK6RFHHOqeWC8CENJZvNfkSSHce5ydlY8n6zq/LFAA8OEP2eROeqh+bFWOrVIMKIi2RY/yE5k8l8DACvFIvPvhMiwlHExK+/X6ntHR+9cKhb2guH2O0NtI3icVv0JplR9MJQFhYWroehB+32+bLnMaxUlAh7qEzXx+NWT1eih5XcFrLWuCgc+1QINYaJbSbGPjk5ut1qMxRMCbc/UBXH132SibGJdILpMGEiZ4z9s4dxHKeJ8Ojo6BbnEZlYMMYVG09PJbdGUfNfxDRh2lJKQeR6yl73UhM2m41lKXSzo7FKPnZvgpVS/8JSSr0RMaaKDcPQdzlNN+VpYe+HiyDUd5W+lnhyivV9TjDFyVAm7aBoGMZXYBxXUo8eP4E/C3ufF8unv3med+fy8vIn0zR/cV13LQiCu41G43632/2x3++vNhqNnzudzj3f9+82m8379FsQBHccx9lYX1//FCaLZANAutFowGAwIPwS5ZL8G3/D9E+eyufzMMkVi8XJb69Ok4g4Qzvw/XQYDtLJc+rGjRvZXC43m8vl5ubm5nL0PD8/Tx9IJw5J2bZ9LWkd/AUa/wOfIeMgQQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/6ffbbbf6f87c1e36c5b43fd3ea8ac4d5/d99f2/output_9_1.png\"\n        srcset=\"/static/6ffbbbf6f87c1e36c5b43fd3ea8ac4d5/e9ff0/output_9_1.png 180w,\n/static/6ffbbbf6f87c1e36c5b43fd3ea8ac4d5/d99f2/output_9_1.png 336w\"\n        sizes=\"(max-width: 336px) 100vw, 336px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>이게 Ridge 방법<br>\n기존 방법보다 축은 위로 쫌 이동했지만</p>\n<p>기울기가 좀 줄었다</p>\n<p>이 두 방식은 Regularization\n다시말해 오버피팅을 방지한 것이다</p>\n<hr>\n<p>, L1 Regularization을 사용할 때는 X가 2차원 이상인 여러 컬럼 값이 있는 데이터일 때 실제 효과를 볼 수 있습니다.</p>\n<p>x가 1차원이었던 iris 꽃잎길이데이터같은 따분한거 쓰지말고</p>\n<p>어른의 데이터인 wine dataset을 볼까?</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>datasets <span class=\"token keyword\">import</span> load_wine\n\nwine <span class=\"token operator\">=</span> load_wine<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nwine_df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span>data<span class=\"token operator\">=</span>wine<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">,</span> columns<span class=\"token operator\">=</span>wine<span class=\"token punctuation\">.</span>feature_names<span class=\"token punctuation\">)</span>\ntarget_df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span>data<span class=\"token operator\">=</span>wine<span class=\"token punctuation\">.</span>target<span class=\"token punctuation\">,</span> columns<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'Y'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">wine_df<span class=\"token punctuation\">.</span>head<span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}</code></pre></div>\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>alcohol</th>\n      <th>malic_acid</th>\n      <th>ash</th>\n      <th>alcalinity_of_ash</th>\n      <th>magnesium</th>\n      <th>total_phenols</th>\n      <th>flavanoids</th>\n      <th>nonflavanoid_phenols</th>\n      <th>proanthocyanins</th>\n      <th>color_intensity</th>\n      <th>hue</th>\n      <th>od280/od315_of_diluted_wines</th>\n      <th>proline</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>14.23</td>\n      <td>1.71</td>\n      <td>2.43</td>\n      <td>15.6</td>\n      <td>127.0</td>\n      <td>2.80</td>\n      <td>3.06</td>\n      <td>0.28</td>\n      <td>2.29</td>\n      <td>5.64</td>\n      <td>1.04</td>\n      <td>3.92</td>\n      <td>1065.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>13.20</td>\n      <td>1.78</td>\n      <td>2.14</td>\n      <td>11.2</td>\n      <td>100.0</td>\n      <td>2.65</td>\n      <td>2.76</td>\n      <td>0.26</td>\n      <td>1.28</td>\n      <td>4.38</td>\n      <td>1.05</td>\n      <td>3.40</td>\n      <td>1050.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13.16</td>\n      <td>2.36</td>\n      <td>2.67</td>\n      <td>18.6</td>\n      <td>101.0</td>\n      <td>2.80</td>\n      <td>3.24</td>\n      <td>0.30</td>\n      <td>2.81</td>\n      <td>5.68</td>\n      <td>1.03</td>\n      <td>3.17</td>\n      <td>1185.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>14.37</td>\n      <td>1.95</td>\n      <td>2.50</td>\n      <td>16.8</td>\n      <td>113.0</td>\n      <td>3.85</td>\n      <td>3.49</td>\n      <td>0.24</td>\n      <td>2.18</td>\n      <td>7.80</td>\n      <td>0.86</td>\n      <td>3.45</td>\n      <td>1480.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>13.24</td>\n      <td>2.59</td>\n      <td>2.87</td>\n      <td>21.0</td>\n      <td>118.0</td>\n      <td>2.80</td>\n      <td>2.69</td>\n      <td>0.39</td>\n      <td>1.82</td>\n      <td>4.32</td>\n      <td>1.04</td>\n      <td>2.93</td>\n      <td>735.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">target_df<span class=\"token punctuation\">.</span>head<span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}</code></pre></div>\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>model_selection <span class=\"token keyword\">import</span> train_test_split\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>linear_model <span class=\"token keyword\">import</span> LinearRegression\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>metrics <span class=\"token keyword\">import</span> mean_absolute_error<span class=\"token punctuation\">,</span> mean_squared_error\n\n<span class=\"token comment\"># 데이터를 준비하고</span>\nX_train<span class=\"token punctuation\">,</span> X_test<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> y_test <span class=\"token operator\">=</span> train_test_split<span class=\"token punctuation\">(</span>wine_df<span class=\"token punctuation\">,</span> target_df<span class=\"token punctuation\">,</span> test_size<span class=\"token operator\">=</span><span class=\"token number\">0.3</span><span class=\"token punctuation\">,</span> random_state<span class=\"token operator\">=</span><span class=\"token number\">101</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 모델을 훈련시킵니다.</span>\nmodel <span class=\"token operator\">=</span> LinearRegression<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 테스트를 해볼까요?</span>\nmodel<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>X_test<span class=\"token punctuation\">)</span>\npred <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>X_test<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 테스트 결과는 이렇습니다!</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"result of linear regression\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Mean Absolute Error:'</span><span class=\"token punctuation\">,</span> mean_absolute_error<span class=\"token punctuation\">(</span>y_test<span class=\"token punctuation\">,</span> pred<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Mean Squared Error:'</span><span class=\"token punctuation\">,</span> mean_squared_error<span class=\"token punctuation\">(</span>y_test<span class=\"token punctuation\">,</span> pred<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Mean Root Squared Error:'</span><span class=\"token punctuation\">,</span> np<span class=\"token punctuation\">.</span>sqrt<span class=\"token punctuation\">(</span>mean_squared_error<span class=\"token punctuation\">(</span>y_test<span class=\"token punctuation\">,</span> pred<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\n\\n coefficient linear regression\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">.</span>coef_<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">result of linear regression\nMean Absolute Error: 0.25128973939722626\nMean Squared Error: 0.1062458740952556\nMean Root Squared Error: 0.32595379134971814\n\n\n coefficient linear regression\n[[-8.09017190e-02  4.34817880e-02 -1.18857931e-01  3.65705449e-02\n  -4.68014203e-04  1.41423581e-01 -4.54107854e-01 -5.13172664e-01\n   9.69318443e-02  5.34311136e-02 -1.27626604e-01 -2.91381844e-01\n  -5.72238959e-04]]</code></pre></div>\n<p>선형회귀로 문제를 풀고</p>\n<p>계수(coefficient)</p>\n<p>절대 오차 ( mean absolute error)</p>\n<p>제곱 오차 ( mean squared error)</p>\n<p>평균 제곱값 오차 (root mean squared error)</p>\n<p>를 출력</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>model_selection <span class=\"token keyword\">import</span> train_test_split\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>linear_model <span class=\"token keyword\">import</span> LinearRegression\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>metrics <span class=\"token keyword\">import</span> mean_absolute_error<span class=\"token punctuation\">,</span> mean_squared_error\n\n<span class=\"token comment\"># 데이터를 준비하고</span>\nX_train<span class=\"token punctuation\">,</span> X_test<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> y_test <span class=\"token operator\">=</span> train_test_split<span class=\"token punctuation\">(</span>wine_df<span class=\"token punctuation\">,</span> target_df<span class=\"token punctuation\">,</span> test_size<span class=\"token operator\">=</span><span class=\"token number\">0.3</span><span class=\"token punctuation\">,</span> random_state<span class=\"token operator\">=</span><span class=\"token number\">101</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 모델을 훈련시킵니다.</span>\nmodel <span class=\"token operator\">=</span> LinearRegression<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 테스트를 해볼까요?</span>\nmodel<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>X_test<span class=\"token punctuation\">)</span>\npred <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>X_test<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 테스트 결과는 이렇습니다!</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"result of linear regression\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Mean Absolute Error:'</span><span class=\"token punctuation\">,</span> mean_absolute_error<span class=\"token punctuation\">(</span>y_test<span class=\"token punctuation\">,</span> pred<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Mean Squared Error:'</span><span class=\"token punctuation\">,</span> mean_squared_error<span class=\"token punctuation\">(</span>y_test<span class=\"token punctuation\">,</span> pred<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Mean Root Squared Error:'</span><span class=\"token punctuation\">,</span> np<span class=\"token punctuation\">.</span>sqrt<span class=\"token punctuation\">(</span>mean_squared_error<span class=\"token punctuation\">(</span>y_test<span class=\"token punctuation\">,</span> pred<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\n\\n coefficient linear regression\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">.</span>coef_<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">result of linear regression\nMean Absolute Error: 0.25128973939722626\nMean Squared Error: 0.1062458740952556\nMean Root Squared Error: 0.32595379134971814\n\n\n coefficient linear regression\n[[-8.09017190e-02  4.34817880e-02 -1.18857931e-01  3.65705449e-02\n  -4.68014203e-04  1.41423581e-01 -4.54107854e-01 -5.13172664e-01\n   9.69318443e-02  5.34311136e-02 -1.27626604e-01 -2.91381844e-01\n  -5.72238959e-04]]</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>linear_model <span class=\"token keyword\">import</span> Lasso\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>metrics <span class=\"token keyword\">import</span> mean_absolute_error<span class=\"token punctuation\">,</span> mean_squared_error\n\n<span class=\"token comment\"># 모델을 준비하고 훈련시킵니다.</span>\nL1 <span class=\"token operator\">=</span> Lasso<span class=\"token punctuation\">(</span>alpha<span class=\"token operator\">=</span><span class=\"token number\">0.05</span><span class=\"token punctuation\">)</span>\nL1<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 테스트를 해봅시다.</span>\npred <span class=\"token operator\">=</span> L1<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>X_test<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 모델 성능은 얼마나 좋을까요?</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"result of Lasso\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Mean Absolute Error:'</span><span class=\"token punctuation\">,</span> mean_absolute_error<span class=\"token punctuation\">(</span>y_test<span class=\"token punctuation\">,</span> pred<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Mean Squared Error:'</span><span class=\"token punctuation\">,</span> mean_squared_error<span class=\"token punctuation\">(</span>y_test<span class=\"token punctuation\">,</span> pred<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Mean Root Squared Error:'</span><span class=\"token punctuation\">,</span> np<span class=\"token punctuation\">.</span>sqrt<span class=\"token punctuation\">(</span>mean_squared_error<span class=\"token punctuation\">(</span>y_test<span class=\"token punctuation\">,</span> pred<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\n\\n coefficient of Lasso\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>L1<span class=\"token punctuation\">.</span>coef_<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">result of Lasso\nMean Absolute Error: 0.24233731936122138\nMean Squared Error: 0.0955956894578189\nMean Root Squared Error: 0.3091855259513597\n\n\n coefficient of Lasso\n[-0.          0.01373795 -0.          0.03065716  0.00154719 -0.\n -0.34143614 -0.          0.          0.06755943 -0.         -0.14558153\n -0.00089635]</code></pre></div>\n<p>coefficient 부분을 보시면 Linear Regression과 L1 Regularization의 차이가 좀 더 두드러짐</p>\n<p>inear Regression에서는 모든 컬럼의 가중치를 탐색하여 구하는 반면, L1 Regularization에서는 총 13개 중 7개를 제외한 나머지의 값들이 모두 0임</p>\n<h2 id=\"l2-norm--ridge\" style=\"position:relative;\"><a href=\"#l2-norm--ridge\" aria-label=\"l2 norm  ridge permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>L2 norm  Ridge</h2>\n<p><img src=\"attachment:image.png\" alt=\"image.png\"></p>\n<p>보면 L1 은 걍 절댓값만 씌우고</p>\n<p>L2 는 제곱을 해,,! 그 차이야,,!!</p>\n<p><img src=\"attachment:image-2.png\" alt=\"image-2.png\"></p>\n<p>L2 는 제곱을 하기 때문에 저렇게 원의 형태가 나와</p>\n<p>하지만 L1 은 사각형이지</p>\n<p>제곱이라 수렴 속도도 빠름 더 가까운 길을 찾을 수 있잖아</p>\n<p>정리하면, L1 Regularization은 가중치가 적은 벡터에 해당하는 계수를 0으로 보내면서 차원 축소와 비슷한 역할을 하는 것이 특징이며, L2 Regularization은 0이 아닌 0에 가깝게 보내지만 제곱 텀이 있기 때문에 L1 Regularization보다는 수렴 속도가 빠르다는 장점</p>\n<p>예를 들어, A=[1,1,1,1,1]A=[1,1,1,1,1] , B=[5,0,0,0,0]B=[5,0,0,0,0] 의 경우<br>\nL1-norm은 같지만, L2-norm은 같지 않습니다.<br>\n즉, 제곱 텀에서 결과에 큰 영향을 미치는 값은 더 크게,<br>\n결과에 영향이 적은 값들은 더 작게 보내면서 수렴 속도가 빨라지는 것입니다.</p>\n<h4 id=\"그러므로-데이터에-따라-적절한-regularization-방법을-활용하는-것이-좋습니다\" style=\"position:relative;\"><a href=\"#%EA%B7%B8%EB%9F%AC%EB%AF%80%EB%A1%9C-%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%97%90-%EB%94%B0%EB%9D%BC-%EC%A0%81%EC%A0%88%ED%95%9C-regularization-%EB%B0%A9%EB%B2%95%EC%9D%84-%ED%99%9C%EC%9A%A9%ED%95%98%EB%8A%94-%EA%B2%83%EC%9D%B4-%EC%A2%8B%EC%8A%B5%EB%8B%88%EB%8B%A4\" aria-label=\"그러므로 데이터에 따라 적절한 regularization 방법을 활용하는 것이 좋습니다 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>그러므로, 데이터에 따라 적절한 Regularization 방법을 활용하는 것이 좋습니다.</h4>\n<h2 id=\"근데-그래서-norm-이란게-뭘까\" style=\"position:relative;\"><a href=\"#%EA%B7%BC%EB%8D%B0-%EA%B7%B8%EB%9E%98%EC%84%9C-norm-%EC%9D%B4%EB%9E%80%EA%B2%8C-%EB%AD%98%EA%B9%8C\" aria-label=\"근데 그래서 norm 이란게 뭘까 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>근데 그래서 Norm 이란게 뭘까…?</h2>\n<ol>\n<li>vector norm</li>\n<li>matrix norm</li>\n</ol>\n<p>Norm이라는 개념은 벡터뿐만 아니라 함수, 행렬에 대해서 크기를 구하는 것으로, 딥러닝을 배우는 과정에서는 주로 벡터, 좀 더 어렵게는 행렬의 Norm 정도만 알면 됩니다.</p>\n<p><img src=\"attachment:image.png\" alt=\"image.png\"></p>\n<ol>\n<li>vector</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">x<span class=\"token operator\">=</span>np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\np<span class=\"token operator\">=</span><span class=\"token number\">5</span>\n\nnorm_x<span class=\"token operator\">=</span>np<span class=\"token punctuation\">.</span>linalg<span class=\"token punctuation\">.</span>norm<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> <span class=\"token builtin\">ord</span><span class=\"token operator\">=</span>p<span class=\"token punctuation\">)</span>\n\nmaking_norm <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>x<span class=\"token operator\">**</span>p<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token operator\">**</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token operator\">/</span>p<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"result of numpy package norm function : %0.5f \"</span><span class=\"token operator\">%</span>norm_x<span class=\"token punctuation\">)</span> \n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"result of making norm : %0.5f \"</span><span class=\"token operator\">%</span>making_norm<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">result of numpy package norm function : 10.00008 \nresult of making norm : 10.00008 </code></pre></div>\n<ol start=\"2\">\n<li>matrix</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">A<span class=\"token operator\">=</span>np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">[</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span><span class=\"token number\">6</span><span class=\"token punctuation\">,</span><span class=\"token number\">8</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\ninf_norm_A<span class=\"token operator\">=</span>np<span class=\"token punctuation\">.</span>linalg<span class=\"token punctuation\">.</span>norm<span class=\"token punctuation\">(</span>A<span class=\"token punctuation\">,</span> <span class=\"token builtin\">ord</span><span class=\"token operator\">=</span>np<span class=\"token punctuation\">.</span>inf<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"result inf norm of A :\"</span><span class=\"token punctuation\">,</span> inf_norm_A<span class=\"token punctuation\">)</span>\none_norm_A<span class=\"token operator\">=</span>np<span class=\"token punctuation\">.</span>linalg<span class=\"token punctuation\">.</span>norm<span class=\"token punctuation\">(</span>A<span class=\"token punctuation\">,</span> <span class=\"token builtin\">ord</span><span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"result one norm of A :\"</span><span class=\"token punctuation\">,</span> one_norm_A<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">result inf norm of A : 18.0\nresult one norm of A : 14.0</code></pre></div>\n<h2 id=\"dropout-은-뭔데\" style=\"position:relative;\"><a href=\"#dropout-%EC%9D%80-%EB%AD%94%EB%8D%B0\" aria-label=\"dropout 은 뭔데 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Dropout 은 뭔데?</h2>\n<p><a href=\"https://jmlr.org/papers/v15/srivastava14a.html\">Dropout 논문</a></p>\n<p>Dropout 은 Regularization 으로 오버피팅을 막는 정칙화 이다.</p>\n<p>fully connected layer에서 오버피팅이 생기는 경우에 주로 Dropout layer를 추가합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n<span class=\"token keyword\">from</span> tensorflow <span class=\"token keyword\">import</span> keras\n<span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n<span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>model_selection <span class=\"token keyword\">import</span> train_test_split\n\nfashion_mnist <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>datasets<span class=\"token punctuation\">.</span>fashion_mnist\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'=3'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">=3</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token punctuation\">(</span>train_images<span class=\"token punctuation\">,</span> train_labels<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>test_images<span class=\"token punctuation\">,</span> test_labels<span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> fashion_mnist<span class=\"token punctuation\">.</span>load_data<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nclass_names <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'T-shirt/top'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Trouser'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Pullover'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Dress'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Coat'</span><span class=\"token punctuation\">,</span>\n               <span class=\"token string\">'Sandal'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Shirt'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Sneaker'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Bag'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Ankle boot'</span><span class=\"token punctuation\">]</span>\n\ntrain_images <span class=\"token operator\">=</span> train_images <span class=\"token operator\">/</span> <span class=\"token number\">255.0</span>\ntest_images <span class=\"token operator\">=</span> test_images <span class=\"token operator\">/</span> <span class=\"token number\">255.0</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">model <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n    keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span>input_shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">28</span><span class=\"token punctuation\">,</span> <span class=\"token number\">28</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">128</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token comment\"># 여기에 dropout layer를 추가해보았습니다. 나머지 layer는 아래의 실습과 같습니다.</span>\n    keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dropout<span class=\"token punctuation\">(</span><span class=\"token number\">0.9</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span><span class=\"token string\">'adam'</span><span class=\"token punctuation\">,</span>loss<span class=\"token operator\">=</span><span class=\"token string\">'sparse_categorical_crossentropy'</span><span class=\"token punctuation\">,</span>\n              metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nhistory<span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>train_images<span class=\"token punctuation\">,</span> train_labels<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Epoch 1/5\n1875/1875 [==============================] - 5s 2ms/step - loss: 1.4060 - accuracy: 0.4571\nEpoch 2/5\n1875/1875 [==============================] - 4s 2ms/step - loss: 1.1796 - accuracy: 0.5296\nEpoch 3/5\n1875/1875 [==============================] - 4s 2ms/step - loss: 1.1358 - accuracy: 0.5459\nEpoch 4/5\n1875/1875 [==============================] - 4s 2ms/step - loss: 1.1104 - accuracy: 0.5530\nEpoch 5/5\n1875/1875 [==============================] - 4s 2ms/step - loss: 1.0902 - accuracy: 0.5628</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">model <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n    keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span>input_shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">28</span><span class=\"token punctuation\">,</span> <span class=\"token number\">28</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token comment\"># 이번에는 dropout layer가 없습니다. </span>\n    keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">128</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span><span class=\"token string\">'adam'</span><span class=\"token punctuation\">,</span>loss<span class=\"token operator\">=</span><span class=\"token string\">'sparse_categorical_crossentropy'</span><span class=\"token punctuation\">,</span>\n              metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nhistory <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>train_images<span class=\"token punctuation\">,</span> train_labels<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Epoch 1/5\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.5047 - accuracy: 0.8254\nEpoch 2/5\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.3759 - accuracy: 0.8648\nEpoch 3/5\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.3370 - accuracy: 0.8777\nEpoch 4/5\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.3138 - accuracy: 0.8853\nEpoch 5/5\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.2967 - accuracy: 0.8910</code></pre></div>\n<p>보면 드랍아웃을 0.9로 주면 정확도가 56% 이다</p>\n<p>아무것도 안한게 89% 인데 ㅋ 어이없어 저렇겐 쓰지마</p>\n<p>근데 오버피팅 줄일때 써봐</p>\n<h3 id=\"overfitting-줄이는-법\" style=\"position:relative;\"><a href=\"#overfitting-%EC%A4%84%EC%9D%B4%EB%8A%94-%EB%B2%95\" aria-label=\"overfitting 줄이는 법 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>overfitting 줄이는 법</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">X_train<span class=\"token punctuation\">,</span> X_valid<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> y_valid <span class=\"token operator\">=</span> train_test_split<span class=\"token punctuation\">(</span>train_images<span class=\"token punctuation\">,</span> train_labels<span class=\"token punctuation\">,</span> test_size<span class=\"token operator\">=</span><span class=\"token number\">0.01</span><span class=\"token punctuation\">,</span> random_state<span class=\"token operator\">=</span><span class=\"token number\">101</span><span class=\"token punctuation\">)</span>\nX_train <span class=\"token operator\">=</span> X_train <span class=\"token operator\">/</span> <span class=\"token number\">255.0</span>\nX_valid <span class=\"token operator\">=</span> X_valid <span class=\"token operator\">/</span> <span class=\"token number\">255.0</span>\n\n<span class=\"token comment\">#Dense layer만으로 만들어 낸 classification 모델입니다.</span>\nmodel <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n    keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span>input_shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">28</span><span class=\"token punctuation\">,</span> <span class=\"token number\">28</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">256</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span><span class=\"token string\">'adam'</span><span class=\"token punctuation\">,</span>loss<span class=\"token operator\">=</span><span class=\"token string\">'sparse_categorical_crossentropy'</span><span class=\"token punctuation\">,</span>\n              metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nhistory<span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">200</span><span class=\"token punctuation\">,</span> batch_size<span class=\"token operator\">=</span><span class=\"token number\">512</span><span class=\"token punctuation\">,</span> validation_data<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>X_valid<span class=\"token punctuation\">,</span> y_valid<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Epoch 1/200\n117/117 [==============================] - 1s 5ms/step - loss: 2.0499 - accuracy: 0.5479 - val_loss: 1.6354 - val_accuracy: 0.5983\nEpoch 2/200\n117/117 [==============================] - 0s 4ms/step - loss: 1.3857 - accuracy: 0.6154 - val_loss: 1.1556 - val_accuracy: 0.6817\nEpoch 3/200\n117/117 [==============================] - 0s 4ms/step - loss: 1.0562 - accuracy: 0.6812 - val_loss: 0.9326 - val_accuracy: 0.7333\nEpoch 4/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.8842 - accuracy: 0.7192 - val_loss: 0.8094 - val_accuracy: 0.7483\nEpoch 5/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.7847 - accuracy: 0.7343 - val_loss: 0.7366 - val_accuracy: 0.7650\nEpoch 6/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.7235 - accuracy: 0.7471 - val_loss: 0.6882 - val_accuracy: 0.7717\nEpoch 7/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.6827 - accuracy: 0.7565 - val_loss: 0.6565 - val_accuracy: 0.7850\nEpoch 8/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.6518 - accuracy: 0.7663 - val_loss: 0.6299 - val_accuracy: 0.7917\nEpoch 9/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.6271 - accuracy: 0.7739 - val_loss: 0.6132 - val_accuracy: 0.7933\nEpoch 10/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.6065 - accuracy: 0.7824 - val_loss: 0.5906 - val_accuracy: 0.7950\nEpoch 11/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.5883 - accuracy: 0.7897 - val_loss: 0.5751 - val_accuracy: 0.7967\nEpoch 12/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.5725 - accuracy: 0.7971 - val_loss: 0.5648 - val_accuracy: 0.8017\nEpoch 13/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.5597 - accuracy: 0.8016 - val_loss: 0.5587 - val_accuracy: 0.8000\nEpoch 14/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.5459 - accuracy: 0.8068 - val_loss: 0.5408 - val_accuracy: 0.8033\nEpoch 15/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.5356 - accuracy: 0.8118 - val_loss: 0.5273 - val_accuracy: 0.8000\nEpoch 16/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.5256 - accuracy: 0.8148 - val_loss: 0.5238 - val_accuracy: 0.8117\nEpoch 17/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.5163 - accuracy: 0.8192 - val_loss: 0.5124 - val_accuracy: 0.8117\nEpoch 18/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.8216 - val_loss: 0.5084 - val_accuracy: 0.8117\nEpoch 19/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.8243 - val_loss: 0.5048 - val_accuracy: 0.8133\nEpoch 20/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4931 - accuracy: 0.8270 - val_loss: 0.4947 - val_accuracy: 0.8183\nEpoch 21/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4868 - accuracy: 0.8289 - val_loss: 0.4901 - val_accuracy: 0.8167\nEpoch 22/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4807 - accuracy: 0.8313 - val_loss: 0.4836 - val_accuracy: 0.8233\nEpoch 23/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4756 - accuracy: 0.8335 - val_loss: 0.4753 - val_accuracy: 0.8250\nEpoch 24/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.8356 - val_loss: 0.4692 - val_accuracy: 0.8267\nEpoch 25/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.8366 - val_loss: 0.4710 - val_accuracy: 0.8283\nEpoch 26/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.8384 - val_loss: 0.4609 - val_accuracy: 0.8267\nEpoch 27/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.8388 - val_loss: 0.4640 - val_accuracy: 0.8250\nEpoch 28/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.8412 - val_loss: 0.4571 - val_accuracy: 0.8333\nEpoch 29/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.8428 - val_loss: 0.4522 - val_accuracy: 0.8333\nEpoch 30/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.8435 - val_loss: 0.4497 - val_accuracy: 0.8317\nEpoch 31/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.8450 - val_loss: 0.4491 - val_accuracy: 0.8317\nEpoch 32/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.8456 - val_loss: 0.4417 - val_accuracy: 0.8333\nEpoch 33/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.8473 - val_loss: 0.4395 - val_accuracy: 0.8367\nEpoch 34/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.8474 - val_loss: 0.4377 - val_accuracy: 0.8333\nEpoch 35/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.8487 - val_loss: 0.4360 - val_accuracy: 0.8317\nEpoch 36/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.8485 - val_loss: 0.4331 - val_accuracy: 0.8367\nEpoch 37/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8499 - val_loss: 0.4331 - val_accuracy: 0.8350\nEpoch 38/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.8499 - val_loss: 0.4268 - val_accuracy: 0.8333\nEpoch 39/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.8517 - val_loss: 0.4282 - val_accuracy: 0.8367\nEpoch 40/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.8526 - val_loss: 0.4243 - val_accuracy: 0.8400\nEpoch 41/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.8534 - val_loss: 0.4206 - val_accuracy: 0.8350\nEpoch 42/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4177 - accuracy: 0.8538 - val_loss: 0.4232 - val_accuracy: 0.8333\nEpoch 43/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4164 - accuracy: 0.8543 - val_loss: 0.4232 - val_accuracy: 0.8383\nEpoch 44/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4138 - accuracy: 0.8559 - val_loss: 0.4183 - val_accuracy: 0.8317\nEpoch 45/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4125 - accuracy: 0.8556 - val_loss: 0.4137 - val_accuracy: 0.8300\nEpoch 46/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4106 - accuracy: 0.8564 - val_loss: 0.4153 - val_accuracy: 0.8317\nEpoch 47/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4095 - accuracy: 0.8566 - val_loss: 0.4131 - val_accuracy: 0.8350\nEpoch 48/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.8581 - val_loss: 0.4158 - val_accuracy: 0.8400\nEpoch 49/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4059 - accuracy: 0.8577 - val_loss: 0.4130 - val_accuracy: 0.8333\nEpoch 50/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4032 - accuracy: 0.8588 - val_loss: 0.4109 - val_accuracy: 0.8367\nEpoch 51/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4019 - accuracy: 0.8594 - val_loss: 0.4092 - val_accuracy: 0.8317\nEpoch 52/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4010 - accuracy: 0.8599 - val_loss: 0.4081 - val_accuracy: 0.8350\nEpoch 53/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3985 - accuracy: 0.8603 - val_loss: 0.4027 - val_accuracy: 0.8333\nEpoch 54/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3972 - accuracy: 0.8607 - val_loss: 0.4011 - val_accuracy: 0.8367\nEpoch 55/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3959 - accuracy: 0.8609 - val_loss: 0.4045 - val_accuracy: 0.8367\nEpoch 56/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3946 - accuracy: 0.8608 - val_loss: 0.3998 - val_accuracy: 0.8383\nEpoch 57/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3925 - accuracy: 0.8622 - val_loss: 0.3959 - val_accuracy: 0.8367\nEpoch 58/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3920 - accuracy: 0.8624 - val_loss: 0.3958 - val_accuracy: 0.8383\nEpoch 59/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3905 - accuracy: 0.8628 - val_loss: 0.3966 - val_accuracy: 0.8350\nEpoch 60/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3898 - accuracy: 0.8634 - val_loss: 0.3964 - val_accuracy: 0.8417\nEpoch 61/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3877 - accuracy: 0.8642 - val_loss: 0.3943 - val_accuracy: 0.8333\nEpoch 62/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3858 - accuracy: 0.8643 - val_loss: 0.3931 - val_accuracy: 0.8450\nEpoch 63/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3848 - accuracy: 0.8643 - val_loss: 0.3928 - val_accuracy: 0.8433\nEpoch 64/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3840 - accuracy: 0.8642 - val_loss: 0.3893 - val_accuracy: 0.8350\nEpoch 65/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3822 - accuracy: 0.8652 - val_loss: 0.3940 - val_accuracy: 0.8367\nEpoch 66/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3828 - accuracy: 0.8659 - val_loss: 0.3843 - val_accuracy: 0.8367\nEpoch 67/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3800 - accuracy: 0.8664 - val_loss: 0.3837 - val_accuracy: 0.8383\nEpoch 68/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3787 - accuracy: 0.8665 - val_loss: 0.3838 - val_accuracy: 0.8367\nEpoch 69/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3773 - accuracy: 0.8672 - val_loss: 0.3854 - val_accuracy: 0.8367\nEpoch 70/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3774 - accuracy: 0.8673 - val_loss: 0.3827 - val_accuracy: 0.8383\nEpoch 71/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3752 - accuracy: 0.8684 - val_loss: 0.3791 - val_accuracy: 0.8367\nEpoch 72/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3738 - accuracy: 0.8686 - val_loss: 0.3844 - val_accuracy: 0.8467\nEpoch 73/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3740 - accuracy: 0.8677 - val_loss: 0.3817 - val_accuracy: 0.8467\nEpoch 74/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3729 - accuracy: 0.8684 - val_loss: 0.3797 - val_accuracy: 0.8417\nEpoch 75/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3706 - accuracy: 0.8687 - val_loss: 0.3812 - val_accuracy: 0.8467\nEpoch 76/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3701 - accuracy: 0.8693 - val_loss: 0.3757 - val_accuracy: 0.8483\nEpoch 77/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3689 - accuracy: 0.8693 - val_loss: 0.3788 - val_accuracy: 0.8450\nEpoch 78/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3684 - accuracy: 0.8705 - val_loss: 0.3774 - val_accuracy: 0.8483\nEpoch 79/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3680 - accuracy: 0.8703 - val_loss: 0.3738 - val_accuracy: 0.8433\nEpoch 80/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3657 - accuracy: 0.8711 - val_loss: 0.3756 - val_accuracy: 0.8450\nEpoch 81/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3648 - accuracy: 0.8716 - val_loss: 0.3760 - val_accuracy: 0.8450\nEpoch 82/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3656 - accuracy: 0.8708 - val_loss: 0.3768 - val_accuracy: 0.8467\nEpoch 83/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3628 - accuracy: 0.8719 - val_loss: 0.3718 - val_accuracy: 0.8467\nEpoch 84/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3612 - accuracy: 0.8729 - val_loss: 0.3743 - val_accuracy: 0.8450\nEpoch 85/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3608 - accuracy: 0.8727 - val_loss: 0.3700 - val_accuracy: 0.8417\nEpoch 86/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3602 - accuracy: 0.8727 - val_loss: 0.3771 - val_accuracy: 0.8467\nEpoch 87/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3612 - accuracy: 0.8727 - val_loss: 0.3671 - val_accuracy: 0.8450\nEpoch 88/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3577 - accuracy: 0.8743 - val_loss: 0.3657 - val_accuracy: 0.8450\nEpoch 89/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3569 - accuracy: 0.8745 - val_loss: 0.3677 - val_accuracy: 0.8500\nEpoch 90/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3559 - accuracy: 0.8743 - val_loss: 0.3750 - val_accuracy: 0.8483\nEpoch 91/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3563 - accuracy: 0.8748 - val_loss: 0.3626 - val_accuracy: 0.8400\nEpoch 92/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3541 - accuracy: 0.8749 - val_loss: 0.3644 - val_accuracy: 0.8433\nEpoch 93/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3536 - accuracy: 0.8752 - val_loss: 0.3652 - val_accuracy: 0.8467\nEpoch 94/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3527 - accuracy: 0.8754 - val_loss: 0.3644 - val_accuracy: 0.8483\nEpoch 95/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3514 - accuracy: 0.8757 - val_loss: 0.3615 - val_accuracy: 0.8500\nEpoch 96/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3521 - accuracy: 0.8755 - val_loss: 0.3620 - val_accuracy: 0.8550\nEpoch 97/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3505 - accuracy: 0.8756 - val_loss: 0.3613 - val_accuracy: 0.8467\nEpoch 98/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3501 - accuracy: 0.8766 - val_loss: 0.3613 - val_accuracy: 0.8483\nEpoch 99/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3491 - accuracy: 0.8769 - val_loss: 0.3630 - val_accuracy: 0.8533\nEpoch 100/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3472 - accuracy: 0.8775 - val_loss: 0.3580 - val_accuracy: 0.8483\nEpoch 101/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3466 - accuracy: 0.8775 - val_loss: 0.3561 - val_accuracy: 0.8433\nEpoch 102/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3466 - accuracy: 0.8774 - val_loss: 0.3581 - val_accuracy: 0.8533\nEpoch 103/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3458 - accuracy: 0.8783 - val_loss: 0.3562 - val_accuracy: 0.8467\nEpoch 104/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3452 - accuracy: 0.8774 - val_loss: 0.3581 - val_accuracy: 0.8417\nEpoch 105/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3444 - accuracy: 0.8783 - val_loss: 0.3597 - val_accuracy: 0.8517\nEpoch 106/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3435 - accuracy: 0.8784 - val_loss: 0.3579 - val_accuracy: 0.8567\nEpoch 107/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3440 - accuracy: 0.8782 - val_loss: 0.3545 - val_accuracy: 0.8550\nEpoch 108/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3414 - accuracy: 0.8794 - val_loss: 0.3543 - val_accuracy: 0.8467\nEpoch 109/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3405 - accuracy: 0.8798 - val_loss: 0.3526 - val_accuracy: 0.8533\nEpoch 110/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3414 - accuracy: 0.8797 - val_loss: 0.3543 - val_accuracy: 0.8483\nEpoch 111/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3400 - accuracy: 0.8797 - val_loss: 0.3533 - val_accuracy: 0.8517\nEpoch 112/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3379 - accuracy: 0.8805 - val_loss: 0.3552 - val_accuracy: 0.8533\nEpoch 113/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3375 - accuracy: 0.8809 - val_loss: 0.3574 - val_accuracy: 0.8533\nEpoch 114/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3399 - accuracy: 0.8790 - val_loss: 0.3517 - val_accuracy: 0.8550\nEpoch 115/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3369 - accuracy: 0.8805 - val_loss: 0.3508 - val_accuracy: 0.8583\nEpoch 116/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3371 - accuracy: 0.8808 - val_loss: 0.3524 - val_accuracy: 0.8533\nEpoch 117/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3347 - accuracy: 0.8813 - val_loss: 0.3503 - val_accuracy: 0.8500\nEpoch 118/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3349 - accuracy: 0.8811 - val_loss: 0.3475 - val_accuracy: 0.8517\nEpoch 119/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3335 - accuracy: 0.8820 - val_loss: 0.3498 - val_accuracy: 0.8517\nEpoch 120/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3327 - accuracy: 0.8825 - val_loss: 0.3527 - val_accuracy: 0.8567\nEpoch 121/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3320 - accuracy: 0.8834 - val_loss: 0.3501 - val_accuracy: 0.8567\nEpoch 122/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3321 - accuracy: 0.8826 - val_loss: 0.3531 - val_accuracy: 0.8550\nEpoch 123/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3318 - accuracy: 0.8824 - val_loss: 0.3479 - val_accuracy: 0.8533\nEpoch 124/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3311 - accuracy: 0.8824 - val_loss: 0.3496 - val_accuracy: 0.8583\nEpoch 125/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3293 - accuracy: 0.8831 - val_loss: 0.3545 - val_accuracy: 0.8550\nEpoch 126/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3290 - accuracy: 0.8835 - val_loss: 0.3524 - val_accuracy: 0.8533\nEpoch 127/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3283 - accuracy: 0.8837 - val_loss: 0.3505 - val_accuracy: 0.8583\nEpoch 128/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3272 - accuracy: 0.8839 - val_loss: 0.3498 - val_accuracy: 0.8583\nEpoch 129/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3272 - accuracy: 0.8844 - val_loss: 0.3493 - val_accuracy: 0.8550\nEpoch 130/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3264 - accuracy: 0.8839 - val_loss: 0.3470 - val_accuracy: 0.8583\nEpoch 131/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3256 - accuracy: 0.8845 - val_loss: 0.3463 - val_accuracy: 0.8583\nEpoch 132/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3251 - accuracy: 0.8844 - val_loss: 0.3508 - val_accuracy: 0.8567\nEpoch 133/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3260 - accuracy: 0.8839 - val_loss: 0.3498 - val_accuracy: 0.8617\nEpoch 134/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3241 - accuracy: 0.8850 - val_loss: 0.3430 - val_accuracy: 0.8600\nEpoch 135/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3235 - accuracy: 0.8855 - val_loss: 0.3427 - val_accuracy: 0.8600\nEpoch 136/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3233 - accuracy: 0.8852 - val_loss: 0.3445 - val_accuracy: 0.8650\nEpoch 137/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3215 - accuracy: 0.8857 - val_loss: 0.3410 - val_accuracy: 0.8600\nEpoch 138/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3216 - accuracy: 0.8857 - val_loss: 0.3469 - val_accuracy: 0.8633\nEpoch 139/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3208 - accuracy: 0.8859 - val_loss: 0.3421 - val_accuracy: 0.8583\nEpoch 140/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3204 - accuracy: 0.8858 - val_loss: 0.3437 - val_accuracy: 0.8583\nEpoch 141/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3201 - accuracy: 0.8862 - val_loss: 0.3454 - val_accuracy: 0.8633\nEpoch 142/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3190 - accuracy: 0.8865 - val_loss: 0.3467 - val_accuracy: 0.8617\nEpoch 143/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3192 - accuracy: 0.8865 - val_loss: 0.3463 - val_accuracy: 0.8667\nEpoch 144/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3196 - accuracy: 0.8865 - val_loss: 0.3384 - val_accuracy: 0.8667\nEpoch 145/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3172 - accuracy: 0.8873 - val_loss: 0.3429 - val_accuracy: 0.8683\nEpoch 146/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3168 - accuracy: 0.8885 - val_loss: 0.3391 - val_accuracy: 0.8583\nEpoch 147/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3158 - accuracy: 0.8880 - val_loss: 0.3397 - val_accuracy: 0.8617\nEpoch 148/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3147 - accuracy: 0.8887 - val_loss: 0.3447 - val_accuracy: 0.8617\nEpoch 149/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3145 - accuracy: 0.8885 - val_loss: 0.3387 - val_accuracy: 0.8633\nEpoch 150/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3140 - accuracy: 0.8889 - val_loss: 0.3411 - val_accuracy: 0.8633\nEpoch 151/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3132 - accuracy: 0.8884 - val_loss: 0.3403 - val_accuracy: 0.8667\nEpoch 152/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3125 - accuracy: 0.8894 - val_loss: 0.3358 - val_accuracy: 0.8617\nEpoch 153/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3122 - accuracy: 0.8892 - val_loss: 0.3364 - val_accuracy: 0.8667\nEpoch 154/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3114 - accuracy: 0.8899 - val_loss: 0.3369 - val_accuracy: 0.8683\nEpoch 155/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3114 - accuracy: 0.8893 - val_loss: 0.3444 - val_accuracy: 0.8683\nEpoch 156/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3112 - accuracy: 0.8894 - val_loss: 0.3356 - val_accuracy: 0.8667\nEpoch 157/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3100 - accuracy: 0.8895 - val_loss: 0.3314 - val_accuracy: 0.8650\nEpoch 158/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3097 - accuracy: 0.8901 - val_loss: 0.3373 - val_accuracy: 0.8650\nEpoch 159/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3094 - accuracy: 0.8899 - val_loss: 0.3380 - val_accuracy: 0.8633\nEpoch 160/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3099 - accuracy: 0.8893 - val_loss: 0.3372 - val_accuracy: 0.8633\nEpoch 161/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3090 - accuracy: 0.8902 - val_loss: 0.3355 - val_accuracy: 0.8633\nEpoch 162/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3077 - accuracy: 0.8906 - val_loss: 0.3374 - val_accuracy: 0.8567\nEpoch 163/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3084 - accuracy: 0.8902 - val_loss: 0.3312 - val_accuracy: 0.8667\nEpoch 164/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3075 - accuracy: 0.8908 - val_loss: 0.3356 - val_accuracy: 0.8717\nEpoch 165/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3059 - accuracy: 0.8901 - val_loss: 0.3358 - val_accuracy: 0.8683\nEpoch 166/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3060 - accuracy: 0.8913 - val_loss: 0.3341 - val_accuracy: 0.8667\nEpoch 167/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3043 - accuracy: 0.8917 - val_loss: 0.3319 - val_accuracy: 0.8617\nEpoch 168/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3042 - accuracy: 0.8916 - val_loss: 0.3283 - val_accuracy: 0.8617\nEpoch 169/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3039 - accuracy: 0.8924 - val_loss: 0.3327 - val_accuracy: 0.8667\nEpoch 170/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3034 - accuracy: 0.8919 - val_loss: 0.3290 - val_accuracy: 0.8733\nEpoch 171/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3031 - accuracy: 0.8923 - val_loss: 0.3332 - val_accuracy: 0.8717\nEpoch 172/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3019 - accuracy: 0.8930 - val_loss: 0.3301 - val_accuracy: 0.8683\nEpoch 173/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3019 - accuracy: 0.8924 - val_loss: 0.3324 - val_accuracy: 0.8650\nEpoch 174/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3011 - accuracy: 0.8934 - val_loss: 0.3306 - val_accuracy: 0.8667\nEpoch 175/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3009 - accuracy: 0.8930 - val_loss: 0.3310 - val_accuracy: 0.8617\nEpoch 176/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.2996 - accuracy: 0.8929 - val_loss: 0.3307 - val_accuracy: 0.8650\nEpoch 177/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.2995 - accuracy: 0.8933 - val_loss: 0.3284 - val_accuracy: 0.8650\nEpoch 178/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.2993 - accuracy: 0.8935 - val_loss: 0.3299 - val_accuracy: 0.8633\nEpoch 179/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.2994 - accuracy: 0.8937 - val_loss: 0.3336 - val_accuracy: 0.8700\nEpoch 180/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.2975 - accuracy: 0.8942 - val_loss: 0.3276 - val_accuracy: 0.8650\nEpoch 181/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.2981 - accuracy: 0.8940 - val_loss: 0.3343 - val_accuracy: 0.8683\nEpoch 182/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.2969 - accuracy: 0.8949 - val_loss: 0.3326 - val_accuracy: 0.8683\nEpoch 183/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.2970 - accuracy: 0.8946 - val_loss: 0.3276 - val_accuracy: 0.8600\nEpoch 184/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.2963 - accuracy: 0.8944 - val_loss: 0.3316 - val_accuracy: 0.8750\nEpoch 185/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.2952 - accuracy: 0.8941 - val_loss: 0.3219 - val_accuracy: 0.8700\nEpoch 186/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.2958 - accuracy: 0.8951 - val_loss: 0.3301 - val_accuracy: 0.8650\nEpoch 187/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.2956 - accuracy: 0.8948 - val_loss: 0.3262 - val_accuracy: 0.8700\nEpoch 188/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.2939 - accuracy: 0.8950 - val_loss: 0.3255 - val_accuracy: 0.8667\nEpoch 189/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.2932 - accuracy: 0.8961 - val_loss: 0.3340 - val_accuracy: 0.8667\nEpoch 190/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.2948 - accuracy: 0.8954 - val_loss: 0.3298 - val_accuracy: 0.8667\nEpoch 191/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.2950 - accuracy: 0.8945 - val_loss: 0.3254 - val_accuracy: 0.8600\nEpoch 192/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.2919 - accuracy: 0.8964 - val_loss: 0.3252 - val_accuracy: 0.8650\nEpoch 193/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.2915 - accuracy: 0.8963 - val_loss: 0.3253 - val_accuracy: 0.8700\nEpoch 194/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.2908 - accuracy: 0.8963 - val_loss: 0.3237 - val_accuracy: 0.8700\nEpoch 195/200\n117/117 [==============================] - 0s 2ms/step - loss: 0.2913 - accuracy: 0.8959 - val_loss: 0.3282 - val_accuracy: 0.8667\nEpoch 196/200\n117/117 [==============================] - 0s 2ms/step - loss: 0.2914 - accuracy: 0.8960 - val_loss: 0.3261 - val_accuracy: 0.8683\nEpoch 197/200\n117/117 [==============================] - 0s 2ms/step - loss: 0.2895 - accuracy: 0.8966 - val_loss: 0.3250 - val_accuracy: 0.8750\nEpoch 198/200\n117/117 [==============================] - 0s 2ms/step - loss: 0.2899 - accuracy: 0.8969 - val_loss: 0.3268 - val_accuracy: 0.8717\nEpoch 199/200\n117/117 [==============================] - 0s 2ms/step - loss: 0.2881 - accuracy: 0.8974 - val_loss: 0.3265 - val_accuracy: 0.8700\nEpoch 200/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.2900 - accuracy: 0.8965 - val_loss: 0.3265 - val_accuracy: 0.8633</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># loss 값을 plot 해보겠습니다.</span>\ny_vloss <span class=\"token operator\">=</span> history<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'val_loss'</span><span class=\"token punctuation\">]</span>\ny_loss <span class=\"token operator\">=</span> history<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'loss'</span><span class=\"token punctuation\">]</span>\nx_len <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>arange<span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>y_loss<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>x_len<span class=\"token punctuation\">,</span> y_vloss<span class=\"token punctuation\">,</span> marker<span class=\"token operator\">=</span><span class=\"token string\">'.'</span><span class=\"token punctuation\">,</span> c<span class=\"token operator\">=</span><span class=\"token string\">'red'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">\"Validation-set Loss\"</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>x_len<span class=\"token punctuation\">,</span> y_loss<span class=\"token punctuation\">,</span> marker<span class=\"token operator\">=</span><span class=\"token string\">'.'</span><span class=\"token punctuation\">,</span> c<span class=\"token operator\">=</span><span class=\"token string\">'blue'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">\"Train-set Loss\"</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>legend<span class=\"token punctuation\">(</span>loc<span class=\"token operator\">=</span><span class=\"token string\">'upper right'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>grid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'Loss graph without dropout layer'</span><span class=\"token punctuation\">)</span> \nplt<span class=\"token punctuation\">.</span>ylim<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">'epoch'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'loss'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 386px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 72.22222222222221%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsTAAALEwEAmpwYAAAC7klEQVQ4y32Uz28TVxDHn6ASEkW9IXHoLRwQEvQMhxxStUDVgIAL/0FQfnBIlL+jaitV6oFLxAou9IKURGuTYJw4dSqL4liV4gbbDZs0trPL2l7vvt9fNOsk5ACs9NHMm519b958R8suXfzmBGPsy2d/LHz9IrN6YaNSPu84zuXp6elvJycnr42Pj9+Ympr6fuz+2A9pbGry2sSDiRuzs7PfzczMXM/lchc3NzfPl8vlC8vLy+dYWKmdBMB2q/Vne/UQieBhkiQ9IUS33+9H5HPOuzxJupxi78Jer/G212g0euWNcm9ra6tXq9XC7e1t1Ov1hwzACdqw02o///9NH8Zaa42FtRbGmCNLABZxpNDeVfA8D9VqFbVajXzLOUez2XzM5ufnv2CMnd7f9zM7//gQUkgppSGEEPbApqS+FEYbaZRSKQe5UmuNVqv16KjCbqebabwKYKxR5hMVHo8djxtjFAAEQeCwOI5PUoVRHGT/LQXYaUQK0BBCgnMxIOEQnEMKAcEFpJQpgtYDlFKKKnTY0NDQOaowTiI3iQ1eLnRUe5cDoJ5pHH9sGrWpbyygtIUyliwZ+L7vsJGRkTOMsVNB8C5D6Z2Aqz9zEVbmA2zkfVRWfWwVdhBWPcStAJHfA+/GMEkfUBFg+oQCONrtlkM9TAnDMGu0gbFK0cZ0+s62RL3SxWZxH8WFNgqPayj89heKP6+i9MtL/P3rMsq/5/Hqp4yqPn2N5m7TYaVSiVRmVCEpRf2QQlmllAWkHVzuUAZr0yMBG0aw3p61b/dg//O03GsaNJtth3melw52p9Nx6ROttTQHj1LaaDWwA18bJZWxdBUQ6sBqSR32/f0PYxMEwQtSigb0IyqmHMYO39MEHE7DQOX2EzY8PExj85Xrulcrlcro2traj4VCYZTI5/M3i8Vius5ms7dzudwt13XvrKys3FxcXLxL66Wlpdv5fH7Udd17c3NzV9j6+jq18Eicj6G1ppSz9BP5XB7xHjFQo2rcvFL8AAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/7659e0a64c70ee324e2c8cf47f322541/7bc0b/output_37_0.png\"\n        srcset=\"/static/7659e0a64c70ee324e2c8cf47f322541/e9ff0/output_37_0.png 180w,\n/static/7659e0a64c70ee324e2c8cf47f322541/f21e7/output_37_0.png 360w,\n/static/7659e0a64c70ee324e2c8cf47f322541/7bc0b/output_37_0.png 386w\"\n        sizes=\"(max-width: 386px) 100vw, 386px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># accuracy 값을 plot 해보겠습니다.</span>\ny_vacc <span class=\"token operator\">=</span> history<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'val_accuracy'</span><span class=\"token punctuation\">]</span>\ny_acc <span class=\"token operator\">=</span> history<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span>\nx_len <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>arange<span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>y_acc<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>x_len<span class=\"token punctuation\">,</span> y_vacc<span class=\"token punctuation\">,</span> marker<span class=\"token operator\">=</span><span class=\"token string\">'.'</span><span class=\"token punctuation\">,</span> c<span class=\"token operator\">=</span><span class=\"token string\">'red'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">\"Validation-set accuracy\"</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>x_len<span class=\"token punctuation\">,</span> y_acc<span class=\"token punctuation\">,</span> marker<span class=\"token operator\">=</span><span class=\"token string\">'.'</span><span class=\"token punctuation\">,</span> c<span class=\"token operator\">=</span><span class=\"token string\">'blue'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">\"Train-set accuracy\"</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>legend<span class=\"token punctuation\">(</span>loc<span class=\"token operator\">=</span><span class=\"token string\">'lower right'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>grid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylim<span class=\"token punctuation\">(</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span> \nplt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'Accuracy graph without dropout layer'</span><span class=\"token punctuation\">)</span> \nplt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">'epoch'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 386px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 72.22222222222221%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsTAAALEwEAmpwYAAAC/klEQVQ4y32U32sUVxTHL5FCS7HQh4JgEARBfAvkSSgItraFGiX2pX9BXrIlJOgfYV98Kn0SIrjYYl62GtzMTJK1kZ1sW8lq0tWa7HZ1dxnd3dkfk5nZmXvvuV+5k2QNRXrhw/fMzOGcc8+ce9n4+PgIY+xj0zRHi8Xi6Ww2e2ZmZubC7Ozsl1qnp6e/SaVSX2vVzM3NfTE1NfVtKvXDV5qrV6+d39h4csq2C2csyzrGOOdHALBWq3UvjmOEYdiLosiLotjz/cAP/NAPg4GXEGoNvUE42I2jgRdHwS7XxEFX8AEcx7nJAIzogJ7nLQOAEFKBJACNAKDwvsUB7HKgHwO9CMoXgOt27rB0Ov0BY+wj13VNwXUAyQMJcrqgWhPq7y2u1nMe5R+0yP6tQXamToXMKyrceU72rS1a/7lA9k8FvrVQglNzbusKE7y+Z+rMzx61hP3jQ2xcz2LzhoFaOofO/TX07i6ht2Cgt2QjePgH5J+PgdIm8M9T4MWmQLOOTquVZmNjY58yxj4Jop5V+b2Kv359JqjbBsIO4LtA7INkBIIE7TeC9psR7TMARAyg2Wym2ejx4yd0hX7HNUqLFe2sffc6qACpIYKUEiQkJOdQB7YQoMQWQhHBdd00Ozl64hhj7MM3z6tG/YUHQVLwmEMIAc7f6WFb63++C52wpbeM/t5frj6tmX3HB+ncOruUifOBDm3Oh+8OBU8CttvtNMvfLR5hjI1UijWr5/iQSgjOudK7OKyJLaXiUiqovUVEB3Cl1F6Fj1YbOiCrVvqG11fJ2JCkZEkphyqVorjXp9h5Q9WXL+nfSoXq9To1Gg2tvNFo6MG+PRxs53U3F4YCcRwNe6ZPzgFCcHTbAV7XA5TLO9jZ3kG5XMb29jaq1ao+YTrgL+zcuc91hUdXVoyzpdLmRD5vX8zn8xOatbW1S4VCIXm2LGtyeTV3+X526UpudfVSJpP5zjTNy4uLi5OWZU0YhvH9/Pz8Wba+vqx3PBzw9yGl1C6f6Uvk//w0bwHIlJYIkoZ5JQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/14349f49de542fb4d16446c01a574836/7bc0b/output_38_0.png\"\n        srcset=\"/static/14349f49de542fb4d16446c01a574836/e9ff0/output_38_0.png 180w,\n/static/14349f49de542fb4d16446c01a574836/f21e7/output_38_0.png 360w,\n/static/14349f49de542fb4d16446c01a574836/7bc0b/output_38_0.png 386w\"\n        sizes=\"(max-width: 386px) 100vw, 386px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>이렇게 200번 epochs 하면 어느순간(loss 한 100부터 accuracy 한 25부터,,)부터 train loss 는 계속 떨어지지만 val loss 는 더이상 움직이지 않는다…</p>\n<p>ㅜㅜ 넘해</p>\n<p>이럴때 드랍아웃으로 오버피팅 방지</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">model <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n    keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span>input_shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">28</span><span class=\"token punctuation\">,</span> <span class=\"token number\">28</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">256</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token comment\"># 여기에 dropout layer를 추가해보았습니다. 나머지 layer는 위의 실습과 같습니다. </span>\n    keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dropout<span class=\"token punctuation\">(</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span><span class=\"token string\">'adam'</span><span class=\"token punctuation\">,</span>loss<span class=\"token operator\">=</span><span class=\"token string\">'sparse_categorical_crossentropy'</span><span class=\"token punctuation\">,</span>\n              metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nhistory<span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">200</span><span class=\"token punctuation\">,</span> batch_size<span class=\"token operator\">=</span><span class=\"token number\">512</span><span class=\"token punctuation\">,</span> validation_data<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>X_valid<span class=\"token punctuation\">,</span> y_valid<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Epoch 1/200\n117/117 [==============================] - 1s 7ms/step - loss: 2.0802 - accuracy: 0.4763 - val_loss: 1.7029 - val_accuracy: 0.5300\nEpoch 2/200\n117/117 [==============================] - 0s 3ms/step - loss: 1.4692 - accuracy: 0.5660 - val_loss: 1.2217 - val_accuracy: 0.6350\nEpoch 3/200\n117/117 [==============================] - 0s 4ms/step - loss: 1.1566 - accuracy: 0.6223 - val_loss: 1.0075 - val_accuracy: 0.7083\nEpoch 4/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.9942 - accuracy: 0.6671 - val_loss: 0.8747 - val_accuracy: 0.7533\nEpoch 5/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.8909 - accuracy: 0.6978 - val_loss: 0.7917 - val_accuracy: 0.7600\nEpoch 6/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.8228 - accuracy: 0.7125 - val_loss: 0.7359 - val_accuracy: 0.7567\nEpoch 7/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.7727 - accuracy: 0.7269 - val_loss: 0.6952 - val_accuracy: 0.7767\nEpoch 8/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.7379 - accuracy: 0.7364 - val_loss: 0.6664 - val_accuracy: 0.7833\nEpoch 9/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.7098 - accuracy: 0.7456 - val_loss: 0.6425 - val_accuracy: 0.7917\nEpoch 10/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.6862 - accuracy: 0.7520 - val_loss: 0.6225 - val_accuracy: 0.7917\nEpoch 11/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.6682 - accuracy: 0.7576 - val_loss: 0.6038 - val_accuracy: 0.7967\nEpoch 12/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.6491 - accuracy: 0.7655 - val_loss: 0.5924 - val_accuracy: 0.7967\nEpoch 13/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.6348 - accuracy: 0.7712 - val_loss: 0.5801 - val_accuracy: 0.7933\nEpoch 14/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.6212 - accuracy: 0.7761 - val_loss: 0.5685 - val_accuracy: 0.7950\nEpoch 15/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.6077 - accuracy: 0.7821 - val_loss: 0.5560 - val_accuracy: 0.7967\nEpoch 16/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.5986 - accuracy: 0.7863 - val_loss: 0.5497 - val_accuracy: 0.8050\nEpoch 17/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.5861 - accuracy: 0.7915 - val_loss: 0.5371 - val_accuracy: 0.8017\nEpoch 18/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.5760 - accuracy: 0.7923 - val_loss: 0.5313 - val_accuracy: 0.8033\nEpoch 19/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.5669 - accuracy: 0.7980 - val_loss: 0.5252 - val_accuracy: 0.7983\nEpoch 20/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.5606 - accuracy: 0.7998 - val_loss: 0.5152 - val_accuracy: 0.8067\nEpoch 21/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.5500 - accuracy: 0.8034 - val_loss: 0.5098 - val_accuracy: 0.8117\nEpoch 22/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.5430 - accuracy: 0.8059 - val_loss: 0.5044 - val_accuracy: 0.8133\nEpoch 23/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.5370 - accuracy: 0.8086 - val_loss: 0.4973 - val_accuracy: 0.8117\nEpoch 24/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.5300 - accuracy: 0.8109 - val_loss: 0.4926 - val_accuracy: 0.8133\nEpoch 25/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.5257 - accuracy: 0.8133 - val_loss: 0.4880 - val_accuracy: 0.8167\nEpoch 26/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.5208 - accuracy: 0.8151 - val_loss: 0.4803 - val_accuracy: 0.8217\nEpoch 27/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.5144 - accuracy: 0.8182 - val_loss: 0.4767 - val_accuracy: 0.8183\nEpoch 28/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.5101 - accuracy: 0.8194 - val_loss: 0.4730 - val_accuracy: 0.8200\nEpoch 29/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.8202 - val_loss: 0.4692 - val_accuracy: 0.8267\nEpoch 30/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.5016 - accuracy: 0.8223 - val_loss: 0.4649 - val_accuracy: 0.8250\nEpoch 31/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4949 - accuracy: 0.8246 - val_loss: 0.4627 - val_accuracy: 0.8217\nEpoch 32/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4908 - accuracy: 0.8260 - val_loss: 0.4581 - val_accuracy: 0.8200\nEpoch 33/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4880 - accuracy: 0.8282 - val_loss: 0.4540 - val_accuracy: 0.8267\nEpoch 34/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4853 - accuracy: 0.8270 - val_loss: 0.4477 - val_accuracy: 0.8250\nEpoch 35/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4800 - accuracy: 0.8301 - val_loss: 0.4479 - val_accuracy: 0.8267\nEpoch 36/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4784 - accuracy: 0.8317 - val_loss: 0.4423 - val_accuracy: 0.8317\nEpoch 37/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4746 - accuracy: 0.8326 - val_loss: 0.4429 - val_accuracy: 0.8283\nEpoch 38/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.8336 - val_loss: 0.4392 - val_accuracy: 0.8350\nEpoch 39/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.8346 - val_loss: 0.4364 - val_accuracy: 0.8333\nEpoch 40/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.8361 - val_loss: 0.4352 - val_accuracy: 0.8333\nEpoch 41/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.8360 - val_loss: 0.4318 - val_accuracy: 0.8367\nEpoch 42/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.8378 - val_loss: 0.4305 - val_accuracy: 0.8317\nEpoch 43/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.8379 - val_loss: 0.4267 - val_accuracy: 0.8317\nEpoch 44/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.8400 - val_loss: 0.4250 - val_accuracy: 0.8317\nEpoch 45/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4527 - accuracy: 0.8407 - val_loss: 0.4234 - val_accuracy: 0.8350\nEpoch 46/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.8398 - val_loss: 0.4185 - val_accuracy: 0.8350\nEpoch 47/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.8415 - val_loss: 0.4165 - val_accuracy: 0.8333\nEpoch 48/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.8418 - val_loss: 0.4174 - val_accuracy: 0.8367\nEpoch 49/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.8442 - val_loss: 0.4194 - val_accuracy: 0.8317\nEpoch 50/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4414 - accuracy: 0.8431 - val_loss: 0.4114 - val_accuracy: 0.8383\nEpoch 51/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.8454 - val_loss: 0.4127 - val_accuracy: 0.8350\nEpoch 52/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.8446 - val_loss: 0.4082 - val_accuracy: 0.8400\nEpoch 53/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.8454 - val_loss: 0.4059 - val_accuracy: 0.8383\nEpoch 54/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.8479 - val_loss: 0.4040 - val_accuracy: 0.8367\nEpoch 55/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.8481 - val_loss: 0.4016 - val_accuracy: 0.8367\nEpoch 56/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4268 - accuracy: 0.8489 - val_loss: 0.4070 - val_accuracy: 0.8400\nEpoch 57/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.8487 - val_loss: 0.4012 - val_accuracy: 0.8367\nEpoch 58/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.8498 - val_loss: 0.3998 - val_accuracy: 0.8383\nEpoch 59/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.8508 - val_loss: 0.3976 - val_accuracy: 0.8333\nEpoch 60/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.8501 - val_loss: 0.3967 - val_accuracy: 0.8383\nEpoch 61/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.8499 - val_loss: 0.3960 - val_accuracy: 0.8350\nEpoch 62/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.8510 - val_loss: 0.3976 - val_accuracy: 0.8367\nEpoch 63/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.8520 - val_loss: 0.3940 - val_accuracy: 0.8400\nEpoch 64/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4154 - accuracy: 0.8527 - val_loss: 0.3922 - val_accuracy: 0.8350\nEpoch 65/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4156 - accuracy: 0.8531 - val_loss: 0.3937 - val_accuracy: 0.8383\nEpoch 66/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4129 - accuracy: 0.8537 - val_loss: 0.3896 - val_accuracy: 0.8400\nEpoch 67/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4136 - accuracy: 0.8532 - val_loss: 0.3890 - val_accuracy: 0.8417\nEpoch 68/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4104 - accuracy: 0.8547 - val_loss: 0.3869 - val_accuracy: 0.8383\nEpoch 69/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8564 - val_loss: 0.3861 - val_accuracy: 0.8467\nEpoch 70/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4075 - accuracy: 0.8553 - val_loss: 0.3848 - val_accuracy: 0.8417\nEpoch 71/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4047 - accuracy: 0.8579 - val_loss: 0.3820 - val_accuracy: 0.8433\nEpoch 72/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4054 - accuracy: 0.8558 - val_loss: 0.3827 - val_accuracy: 0.8400\nEpoch 73/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4042 - accuracy: 0.8575 - val_loss: 0.3828 - val_accuracy: 0.8400\nEpoch 74/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.4020 - accuracy: 0.8579 - val_loss: 0.3800 - val_accuracy: 0.8433\nEpoch 75/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4001 - accuracy: 0.8583 - val_loss: 0.3794 - val_accuracy: 0.8450\nEpoch 76/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4005 - accuracy: 0.8568 - val_loss: 0.3768 - val_accuracy: 0.8450\nEpoch 77/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.4001 - accuracy: 0.8576 - val_loss: 0.3765 - val_accuracy: 0.8467\nEpoch 78/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3980 - accuracy: 0.8592 - val_loss: 0.3773 - val_accuracy: 0.8467\nEpoch 79/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3976 - accuracy: 0.8593 - val_loss: 0.3762 - val_accuracy: 0.8517\nEpoch 80/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3961 - accuracy: 0.8594 - val_loss: 0.3729 - val_accuracy: 0.8450\nEpoch 81/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3945 - accuracy: 0.8586 - val_loss: 0.3714 - val_accuracy: 0.8433\nEpoch 82/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3916 - accuracy: 0.8619 - val_loss: 0.3736 - val_accuracy: 0.8467\nEpoch 83/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3925 - accuracy: 0.8623 - val_loss: 0.3728 - val_accuracy: 0.8433\nEpoch 84/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3913 - accuracy: 0.8614 - val_loss: 0.3716 - val_accuracy: 0.8483\nEpoch 85/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3890 - accuracy: 0.8621 - val_loss: 0.3704 - val_accuracy: 0.8433\nEpoch 86/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3872 - accuracy: 0.8621 - val_loss: 0.3699 - val_accuracy: 0.8450\nEpoch 87/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3875 - accuracy: 0.8614 - val_loss: 0.3710 - val_accuracy: 0.8483\nEpoch 88/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3863 - accuracy: 0.8630 - val_loss: 0.3666 - val_accuracy: 0.8417\nEpoch 89/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3847 - accuracy: 0.8626 - val_loss: 0.3684 - val_accuracy: 0.8467\nEpoch 90/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3837 - accuracy: 0.8634 - val_loss: 0.3681 - val_accuracy: 0.8450\nEpoch 91/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3835 - accuracy: 0.8646 - val_loss: 0.3655 - val_accuracy: 0.8517\nEpoch 92/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3840 - accuracy: 0.8640 - val_loss: 0.3673 - val_accuracy: 0.8467\nEpoch 93/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3825 - accuracy: 0.8646 - val_loss: 0.3628 - val_accuracy: 0.8500\nEpoch 94/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3796 - accuracy: 0.8639 - val_loss: 0.3630 - val_accuracy: 0.8450\nEpoch 95/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3789 - accuracy: 0.8657 - val_loss: 0.3628 - val_accuracy: 0.8517\nEpoch 96/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3788 - accuracy: 0.8660 - val_loss: 0.3638 - val_accuracy: 0.8517\nEpoch 97/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3784 - accuracy: 0.8671 - val_loss: 0.3629 - val_accuracy: 0.8533\nEpoch 98/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3768 - accuracy: 0.8661 - val_loss: 0.3609 - val_accuracy: 0.8567\nEpoch 99/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3752 - accuracy: 0.8662 - val_loss: 0.3623 - val_accuracy: 0.8550\nEpoch 100/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3743 - accuracy: 0.8666 - val_loss: 0.3586 - val_accuracy: 0.8550\nEpoch 101/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3751 - accuracy: 0.8674 - val_loss: 0.3573 - val_accuracy: 0.8417\nEpoch 102/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3748 - accuracy: 0.8675 - val_loss: 0.3605 - val_accuracy: 0.8550\nEpoch 103/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3722 - accuracy: 0.8695 - val_loss: 0.3577 - val_accuracy: 0.8533\nEpoch 104/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3718 - accuracy: 0.8669 - val_loss: 0.3558 - val_accuracy: 0.8517\nEpoch 105/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3714 - accuracy: 0.8672 - val_loss: 0.3577 - val_accuracy: 0.8550\nEpoch 106/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3703 - accuracy: 0.8689 - val_loss: 0.3540 - val_accuracy: 0.8533\nEpoch 107/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3681 - accuracy: 0.8686 - val_loss: 0.3565 - val_accuracy: 0.8533\nEpoch 108/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3705 - accuracy: 0.8687 - val_loss: 0.3529 - val_accuracy: 0.8500\nEpoch 109/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3668 - accuracy: 0.8696 - val_loss: 0.3523 - val_accuracy: 0.8533\nEpoch 110/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3671 - accuracy: 0.8700 - val_loss: 0.3537 - val_accuracy: 0.8550\nEpoch 111/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3668 - accuracy: 0.8699 - val_loss: 0.3520 - val_accuracy: 0.8550\nEpoch 112/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3648 - accuracy: 0.8715 - val_loss: 0.3499 - val_accuracy: 0.8583\nEpoch 113/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3622 - accuracy: 0.8721 - val_loss: 0.3496 - val_accuracy: 0.8600\nEpoch 114/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3636 - accuracy: 0.8721 - val_loss: 0.3508 - val_accuracy: 0.8467\nEpoch 115/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3637 - accuracy: 0.8709 - val_loss: 0.3480 - val_accuracy: 0.8550\nEpoch 116/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3616 - accuracy: 0.8717 - val_loss: 0.3514 - val_accuracy: 0.8583\nEpoch 117/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3602 - accuracy: 0.8720 - val_loss: 0.3462 - val_accuracy: 0.8533\nEpoch 118/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3616 - accuracy: 0.8716 - val_loss: 0.3518 - val_accuracy: 0.8567\nEpoch 119/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3597 - accuracy: 0.8719 - val_loss: 0.3479 - val_accuracy: 0.8583\nEpoch 120/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3584 - accuracy: 0.8726 - val_loss: 0.3491 - val_accuracy: 0.8583\nEpoch 121/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3588 - accuracy: 0.8727 - val_loss: 0.3466 - val_accuracy: 0.8583\nEpoch 122/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3576 - accuracy: 0.8732 - val_loss: 0.3459 - val_accuracy: 0.8517\nEpoch 123/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3544 - accuracy: 0.8743 - val_loss: 0.3451 - val_accuracy: 0.8583\nEpoch 124/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3557 - accuracy: 0.8739 - val_loss: 0.3430 - val_accuracy: 0.8550\nEpoch 125/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3555 - accuracy: 0.8745 - val_loss: 0.3430 - val_accuracy: 0.8600\nEpoch 126/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3546 - accuracy: 0.8729 - val_loss: 0.3442 - val_accuracy: 0.8583\nEpoch 127/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3545 - accuracy: 0.8746 - val_loss: 0.3435 - val_accuracy: 0.8600\nEpoch 128/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3551 - accuracy: 0.8736 - val_loss: 0.3405 - val_accuracy: 0.8550\nEpoch 129/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3532 - accuracy: 0.8750 - val_loss: 0.3415 - val_accuracy: 0.8567\nEpoch 130/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3521 - accuracy: 0.8753 - val_loss: 0.3397 - val_accuracy: 0.8583\nEpoch 131/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3499 - accuracy: 0.8756 - val_loss: 0.3405 - val_accuracy: 0.8550\nEpoch 132/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3513 - accuracy: 0.8753 - val_loss: 0.3395 - val_accuracy: 0.8617\nEpoch 133/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3489 - accuracy: 0.8758 - val_loss: 0.3397 - val_accuracy: 0.8600\nEpoch 134/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3509 - accuracy: 0.8758 - val_loss: 0.3412 - val_accuracy: 0.8567\nEpoch 135/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3483 - accuracy: 0.8770 - val_loss: 0.3386 - val_accuracy: 0.8583\nEpoch 136/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3483 - accuracy: 0.8758 - val_loss: 0.3384 - val_accuracy: 0.8583\nEpoch 137/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3462 - accuracy: 0.8777 - val_loss: 0.3378 - val_accuracy: 0.8583\nEpoch 138/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3465 - accuracy: 0.8774 - val_loss: 0.3392 - val_accuracy: 0.8617\nEpoch 139/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3469 - accuracy: 0.8769 - val_loss: 0.3361 - val_accuracy: 0.8583\nEpoch 140/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3464 - accuracy: 0.8778 - val_loss: 0.3370 - val_accuracy: 0.8567\nEpoch 141/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3433 - accuracy: 0.8785 - val_loss: 0.3343 - val_accuracy: 0.8600\nEpoch 142/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3455 - accuracy: 0.8782 - val_loss: 0.3373 - val_accuracy: 0.8600\nEpoch 143/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3445 - accuracy: 0.8778 - val_loss: 0.3357 - val_accuracy: 0.8583\nEpoch 144/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3435 - accuracy: 0.8786 - val_loss: 0.3356 - val_accuracy: 0.8617\nEpoch 145/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3420 - accuracy: 0.8781 - val_loss: 0.3364 - val_accuracy: 0.8650\nEpoch 146/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3446 - accuracy: 0.8782 - val_loss: 0.3342 - val_accuracy: 0.8600\nEpoch 147/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3422 - accuracy: 0.8781 - val_loss: 0.3342 - val_accuracy: 0.8650\nEpoch 148/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3424 - accuracy: 0.8787 - val_loss: 0.3343 - val_accuracy: 0.8550\nEpoch 149/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3397 - accuracy: 0.8788 - val_loss: 0.3328 - val_accuracy: 0.8600\nEpoch 150/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3378 - accuracy: 0.8798 - val_loss: 0.3332 - val_accuracy: 0.8633\nEpoch 151/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3398 - accuracy: 0.8788 - val_loss: 0.3333 - val_accuracy: 0.8567\nEpoch 152/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3389 - accuracy: 0.8793 - val_loss: 0.3336 - val_accuracy: 0.8650\nEpoch 153/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3384 - accuracy: 0.8806 - val_loss: 0.3335 - val_accuracy: 0.8600\nEpoch 154/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3365 - accuracy: 0.8803 - val_loss: 0.3319 - val_accuracy: 0.8567\nEpoch 155/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3381 - accuracy: 0.8811 - val_loss: 0.3323 - val_accuracy: 0.8617\nEpoch 156/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3382 - accuracy: 0.8801 - val_loss: 0.3308 - val_accuracy: 0.8617\nEpoch 157/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3364 - accuracy: 0.8808 - val_loss: 0.3269 - val_accuracy: 0.8617\nEpoch 158/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3374 - accuracy: 0.8804 - val_loss: 0.3304 - val_accuracy: 0.8683\nEpoch 159/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3361 - accuracy: 0.8809 - val_loss: 0.3298 - val_accuracy: 0.8583\nEpoch 160/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3343 - accuracy: 0.8813 - val_loss: 0.3296 - val_accuracy: 0.8650\nEpoch 161/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3336 - accuracy: 0.8816 - val_loss: 0.3282 - val_accuracy: 0.8700\nEpoch 162/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3335 - accuracy: 0.8817 - val_loss: 0.3293 - val_accuracy: 0.8600\nEpoch 163/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3334 - accuracy: 0.8810 - val_loss: 0.3317 - val_accuracy: 0.8650\nEpoch 164/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3312 - accuracy: 0.8828 - val_loss: 0.3252 - val_accuracy: 0.8633\nEpoch 165/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3315 - accuracy: 0.8819 - val_loss: 0.3271 - val_accuracy: 0.8700\nEpoch 166/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3320 - accuracy: 0.8823 - val_loss: 0.3270 - val_accuracy: 0.8633\nEpoch 167/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3322 - accuracy: 0.8825 - val_loss: 0.3263 - val_accuracy: 0.8650\nEpoch 168/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3315 - accuracy: 0.8830 - val_loss: 0.3270 - val_accuracy: 0.8600\nEpoch 169/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3307 - accuracy: 0.8824 - val_loss: 0.3241 - val_accuracy: 0.8617\nEpoch 170/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3296 - accuracy: 0.8829 - val_loss: 0.3249 - val_accuracy: 0.8650\nEpoch 171/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3314 - accuracy: 0.8823 - val_loss: 0.3261 - val_accuracy: 0.8650\nEpoch 172/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3277 - accuracy: 0.8836 - val_loss: 0.3255 - val_accuracy: 0.8650\nEpoch 173/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3312 - accuracy: 0.8824 - val_loss: 0.3264 - val_accuracy: 0.8633\nEpoch 174/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3284 - accuracy: 0.8830 - val_loss: 0.3247 - val_accuracy: 0.8650\nEpoch 175/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3266 - accuracy: 0.8836 - val_loss: 0.3226 - val_accuracy: 0.8683\nEpoch 176/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3266 - accuracy: 0.8835 - val_loss: 0.3229 - val_accuracy: 0.8633\nEpoch 177/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3261 - accuracy: 0.8841 - val_loss: 0.3252 - val_accuracy: 0.8633\nEpoch 178/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3229 - accuracy: 0.8872 - val_loss: 0.3233 - val_accuracy: 0.8650\nEpoch 179/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3282 - accuracy: 0.8845 - val_loss: 0.3215 - val_accuracy: 0.8667\nEpoch 180/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3264 - accuracy: 0.8844 - val_loss: 0.3245 - val_accuracy: 0.8617\nEpoch 181/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3247 - accuracy: 0.8846 - val_loss: 0.3210 - val_accuracy: 0.8633\nEpoch 182/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3253 - accuracy: 0.8843 - val_loss: 0.3230 - val_accuracy: 0.8667\nEpoch 183/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3243 - accuracy: 0.8842 - val_loss: 0.3240 - val_accuracy: 0.8650\nEpoch 184/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3248 - accuracy: 0.8845 - val_loss: 0.3199 - val_accuracy: 0.8700\nEpoch 185/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3242 - accuracy: 0.8856 - val_loss: 0.3225 - val_accuracy: 0.8733\nEpoch 186/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3236 - accuracy: 0.8844 - val_loss: 0.3208 - val_accuracy: 0.8650\nEpoch 187/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3223 - accuracy: 0.8859 - val_loss: 0.3167 - val_accuracy: 0.8667\nEpoch 188/200\n117/117 [==============================] - 0s 4ms/step - loss: 0.3214 - accuracy: 0.8849 - val_loss: 0.3201 - val_accuracy: 0.8633\nEpoch 189/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3260 - accuracy: 0.8848 - val_loss: 0.3202 - val_accuracy: 0.8717\nEpoch 190/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3214 - accuracy: 0.8855 - val_loss: 0.3192 - val_accuracy: 0.8633\nEpoch 191/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3205 - accuracy: 0.8861 - val_loss: 0.3214 - val_accuracy: 0.8650\nEpoch 192/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3213 - accuracy: 0.8857 - val_loss: 0.3180 - val_accuracy: 0.8700\nEpoch 193/200\n117/117 [==============================] - 0s 2ms/step - loss: 0.3203 - accuracy: 0.8859 - val_loss: 0.3191 - val_accuracy: 0.8617\nEpoch 194/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3223 - accuracy: 0.8858 - val_loss: 0.3170 - val_accuracy: 0.8683\nEpoch 195/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3216 - accuracy: 0.8862 - val_loss: 0.3222 - val_accuracy: 0.8667\nEpoch 196/200\n117/117 [==============================] - 0s 2ms/step - loss: 0.3196 - accuracy: 0.8860 - val_loss: 0.3167 - val_accuracy: 0.8700\nEpoch 197/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3179 - accuracy: 0.8880 - val_loss: 0.3194 - val_accuracy: 0.8700\nEpoch 198/200\n117/117 [==============================] - 0s 3ms/step - loss: 0.3185 - accuracy: 0.8865 - val_loss: 0.3178 - val_accuracy: 0.8633\nEpoch 199/200\n117/117 [==============================] - 0s 2ms/step - loss: 0.3152 - accuracy: 0.8877 - val_loss: 0.3137 - val_accuracy: 0.8667\nEpoch 200/200\n117/117 [==============================] - 0s 2ms/step - loss: 0.3166 - accuracy: 0.8876 - val_loss: 0.3202 - val_accuracy: 0.8650</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># loss 값을 plot 해보겠습니다. </span>\ny_vloss <span class=\"token operator\">=</span> history<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'val_loss'</span><span class=\"token punctuation\">]</span>\ny_loss <span class=\"token operator\">=</span> history<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'loss'</span><span class=\"token punctuation\">]</span>\nx_len <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>arange<span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>y_loss<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>x_len<span class=\"token punctuation\">,</span> y_vloss<span class=\"token punctuation\">,</span> marker<span class=\"token operator\">=</span><span class=\"token string\">'.'</span><span class=\"token punctuation\">,</span> c<span class=\"token operator\">=</span><span class=\"token string\">'red'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">\"Validation-set Loss\"</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>x_len<span class=\"token punctuation\">,</span> y_loss<span class=\"token punctuation\">,</span> marker<span class=\"token operator\">=</span><span class=\"token string\">'.'</span><span class=\"token punctuation\">,</span> c<span class=\"token operator\">=</span><span class=\"token string\">'blue'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">\"Train-set Loss\"</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>legend<span class=\"token punctuation\">(</span>loc<span class=\"token operator\">=</span><span class=\"token string\">'upper right'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>grid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylim<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'Loss graph with dropout layer'</span><span class=\"token punctuation\">)</span> \nplt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">'epoch'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'loss'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 386px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 72.22222222222221%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsTAAALEwEAmpwYAAAC9UlEQVQ4y32US2sbVxTHL0mh0IbuCll05yYE0k2XKdQLp5S21ClpNv0AKV4YhMEQ6MYfwl1lEUJN1VdIQykxzkix60qWI8WGVHKaxjEzQp666DUaaaSZ+/6XM37ENKEXfpx7z5w78z8Phr17/p0TjLHX793+5a2fvls/V35YObOxsXFmbm7u/ZmZmQ+mpqY+yWQyH05PT380Ozt78eqXVyevfXVtIpPJfDw/P3/Bdd23q9Xq2Vqtdm5lZeU0E83WSQCstev/uvukg4QnYZIkEed8EMdxFMfxMEmSASeEGIx6YTSs+wPP86JarRbt7OxEruuGjUYDnufdYABO0Av7YXh/r9qBscZaa0EYY44sAVjEQ4XWnoTv+9je3obrurS3nHM0m83v2eLi4iuMsdc67U6u/sCHkFJKIY2U0gghyFqyB3sjpDDaKKPUPuSjK1prtFqtb48UCjHIeat1BD2jAAOtX1R4XPVxvzF0BwiCIMviOD5JCvtylA8euVjLbitKDpAQgkNyDp4cwCU4F5BSpgghDlFKKVKYZWNjY6fTGg6GDtWofuuBKt58ioanwDV5/rv2a0lYa1KM0YoUd7vdLJuYmDjFGHu11+vllKZgpcLKY9Su/461rx+i/M2fqP78F2r3fTz5Y4S93QTDPkccCQwjgThWSIRW2mi02+0s1TAlDMO8NQZSKnUkph9APKtjt9yAt/wM7t0tPLr9FKUf6yjd+RtrdztYyw1QzEXq8eYIzX9aWba5uUldZqSQOiWFUFJISwhtrDrML8VaQFvApNZCWqO4FcORHA0Ems12lvm+nw52v993qA5aa2kOllbKGK2NkiqFEkutJrc2ihKlQGskfa/b7TwfmyAIfqNO0YC+pIsph77jzw/tfpfbP7Dx8XEamzccx3lva2trcn19/dNSqTRJFAqFS+VyOT3n8/nLq6urnzmO83mxWLy0tLR0hc7Ly8uXC4XCpOM4XywsLFxglUqFSnjUnJehtaaQN+kn8n9xxL9MAaP24DqSKAAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/3c940df8a06089ad50c2fbe8c6ea158f/7bc0b/output_41_0.png\"\n        srcset=\"/static/3c940df8a06089ad50c2fbe8c6ea158f/e9ff0/output_41_0.png 180w,\n/static/3c940df8a06089ad50c2fbe8c6ea158f/f21e7/output_41_0.png 360w,\n/static/3c940df8a06089ad50c2fbe8c6ea158f/7bc0b/output_41_0.png 386w\"\n        sizes=\"(max-width: 386px) 100vw, 386px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># accuracy 값을 plot 해보겠습니다. </span>\ny_vacc <span class=\"token operator\">=</span> history<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'val_accuracy'</span><span class=\"token punctuation\">]</span>\ny_acc <span class=\"token operator\">=</span> history<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span>\nx_len <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>arange<span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>y_acc<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>x_len<span class=\"token punctuation\">,</span> y_vacc<span class=\"token punctuation\">,</span> marker<span class=\"token operator\">=</span><span class=\"token string\">'.'</span><span class=\"token punctuation\">,</span> c<span class=\"token operator\">=</span><span class=\"token string\">'red'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">\"Validation-set accuracy\"</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>x_len<span class=\"token punctuation\">,</span> y_acc<span class=\"token punctuation\">,</span> marker<span class=\"token operator\">=</span><span class=\"token string\">'.'</span><span class=\"token punctuation\">,</span> c<span class=\"token operator\">=</span><span class=\"token string\">'blue'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">\"Train-set accuracy\"</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>legend<span class=\"token punctuation\">(</span>loc<span class=\"token operator\">=</span><span class=\"token string\">'lower right'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>grid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylim<span class=\"token punctuation\">(</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span> \nplt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'Accuracy graph with dropout layer'</span><span class=\"token punctuation\">)</span> \nplt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">'epoch'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 386px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 72.22222222222221%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsTAAALEwEAmpwYAAADEElEQVQ4y41Uz2sbRxQeHAItJYUcCjkYH5pTbi6GkFx6aGlDwU5Ic8kfYIMPFj7Yf4Rv/XXpxcFQixoX0pjEppU2yNiyskqckjo2DWvJklP9sCWvvNrV7mrnzcxXZv2jaumhDx7fx7zZb99782bY0NBQH2PsPcMw+k3TvGZZ1oczMzM3JiYmbk1OTn42PT39yejo6PDU1NSniUTiViKR+HxsbGxYr4+Pj38xO/vgo+3tnav6W8MwrjDO+QUArNlsPo6iCEEQON1u142iyA2CwPM7vh/4gRcEoRsGXdfvBG7gh14YhG7H87041vGdKAxRr9dnGYA+Lei67lMAEEIoISSkkIAiAAr/w5QEYNutH1kymbzIGHu31bLTxAlcEAeEVFCy6ULW6qQqliOt5w35cuVPmfv5rTQf12T+YUmaD17JjR/eyOy3z/jW4jZqlcN5nWHs7bab1r/ijkdbWQe5+SI2v8vit68y2PxmDdb3Bg4XMzh+sgbHeI72ShbOShbus9fomL8TWXtoNZtJNjg4eJkx9r4TeEa4Y2H16xdkvfbQsT0ItwWQCyACIOPixWkT5CnXSABp3mg0kqy/v39AZ8i7TurNwx3UDuLGxUYKIAkQSRAJSCIIziH/wQmCiJSUsG07ya4ODFxhjL1zXNpPFV62ICAo6nIQETj/G3u5xn/FSQiBpi757JTtQilds1yQUiRI6NOON5/hOef8fK1HPBY8OjpKsvyieYEx1ld+VTLst+04Q8650lX0YsyFUFwIBXViUsoz50qpkwzXftrSgqy0fZByG13dZi6EjE2cEo1CKRk5bRnVD2V5f1+W9vZkpVKR1WpVI69Wq3qw589LLv1xsOo0QpCIEEUnPdM358yJOI6PfBxUfBSLBRR2CygWi9jd3UW5XNY3TAsusOvXP9YZXnr0yLi5ubkzYpq54Y2N3EgulxtZX1+/nc/nhzU3DOPu08zqnSe//PrlaiZze2lp6V46nb6zvLx81zCMkVQqdX9ubu4mW1hY0xXHw02E80HvdSGE3vKBfkT+K97rfwFv9ZYsQOGykwAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/07db8a2400447ea8b0cf8954c55862e6/7bc0b/output_42_0.png\"\n        srcset=\"/static/07db8a2400447ea8b0cf8954c55862e6/e9ff0/output_42_0.png 180w,\n/static/07db8a2400447ea8b0cf8954c55862e6/f21e7/output_42_0.png 360w,\n/static/07db8a2400447ea8b0cf8954c55862e6/7bc0b/output_42_0.png 386w\"\n        sizes=\"(max-width: 386px) 100vw, 386px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>진짜 조금 바뀌긴 했지만 차이가 있긴 있다</p>\n<p>사실 더 복잡한 네트워크나, 더 어려운 데이터의 경우에는 이러한 오버피팅이 더 자주 있는 일이므로, Dropout layer를 추가하는 경우가 많습니다. 하지만 이 또한 확률 값이 파라미터로 들어가므로, 어떠한 값을 선택하느냐는 데이터와 네트워크에 따라 달린 일입니다.</p>\n<h2 id=\"batch-normalization\" style=\"position:relative;\"><a href=\"#batch-normalization\" aria-label=\"batch normalization permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Batch Normalization</h2>\n<h3 id=\"요건-기울기소실-이랑-기울기포화-문제를-해결한다\" style=\"position:relative;\"><a href=\"#%EC%9A%94%EA%B1%B4-%EA%B8%B0%EC%9A%B8%EA%B8%B0%EC%86%8C%EC%8B%A4-%EC%9D%B4%EB%9E%91-%EA%B8%B0%EC%9A%B8%EA%B8%B0%ED%8F%AC%ED%99%94-%EB%AC%B8%EC%A0%9C%EB%A5%BC-%ED%95%B4%EA%B2%B0%ED%95%9C%EB%8B%A4\" aria-label=\"요건 기울기소실 이랑 기울기포화 문제를 해결한다 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>요건 기울기소실 이랑 기울기포화 문제를 해결한다.</h3>\n<p><a href=\"https://arxiv.org/pdf/1502.03167.pdf\">논문</a></p>\n<p>쉽게 말하면 미니배치에서</p>\n<p>평균이랑 분산을 구해가지고</p>\n<p>x에서 평균뺀거를 분산으로 나눈 값으로 정규화 하는거</p>\n<p>특히 중요한 부분은 분모에 엡실론(0.001)) 가 추가된 것이다 이 부분으로</p>\n<p>가중치 소실, 포화를 막을 수 있다. 그래서 이걸로\n오버피팅으로 학습이 잘되지 않는 것을 막을 수 있닫.</p>\n<p>fashion_mnist 데이터로 가져가보자</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n<span class=\"token keyword\">from</span> tensorflow <span class=\"token keyword\">import</span> keras\n<span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n<span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt\n\nfashion_mnist <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>datasets<span class=\"token punctuation\">.</span>fashion_mnist\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'=3'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">=3</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token punctuation\">(</span>train_images<span class=\"token punctuation\">,</span> train_labels<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>test_images<span class=\"token punctuation\">,</span> test_labels<span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> fashion_mnist<span class=\"token punctuation\">.</span>load_data<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nclass_names <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'T-shirt/top'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Trouser'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Pullover'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Dress'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Coat'</span><span class=\"token punctuation\">,</span>\n               <span class=\"token string\">'Sandal'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Shirt'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Sneaker'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Bag'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Ankle boot'</span><span class=\"token punctuation\">]</span>\n\ntrain_images <span class=\"token operator\">=</span> train_images <span class=\"token operator\">/</span> <span class=\"token number\">255.0</span>\ntest_images <span class=\"token operator\">=</span> test_images <span class=\"token operator\">/</span> <span class=\"token number\">255.0</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>model_selection <span class=\"token keyword\">import</span> train_test_split\n\nX_train<span class=\"token punctuation\">,</span> X_valid<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> y_valid <span class=\"token operator\">=</span> train_test_split<span class=\"token punctuation\">(</span>train_images<span class=\"token punctuation\">,</span> train_labels<span class=\"token punctuation\">,</span> test_size<span class=\"token operator\">=</span><span class=\"token number\">0.3</span><span class=\"token punctuation\">,</span> random_state<span class=\"token operator\">=</span><span class=\"token number\">101</span><span class=\"token punctuation\">)</span>\n\nmodel <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n    keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span>input_shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">28</span><span class=\"token punctuation\">,</span> <span class=\"token number\">28</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">128</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span><span class=\"token string\">'adam'</span><span class=\"token punctuation\">,</span>loss<span class=\"token operator\">=</span><span class=\"token string\">'sparse_categorical_crossentropy'</span><span class=\"token punctuation\">,</span>\n              metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nhistory<span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">20</span><span class=\"token punctuation\">,</span> batch_size<span class=\"token operator\">=</span><span class=\"token number\">2048</span><span class=\"token punctuation\">,</span> validation_data<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>X_valid<span class=\"token punctuation\">,</span> y_valid<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Epoch 1/20\n21/21 [==============================] - 1s 23ms/step - loss: 1.2103 - accuracy: 0.6096 - val_loss: 0.7485 - val_accuracy: 0.7401\nEpoch 2/20\n21/21 [==============================] - 0s 10ms/step - loss: 0.6556 - accuracy: 0.7789 - val_loss: 0.5983 - val_accuracy: 0.8006\nEpoch 3/20\n21/21 [==============================] - 0s 10ms/step - loss: 0.5541 - accuracy: 0.8160 - val_loss: 0.5364 - val_accuracy: 0.8184\nEpoch 4/20\n21/21 [==============================] - 0s 9ms/step - loss: 0.5061 - accuracy: 0.8299 - val_loss: 0.5008 - val_accuracy: 0.8274\nEpoch 5/20\n21/21 [==============================] - 0s 9ms/step - loss: 0.4775 - accuracy: 0.8394 - val_loss: 0.4801 - val_accuracy: 0.8369\nEpoch 6/20\n21/21 [==============================] - 0s 9ms/step - loss: 0.4555 - accuracy: 0.8452 - val_loss: 0.4612 - val_accuracy: 0.8456\nEpoch 7/20\n21/21 [==============================] - 0s 9ms/step - loss: 0.4391 - accuracy: 0.8502 - val_loss: 0.4470 - val_accuracy: 0.8479\nEpoch 8/20\n21/21 [==============================] - 0s 8ms/step - loss: 0.4251 - accuracy: 0.8559 - val_loss: 0.4369 - val_accuracy: 0.8503\nEpoch 9/20\n21/21 [==============================] - 0s 6ms/step - loss: 0.4144 - accuracy: 0.8578 - val_loss: 0.4295 - val_accuracy: 0.8530\nEpoch 10/20\n21/21 [==============================] - 0s 6ms/step - loss: 0.4059 - accuracy: 0.8595 - val_loss: 0.4182 - val_accuracy: 0.8566\nEpoch 11/20\n21/21 [==============================] - 0s 7ms/step - loss: 0.3950 - accuracy: 0.8646 - val_loss: 0.4125 - val_accuracy: 0.8588\nEpoch 12/20\n21/21 [==============================] - 0s 6ms/step - loss: 0.3900 - accuracy: 0.8662 - val_loss: 0.4139 - val_accuracy: 0.8543\nEpoch 13/20\n21/21 [==============================] - 0s 6ms/step - loss: 0.3826 - accuracy: 0.8678 - val_loss: 0.4036 - val_accuracy: 0.8598\nEpoch 14/20\n21/21 [==============================] - 0s 6ms/step - loss: 0.3731 - accuracy: 0.8719 - val_loss: 0.3979 - val_accuracy: 0.8619\nEpoch 15/20\n21/21 [==============================] - 0s 6ms/step - loss: 0.3696 - accuracy: 0.8723 - val_loss: 0.3929 - val_accuracy: 0.8624\nEpoch 16/20\n21/21 [==============================] - 0s 6ms/step - loss: 0.3614 - accuracy: 0.8761 - val_loss: 0.3878 - val_accuracy: 0.8650\nEpoch 17/20\n21/21 [==============================] - 0s 6ms/step - loss: 0.3560 - accuracy: 0.8774 - val_loss: 0.3865 - val_accuracy: 0.8647\nEpoch 18/20\n21/21 [==============================] - 0s 6ms/step - loss: 0.3514 - accuracy: 0.8776 - val_loss: 0.3858 - val_accuracy: 0.8644\nEpoch 19/20\n21/21 [==============================] - 0s 6ms/step - loss: 0.3476 - accuracy: 0.8803 - val_loss: 0.3774 - val_accuracy: 0.8686\nEpoch 20/20\n21/21 [==============================] - 0s 6ms/step - loss: 0.3385 - accuracy: 0.8828 - val_loss: 0.3780 - val_accuracy: 0.8672</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># loss 값을 plot 해보겠습니다. </span>\ny_vloss <span class=\"token operator\">=</span> history<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'val_loss'</span><span class=\"token punctuation\">]</span>\ny_loss <span class=\"token operator\">=</span> history<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'loss'</span><span class=\"token punctuation\">]</span>\nx_len <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>arange<span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>y_loss<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>x_len<span class=\"token punctuation\">,</span> y_vloss<span class=\"token punctuation\">,</span> marker<span class=\"token operator\">=</span><span class=\"token string\">'.'</span><span class=\"token punctuation\">,</span> c<span class=\"token operator\">=</span><span class=\"token string\">'red'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">\"Validation-set Loss\"</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>x_len<span class=\"token punctuation\">,</span> y_loss<span class=\"token punctuation\">,</span> marker<span class=\"token operator\">=</span><span class=\"token string\">'.'</span><span class=\"token punctuation\">,</span> c<span class=\"token operator\">=</span><span class=\"token string\">'blue'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">\"Train-set Loss\"</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>legend<span class=\"token punctuation\">(</span>loc<span class=\"token operator\">=</span><span class=\"token string\">'upper right'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>grid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylim<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'Loss graph without batch normalization'</span><span class=\"token punctuation\">)</span> \nplt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">'epoch'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'loss'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 386px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 72.22222222222221%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsTAAALEwEAmpwYAAADBklEQVQ4y3WSS28TVxTHrwAJqQVV6qpddBWpLKCrrLNoSguBLAqi9BtEWXhhrCzoh+muVugmD2XRyDbJhiBFURIXN1aaJrZjj03sGXvG4/jOff+rMxYgVfRIR//7ODP3dx5senr6CmPs00Kh8NWrV399vby8/E0mk7mXzWbvLiwsPMzlct+RZrPZ7xcXF+ee//L822dLz+7mcrl7mUxmfmlp6YfNzc3bp6ent7a3t79kSsqrAJjv+xudtoCUIuKcx5zzS875SAgRJ0kSSynjRIiYR8N4VG/FjfPzuFKpxGdnZ3GtVgubzSYajcavDMAV+uEwHr30AwBwzhhDC1hr4ZzDh70BH2v0Ogqe5+Hk5AS1Wg2tVstJKdHr9ZbZHy9eXGOMfRJ22sWgPQZPjJJSWKUUBZFaUq21FUKkqrSwZHRnjKFzRQ8HQfDbe0Ix6hcHf/cwvIQGLKydkFEgkZJN9oDRE2Kt9TtNF1EU5RkX4ioRDkbDUvI2QHPP05xLOGgYp6GMBqVD3yRCQCmNJBHQqSZQSpFqawwR5tnU1NQXRBjHowK9Mm4PdP0wgN8WCL0Y+pJPiJyDcwRCtBNCh4kZICUMiXB2dvYGY+x6GIZFrQ0cnFZaIfQTdOsRmm981F+fo73fRrfcQq/cxMWfHoJ/+vBPLsBbXfBWR5tggKDby1MNU4+iqES1MsZoSoNIHNUSVEsNY4FoaBBGFv0LjrgzQlAfoHMcovEm0N3aJXoXQZ7t7+9TlxkRUtGpwFJKwnRSkFK3FY2S01pQAs5YRdnSinrklDVEgH6/n2ee56WDPRwOCy6tk1M0Gs65dCTISGlP59Y6qxXdIx2bdHxkmhLCMPwwNoPBYJs6SS7Sbqq0u++czj+mFEfxlJ3v+7+zmZkZGpubq6urMzs7O48PDg7mtra2fiyXyw+KxeKjo6Oj+6VS6VGlUplbW1t7uru7O7+xsfFTtVq9v7Ky8vPh4eGD9fX1J8fHx/PVavUOC4KASvi+Of/18XicKmPsc8bYZ/8XR763t8f+BXp2qO3PX9GyAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/6a1f7c39ee994f85d98d4d22baf532e5/7bc0b/output_50_0.png\"\n        srcset=\"/static/6a1f7c39ee994f85d98d4d22baf532e5/e9ff0/output_50_0.png 180w,\n/static/6a1f7c39ee994f85d98d4d22baf532e5/f21e7/output_50_0.png 360w,\n/static/6a1f7c39ee994f85d98d4d22baf532e5/7bc0b/output_50_0.png 386w\"\n        sizes=\"(max-width: 386px) 100vw, 386px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>일반적인 Dense FC layer 를 쓰면 저렇게 val loss가 7.5 쯤에서 멈춘다</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># accuracy 값을 plot 해보겠습니다. </span>\ny_vacc <span class=\"token operator\">=</span> history<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'val_accuracy'</span><span class=\"token punctuation\">]</span>\ny_acc <span class=\"token operator\">=</span> history<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span>\nx_len <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>arange<span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>y_acc<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>x_len<span class=\"token punctuation\">,</span> y_vacc<span class=\"token punctuation\">,</span> marker<span class=\"token operator\">=</span><span class=\"token string\">'.'</span><span class=\"token punctuation\">,</span> c<span class=\"token operator\">=</span><span class=\"token string\">'red'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">\"Validation-set accuracy\"</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>x_len<span class=\"token punctuation\">,</span> y_acc<span class=\"token punctuation\">,</span> marker<span class=\"token operator\">=</span><span class=\"token string\">'.'</span><span class=\"token punctuation\">,</span> c<span class=\"token operator\">=</span><span class=\"token string\">'blue'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">\"Train-set accuracy\"</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>legend<span class=\"token punctuation\">(</span>loc<span class=\"token operator\">=</span><span class=\"token string\">'lower right'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>grid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylim<span class=\"token punctuation\">(</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'Accuracy graph without batch normalization'</span><span class=\"token punctuation\">)</span> \nplt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">'epoch'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 386px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 72.22222222222221%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsTAAALEwEAmpwYAAADCklEQVQ4y32TS2sbVxTHDw6BloaUdhXSkkWyCmRh8NaFQBOITQJJyeMLeCG8sWywv013EXVxqRZd2XJtMHZtk+AYFJWoUjS2HuMZzVOjGc3cx7mn3LEtki56hzu/++LM+f/vGZiampoAgK92dna+W19fv7e0tPTjwsLCQ81CoTAzPz8/UywWH2guLi4+KBQKsysrK/eLxeJDvT83N/dkeXn5/uHh4d3t7e0bwDm/QkTgOM4fWZYRYyxI0zRK0zSO4zjJ0kyPI8ZYNBqNoixjUZKMIsZ4znweJwFnnGzb/hmIaEIHjKLoTyIipZQSQmqSIqTzpi7e6rP5J8wHYRj+AqVS6SoAfOn7XkUIQVJJLpEhKqmGg1QN+jGGdoRDN0GnM0CzFeHphxB7zSG2ay52ah4ab7rc/rtPlmm/1hnCeYbDiv4KGzLRbQzJbMR01s7I+uDT2XuH+nWfvLpFccuixDgj1nVoZLqUnfmU2KGQiaDA9UowOTn5DQBcD+PBZty2yXhriUGQUppkxAUjRTJ/tDyhBCEp4ihzM5gUJEkRk1xoO1zPLcH3N2/e0hmmXn/D/celESdB+TFFUkpCiSS1p6hIcEEKkbQ12j7Ni3Wh1QVBUII7t2/fAIAvQs/bsC1JiFKwjOWHOedj6uCMsTER8dO50JfoeV5pfMuuN6g4DuoMxGWA/JIuqAPodfyfgL7vl2B/37oCABOGEVTCUJeLEIwxJYRQl+ScKymlYpwroTAfa1P13nmZCa4l5xm22z0dEMJwsIGodP1xIQQqpVBKibppKiLM/AC51Ufj9BQNw8BOp4O9Xg+73S43TZMsy3o9lhwE/va5X4L0H6PlaUmXXaIg34nJ6ib08WOTGo0GtVqtnCcnJ5QkCZmm+StMT0/rDK+Vy+Ufdnd3f3r37mhma2vr6fHx8WylUnlWq9UebW5uPntfrc789nv55c5f+4/L5fKLo6OjR6urq6/29vZm19bWntfr9cfVavUeNJtNrXhc4P/tSZLkBIBvAeDry/UwDD87h4hwcHAA/wLoLKAxXQohggAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/3efbcc1914c76a9b1265a4d0a9e655c9/7bc0b/output_52_0.png\"\n        srcset=\"/static/3efbcc1914c76a9b1265a4d0a9e655c9/e9ff0/output_52_0.png 180w,\n/static/3efbcc1914c76a9b1265a4d0a9e655c9/f21e7/output_52_0.png 360w,\n/static/3efbcc1914c76a9b1265a4d0a9e655c9/7bc0b/output_52_0.png 386w\"\n        sizes=\"(max-width: 386px) 100vw, 386px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<h3 id=\"배치-노말라이제이션-쓰면\" style=\"position:relative;\"><a href=\"#%EB%B0%B0%EC%B9%98-%EB%85%B8%EB%A7%90%EB%9D%BC%EC%9D%B4%EC%A0%9C%EC%9D%B4%EC%85%98-%EC%93%B0%EB%A9%B4\" aria-label=\"배치 노말라이제이션 쓰면 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>배치 노말라이제이션 쓰면</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">model <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n    keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span>input_shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">28</span><span class=\"token punctuation\">,</span> <span class=\"token number\">28</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">128</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token comment\">#여기에 batchnormalization layer를 추가해보았습니다. 나머지 layer는 위의 실습과 같습니다.</span>\n    keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>BatchNormalization<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span><span class=\"token string\">'adam'</span><span class=\"token punctuation\">,</span>loss<span class=\"token operator\">=</span><span class=\"token string\">'sparse_categorical_crossentropy'</span><span class=\"token punctuation\">,</span>\n              metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nhistory<span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">20</span><span class=\"token punctuation\">,</span> batch_size<span class=\"token operator\">=</span><span class=\"token number\">2048</span><span class=\"token punctuation\">,</span> validation_data<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>X_valid<span class=\"token punctuation\">,</span> y_valid<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Epoch 1/20\n21/21 [==============================] - 1s 25ms/step - loss: 0.8808 - accuracy: 0.7005 - val_loss: 1.0613 - val_accuracy: 0.6525\nEpoch 2/20\n21/21 [==============================] - 0s 9ms/step - loss: 0.5167 - accuracy: 0.8267 - val_loss: 0.8411 - val_accuracy: 0.7488\nEpoch 3/20\n21/21 [==============================] - 0s 10ms/step - loss: 0.4500 - accuracy: 0.8469 - val_loss: 0.7390 - val_accuracy: 0.7935\nEpoch 4/20\n21/21 [==============================] - 0s 9ms/step - loss: 0.4127 - accuracy: 0.8584 - val_loss: 0.6659 - val_accuracy: 0.8183\nEpoch 5/20\n21/21 [==============================] - 0s 10ms/step - loss: 0.3869 - accuracy: 0.8680 - val_loss: 0.6321 - val_accuracy: 0.8328\nEpoch 6/20\n21/21 [==============================] - 0s 9ms/step - loss: 0.3640 - accuracy: 0.8746 - val_loss: 0.5769 - val_accuracy: 0.8439\nEpoch 7/20\n21/21 [==============================] - 0s 10ms/step - loss: 0.3465 - accuracy: 0.8790 - val_loss: 0.5427 - val_accuracy: 0.8486\nEpoch 8/20\n21/21 [==============================] - 0s 6ms/step - loss: 0.3321 - accuracy: 0.8842 - val_loss: 0.5140 - val_accuracy: 0.8510\nEpoch 9/20\n21/21 [==============================] - 0s 7ms/step - loss: 0.3164 - accuracy: 0.8903 - val_loss: 0.4943 - val_accuracy: 0.8492\nEpoch 10/20\n21/21 [==============================] - 0s 7ms/step - loss: 0.3045 - accuracy: 0.8935 - val_loss: 0.4571 - val_accuracy: 0.8611\nEpoch 11/20\n21/21 [==============================] - 0s 7ms/step - loss: 0.2944 - accuracy: 0.8968 - val_loss: 0.4447 - val_accuracy: 0.8588\nEpoch 12/20\n21/21 [==============================] - 0s 6ms/step - loss: 0.2839 - accuracy: 0.9001 - val_loss: 0.4193 - val_accuracy: 0.8649\nEpoch 13/20\n21/21 [==============================] - 0s 7ms/step - loss: 0.2733 - accuracy: 0.9047 - val_loss: 0.4101 - val_accuracy: 0.8683\nEpoch 14/20\n21/21 [==============================] - 0s 6ms/step - loss: 0.2639 - accuracy: 0.9089 - val_loss: 0.4099 - val_accuracy: 0.8638\nEpoch 15/20\n21/21 [==============================] - 0s 6ms/step - loss: 0.2580 - accuracy: 0.9097 - val_loss: 0.3807 - val_accuracy: 0.8750\nEpoch 16/20\n21/21 [==============================] - 0s 6ms/step - loss: 0.2502 - accuracy: 0.9125 - val_loss: 0.3694 - val_accuracy: 0.8753\nEpoch 17/20\n21/21 [==============================] - 0s 6ms/step - loss: 0.2434 - accuracy: 0.9149 - val_loss: 0.3822 - val_accuracy: 0.8688\nEpoch 18/20\n21/21 [==============================] - 0s 7ms/step - loss: 0.2365 - accuracy: 0.9167 - val_loss: 0.3545 - val_accuracy: 0.8790\nEpoch 19/20\n21/21 [==============================] - 0s 6ms/step - loss: 0.2273 - accuracy: 0.9210 - val_loss: 0.3586 - val_accuracy: 0.8746\nEpoch 20/20\n21/21 [==============================] - 0s 7ms/step - loss: 0.2213 - accuracy: 0.9223 - val_loss: 0.3413 - val_accuracy: 0.8785</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># loss 값을 plot 해보겠습니다. </span>\ny_vloss <span class=\"token operator\">=</span> history<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'val_loss'</span><span class=\"token punctuation\">]</span>\ny_loss <span class=\"token operator\">=</span> history<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'loss'</span><span class=\"token punctuation\">]</span>\nx_len <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>arange<span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>y_loss<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>x_len<span class=\"token punctuation\">,</span> y_vloss<span class=\"token punctuation\">,</span> marker<span class=\"token operator\">=</span><span class=\"token string\">'.'</span><span class=\"token punctuation\">,</span> c<span class=\"token operator\">=</span><span class=\"token string\">'red'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">\"Validation-set Loss\"</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>x_len<span class=\"token punctuation\">,</span> y_loss<span class=\"token punctuation\">,</span> marker<span class=\"token operator\">=</span><span class=\"token string\">'.'</span><span class=\"token punctuation\">,</span> c<span class=\"token operator\">=</span><span class=\"token string\">'blue'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">\"Train-set Loss\"</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>legend<span class=\"token punctuation\">(</span>loc<span class=\"token operator\">=</span><span class=\"token string\">'upper right'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>grid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylim<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'Loss graph with batch normalization'</span><span class=\"token punctuation\">)</span> \nplt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">'epoch'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'loss'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 386px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 72.22222222222221%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsTAAALEwEAmpwYAAADI0lEQVQ4y3VSTUtkRxQtZgKBfBDIahbZOYsMZJVZZdEEJBhHXGTCJPkJImhrthMmP8F/kF2akI12ELKwW4MLFyLaQtMiKm2/fs+2+/X76tf93qvPe0K1M2MIzIXLqbpVVJ177mFPn375gDH24e5u/bOjnZ3PTxuNx69+fVVaX1//ZmlpaWF1dXVuZWXl27W1tbnl5eX5l7+8/Lr8c3muXC7bs8WNjY2vLi8vHzebzSf7+/uPmBDyIQA29Ifb/OYGXIgkz/O04HycZdmEcz4uiiIVQthamiejdHztpo7jpM1mM726uhq32+2k2+2i0+n8xgA8sA92e8XuxAmBYkIKABkDYwyICFpr2DBGI88U/J6E53m4uLhAu92G67okhIDv+3+wra2/32OMfdD345p/y6GdjuR5bqQxRnBOUkojhDBKKcM5n6JU3NiwZ1prW5f24yAIfn/LME3T2jAEUBRKX3dAWQZjmVpmrxlapkSAVnd7pdQbnC6SJKmwPM8fWoZxHNZ9X4FLo2SRQTpdiK4LOR5DSAVFBC4lpJTgnEMrBV4UUFKiKApl5QmCoMJmZmYeWYZFMd5JU4LnkdLGTH+mSQrq3cB0u6AwgppkMIbumb3uQBkzLcRxXGGzs7MfMcbej+O4RqQRRVq12xL9vsJorCEUQRQFkEYwfQ/wOlCda9DQhxz0YYIhRJJYYRGGYcVqOM0kSepmyswo21aSGNzeKjgdDdfV8EOg1zcYBgZZpiDjMfJBCD4IIT1XIfQR+YMKOz4+tlNmlqEV3QoshCAiRVoLMkZRUUgaJYriSFAUKXIcQd4tyLnR5PZAjqukHehgEFaY53lTY49Gox07eiKS1hrGkFFWzWloY51JpP6D1qbSWMhzKTkHoii+t00URf9YsW3aKdq2rVnf5F1dQMo7vN/bexxW/+Fw+CcrlUrWNh9vbW2VDg4Ovj85OXm2t7f33enp6UKtVnvearXm6/X682az+axarf54eHi4uL29/cPZ2dn85ubmT41GY6Fa/evF+fn5Yqt19gULgsBK+HY4/88sy6bIGPuUMfbJu+7ZPDo6Yv8CUj2pel0/ITIAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/baa29ed3f08a5d4b724717acc1de9ef2/7bc0b/output_55_0.png\"\n        srcset=\"/static/baa29ed3f08a5d4b724717acc1de9ef2/e9ff0/output_55_0.png 180w,\n/static/baa29ed3f08a5d4b724717acc1de9ef2/f21e7/output_55_0.png 360w,\n/static/baa29ed3f08a5d4b724717acc1de9ef2/7bc0b/output_55_0.png 386w\"\n        sizes=\"(max-width: 386px) 100vw, 386px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># accuracy 값을 plot 해보겠습니다. </span>\ny_vacc <span class=\"token operator\">=</span> history<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'val_accuracy'</span><span class=\"token punctuation\">]</span>\ny_acc <span class=\"token operator\">=</span> history<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span>\nx_len <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>arange<span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>y_acc<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>x_len<span class=\"token punctuation\">,</span> y_vacc<span class=\"token punctuation\">,</span> marker<span class=\"token operator\">=</span><span class=\"token string\">'.'</span><span class=\"token punctuation\">,</span> c<span class=\"token operator\">=</span><span class=\"token string\">'red'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">\"Validation-set accuracy\"</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>x_len<span class=\"token punctuation\">,</span> y_acc<span class=\"token punctuation\">,</span> marker<span class=\"token operator\">=</span><span class=\"token string\">'.'</span><span class=\"token punctuation\">,</span> c<span class=\"token operator\">=</span><span class=\"token string\">'blue'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">\"Train-set accuracy\"</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>legend<span class=\"token punctuation\">(</span>loc<span class=\"token operator\">=</span><span class=\"token string\">'lower right'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>grid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylim<span class=\"token punctuation\">(</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span> \nplt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'Accurcy graph with batch normalization'</span><span class=\"token punctuation\">)</span> \nplt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">'epoch'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 386px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 72.22222222222221%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsTAAALEwEAmpwYAAADGElEQVQ4y31Tz2skRRgtsgiKouhJIboHEQ96COYaDy64ZsIeXPHHX7C72Q0TWAzkb8nBm4Mj0Z2Dp6THCJJoTkNkjGScSSbzq9MzPf1jOtPd1VX11ZPq7ITVgx88XtfXxev3vq5ii4uLc4yxF3d2dt48OTl5Z2tr64P19fWPNzc3P1pbW1teXX1YKBaLt4vF9duPHq19srGxcevx469vPXjwsHDv3mrh/v3VlXL5x/dqtfq7llV9gwkhbgBgruv+xDkH5zxMkiRKU345nU6nSZJecp5GUmYR50kkBI8yHkeaskhkcUTKrKeBJoHRaPgNAzBnBKMo+llrmNJaS0NPAXABZBJIuEamAC8E3ABwXGA4BvoOdDABxl74HSuVSs8xxl7wPM8ikhBCCH8iyR5q6p7GutuYUOckpH7r8gp/DMk5tilq2RQ2uhT93aPgr7aIO0O4F863xmGOOI6sNAV6A0i7ESBuDpB2LsC7DvSFDXgjYGgDySUw8YEsheYJIDh0GkuQRBgEJbawsPAqY+zlMPSqzogwPetL7XSheAIhM0hocKUgNJBKBaEIXEhI0uBZBqEU0iyTpDXG43GJzc/Pv2UchjHfdZsB4LlS5IMElFIgRVBS5Q0lpRlwzqbk07WUV43AOLx58+3XGWPP93rRbthyoLWSWZblm4UQ12zETX/GRPTsWhphz/NK13857PUtCkIQIGcCRmzGRsD06X8Efd8vsYtu5wZjbC4Yjy0TRarcoZZS6hkLIbRSSmdCaKkpfzZTMe9MSZlP6cph37aNIJtE0a75itZaSGlmrEkpRaYMa4C4H5BwRtTudKjdblOv16PBYED9fl/Ytg3HuTo2eWTf938x0QzMjTHxTKQZFEn47hROP8bpaQvNZhNnZ2c5n5+fI45j2Lb9PVtaWjIOX6pUKh/u7+9/VqvVCnt7e58eHR2tWJZ19/j4eLlard79s14v/PCk8uWvv/1+p1KpfFGr1ZbL5fJXBwcHK9vb2583Go079Xr9fdZqtUzi6wP+X8RxnDNj7DXG2CuzfhiG/9pHROzw8JD9A/hQoR0ACR8rAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/d8558b14bc2e985dfb95c978261e3a12/7bc0b/output_56_0.png\"\n        srcset=\"/static/d8558b14bc2e985dfb95c978261e3a12/e9ff0/output_56_0.png 180w,\n/static/d8558b14bc2e985dfb95c978261e3a12/f21e7/output_56_0.png 360w,\n/static/d8558b14bc2e985dfb95c978261e3a12/7bc0b/output_56_0.png 386w\"\n        sizes=\"(max-width: 386px) 100vw, 386px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<div class=\"table-of-contents\">\n<ul>\n<li>\n<p><a href=\"#l2-norm--ridge\">L2 norm  Ridge</a></p>\n<ul>\n<li>\n<ul>\n<li><a href=\"#%EA%B7%B8%EB%9F%AC%EB%AF%80%EB%A1%9C-%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%97%90-%EB%94%B0%EB%9D%BC-%EC%A0%81%EC%A0%88%ED%95%9C-regularization-%EB%B0%A9%EB%B2%95%EC%9D%84-%ED%99%9C%EC%9A%A9%ED%95%98%EB%8A%94-%EA%B2%83%EC%9D%B4-%EC%A2%8B%EC%8A%B5%EB%8B%88%EB%8B%A4\">그러므로, 데이터에 따라 적절한 Regularization 방법을 활용하는 것이 좋습니다.</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><a href=\"#%EA%B7%BC%EB%8D%B0-%EA%B7%B8%EB%9E%98%EC%84%9C-norm-%EC%9D%B4%EB%9E%80%EA%B2%8C-%EB%AD%98%EA%B9%8C\">근데 그래서 Norm 이란게 뭘까…?</a></p>\n</li>\n<li>\n<p><a href=\"#dropout-%EC%9D%80-%EB%AD%94%EB%8D%B0\">Dropout 은 뭔데?</a></p>\n<ul>\n<li><a href=\"#overfitting-%EC%A4%84%EC%9D%B4%EB%8A%94-%EB%B2%95\">overfitting 줄이는 법</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#batch-normalization\">Batch Normalization</a></p>\n<ul>\n<li><a href=\"#%EC%9A%94%EA%B1%B4-%EA%B8%B0%EC%9A%B8%EA%B8%B0%EC%86%8C%EC%8B%A4-%EC%9D%B4%EB%9E%91-%EA%B8%B0%EC%9A%B8%EA%B8%B0%ED%8F%AC%ED%99%94-%EB%AC%B8%EC%A0%9C%EB%A5%BC-%ED%95%B4%EA%B2%B0%ED%95%9C%EB%8B%A4\">요건 기울기소실 이랑 기울기포화 문제를 해결한다.</a></li>\n<li><a href=\"#%EB%B0%B0%EC%B9%98-%EB%85%B8%EB%A7%90%EB%9D%BC%EC%9D%B4%EC%A0%9C%EC%9D%B4%EC%85%98-%EC%93%B0%EB%A9%B4\">배치 노말라이제이션 쓰면</a></li>\n</ul>\n</li>\n</ul>\n</div>","excerpt":"정규화(라고 다같은 정규화가 아니다) Regularization : 정칙화라고 불리며, 오버피팅을 해결하기 위한 방법 중의 하나 Regularization 기법들은 모델이 train set의 정답을 맞히지 못하도록 오버피팅을 방해(train loss가 증가) 하는 역할을 합니다. 그래서 train loss는 약간 증가하지만 결과적으로, validation loss나 최종적인 test loss를 감소시키려는 목적 (이건 오버피팅 방지) Normalization : 정규화라고 불리며, 이는 데이터의 형태를 좀 더 의미 있게, 혹은 트레이닝에 적합하게 전처리하는 과정 (이건 전처리) 예를 들어 데이터를 z-socre 변환 0 과 1 사이 값으로 분포 조정     이게 Lasso 방식이고  이게 Ridge 방법 기존 방법보다 축은 위로 쫌 이동했지만 기울기가 좀 줄었다 이 두 방식은 Regularization\n다시말해 오버피팅을 방지한 것이다 , L1 Regularization을 사용할 …","frontmatter":{"date":"April 21, 2022","title":"정규화 정칙화 차이","categories":"DeepML","author":"하성민","emoji":"😁"},"fields":{"slug":"/DML_norm/"}},"next":{"id":"485c4944-42ec-5a62-b090-39cf2a45524f","html":"<h1 id=\"span-stylebackground-color-fff5b1딥러닝-네트워크를-구성하는-레이어-이게-뭘까span\" style=\"position:relative;\"><a href=\"#span-stylebackground-color-fff5b1%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC%EB%A5%BC-%EA%B5%AC%EC%84%B1%ED%95%98%EB%8A%94-%EB%A0%88%EC%9D%B4%EC%96%B4-%EC%9D%B4%EA%B2%8C-%EB%AD%98%EA%B9%8Cspan\" aria-label=\"span stylebackground color fff5b1딥러닝 네트워크를 구성하는 레이어 이게 뭘까span permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><span style='background-color: #fff5b1'>딥러닝 네트워크를 구성하는 레이어, 이게 뭘까?</span></h1>\n<p>ANN : artificial NN 인공신경망</p>\n<p>딥러닝은 y = Wx + by=Wx+b 에서 최적의 <code class=\"language-text\">레이어 W(Weight)</code>과 <code class=\"language-text\">편향 b</code>를 찾는 과정!</p>\n<p>레이어 로 이루어져 있는데.</p>\n<p>레이어 : 하나의 물체가 여러개의 논리적인 세부 객체로 구성되어 있는 경우, 그 내부 객체를 이르는 말</p>\n<p>Linear</p>\n<p>Convolutional</p>\n<p>Embedding</p>\n<p>Recurrent</p>\n<p>이렇게 있음 레이어들이.</p>\n<p>Fully Connected Layer,<br>\nFeedforward Neural Network,<br>\nMultilayer Perceptrons,<br>\nDense Layer…</p>\n<p>등 다양한 이름으로 불리지만 그 모든 것들은 결국 Linear 레이어에 해당</p>\n<p>선형 대수학의 선형변환 (Linear Transform) 과 동일한 기능을 한다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n\nbatch_size <span class=\"token operator\">=</span> <span class=\"token number\">64</span>\nboxes <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>batch_size<span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>     <span class=\"token comment\"># Tensorflow는 Batch를 기반으로 동작하기에,</span>\n                                         <span class=\"token comment\"># 우리는 사각형 2개 세트를 batch_size개만큼</span>\n                                         <span class=\"token comment\"># 만든 후 처리를 하게 됩니다.</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"1단계 연산 준비:\"</span><span class=\"token punctuation\">,</span> boxes<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n\nfirst_linear <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span>units<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> use_bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span> \n<span class=\"token comment\"># units은 출력 차원 수를 의미합니다.</span>\n<span class=\"token comment\"># Weight 행렬 속 실수를 인간의 뇌 속 하나의 뉴런 '유닛' 취급을 하는 거죠!</span>\n\nfirst_out <span class=\"token operator\">=</span> first_linear<span class=\"token punctuation\">(</span>boxes<span class=\"token punctuation\">)</span>\nfirst_out <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>squeeze<span class=\"token punctuation\">(</span>first_out<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># (4, 1)을 (4,)로 변환해줍니다.</span>\n                                           <span class=\"token comment\"># (불필요한 차원 축소)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"1단계 연산 결과:\"</span><span class=\"token punctuation\">,</span> first_out<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"1단계 Linear Layer의 Weight 형태:\"</span><span class=\"token punctuation\">,</span> first_linear<span class=\"token punctuation\">.</span>weights<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\n2단계 연산 준비:\"</span><span class=\"token punctuation\">,</span> first_out<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n\nsecond_linear <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span>units<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> use_bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\nsecond_out <span class=\"token operator\">=</span> second_linear<span class=\"token punctuation\">(</span>first_out<span class=\"token punctuation\">)</span>\nsecond_out <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>squeeze<span class=\"token punctuation\">(</span>second_out<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"2단계 연산 결과:\"</span><span class=\"token punctuation\">,</span> second_out<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"2단계 Linear Layer의 Weight 형태:\"</span><span class=\"token punctuation\">,</span> second_linear<span class=\"token punctuation\">.</span>weights<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">1단계 연산 준비: (64, 4, 2)\n1단계 연산 결과: (64, 4)\n1단계 Linear Layer의 Weight 형태: (2, 1)\n\n2단계 연산 준비: (64, 4)\n2단계 연산 결과: (64,)\n2단계 Linear Layer의 Weight 형태: (4, 1)</code></pre></div>\n<p>축소만 하는 방식</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n\nbatch_size <span class=\"token operator\">=</span> <span class=\"token number\">64</span>\nboxes <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>batch_size<span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"1단계 연산 준비:\"</span><span class=\"token punctuation\">,</span> boxes<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n\nfirst_linear <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span>units<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> use_bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\nfirst_out <span class=\"token operator\">=</span> first_linear<span class=\"token punctuation\">(</span>boxes<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"1단계 연산 결과:\"</span><span class=\"token punctuation\">,</span> first_out<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"1단계 Linear Layer의 Weight 형태:\"</span><span class=\"token punctuation\">,</span> first_linear<span class=\"token punctuation\">.</span>weights<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\n2단계 연산 준비:\"</span><span class=\"token punctuation\">,</span> first_out<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n\nsecond_linear <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span>units<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> use_bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\nsecond_out <span class=\"token operator\">=</span> second_linear<span class=\"token punctuation\">(</span>first_out<span class=\"token punctuation\">)</span>\nsecond_out <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>squeeze<span class=\"token punctuation\">(</span>second_out<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"2단계 연산 결과:\"</span><span class=\"token punctuation\">,</span> second_out<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"2단계 Linear Layer의 Weight 형태:\"</span><span class=\"token punctuation\">,</span> second_linear<span class=\"token punctuation\">.</span>weights<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\n3단계 연산 준비:\"</span><span class=\"token punctuation\">,</span> second_out<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n\nthird_linear <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span>units<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> use_bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\nthird_out <span class=\"token operator\">=</span> third_linear<span class=\"token punctuation\">(</span>second_out<span class=\"token punctuation\">)</span>\nthird_out <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>squeeze<span class=\"token punctuation\">(</span>third_out<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"3단계 연산 결과:\"</span><span class=\"token punctuation\">,</span> third_out<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"3단계 Linear Layer의 Weight 형태:\"</span><span class=\"token punctuation\">,</span> third_linear<span class=\"token punctuation\">.</span>weights<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n\ntotal_params <span class=\"token operator\">=</span> \\\nfirst_linear<span class=\"token punctuation\">.</span>count_params<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> \\\nsecond_linear<span class=\"token punctuation\">.</span>count_params<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> \\\nthird_linear<span class=\"token punctuation\">.</span>count_params<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"총 Parameters:\"</span><span class=\"token punctuation\">,</span> total_params<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">1단계 연산 준비: (64, 4, 2)\n1단계 연산 결과: (64, 4, 3)\n1단계 Linear Layer의 Weight 형태: (2, 3)\n\n2단계 연산 준비: (64, 4, 3)\n2단계 연산 결과: (64, 4)\n2단계 Linear Layer의 Weight 형태: (3, 1)\n\n3단계 연산 준비: (64, 4)\n3단계 연산 결과: (64,)\n3단계 Linear Layer의 Weight 형태: (4, 1)\n총 Parameters: 13</code></pre></div>\n<p>한번 증가(2,3) 시켰다가 축소시키는 방식</p>\n<p>파라미터를 늘리면 (2,3) (3,1) (4,1) = 13  <code class=\"language-text\">(use_bias=False)</code> 일때\n더 많은 데이터를 보존할 수는 잇겟지만</p>\n<p><code class=\"language-text\">use_bias</code> 하면 3 + 1 + 1 해서 총 18 파라미터가 된다</p>\n<p>너무 많은 파라미터는 과적합을 초래한다.</p>\n<h3 id=\"convlutional-레이어\" style=\"position:relative;\"><a href=\"#convlutional-%EB%A0%88%EC%9D%B4%EC%96%B4\" aria-label=\"convlutional 레이어 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>convlutional 레이어</h3>\n<p>필터(커널)를 만들어서 그 필터만큼의 픽셀값들을 다 곱한다음 더해 다음 레이어로 출력</p>\n<p><img src=\"attachment:image.png\" alt=\"image.png\"></p>\n<p>보통 3x3 사이즈 등의 커널을 만든다</p>\n<p>커널의 이동 사이즈를 stride 라고 부른다</p>\n<p>convolutional 레이어는 필터 개수 x필터 가로 x 필터 세로 로 이루어진 weight 값을 가진다</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n\nbatch_size <span class=\"token operator\">=</span> <span class=\"token number\">64</span>\npic <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>batch_size<span class=\"token punctuation\">,</span> <span class=\"token number\">1920</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1080</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"입력 이미지 데이터:\"</span><span class=\"token punctuation\">,</span> pic<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\nconv_layer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span>filters<span class=\"token operator\">=</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span>\n                                    kernel_size<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                                    strides<span class=\"token operator\">=</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span>\n                                    use_bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\nconv_out <span class=\"token operator\">=</span> conv_layer<span class=\"token punctuation\">(</span>pic<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\nConvolution 결과:\"</span><span class=\"token punctuation\">,</span> conv_out<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Convolution Layer의 Parameter 수:\"</span><span class=\"token punctuation\">,</span> conv_layer<span class=\"token punctuation\">.</span>count_params<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nflatten_out <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>conv_out<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\n1차원으로 펼친 데이터:\"</span><span class=\"token punctuation\">,</span> flatten_out<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n\nlinear_layer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span>units<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> use_bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\nlinear_out <span class=\"token operator\">=</span> linear_layer<span class=\"token punctuation\">(</span>flatten_out<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\nLinear 결과:\"</span><span class=\"token punctuation\">,</span> linear_out<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Linear Layer의 Parameter 수:\"</span><span class=\"token punctuation\">,</span> linear_layer<span class=\"token punctuation\">.</span>count_params<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">입력 이미지 데이터: (64, 1920, 1080, 3)\n\nConvolution 결과: (64, 384, 216, 16)\nConvolution Layer의 Parameter 수: 1200\n\n1차원으로 펼친 데이터: (64, 1327104)\n\nLinear 결과: (64, 1)\nLinear Layer의 Parameter 수: 1327104</code></pre></div>\n<h2 id=\"pooling-layer\" style=\"position:relative;\"><a href=\"#pooling-layer\" aria-label=\"pooling layer permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>pooling layer</h2>\n<p>컨볼류셔널 레이어는 필터 사이즈에 의존하게 된다.</p>\n<p>근데 필터사이즈를 키우다보면 결국 컨볼루셔널 레이어의 정체성이 약해지는데</p>\n<p>그래서 필터사이즈가 아닌 receptive Field (수용 영역)을 키워야 한다.</p>\n<p>수용 영역:  출력 레이어의 뉴런 하나에 영향을 미치는 입력 뉴런들의 공간 크기\n(그럼 컨볼류셔널에서는 커널사이즈와 같다.)</p>\n<p>맥스풀링도 맥스풀링 사이즈가 나와야 되는 거 아닌가?</p>\n<p>맥스풀링을 하면 수용영역의 크기는 키울 수 잇지만,<br>\n파라미터 사이즈는 늘지 않는다.</p>\n<p>장점</p>\n<ol>\n<li>\n<p>translate invariance</p>\n</li>\n<li>\n<p>Non-linear 함수와 동일한 특징 추출 효과</p>\n</li>\n<li>\n<p>수용 영역 (receptive Field) 극대화 효과</p>\n</li>\n</ol>\n<div class=\"table-of-contents\">\n<ul>\n<li>\n<ul>\n<li><a href=\"#convlutional-%EB%A0%88%EC%9D%B4%EC%96%B4\">convlutional 레이어</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#pooling-layer\">pooling layer</a></p>\n</li>\n</ul>\n</div>","frontmatter":{"date":"April 21, 2022","title":"인공지능 기초 레이어 이해하기","categories":"beginner","author":"하성민","emoji":"😁"},"fields":{"slug":"/DML_AI4/"}},"prev":{"id":"147c5f3d-9759-59db-a2bd-19a14e906af3","html":"<h1 id=\"span-stylebackground-color-fff5b1활성화함수-데이터를-죽여살려-span\" style=\"position:relative;\"><a href=\"#span-stylebackground-color-fff5b1%ED%99%9C%EC%84%B1%ED%99%94%ED%95%A8%EC%88%98-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A5%BC-%EC%A3%BD%EC%97%AC%EC%82%B4%EB%A0%A4-span\" aria-label=\"span stylebackground color fff5b1활성화함수 데이터를 죽여살려 span permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><span style='background-color: #fff5b1'>활성화함수, 데이터를 죽여살려? </span></h1>\n<p>영어로는 activation 함수라고 한다.</p>\n<p>활성화 되었다?</p>\n<p>=> 어떤 조건을 만족시켰다. 라는 뜻.</p>\n<p>신경망 속의 퍼셉트론 perceptron 혹은 node 도<br>\n‘특정조건’ 이 갖춰지면 ‘활성화’ 된다.</p>\n<p>특정 조건 이란 어떤 임계치를 넘었냐 넘지 않았느냐로 구분된다.</p>\n<p>예를 들어 시그모이드 함수가 있다.</p>\n<h2 id=\"활성화-함수-시그모이드-의-예\" style=\"position:relative;\"><a href=\"#%ED%99%9C%EC%84%B1%ED%99%94-%ED%95%A8%EC%88%98-%EC%8B%9C%EA%B7%B8%EB%AA%A8%EC%9D%B4%EB%93%9C-%EC%9D%98-%EC%98%88\" aria-label=\"활성화 함수 시그모이드 의 예 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>활성화 함수 시그모이드 의 예</h2>\n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 598px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 53.888888888888886%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAABJ0AAASdAHeZh94AAABCklEQVQoz51SyY6DMAzl//+rGk0vHU4cALEJse9L2BKP7IoqpNCRxtITiWO/Z2xroJgQArgQdP55POB2+4L79x2qqn6+c0ExKvZcTSWTAybGIM9zGIYBtm17+c9sf9Pki0q4LAtkWXZIZIxBXdfktywLXNel+1uFsrosUFXViwiTgyCAKIqgKAqYpolEOedHQrVC+dz3PZHatg3jOP7vl2VfkiRgmuZxaJz/PZSz6tB0XYd5nuFKWDVNVdr7gRaGITX+anBn0K56gmQI7OGndXmrEKeHzUaUZQme59EA0jSlANxD3EGsHL9XWNf1WaHv+0RgGAY4jgNxHEPbtrQmXdeRyC74CU3TEOkvlrhc3IGlWg0AAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"image1\" title=\"image1\" src=\"/static/c1afe6b5917bd57f46b9f01956e51f00/0c69d/image1.png\" srcset=\"/static/c1afe6b5917bd57f46b9f01956e51f00/e9ff0/image1.png 180w,\n/static/c1afe6b5917bd57f46b9f01956e51f00/f21e7/image1.png 360w,\n/static/c1afe6b5917bd57f46b9f01956e51f00/0c69d/image1.png 598w\" sizes=\"(max-width: 598px) 100vw, 598px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n그림을 보면, x 값은 무한하고, y의 값은 0에서 1 사이로 이루어져 있다.\n<p>만약 출력값이 0.5 이상이면 활성화 된것으로 보고,<br>\n그 미만이면 비활성화 라고 생각 했을때,</p>\n<p>시그모이드 함수는 입력값이 0 이하일때는 비활성화<br>\n0 이상일 때만 활성화로 만들어 준다.</p>\n<p>시그모이드 함수는 무조건 출력이 0 에서 1 사이니까</p>\n<p>이진 분류에 용이하다.</p>\n<p>0 혹은 1에 수렴하기 때문이다</p>\n<h4 id=\"딥러닝에서-활성화-함수를-쓰는-큰-이유는\" style=\"position:relative;\"><a href=\"#%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%97%90%EC%84%9C-%ED%99%9C%EC%84%B1%ED%99%94-%ED%95%A8%EC%88%98%EB%A5%BC-%EC%93%B0%EB%8A%94-%ED%81%B0-%EC%9D%B4%EC%9C%A0%EB%8A%94\" aria-label=\"딥러닝에서 활성화 함수를 쓰는 큰 이유는 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>딥러닝에서 활성화 함수를 쓰는 큰 이유는</h4>\n<p>딥러닝 모델의 <strong>표현력</strong> 을 향상시켜주기 위해서이다.</p>\n<p>다른 말로</p>\n<p>representation capacity<br>\nexpressivity</p>\n<p>를 향상시킨다고 한다.</p>\n<p>만약에 y = wx + b 라는 모델이 있다.</p>\n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 460px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 67.77777777777777%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAABJ0AAASdAHeZh94AAABcElEQVQ4y6VTTWvCQBDd//8nvLTowUO8iEiIUtAeihSNqAVDMLGI+TJt0m6SzfrKrkaSRgrWgZednZ28nZmdIXmew3VdCDkejxcU+0LCbhd0tTrZOa/4l32JIPQ876pDQRf2+/iazqTO87xycY2Qcw7f9yvGcmSxpoEtFvhLyv7kasrnw6DXw3Y4xNbz8G7bsG0blmUhDEMZxHK5rGRXJ+Qc/HwQaRr2oxG08RimYcA0TSiKglarhc1mg/V6DVVVMZ/PT6XgXJIS8QmCoJLCh6oi0XUZ6WcYXuxZlskfCynrl5QppdjtdrLYUZbh9eER0WQCBiClFCKDJEkkGGMS5X2aphLiMmEjnuvCMAxElOKt2cRzpyOJfdeV9RHRCwhd1K3Qy3axHg4HOI4DIl+SUsSDAVJdx71C4jzHS6OBZHbuM8ZqfXYLiKkoeGq3K037u7duivB7OkWcpoLhbrLTpABw9vva6P2bkGVZZVLufZQfm3U+PkcYfvoAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"image2\" title=\"image2\" src=\"/static/e14cf6b3a95adbc6f4d9415af75dafd7/08a84/image2.png\" srcset=\"/static/e14cf6b3a95adbc6f4d9415af75dafd7/e9ff0/image2.png 180w,\n/static/e14cf6b3a95adbc6f4d9415af75dafd7/f21e7/image2.png 360w,\n/static/e14cf6b3a95adbc6f4d9415af75dafd7/08a84/image2.png 460w\" sizes=\"(max-width: 460px) 100vw, 460px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n이 모델로는 x^2 나 sin(x) 의 분포를 절대 표현할 수 없다.  \n다시 말해서, 선형 함수 (y = wx +b ) 에 어떤 수를 곱하거나 더한다고 해서    \n비선형 함수로 만들 수는 없다.\n<p>그런데 비선형 활성화 함수와 선형함수를 연산해준다면<br>\n이런 비선형 데이터를 표현할 수 있다.</p>\n<h3 id=\"활성화-함수의-종류\" style=\"position:relative;\"><a href=\"#%ED%99%9C%EC%84%B1%ED%99%94-%ED%95%A8%EC%88%98%EC%9D%98-%EC%A2%85%EB%A5%98\" aria-label=\"활성화 함수의 종류 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>활성화 함수의 종류</h3>\n<ol start=\"0\">\n<li>\n<p>이진 계단 함수 ( Binary step Function)</p>\n</li>\n<li>\n<p>선형 활성화 함수</p>\n</li>\n</ol>\n<p>선형 활성화 함수를 쓰면 가중치가 많을 필요가 없다.\n어차피 선형 함수끼리는 곱해도 선형함수기 때문에\n다 합성되어 그냥 커다란 하나의 함수로 치환 가능하기 때문이다.</p>\n<p>그럼 이건 비선형 분포를 예측할 수가 없다.<br>\n이러니 표현력이 떨어진다.</p>\n<ol start=\"2\">\n<li>비선형 활성화 함수</li>\n</ol>\n<p>비선형 활성화 함수를 썼을 때</p>\n<p>representation capacity 가 오른다.</p>\n<hr>\n<h2 id=\"binary-step-function\" style=\"position:relative;\"><a href=\"#binary-step-function\" aria-label=\"binary step function permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>binary step function</h2>\n<p>얘는 출력이 0 혹은 1 밖에 없다.</p>\n<p>그래서 얘는 이진 분류 문제에서 쓰인다.</p>\n<p>임계점 이 있으면 걔를 기준으로 0과 1을 출력한다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n<span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt\n<span class=\"token keyword\">from</span> PIL <span class=\"token keyword\">import</span> Image\n<span class=\"token keyword\">from</span> itertools <span class=\"token keyword\">import</span> product\n<span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n\ntf<span class=\"token punctuation\">.</span>random<span class=\"token punctuation\">.</span>set_seed<span class=\"token punctuation\">(</span><span class=\"token number\">7879</span><span class=\"token punctuation\">)</span>\n</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">binary_step</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> threshold<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>  <span class=\"token comment\"># 0보다 작으면 0, 같거나 크면 1</span>\n    <span class=\"token keyword\">return</span> <span class=\"token number\">0</span> <span class=\"token keyword\">if</span> x<span class=\"token operator\">&lt;</span>threshold <span class=\"token keyword\">else</span> <span class=\"token number\">1</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">binary_step<span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">1</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">binary_step<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">6</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">0</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt\n<span class=\"token keyword\">from</span> PIL <span class=\"token keyword\">import</span> Image\n<span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">plot_and_visulize</span><span class=\"token punctuation\">(</span>image_url<span class=\"token punctuation\">,</span> function<span class=\"token punctuation\">,</span> derivative<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    X <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">10</span> <span class=\"token operator\">+</span> x<span class=\"token operator\">/</span><span class=\"token number\">100</span> <span class=\"token keyword\">for</span> x <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">2000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\n    y <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>function<span class=\"token punctuation\">(</span>y<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> y <span class=\"token keyword\">in</span> X<span class=\"token punctuation\">]</span>\n    \n    plt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">12</span><span class=\"token punctuation\">,</span><span class=\"token number\">12</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    \n    <span class=\"token comment\"># 함수 그래프</span>\n    plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'function'</span><span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span>y<span class=\"token punctuation\">)</span>\n    \n    <span class=\"token comment\"># 함수의 미분 그래프</span>\n    plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'derivative'</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">if</span> derivative<span class=\"token punctuation\">:</span>\n        dev_y <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>derivative<span class=\"token punctuation\">(</span>y<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> y <span class=\"token keyword\">in</span> X<span class=\"token punctuation\">]</span>\n        plt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span>dev_y<span class=\"token punctuation\">)</span>\n    \n    <span class=\"token comment\"># 무작위 샘플들 분포</span>\n    samples <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>random<span class=\"token punctuation\">.</span>rand<span class=\"token punctuation\">(</span><span class=\"token number\">1000</span><span class=\"token punctuation\">)</span>\n    samples <span class=\"token operator\">-=</span> np<span class=\"token punctuation\">.</span>mean<span class=\"token punctuation\">(</span>samples<span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'samples'</span><span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>hist<span class=\"token punctuation\">(</span>samples<span class=\"token punctuation\">,</span><span class=\"token number\">100</span><span class=\"token punctuation\">)</span>\n    \n    <span class=\"token comment\"># 활성화 함수를 통과한 샘플들 분포</span>\n    act_values <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>function<span class=\"token punctuation\">(</span>y<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> y <span class=\"token keyword\">in</span> samples<span class=\"token punctuation\">]</span>\n    plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">4</span><span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'activation values'</span><span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>hist<span class=\"token punctuation\">(</span>act_values<span class=\"token punctuation\">,</span><span class=\"token number\">100</span><span class=\"token punctuation\">)</span>\n    \n    <span class=\"token comment\"># 원본 이미지</span>\n    image <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span>Image<span class=\"token punctuation\">.</span><span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>image_url<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>np<span class=\"token punctuation\">.</span>float64<span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token operator\">/</span><span class=\"token number\">255.</span> <span class=\"token comment\"># 구분을 위해 gray-scale해서 확인</span>\n    image <span class=\"token operator\">-=</span> np<span class=\"token punctuation\">.</span>median<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">)</span> <span class=\"token comment\">#중앙값을 빼줬으니 125 이하는 0, 125 이상은 1로 바뀜</span>\n    plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'origin image'</span><span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>imshow<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> cmap<span class=\"token operator\">=</span><span class=\"token string\">'gray'</span><span class=\"token punctuation\">)</span>\n    \n    <span class=\"token comment\"># 활성화 함수를 통과한 이미지</span>\n    activation_image <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n    h<span class=\"token punctuation\">,</span> w <span class=\"token operator\">=</span> image<span class=\"token punctuation\">.</span>shape\n    <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>w<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">for</span> j <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>h<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            activation_image<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">+=</span> function<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">6</span><span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'activation results'</span><span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>imshow<span class=\"token punctuation\">(</span>activation_image<span class=\"token punctuation\">,</span> cmap<span class=\"token operator\">=</span><span class=\"token string\">'gray'</span><span class=\"token punctuation\">)</span>\n    \n    <span class=\"token keyword\">return</span> plt</code></pre></div>\n<p>내 사진의 pixel 데이터를 가지고<br>\n직저 만든 활성화 함수 Binary step Function 에 넣어보았다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> os\nimg_path <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>getenv<span class=\"token punctuation\">(</span><span class=\"token string\">'HOME'</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span><span class=\"token string\">'/aiffel/Study/26/activation/me.jpg'</span>\nax <span class=\"token operator\">=</span> plot_and_visulize<span class=\"token punctuation\">(</span>img_path<span class=\"token punctuation\">,</span> binary_step<span class=\"token punctuation\">)</span>\nax<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 97.22222222222223%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAATCAYAAACQjC21AAAACXBIWXMAAAsTAAALEwEAmpwYAAAE4UlEQVQ4y32Se0xTdxTHf6QOB7rYRJPtD2D6xxKzjYdsRje3QOaGyRKmkrEskSxL2HCBiNaN4WOUVhhgZlU2dSqUQgsUlA4KBSnbgLHMWqTFWieDzdau2Iv0cimt9972vs5yS33sj+0kJ+f+7jn55HseqKSkZBVBEN9SFKWlaVq9sEC0zri9HT48oMEWlhp9/sWueXwhFwAQjuNVNE23URSlJgiiFcOwzmAw2EJRVCNFUR04jhcipVIppWmaAtEEAXgBIMzyy08A4HkeaJquEoEkSbqWywR40h6+SZLUI4VCsYamaV8sx3A8z1ERlgMAFgDoGPBIDDgZA0QEQeBizgqCEI4BG9GxY8ceAwXhSSAnxIAURf0XkI3Fx8C6ujppJBKhH8oXW6YZ7l/thMPhahFI07QL/sfEOSLZvpJnXJ5Z3ew80eed83d7MH8P5id6QsFgdzAY7CIIYgTDsA9E4NzcXD1JkiaSJC+HQqEfSJI0iDEUCl0mSXIQw7BS9HbOjhXXLJa0qanbm/6cmUnv7u55veHixe1TU7czxq470pw3HZutVutzCKE4+8T1jX97POnT09NpGo0mW6fTZXV2dr7pcrlSXW73prHfrqagfSXF60iKCkUYFoJUBASeB47jot9TvgAskTSEaUopKvQTgb9YTsyz0ZonnWE5mJ0n2lD153ufdd0P+KxuAnyLFEsxHG+5g/Pm3+f4yxPesD9IAwjsURGILSw5+OULYcRxi4uLxYj43+sPqNFoU83a5rGZuaPdTlD03uIax+4Iso5JobjVJrxz8pdIj90rFkaBPjxwU1w9LG/3kQGI1yGAd35RjYD4Ubq32TL/1olRSK0chNRKM7xcOQjv1o/B8+UmtqDBAkPO2a9iQCf/aPkCPHRRqahw1h9oQnC1Ye0njb/6NpT3wQuHTUxSWW8k5cu+8IbyPibpix5qa7UZBuzuI/cAkPf+wqQ4a47jxDsM8zwveoRlWTrMsHAX8zeiVnnhio9Uhpcku2teScj7OiNhh2zr09tL3kh8r+LVVXu+S91Y/P3mKxMz60SFgz+Pvjh5w7FpdHQk49y5c9suXbq0bWBgYKvdbs+Y+mM603hlaD3CAeJazdfQiMmwe6C3e1LTcH78/Jl6m+p4je3jPR92oRFAZ7RdCFskJSL0wYMHr01MTFiLiopsmZmZNoSQPSUl5SeE0OpPPytG6NbNGxJmyY+0rW2HzUNDcEKlgqqqamhuboH38/MXUbx0NUIIYfe8UaDD4SjAMAxOnz4NO3fuhAMHDsCWLVsAIbRerEN+v1/CMAwymUyy8fFxqKysjCgUCvbUqVNQUFBwVyqVJiQnJ6NQKBQF2u32fIZhoLa2lquoqGDlcjnk5uaG4uPjk6JAm80mcTqdSK1WywwGA2g0mkhTUxPT0dEBFy5cuCuTyRLkcjmqr6+XaLVatH///vyDBw/Crl27WKVSyRQWFgrp6enBxMTEpJUrVyLU398vMZvNqKys7LBWq4Xh4WEwGo1gsVigpaWFyMrKSszLy0PJyckStGx7srOzwePxQG9vL+A4DnV1dWLLKdGsXq+PGx4eRqWlpdvOnj17Uq/X17S3t9dqNJpvVCrVkba2tqd0Oh3KycmJiwFTy8vLj7vd7lqj0VhrtVqPHzp0qNpgMKxpb29H/wDMAUgBwy5jOwAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/89d13708e349696eefa28a8b33dc4017/37523/output_7_0.png\"\n        srcset=\"/static/89d13708e349696eefa28a8b33dc4017/e9ff0/output_7_0.png 180w,\n/static/89d13708e349696eefa28a8b33dc4017/f21e7/output_7_0.png 360w,\n/static/89d13708e349696eefa28a8b33dc4017/37523/output_7_0.png 720w,\n/static/89d13708e349696eefa28a8b33dc4017/01dae/output_7_0.png 721w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>이렇듯 이진 함수는 값이 있고 없고로 저렇게 0 혹은 1로 딱 구분해준다!</p>\n<p>Binary step Func 은 단층  perceptron 구조 신경망에서 많이 사용됨</p>\n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 58.333333333333336%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAABJ0AAASdAHeZh94AAACIklEQVQoz12TW2/aQBCF+fF9rxRVldIoL81Fah9apUS5kBCHWxMIIMy1DgkBAjG21971mjV9O9UsmEAfRjtjeWe/M2c3JUMfkQwgAheuM4XPZmCeDR54CLm3rmf2q84D39E1BeXJ/mRNURKrEOPRMy4vznB1dYHT019omnVksxlcZ85Rr1eRz93AMK5RKNwinT6BYWRxd1daNtts+N7d1ytRMjbTOVEQ1TziUBGH4B4EZ5osFExHsv+dUAaI6AOtEde0i1iuT6Y6Wm2gPNlIAJtSk0gtm3Go0IZnD2A2ajAbVU1j9VrI53MoV8owG3Xkcgb6fQtqLjS1XIEkhBSpNV3IIIWLUPiYToZomTXEscTLoI9KMQurZ8J1bE1Jh9n2BB5fjmouAx0ryRxSCsQrwnargUerjVLBQL1WRuXHN5QOPqL7ex/dZgWTyRDnZyfo/enACwUCzsA4g88ZBBEqrwflDxCFdE1cbYT9NsZw9Iyvu59g7O6g+P0L2rnPON77gKPjQ7wMLDDm6AZuwDByXYw9Dz4nyXyKSMx0w2g1YDKF3L29uUTlcB/lox0MHvbwUEij1+toBeQwzSyR+59kGjDT84iV1D+X74vgguGxWYfx8wCNSkZT/V1I9B+7eHqy4PBtQzZM4VBiCu+tj06niVr1Hq/jgTZAUcQRlIrWzi5UqHMyUIbB9kvZLETgwJlNtFy6GvpUkqblsa1ntnkfN+/iP0Fwca1vzPdMAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"image3\" title=\"image3\" src=\"/static/2b42b8842f5620b8dcb726e4ea9e9670/37523/image3.png\" srcset=\"/static/2b42b8842f5620b8dcb726e4ea9e9670/e9ff0/image3.png 180w,\n/static/2b42b8842f5620b8dcb726e4ea9e9670/f21e7/image3.png 360w,\n/static/2b42b8842f5620b8dcb726e4ea9e9670/37523/image3.png 720w,\n/static/2b42b8842f5620b8dcb726e4ea9e9670/e9beb/image3.png 730w\" sizes=\"(max-width: 720px) 100vw, 720px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 퍼셉트론</span>\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">Perceptron</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">object</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> input_size<span class=\"token punctuation\">,</span> activation_ftn<span class=\"token punctuation\">,</span> threshold<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> learning_rate<span class=\"token operator\">=</span><span class=\"token number\">0.01</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>weights <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>random<span class=\"token punctuation\">.</span>randn<span class=\"token punctuation\">(</span>input_size<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>bias <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>random<span class=\"token punctuation\">.</span>randn<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>activation_ftn <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>vectorize<span class=\"token punctuation\">(</span>activation_ftn<span class=\"token punctuation\">)</span> <span class=\"token comment\">#선형 변환 해주겠다는 뜻</span>\n        self<span class=\"token punctuation\">.</span>learning_rate <span class=\"token operator\">=</span> learning_rate\n        self<span class=\"token punctuation\">.</span>threshold <span class=\"token operator\">=</span> threshold\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">train</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> training_inputs<span class=\"token punctuation\">,</span> labels<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">100</span><span class=\"token punctuation\">,</span> verbose<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token triple-quoted-string string\">'''\n        verbose : 1-매 에포크 결과 출력, \n                  0-마지막 결과만 출력 \n        '''</span>\n        <span class=\"token keyword\">for</span> epoch <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>epochs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">for</span> inputs<span class=\"token punctuation\">,</span> label <span class=\"token keyword\">in</span> <span class=\"token builtin\">zip</span><span class=\"token punctuation\">(</span>training_inputs<span class=\"token punctuation\">,</span> labels<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n                prediction <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>__call__<span class=\"token punctuation\">(</span>inputs<span class=\"token punctuation\">)</span>\n                self<span class=\"token punctuation\">.</span>weights <span class=\"token operator\">+=</span> self<span class=\"token punctuation\">.</span>learning_rate <span class=\"token operator\">*</span> <span class=\"token punctuation\">(</span>label <span class=\"token operator\">-</span> prediction<span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> inputs\n                self<span class=\"token punctuation\">.</span>bias <span class=\"token operator\">+=</span> self<span class=\"token punctuation\">.</span>learning_rate <span class=\"token operator\">*</span> <span class=\"token punctuation\">(</span>label <span class=\"token operator\">-</span> prediction<span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">if</span> verbose <span class=\"token operator\">==</span> <span class=\"token number\">1</span><span class=\"token punctuation\">:</span>\n                pred <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>__call__<span class=\"token punctuation\">(</span>training_inputs<span class=\"token punctuation\">)</span>\n                accuracy <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>pred<span class=\"token operator\">==</span>labels<span class=\"token punctuation\">)</span><span class=\"token operator\">/</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>pred<span class=\"token punctuation\">)</span>\n                <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>epoch<span class=\"token punctuation\">}</span></span><span class=\"token string\">th epoch, accuracy : </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>accuracy<span class=\"token punctuation\">}</span></span><span class=\"token string\">'</span></span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> verbose <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n            pred <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>__call__<span class=\"token punctuation\">(</span>training_inputs<span class=\"token punctuation\">)</span>\n            accuracy <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>pred<span class=\"token operator\">==</span>labels<span class=\"token punctuation\">)</span><span class=\"token operator\">/</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>pred<span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>epoch<span class=\"token punctuation\">}</span></span><span class=\"token string\">th epoch, accuracy : </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>accuracy<span class=\"token punctuation\">}</span></span><span class=\"token string\">'</span></span><span class=\"token punctuation\">)</span>\n    \n    <span class=\"token keyword\">def</span> <span class=\"token function\">get_weights</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>weights<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>bias\n                \n    <span class=\"token keyword\">def</span> <span class=\"token function\">__call__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> inputs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        summation <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>dot<span class=\"token punctuation\">(</span>inputs<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>weights<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> self<span class=\"token punctuation\">.</span>bias\n        <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>activation_ftn<span class=\"token punctuation\">(</span>summation<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>threshold<span class=\"token punctuation\">)</span></code></pre></div>\n<p>근데 요런 신경망은 and 나 or 에 대해선 설명할 수 있다.</p>\n<p>다시말해 하나의 선을 딱 그어서 구분하는 문제는 설명 가능하다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">scatter_plot</span><span class=\"token punctuation\">(</span>plt<span class=\"token punctuation\">,</span> X<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">,</span> threshold <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> three_d<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    ax <span class=\"token operator\">=</span> plt\n    <span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> three_d<span class=\"token punctuation\">:</span>\n        area1 <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>ma<span class=\"token punctuation\">.</span>masked_where<span class=\"token punctuation\">(</span>y <span class=\"token operator\">&lt;=</span> threshold<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">)</span>\n        area2 <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>ma<span class=\"token punctuation\">.</span>masked_where<span class=\"token punctuation\">(</span>y <span class=\"token operator\">></span> threshold<span class=\"token punctuation\">,</span> y<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        ax<span class=\"token punctuation\">.</span>scatter<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> X<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> s <span class=\"token operator\">=</span> area1<span class=\"token operator\">*</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'True'</span><span class=\"token punctuation\">)</span>\n        ax<span class=\"token punctuation\">.</span>scatter<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> X<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> s <span class=\"token operator\">=</span> area2<span class=\"token operator\">*</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'False'</span><span class=\"token punctuation\">)</span>\n        ax<span class=\"token punctuation\">.</span>legend<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n        area1 <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>ma<span class=\"token punctuation\">.</span>masked_where<span class=\"token punctuation\">(</span>y <span class=\"token operator\">&lt;=</span> threshold<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">)</span>\n        area2 <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>ma<span class=\"token punctuation\">.</span>masked_where<span class=\"token punctuation\">(</span>y <span class=\"token operator\">></span> threshold<span class=\"token punctuation\">,</span> y<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        ax<span class=\"token punctuation\">.</span>scatter<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> X<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> y<span class=\"token operator\">-</span>threshold<span class=\"token punctuation\">,</span> s <span class=\"token operator\">=</span> area1<span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'True'</span><span class=\"token punctuation\">)</span>\n        ax<span class=\"token punctuation\">.</span>scatter<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> X<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> y<span class=\"token operator\">-</span>threshold<span class=\"token punctuation\">,</span> s <span class=\"token operator\">=</span> area2<span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'False'</span><span class=\"token punctuation\">)</span>\n        ax<span class=\"token punctuation\">.</span>scatter<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> X<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> s <span class=\"token operator\">=</span> <span class=\"token number\">0.05</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'zero'</span><span class=\"token punctuation\">,</span> c<span class=\"token operator\">=</span><span class=\"token string\">'gray'</span><span class=\"token punctuation\">)</span>\n        ax<span class=\"token punctuation\">.</span>legend<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> ax</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># AND gate, OR gate</span>\nX <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nplt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># OR gate</span>\nor_y <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>x1 <span class=\"token operator\">|</span> x2 <span class=\"token keyword\">for</span> x1<span class=\"token punctuation\">,</span>x2 <span class=\"token keyword\">in</span> X<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nax1 <span class=\"token operator\">=</span> plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\nax1<span class=\"token punctuation\">.</span>set_title<span class=\"token punctuation\">(</span><span class=\"token string\">'OR gate '</span> <span class=\"token operator\">+</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>or_y<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nax1 <span class=\"token operator\">=</span> scatter_plot<span class=\"token punctuation\">(</span>ax1<span class=\"token punctuation\">,</span> X<span class=\"token punctuation\">,</span> or_y<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># AND gate</span>\nand_y <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>x1 <span class=\"token operator\">&amp;</span> x2 <span class=\"token keyword\">for</span> x1<span class=\"token punctuation\">,</span>x2 <span class=\"token keyword\">in</span> X<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nax2 <span class=\"token operator\">=</span> plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\nax2<span class=\"token punctuation\">.</span>set_title<span class=\"token punctuation\">(</span><span class=\"token string\">'AND gate '</span> <span class=\"token operator\">+</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>and_y<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nax2 <span class=\"token operator\">=</span> scatter_plot<span class=\"token punctuation\">(</span>ax2<span class=\"token punctuation\">,</span> X<span class=\"token punctuation\">,</span> and_y<span class=\"token punctuation\">)</span>\n\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 595px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 53.888888888888886%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB5klEQVQoz4WSPY/TQBCGF/7EFUj8AxBJrqKgg5M4OoQEOu7jBwRdeQ0VPRUdBQUFQiI0EUYOPmzHHQVCXIiOw1FwYtnrswsIJzvYuzOL1h9cHEC80mq861fP7MwOGX4+uhyG4dpwOFzvdDpbiqLcsSzr5mAwuBFF0dpo7FwhhJzRe6/OBb533fP8q91ud0N6VVW9rev6Ldd1r/k0WH/3/sN5MvtxcoiIAgCEjNWq9sn8py+BzujLDgIXAFjzVV5AFK5Hd0mSJB9FIS6EwIUl94Ix5kjgZDrdLH3Zkg8RMZU/ojBskziOD0RxyrGuHMg5n0jgdDLZLH1syYdlEhGWwEEFLGOeGBGBMS7iOJbAs7Zt71TAyld4ZVLIsiwTQRC0f5e8CCzqAJjNvgvXdSWQUEo3/gaUzCxNs+PjQNi2XS+5DkSQ32ma5jccj8fby8BTMGQyUkr/30PGWN5Dx/m69a8eIuJpD5P5/KB8PRB1wQKQ+JTeLc+Z+FMFMIra5GT27VM5S8g5L2YKQL5uNYdTWfLo6HAb8jnMJepe4AggAm96jzx7+uSCaRotwzAuqarasiwrj6qqNvv9fvP5i5cX5Q0f3N9b0fffrGrafsMwjIamac1er9c0TbOhKK9bpvF29fGjhyu/ACZQ8NrNpxuvAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/63ab4aaa594414b1710b1142bfd534db/3dd3e/output_13_0.png\"\n        srcset=\"/static/63ab4aaa594414b1710b1142bfd534db/e9ff0/output_13_0.png 180w,\n/static/63ab4aaa594414b1710b1142bfd534db/f21e7/output_13_0.png 360w,\n/static/63ab4aaa594414b1710b1142bfd534db/3dd3e/output_13_0.png 595w\"\n        sizes=\"(max-width: 595px) 100vw, 595px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># OR gate</span>\nor_p <span class=\"token operator\">=</span> Perceptron<span class=\"token punctuation\">(</span>input_size<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> activation_ftn<span class=\"token operator\">=</span>binary_step<span class=\"token punctuation\">)</span>\nor_p<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> or_y<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">1000</span><span class=\"token punctuation\">,</span> verbose<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>or_p<span class=\"token punctuation\">.</span>get_weights<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 가중치와 편향값은 훈련마다 달라질 수 있습니다.</span>\n\n<span class=\"token comment\"># AND gate</span>\nand_p <span class=\"token operator\">=</span> Perceptron<span class=\"token punctuation\">(</span>input_size<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> activation_ftn<span class=\"token operator\">=</span>binary_step<span class=\"token punctuation\">)</span>\nand_p<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> and_y<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">1000</span><span class=\"token punctuation\">,</span> verbose<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>and_p<span class=\"token punctuation\">.</span>get_weights<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 가중치와 편향값은 훈련마다 달라질 수 있습니다.</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">999th epoch, accuracy : 1.0\n(array([0.802858  , 0.99642675]), array([-0.78371765]))\n999th epoch, accuracy : 1.0\n(array([0.65508949, 0.02640151]), array([-0.67231513]))</code></pre></div>\n<p>이 정확도를 어떻게 나타냈는지를 보면 다음과 같다.</p>\n<p>x,y 축을 100등분한 다음 True 와 False 의 경계선을 하나 골라 그었다고 생각하면 된다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> itertools <span class=\"token keyword\">import</span> product\n\n<span class=\"token comment\"># 그래프로 그려보기</span>\ntest_X <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span>x<span class=\"token operator\">/</span><span class=\"token number\">100</span><span class=\"token punctuation\">,</span>y<span class=\"token operator\">/</span><span class=\"token number\">100</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span>y<span class=\"token punctuation\">)</span> <span class=\"token keyword\">in</span> product<span class=\"token punctuation\">(</span><span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">101</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">101</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\npred_or_y <span class=\"token operator\">=</span> or_p<span class=\"token punctuation\">(</span>test_X<span class=\"token punctuation\">)</span>\npred_and_y <span class=\"token operator\">=</span> and_p<span class=\"token punctuation\">(</span>test_X<span class=\"token punctuation\">)</span>\n\nplt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nax1 <span class=\"token operator\">=</span> plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\nax1<span class=\"token punctuation\">.</span>set_title<span class=\"token punctuation\">(</span><span class=\"token string\">'predict OR gate'</span><span class=\"token punctuation\">)</span>\nax1 <span class=\"token operator\">=</span> scatter_plot<span class=\"token punctuation\">(</span>ax1<span class=\"token punctuation\">,</span> test_X<span class=\"token punctuation\">,</span> pred_or_y<span class=\"token punctuation\">)</span>\n\nax2 <span class=\"token operator\">=</span> plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> projection<span class=\"token operator\">=</span><span class=\"token string\">'3d'</span><span class=\"token punctuation\">)</span>\nax2<span class=\"token punctuation\">.</span>set_title<span class=\"token punctuation\">(</span><span class=\"token string\">'predict OR gate 3D'</span><span class=\"token punctuation\">)</span>\nax2 <span class=\"token operator\">=</span> scatter_plot<span class=\"token punctuation\">(</span>ax2<span class=\"token punctuation\">,</span> test_X<span class=\"token punctuation\">,</span> pred_or_y<span class=\"token punctuation\">,</span> three_d<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\nax3 <span class=\"token operator\">=</span> plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span>\nax3<span class=\"token punctuation\">.</span>set_title<span class=\"token punctuation\">(</span><span class=\"token string\">'predict AND gate'</span><span class=\"token punctuation\">)</span>\nax3 <span class=\"token operator\">=</span> scatter_plot<span class=\"token punctuation\">(</span>ax3<span class=\"token punctuation\">,</span> test_X<span class=\"token punctuation\">,</span> pred_and_y<span class=\"token punctuation\">)</span>\n\nax4 <span class=\"token operator\">=</span> plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span> projection<span class=\"token operator\">=</span><span class=\"token string\">'3d'</span><span class=\"token punctuation\">)</span>\nax4<span class=\"token punctuation\">.</span>set_title<span class=\"token punctuation\">(</span><span class=\"token string\">'predict AND gate 3D'</span><span class=\"token punctuation\">)</span>\nax4 <span class=\"token operator\">=</span> scatter_plot<span class=\"token punctuation\">(</span>ax4<span class=\"token punctuation\">,</span> test_X<span class=\"token punctuation\">,</span> pred_and_y<span class=\"token punctuation\">,</span> three_d<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 607px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 97.22222222222223%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAATCAYAAACQjC21AAAACXBIWXMAAAsTAAALEwEAmpwYAAAFGElEQVQ4y2WUa0xTZxzG380B03mbm8zpEncx0czEuS1ui37Yt2XxgzG7ZNFtcTPzMt28cRPBtuLihYu4uS1eUSjDO4iotIBSqRQKVRBFRIrQVm7ntKen7WnP6enb91laZFnim/zy//bkfd7n+b/k42TygrG5Y1WZuWvTserWrfll1ZrCMzXZBaeN2Z19AxsGXM5Uu93+kcvlIqoaWa4oyman05kuDDl3xnA6+rO9fmkTA1JoJPIugf+rhLUlt7k5O65hgfYa5muNmK81YN7OauQbOlHV1Anr/Z49j5zDBEAjx3EQvV5Yezm093EIymH876wluJye9EdRSe/MbeVITjOos9Mu0VlpVfSNtCr62rZKeYG2GkX1D7T/WOyE0miNKPoQ9HnDuVXtdMaWcvpZXi39/ohZaesdgtPevYmQO0hA6Rd9tZmLMW97eXR6ei17J6OSvZlxhc1Mvawu3GXAKVOX7ljtXRKU5TpRFCGKXqpIfvZzsZWNW3eBrT7eqA4Mc7C1tmwjxIpESf9dH7IJHmvmRpduP4Sp6TfwdsZlNiu1Ul24y4hTpge64zHBUKjOLwXh9QXokMuBtq5e/GXsgOQTVb/ohflWYwohRiSG9Cv7aNYEQDc+GtZMw+bMDExLv85eT61SP9hVjZOmLt3Jhh6iqJE6r5vDw9PZ1HJkKxqbbei4bYXNZlOdThcedccsdyEhpF9pR1YSItqXVWgnUmgT6fGsb2hy6lV5nq4eetN9bUmTg4QZjI7btWjatyxszlwUqTmRQ68Y6qittVWOhSUIwo+EyEhQSldyyEoEtJPBNJMR1UwGtOPQvON9LMvR4+hN+57CmodEkiSL6AtAELxwdTbhnqEI7TYrPIIASZJAKV1PyHup4wcNhRX+02taA+c2NEjnY2xsEM//2oAz3za0lxd0Vli61ly19ZJolOVSSm+FVfVaKIJqSaE1fr+vVhTFagBWAJ+TTEII2jYS6AjBzQQCJD7lOYK7X5N+2zXiBshj4HkAJBwOx/r4DDzPxychiw8luE1HCpRLW0v5s1vKHCUbyp36jeWO4vUVvm5zkcPputjb51juGBgijLEMxthZURTPjYyMVPA8X+HxeMolSdIHAoGLsix/Sog7Hgoff0PdFEA3aRTNS2AXfsJwzUF03rHs7eloIYxFLbF1oJQiEAjEURQFlEYwODAAURTXEVIer008ZaadojLNZBpHO4Uig8hqzgzcM13U2s3nSZRGjKFQCF5BCLt5jnIjw5TnhunwCKc8GRpBc3NTCiGNoz18KhhlsaRHYdg5QaX754Azn9IN3jhK5FCwTvQKEEUf9UoyBH8Igj8Izi2ovNuDJoslhRBb3PJ/grHqYEww+0U1uu8tSObDOm/9n0QJSXWBUBiCx037KnPRW5mPwY4G8INO1c3zaGtr20xIwzM3ZGOMCfrNR3X+Zj2hlNZxjodo+30FbUqbz1qyFjFr1iJmy1uuuh51oKf/yS/xzyGkX2HHjgQwzSSVaSZGxkBWkhzdOxv+hiNa0VJM1Ag1ujrMuHNii2LJ/TJyI/OTiClrSaS7rljmPV74RO8PhPQjQS5bxcdt7k4Gcl4dZfd0QDcV0by5CDQe3yuYDscsN0khBQGFght0oa/VAHuLAYIvCFmWYwVYT8grS5Ie15fqPDUFh/iawkLOeODg2Bwx5B/grv997JHVuNTRbiJgbDXA8uRgYLdfCv0mhug+3hfc7xU8OQAKo9Hoh/8CV4ZILsh6JXgAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/908e4c3c7ab00f9719162e96d410778e/ef9e5/output_16_0.png\"\n        srcset=\"/static/908e4c3c7ab00f9719162e96d410778e/e9ff0/output_16_0.png 180w,\n/static/908e4c3c7ab00f9719162e96d410778e/f21e7/output_16_0.png 360w,\n/static/908e4c3c7ab00f9719162e96d410778e/ef9e5/output_16_0.png 607w\"\n        sizes=\"(max-width: 607px) 100vw, 607px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>하지만 이대로는 XOR 문제를 풀수가 없다, 정확도가 25%밖에 안나온다</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># XOR gate</span>\nthreshold <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\nX <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nplt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nxor_y <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>x1 <span class=\"token operator\">^</span> x2 <span class=\"token keyword\">for</span> x1<span class=\"token punctuation\">,</span>x2 <span class=\"token keyword\">in</span> X<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'XOR gate '</span><span class=\"token operator\">+</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>xor_y<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nplt <span class=\"token operator\">=</span> scatter_plot<span class=\"token punctuation\">(</span>plt<span class=\"token punctuation\">,</span> X<span class=\"token punctuation\">,</span> xor_y<span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 316px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 101.11111111111111%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAAsTAAALEwEAmpwYAAACOklEQVQ4y61Uz2sTQRR+WKE09iqiYH8IgjdR8L/xIIr0T/Ca2ESqq4I0BC8NAelRc5KgpDnERESQhHQpJiTbsHF/zJhdjW1nTXZ3RmaS0KyVkiUOPOY7vPfxvvc9HgAArN27A4yxEwEAFwFgBQCWAeDSKBYA4AIAzNu2/a8amHsmPVlpq9/edC37nW1ZOcuycrZt53Rd39E0rdBut4v852EYRp7/GOP3PMcS+fbbH12zWN/bfcAJz6aSm9d7h4SymZ7HsKm9hng8Di1FuUwI6THGKKXUpZR64cL/zSkRxq+E5kwmc404zgEbMVIaollKeY0rCBHa5nwLsVjspuM4v8aEYcUGCCVJgkajsUQIOZyGkA47CuAAIbc6m81eJYQchOnwrzRBiDEWkiPRaHRqyZMd+r7PPM9nrjtwOTZNcxvS6TRUKpXlMJLHZvT7A+Z6PtM0zVUUhem6PpRcKBSuTCv5eH6MeYM+Y16f4e9dd19RmKqqQvJiGJcDkikVkn3fPzalWCxCuVxencWUgMuyLEOpVFoNI/nUtQGAc4lE4sZ/W2xuSj6/EzQlBOeJDtNbWyDv1paOiPNzOGc6GB0I9xQcCJ9SRyw2QuI4RNYfPb41OOrNeLwY00ycFdcmmXp5/svnT9K+0nqKMV6v1+vPm82mwK1WS5Jl+QVCKK6q6katVts0DCPBo1qtJjudzgZC6OHe13rqQ/njbUF49/4a/+b5PA3D5PgMxwih8Vmfc113jCMT535xAouaPwW8Ya9ZIRKDAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/672b6bf5b43cef57d2066898669f5a58/67145/output_18_0.png\"\n        srcset=\"/static/672b6bf5b43cef57d2066898669f5a58/e9ff0/output_18_0.png 180w,\n/static/672b6bf5b43cef57d2066898669f5a58/67145/output_18_0.png 316w\"\n        sizes=\"(max-width: 316px) 100vw, 316px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># XOR gate가 풀릴까?</span>\nxor_p <span class=\"token operator\">=</span> Perceptron<span class=\"token punctuation\">(</span>input_size<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> activation_ftn<span class=\"token operator\">=</span>binary_step<span class=\"token punctuation\">,</span> threshold<span class=\"token operator\">=</span>threshold<span class=\"token punctuation\">)</span>\nxor_p<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> xor_y<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">1000</span><span class=\"token punctuation\">,</span> verbose<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>xor_p<span class=\"token punctuation\">.</span>get_weights<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 그래프로 그려보기</span>\ntest_X <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span>x<span class=\"token operator\">/</span><span class=\"token number\">100</span><span class=\"token punctuation\">,</span>y<span class=\"token operator\">/</span><span class=\"token number\">100</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span>y<span class=\"token punctuation\">)</span> <span class=\"token keyword\">in</span> product<span class=\"token punctuation\">(</span><span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">101</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">101</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\npred_xor_y <span class=\"token operator\">=</span> xor_p<span class=\"token punctuation\">(</span>test_X<span class=\"token punctuation\">)</span>\n\nplt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nax1 <span class=\"token operator\">=</span> plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\nax1<span class=\"token punctuation\">.</span>set_title<span class=\"token punctuation\">(</span><span class=\"token string\">'predict XOR gate?'</span><span class=\"token punctuation\">)</span>\nax1 <span class=\"token operator\">=</span> scatter_plot<span class=\"token punctuation\">(</span>ax1<span class=\"token punctuation\">,</span> test_X<span class=\"token punctuation\">,</span> pred_xor_y<span class=\"token punctuation\">)</span>\n\nax2 <span class=\"token operator\">=</span> plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> projection<span class=\"token operator\">=</span><span class=\"token string\">'3d'</span><span class=\"token punctuation\">)</span>\nax2<span class=\"token punctuation\">.</span>set_title<span class=\"token punctuation\">(</span><span class=\"token string\">'predict XOR gate 3D?'</span><span class=\"token punctuation\">)</span>\nax2 <span class=\"token operator\">=</span> scatter_plot<span class=\"token punctuation\">(</span>ax2<span class=\"token punctuation\">,</span> test_X<span class=\"token punctuation\">,</span> pred_xor_y<span class=\"token punctuation\">,</span> three_d<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">999th epoch, accuracy : 0.25\n(array([-0.01313922, -0.01549442]), array([0.00652869]))</code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 610px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 52.222222222222214%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsTAAALEwEAmpwYAAACs0lEQVQoz2XSTUgUcRjH8ZEKCrO0kx7Kg7oHD0EX34MsKrp0qVPQoUOUp17IzLfVqIjSJEQxLSxBXQuhLEjDwLfUdNcKd31p7YV0d3Z2Z5TV2Znd/85/nl9sW1B0+F4/8LwIXbaeFL+9ryQ40VEy19dY+rG3odzx9G7lbF9zmd/nPbf0/ceFL0vuNAAJACxe0Zfd3d1daLPZijo7O/fbbLaCFY8nOxqNWjRN2yq8n5m1sI6TwK1UoC4TuJsB3EkH7u8Fm2yDd+oFlt3OAgC7iSgKwDQMw9R13WSMmZzzWNzn84ExliMMDo9bWEsxR5nAqTqRU9W2eNWJHNcEZjTlIzA3mgMgPYZxw4Ae2iBFlqEoMoLBIEKqClEUYxUKMy53RqT1CFCxGVSbTFSzI15tMqF8k2E0F8LvGssFsCcSDvPSHjvah+bNiK5RQFZIDvhpVZFNSZLQ399/VLDbHVm89SCofMsfEGRNAtXsJFTEwcBcHFRV1XQsiRhZ9JO87IYsB7AWitCaGo7hmJp6f0Do/biaqbQeByoE8JpdhJokxPoFlv8L6lrIZGEdytgTct4+ioWWM/j6soE8jgGSvCt4M/j2kPBq+mvW2aZXGC3bB9RuIsP6Z+z/wbCumc75zxiqO02TV7JpsjKHxi9baLbtPEmiF15RKhDcU4NZxxoneNrFXj5cVWTAKnCzejsna5KBawl/H2XPxnrQWPaI9HnWzj+0XzLHrh82HY8ucMnn48F1FUYknCPMu5xZp1pGkHb1NSxVA+itPQHcSIF5MxWwJsJ4UAxlcSL2NumMMUQZQ0jTEVQ1+L4tQBI9UEM6iEwAyBfaHrSkPn/nbOga+nTv8fBCfceQ615gtD3e8MN6afJZ86fp8Yzfj50HINdg4VxF8uauarxQWQvmRfRQbCV5Uca2/wS/nVMGZEMs4AAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/22359183991f20033bfa35f9058d38fa/5aae9/output_19_1.png\"\n        srcset=\"/static/22359183991f20033bfa35f9058d38fa/e9ff0/output_19_1.png 180w,\n/static/22359183991f20033bfa35f9058d38fa/f21e7/output_19_1.png 360w,\n/static/22359183991f20033bfa35f9058d38fa/5aae9/output_19_1.png 610w\"\n        sizes=\"(max-width: 610px) 100vw, 610px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>이를 해결한 방법이 바로 다층 perceptron 을 이용하는 방법이다.</p>\n<p>Multi-Layer Perceptron</p>\n<p>MLP</p>\n<p>조심해야할거!!! 여기서 layer 는 perceptron 을 얼마나 쓰냐에 대한 layer 이지<br>\n우리가 평소에 말하는 layer 가 아니다!!</p>\n<p>multi layer 는 노드가 2개 이상인 layer 하나를 의미한다! layer 가 여러개인게 아니다!</p>\n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 64.99999999999999%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAABJ0AAASdAHeZh94AAACW0lEQVQ4y3WT208TQRSH+/8/8CBqAC8koiEKStAAVgFraaGFll62pffLdktbdtvdndlLIT58ZldsoNaHk5lMznzzO+f8JuLLEde9Glqvg+8JpBgjpYkjdMRYRe22cB0LKSY40vxnnY/I1BP01Cbfont4ro0jJmGysA0816JWLdFTW/ePTe5j/F9wJDgIkpOJGKVSHs+XCGniTx08T+DICcVCFtPUkY6F60t835nB5iMEBso6rRqpVIL+oMfE1CldnnKtNZlOHW6GGoqSw/EljUqRZiX3py2LSpa2ge/ZDIZ9qhWFUjlPemeLzIdlcrGXqJ06t3cerU6Di9h3zt6sUDh8TunyGNeVYWuEmGDZ9wp9x0DrVkgk42HZB/u77D9bovjlFZnoEqlElFq9SjafYXvlCecbayiHyySi6xQLebpqG90y6ek6ujkmEsi0LSNUl8umSZ+f0s6mOf+0Rj23h6EPCAZXLhdoVhQyO+9Q4m/ROmVcRzwayqMeGsaQ7a1NqtUS019T1EEf0zK5u/NoN6vUGhWmdz7Dm2sGAw3PFY8m/XcfCeoPmq322lykk6TSSQZal2z8AK2jYBgjioXMzIueY4UCFsFChZ5rMrrucHp2wk2g8uN7jl6vUtp9gRJfJX58gGUaM+BDwEIfetJgfKPSqFdQ1RZ55ZIf66ucbT7l4usStfIFU99F2OPZpYfweWhEiiDBDs0dJPq3Lt2rIunPGzSUGI606GsdfsaOOE2ekMmkicWOuSoXcebAITD4CfNudz2BLS0cKWYKgmkb+pCxMWI07IfOWFTybzeYteA2TAinAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"image4\" title=\"image4\" src=\"/static/c750aefadc345879c3263b98f50658d5/37523/image4.png\" srcset=\"/static/c750aefadc345879c3263b98f50658d5/e9ff0/image4.png 180w,\n/static/c750aefadc345879c3263b98f50658d5/f21e7/image4.png 360w,\n/static/c750aefadc345879c3263b98f50658d5/37523/image4.png 720w,\n/static/c750aefadc345879c3263b98f50658d5/d0cc0/image4.png 732w\" sizes=\"(max-width: 720px) 100vw, 720px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n<p>이처럼 층을 여러개 쌓아버리면 비선형 인 XOR 도 에측은 할 수 있지만</p>\n<p>그럼에도 불구하고 문제점</p>\n<ol>\n<li>역전파 알고리즘으로 가중치 업데이트를 못한다</li>\n</ol>\n<p>사실 이진 함수 Binary step function 은 역전파 알고리즘을 사용할 수 없다 back propagation<br>\n역전파를 하려면 미분이 필요한데 얘네는 다 상수라 미분값이 0이기 때문이다.</p>\n<ol start=\"2\">\n<li>다중 출력을 할 수 없다.</li>\n</ol>\n<p>출력이 0 1 둘중 하나밖에 안나오니까\n다중 클래스 중 하나를 골라야 할 때는 쓸 수 없다.</p>\n<p>결론 : 어차피 옛날거니까 걍 넘어가자</p>\n<h4 id=\"선형활성화-함수는-아까-말햇듯이-얼마나-넣든-하나의-활성화-함수랑-똑같고-별로니까-넘어간다\" style=\"position:relative;\"><a href=\"#%EC%84%A0%ED%98%95%ED%99%9C%EC%84%B1%ED%99%94-%ED%95%A8%EC%88%98%EB%8A%94-%EC%95%84%EA%B9%8C-%EB%A7%90%ED%96%87%EB%93%AF%EC%9D%B4-%EC%96%BC%EB%A7%88%EB%82%98-%EB%84%A3%EB%93%A0-%ED%95%98%EB%82%98%EC%9D%98-%ED%99%9C%EC%84%B1%ED%99%94-%ED%95%A8%EC%88%98%EB%9E%91-%EB%98%91%EA%B0%99%EA%B3%A0-%EB%B3%84%EB%A1%9C%EB%8B%88%EA%B9%8C-%EB%84%98%EC%96%B4%EA%B0%84%EB%8B%A4\" aria-label=\"선형활성화 함수는 아까 말햇듯이 얼마나 넣든 하나의 활성화 함수랑 똑같고 별로니까 넘어간다 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>선형활성화 함수는 아까 말햇듯이 얼마나 넣든 하나의 활성화 함수랑 똑같고 별로니까 넘어간다</h4>\n<h1 id=\"이제-진짜-중요한-비선형-활성화-함수-non-linear\" style=\"position:relative;\"><a href=\"#%EC%9D%B4%EC%A0%9C-%EC%A7%84%EC%A7%9C-%EC%A4%91%EC%9A%94%ED%95%9C-%EB%B9%84%EC%84%A0%ED%98%95-%ED%99%9C%EC%84%B1%ED%99%94-%ED%95%A8%EC%88%98-non-linear\" aria-label=\"이제 진짜 중요한 비선형 활성화 함수 non linear permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>이제 진짜 중요한 비선형 활성화 함수 Non-Linear</h1>\n<ol>\n<li>역전파 알고리즘 사용 가능</li>\n<li>다중 출력 가능</li>\n<li>비선형 특징 예측 가능</li>\n</ol>\n<p>와우;; 인공지능 만능열쇠 Non-linear</p>\n<h3 id=\"종류\" style=\"position:relative;\"><a href=\"#%EC%A2%85%EB%A5%98\" aria-label=\"종류 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>종류</h3>\n<ol>\n<li>시그모이드(logistic)</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> os\nimg_path <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>getenv<span class=\"token punctuation\">(</span><span class=\"token string\">'HOME'</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span><span class=\"token string\">'/aiffel/Study/26/activation/me.jpg'</span>\n\n<span class=\"token comment\"># 시그모이드 함수</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">sigmoid</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">return</span> <span class=\"token number\">1</span><span class=\"token operator\">/</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token operator\">+</span>np<span class=\"token punctuation\">.</span>exp<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>astype<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>float64<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">dev_sigmoid</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">return</span> sigmoid<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token operator\">*</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token operator\">-</span>sigmoid<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 시각화</span>\nax <span class=\"token operator\">=</span> plot_and_visulize<span class=\"token punctuation\">(</span>img_path<span class=\"token punctuation\">,</span> sigmoid<span class=\"token punctuation\">,</span> dev_sigmoid<span class=\"token punctuation\">)</span>\nax<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 713px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 97.77777777777777%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAAsTAAALEwEAmpwYAAAFdElEQVQ4y0WQe1DUVRTHb/zR9EfhHzKl05QzTaaElhOQMKCZOaUDqU3jgOADTBFZ4yXgDBCYoaXuAi0L7Aa74fLYWFhe7rK8XxpvEBLJ0EDexmPZZV+/3+/e3+80v4XizJy5c8/9ns8934Pq6+tdlpaWgo1GY7DZbD45MjJycaC/XzC3sBT85+SLk2PT/5ybnnvhDgBoamrqoMlkClldXT05NzsTUtfYEvPkyV/n+T6j0Xh6eXn5OBoYGPCmaRo4jgPCssAHQzgw2xnAmAAmLNhstmweaDKZWngdy7KOXKUI0JgFjr9zHNA0vYiGhoY+xhjzJMInx3Gshfr/TvEf0DSdzgMtFosO1oLGLEdMNoalsWMKzBcxxhNoeHiYB3IAwAFwLCYsa2cIL2I5jqN5IUVRDqDZbF4HcgyNiUPHJ8dxZB343AEkBMN/YaPXbK4HXp8wY31C/XqdWKi1HiuN+XVxjiLBU2hwcGCvzU4BjQmY7TRnpR12WUJYIIQw/K7sdrsDaFgx6vnhzTaarLsgDGFZk41mKQaDzU5NooS4K87psoK9kkKNe2lFtUdRUZF3Xl7evoaGBvemxsaP6vS1XiUlJdt4oChL6pohV3kVl1W5/6pQ+OZKpftVRUqfquoaD6VG556Vr9yDuru7t1N2m4aiaI2dostMxhXt3Nx8PUVR5TY7VWpYtTYsrxhDHRMalpMJxrUEM+rFxQX9zOxcw/jUbJ3Faq1YXrVVWSwWGerq/H2/nWZg3kRB78QyPFu0wpKFAQtNwEoTmDbYgGEYKQ80Gk0P+F3xNQvNwrIVw4yRApqwML5khRmDxYgeDfR4P5o2YM3ADM5qHsPi5jFS1PWcDE4a8MNJgz3//jgMTiyIeODz+UXd/adLcKmon+I1Zf1TRDs8SxZW7Uxp3xTktT8dRysTI15C/Sg5nNlBfH5sxsck98n5u33k+r3HJLb0of3C3T6o6JsQtQOg6t5nuhBFL7il6OnDGe0kUNZFfrj3mIibx5jg/G6IKx2cQMbJUZ8vxR3gElMNb1/VwpYrNbDvVgt4pDXCjuRa8L3VCuqe8RzB34Bua4fatifXwbarWngrQQvvJtbCp8JW2JmsB7fUerhU2LeEJkd6d/mJGh5silC3bI2trN8SW1m/dlbVb46qrP0gueaRuuvp5e8oQDfKu0TvxFcOukSW67fEVDS8Ea1pfD26omHrlao6l2/LOs/90l6BEEIv8fspzUx9M/vW956C0KBPQgO++kxwNsAr8AtfN/69Z56gDw997cTrTr+GXlHmiNzDzwQcuHDqxKEzX/sfCDr6ubffe69u/gMAIQBwAGvuaTOqa2ogP19OS6UyLBZnQfCpU5Mnzl5w9ti9A1WqS5x+uytHN366/b6+ro5RKpVEKpNhqVRKRcfEwNFjx8MO+nptADUajaSpqQkSExPZhIQErrCwEPz8/OcRQpt4G2nXrzvV1epQ6Llvdnd0dEBurhTCw8NBJpOxcfHx4OrqesnNdecGsLW1Vdzd3Q03b95k0tPTSWZmJggEghl/f3/ngIAApFarnXp6elBUVNSu0dFRNicnh7tz5w4rEomY1NRUCAoKuhgYGLgBzM7O/lmlUoFSqaQVCgWuqqoCuVw+HRER4RwbG4uKi4uddDodio6OdisoKCAlJSWsTCYj5eXlNN8nFAovZmdnbwCTkpKkarUa2traQKfTQWdnJxQWFhpCQkKcw8LCkEKhcBIKhejIkSN7JBIJtLS0gFarBd4+f4pEostyudwBdGRkZKRPenp6tEQiicjNzRUIhcLI5OTk8yqV6mWlUokyMjJQfHw88vT03JyWlhYuFosv89qcnJyIlJSUuGvXru1OSkpC/wJKjHCn8l9BbwAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/dc969baa3b6f00349215cd81622a2ecd/01267/output_24_0.png\"\n        srcset=\"/static/dc969baa3b6f00349215cd81622a2ecd/e9ff0/output_24_0.png 180w,\n/static/dc969baa3b6f00349215cd81622a2ecd/f21e7/output_24_0.png 360w,\n/static/dc969baa3b6f00349215cd81622a2ecd/01267/output_24_0.png 713w\"\n        sizes=\"(max-width: 713px) 100vw, 713px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 수치 미분</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">num_derivative</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> function<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    h <span class=\"token operator\">=</span> <span class=\"token number\">1e-15</span> <span class=\"token comment\"># 이 값을 바꾸어 가며 그래프를 확인해 보세요</span>\n    numerator <span class=\"token operator\">=</span> function<span class=\"token punctuation\">(</span>x<span class=\"token operator\">+</span>h<span class=\"token punctuation\">)</span><span class=\"token operator\">-</span>function<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> numerator<span class=\"token operator\">/</span>h\n\n<span class=\"token comment\"># 두 그래프의 차이</span>\ndiff_X <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">5</span><span class=\"token operator\">+</span>x<span class=\"token operator\">/</span><span class=\"token number\">100</span> <span class=\"token keyword\">for</span> x <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">1001</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\ndev_y <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>dev_sigmoid<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> x <span class=\"token keyword\">in</span> diff_X<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nnum_dev_y <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>num_derivative<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> sigmoid<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> x <span class=\"token keyword\">in</span> diff_X<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\ndiff_y <span class=\"token operator\">=</span> dev_y <span class=\"token operator\">-</span> num_dev_y\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>diff_X<span class=\"token punctuation\">,</span> num_dev_y<span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'numerical'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>diff_X<span class=\"token punctuation\">,</span> dev_y<span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'analytic'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>diff_X<span class=\"token punctuation\">,</span> diff_y<span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'differnce'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>legend<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 380px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 64.99999999999999%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsTAAALEwEAmpwYAAADIElEQVQ4y22SzW8bRRjGl/IfoPLdIxJXDkipRHtIDuSAVIEEDQoNihQpIBLnSBsOrfAhB+ilyGqLakrVSo1UwkccJ4IqaSjGadOg2LWSqKRx/bF21ju7m/2atR3v7DzVTrINB0Z69M68mvnpmWdGkiTpUHd39xFCyG/NZnOZUpqhlGYjeZ4nqu24WfhtoU67lbUdJ6voZlYlWrZUKmUq1eo/m5ubCQmAFI/HDzebTQP/MwK+V9cVF5nHBtbqNrbtNgAOahvQNYLV1RwqlQoIIfelcAwMDLzmum4lPMg59znnLBRjAQPAvA5nn1/NsHe/vc1GJ/Ps9roi+ruBw1xbZ4WHDzuKokDX9QXhcGxs7CVKqbwPDMLK9q0pdhvjNxbx/vk0zk7exfCVBYz/uobZQg0z+ToWH6mwWz7rMA6V6IsCGIvFXqaUViNgEAgmOgHHd6klfJN6gFXZwXS+gXfO/oLXYzdxdCKDDy7+haFry9hsOMxq+ZAb2qK48uDg4KuRwzC2KL/cRhEK0Z7lObU+j3Oz9xC7dQNHz1/GiQs5fHY9h5LmMbcd7AFDh6dPf/Wi6zrVVtuFTY1AVp5gbuVv3Nt6JEB3yn/iUv57/LiWxJeZEXy9fAZvXXsbxy+ew8c/zKAga0x1KGRl3+GnA0NHLMuQt7XH2KjkgrxcwPL2CubKacSX4uhP96N3qhcnUyfx3s8n8MaVN9Fzqwc9Px3HJzODuPvkAfuXVCGrdQF8bnz8zGHP8/57ZR5pQ9/gZbvME7kEH/pjiMeX4vzY5DHeO9XL+9On+Mj8F7zilBllFDUiC+Dzw8PDr1BKS4IWBJ2AB36o8AsBENpp7fjOruMncgk/WUj6E/cn/A9TH/kj8yN+0Szu2rsOaqS2EAIPjY6OhkArCp9zLrT3sQOhaK16KhpeYy/byh0kC0nUnBrcjos6qa8Ih319fS/U6/Wrtm3PEUJmTdNMWZY1rWnarGEY6WhOdDLjOd60tWOlNU1L8yafdi03pahK2jCN34ul4oR4lK6uLsk0TfHikRqNxrP51tbWQb960Id5sF9WZYkYRHoKzek9WwOtiYwAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/cc54f650bd2a539ca775e10e0dba1890/3f520/output_25_0.png\"\n        srcset=\"/static/cc54f650bd2a539ca775e10e0dba1890/e9ff0/output_25_0.png 180w,\n/static/cc54f650bd2a539ca775e10e0dba1890/f21e7/output_25_0.png 360w,\n/static/cc54f650bd2a539ca775e10e0dba1890/3f520/output_25_0.png 380w\"\n        sizes=\"(max-width: 380px) 100vw, 380px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># OR gate</span>\nor_sigmoid_model <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Input<span class=\"token punctuation\">(</span>shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'sigmoid'</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nor_sigmoid_model<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>loss<span class=\"token operator\">=</span><span class=\"token string\">'mse'</span><span class=\"token punctuation\">,</span> optimizer<span class=\"token operator\">=</span>tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>optimizers<span class=\"token punctuation\">.</span>Adam<span class=\"token punctuation\">(</span>learning_rate<span class=\"token operator\">=</span><span class=\"token number\">0.01</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nor_sigmoid_model<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> or_y<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">1000</span><span class=\"token punctuation\">,</span> verbose<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># AND gate</span>\nand_sigmoid_model <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Input<span class=\"token punctuation\">(</span>shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'sigmoid'</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nand_sigmoid_model<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>loss<span class=\"token operator\">=</span><span class=\"token string\">'mse'</span><span class=\"token punctuation\">,</span> optimizer<span class=\"token operator\">=</span>tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>optimizers<span class=\"token punctuation\">.</span>Adam<span class=\"token punctuation\">(</span>learning_rate<span class=\"token operator\">=</span><span class=\"token number\">0.01</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nand_sigmoid_model<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> and_y<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">1000</span><span class=\"token punctuation\">,</span> verbose<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># XOR gate</span>\nxor_sigmoid_model <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Input<span class=\"token punctuation\">(</span>shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'sigmoid'</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nxor_sigmoid_model<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>loss<span class=\"token operator\">=</span><span class=\"token string\">'mse'</span><span class=\"token punctuation\">,</span> optimizer<span class=\"token operator\">=</span>tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>optimizers<span class=\"token punctuation\">.</span>Adam<span class=\"token punctuation\">(</span>learning_rate<span class=\"token operator\">=</span><span class=\"token number\">0.01</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nxor_sigmoid_model<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> xor_y<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">1000</span><span class=\"token punctuation\">,</span> verbose<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 그래프로 그려보기</span>\ntest_X <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span>x<span class=\"token operator\">/</span><span class=\"token number\">100</span><span class=\"token punctuation\">,</span>y<span class=\"token operator\">/</span><span class=\"token number\">100</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span>y<span class=\"token punctuation\">)</span> <span class=\"token keyword\">in</span> product<span class=\"token punctuation\">(</span><span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">101</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">101</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\npred_or_y <span class=\"token operator\">=</span> or_sigmoid_model<span class=\"token punctuation\">(</span>test_X<span class=\"token punctuation\">)</span>\npred_and_y <span class=\"token operator\">=</span> and_sigmoid_model<span class=\"token punctuation\">(</span>test_X<span class=\"token punctuation\">)</span>\npred_xor_y <span class=\"token operator\">=</span> xor_sigmoid_model<span class=\"token punctuation\">(</span>test_X<span class=\"token punctuation\">)</span>\n\nplt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span><span class=\"token number\">15</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nax1 <span class=\"token operator\">=</span> plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\nax1<span class=\"token punctuation\">.</span>set_title<span class=\"token punctuation\">(</span><span class=\"token string\">'predict OR gate'</span><span class=\"token punctuation\">)</span>\nax1 <span class=\"token operator\">=</span> scatter_plot<span class=\"token punctuation\">(</span>ax1<span class=\"token punctuation\">,</span> test_X<span class=\"token punctuation\">,</span> pred_or_y<span class=\"token punctuation\">,</span> threshold<span class=\"token operator\">=</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span>\n\nax2 <span class=\"token operator\">=</span> plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> projection<span class=\"token operator\">=</span><span class=\"token string\">'3d'</span><span class=\"token punctuation\">)</span>\nax2<span class=\"token punctuation\">.</span>set_title<span class=\"token punctuation\">(</span><span class=\"token string\">'predict OR gate 3D'</span><span class=\"token punctuation\">)</span>\nax2 <span class=\"token operator\">=</span> scatter_plot<span class=\"token punctuation\">(</span>ax2<span class=\"token punctuation\">,</span> test_X<span class=\"token punctuation\">,</span> pred_or_y<span class=\"token punctuation\">,</span> threshold<span class=\"token operator\">=</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span> three_d<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\nax3 <span class=\"token operator\">=</span> plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span>\nax3<span class=\"token punctuation\">.</span>set_title<span class=\"token punctuation\">(</span><span class=\"token string\">'predict AND gate'</span><span class=\"token punctuation\">)</span>\nax3 <span class=\"token operator\">=</span> scatter_plot<span class=\"token punctuation\">(</span>ax3<span class=\"token punctuation\">,</span> test_X<span class=\"token punctuation\">,</span> pred_and_y<span class=\"token punctuation\">,</span> threshold<span class=\"token operator\">=</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span>\n\nax4 <span class=\"token operator\">=</span> plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span> projection<span class=\"token operator\">=</span><span class=\"token string\">'3d'</span><span class=\"token punctuation\">)</span>\nax4<span class=\"token punctuation\">.</span>set_title<span class=\"token punctuation\">(</span><span class=\"token string\">'predict AND gate 3D'</span><span class=\"token punctuation\">)</span>\nax4 <span class=\"token operator\">=</span> scatter_plot<span class=\"token punctuation\">(</span>ax4<span class=\"token punctuation\">,</span> test_X<span class=\"token punctuation\">,</span> pred_and_y<span class=\"token punctuation\">,</span> threshold<span class=\"token operator\">=</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span> three_d<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\nax5 <span class=\"token operator\">=</span> plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span>\nax5<span class=\"token punctuation\">.</span>set_title<span class=\"token punctuation\">(</span><span class=\"token string\">'predict XOR gate'</span><span class=\"token punctuation\">)</span>\nax5 <span class=\"token operator\">=</span> scatter_plot<span class=\"token punctuation\">(</span>ax5<span class=\"token punctuation\">,</span> test_X<span class=\"token punctuation\">,</span> pred_xor_y<span class=\"token punctuation\">,</span> threshold<span class=\"token operator\">=</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span>\n\nax6 <span class=\"token operator\">=</span> plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">6</span><span class=\"token punctuation\">,</span> projection<span class=\"token operator\">=</span><span class=\"token string\">'3d'</span><span class=\"token punctuation\">)</span>\nax6<span class=\"token punctuation\">.</span>set_title<span class=\"token punctuation\">(</span><span class=\"token string\">'predict XOR gate 3D'</span><span class=\"token punctuation\">)</span>\nax6 <span class=\"token operator\">=</span> scatter_plot<span class=\"token punctuation\">(</span>ax6<span class=\"token punctuation\">,</span> test_X<span class=\"token punctuation\">,</span> pred_xor_y<span class=\"token punctuation\">,</span> threshold<span class=\"token operator\">=</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span> three_d<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 605px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 142.22222222222223%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,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'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/3a79ce8c8d2b15940e8dfba11231f3bf/90cbd/output_26_0.png\"\n        srcset=\"/static/3a79ce8c8d2b15940e8dfba11231f3bf/e9ff0/output_26_0.png 180w,\n/static/3a79ce8c8d2b15940e8dfba11231f3bf/f21e7/output_26_0.png 360w,\n/static/3a79ce8c8d2b15940e8dfba11231f3bf/90cbd/output_26_0.png 605w\"\n        sizes=\"(max-width: 605px) 100vw, 605px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>근데 사실 얘도 XOR 문제를 못푼다. 다른 비선형 함수를 써줘야 된다.</p>\n<p>2차 다항식(quadratic polynomial)을 추가한 시그모이드 함수를 사용한다면 XOR gate를 구현할 수 있다</p>\n<p>이 밖에도 layer를 추가해 준다면 XOR gate를 무리 없이 구현하는 것을 확인할 수 있다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 레이어를 추가했을 때</span>\n<span class=\"token comment\"># XOR gate</span>\nxor_sigmoid_model <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Input<span class=\"token punctuation\">(</span>shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'sigmoid'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 2 nodes로 변경</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nxor_sigmoid_model<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>loss<span class=\"token operator\">=</span><span class=\"token string\">'mse'</span><span class=\"token punctuation\">,</span> optimizer<span class=\"token operator\">=</span>tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>optimizers<span class=\"token punctuation\">.</span>Adam<span class=\"token punctuation\">(</span>learning_rate<span class=\"token operator\">=</span><span class=\"token number\">0.01</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nxor_sigmoid_model<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> xor_y<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">1000</span><span class=\"token punctuation\">,</span> verbose<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n\nplt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\npred_xor_y <span class=\"token operator\">=</span> xor_sigmoid_model<span class=\"token punctuation\">(</span>test_X<span class=\"token punctuation\">)</span>\n\nax1 <span class=\"token operator\">=</span> plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\nax1<span class=\"token punctuation\">.</span>set_title<span class=\"token punctuation\">(</span><span class=\"token string\">'predict XOR gate'</span><span class=\"token punctuation\">)</span>\nax1 <span class=\"token operator\">=</span> scatter_plot<span class=\"token punctuation\">(</span>ax1<span class=\"token punctuation\">,</span> test_X<span class=\"token punctuation\">,</span> pred_xor_y<span class=\"token punctuation\">,</span> threshold<span class=\"token operator\">=</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span>\n\nax2 <span class=\"token operator\">=</span> plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> projection<span class=\"token operator\">=</span><span class=\"token string\">'3d'</span><span class=\"token punctuation\">)</span>\nax2<span class=\"token punctuation\">.</span>set_title<span class=\"token punctuation\">(</span><span class=\"token string\">'predict XOR gate 3D'</span><span class=\"token punctuation\">)</span>\nax2 <span class=\"token operator\">=</span> scatter_plot<span class=\"token punctuation\">(</span>ax2<span class=\"token punctuation\">,</span> test_X<span class=\"token punctuation\">,</span> pred_xor_y<span class=\"token punctuation\">,</span> threshold<span class=\"token operator\">=</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span> three_d<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">/opt/conda/lib/python3.9/site-packages/matplotlib/collections.py:1003: RuntimeWarning: invalid value encountered in sqrt\n  scale = np.sqrt(self._sizes) * dpi / 72.0 * self._factor</code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 610px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 52.222222222222214%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsTAAALEwEAmpwYAAAC7UlEQVQozz2SW0wTaRzFxzcffPAe3QAFsV3dFzcxoYiYmGiiidHE+Gr0yc2uye6KCm1A4oOaaMJFpagRzdJwcbvbuNgLIiItorVQDGlRqggiFqbXGb6OCMzMN98xA2b/ycn/7ZeTcw7394P2Nd6B6G//BMZ+vet6cb7J2Vk56rhUGXlksyTj/C/jH6f+HP8wthnACgAmQsi25tb2kvv2tt0trW2lDoejZHpmZruiKKa5ubmVXPh1yHSy6SV+qn6Mosvd2HHZD/uVU8D1QswHmjAz0IHY2EgJgFzGmMIADWAUmqLJsqypKtUopTQej0NRlCKu3//MdPiGn67+o4Pmlrvo5nMuuv58F31YdYDCyskLtlKkR3xFAAyaxjSd5xyYYNX/hkBEAVKWQJIk8DyP6VislBsdCRcebejDxrOPUGD1sAKLm+VYOlmB1cv6rT+raNyBycgrM4A8RV6kiXQGe672aNwpJzttD7LsrMhmCdESiQQed3Ud4IZDQaMO3FC2DMyr8KDA4sIPlifMdLZdDTWcACJ2cxrIgzKv/Tc0hZ0XPey4rRv5Vi/O3Xayj6PDLMYn8fRJ1z4uGhneeszmXwLmWz3MYHFDh26xutmaMo96pL4H09GhZYfzXzSvsxl2Vy8bev4Uba4e/F7XwsLOa0yIx9Dt69/PvR0OGQ/Zgv87NFiWpcM3lnWoB+v9CEQ/LwHnSUr7+q4XmXSavf8wzoYGg+zTxDgj8UmWjseQnVss5hBsMt5qrKFrz7hoToVX1YvJLXdTQ4VbXXemQz5Y14uBtxN6KXmSJKlJgTBBECkhRCNZSRNEkSZSGSrOEsiLC0Xcq/CYEff2oq7yJAzVPmyr8sJY1YkfL3Qip9yNIzf7MBid0mdjkGUZiwsLyBICQRCQyWSQTCYhZbP4fru4+jvNm/iAoy7jv1vb3vemptU3Utviiyzpr2fhmocv3zQGBl8Xfh92MQAzY8wsiqKZ5/ndqVSqWFEUPRL9r/oGtVtGGZloST0AAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/69cd79a0bf81c5ab624598457dce23e6/5aae9/output_28_1.png\"\n        srcset=\"/static/69cd79a0bf81c5ab624598457dce23e6/e9ff0/output_28_1.png 180w,\n/static/69cd79a0bf81c5ab624598457dce23e6/f21e7/output_28_1.png 360w,\n/static/69cd79a0bf81c5ab624598457dce23e6/5aae9/output_28_1.png 610w\"\n        sizes=\"(max-width: 610px) 100vw, 610px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<h3 id=\"시그모이드는\" style=\"position:relative;\"><a href=\"#%EC%8B%9C%EA%B7%B8%EB%AA%A8%EC%9D%B4%EB%93%9C%EB%8A%94\" aria-label=\"시그모이드는 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>시그모이드는</h3>\n<p>0에서 1 사이 값을 나타내주기 때문에 이진 분류에서 많이 쓰인다.</p>\n<p>근데 softmax 는 굳이 0,1 이 아니더라도 가위바위보, 사진 분별 등 다양한 클래스로 이미지의 확률을 나타낼 수 잇다. 모든 class의 확률을 더하면 1이 된다는 특징이 있다. 다만 이건 hidden layer 에 들어가는 활성화 함수가 아니다.</p>\n<ol start=\"2\">\n<li>하이퍼볼릭 탄젠트 함수 ; tanh</li>\n</ol>\n<p>얘는 쌍곡선 함수이다.</p>\n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 326px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 109.44444444444446%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAWCAYAAADAQbwGAAAACXBIWXMAABJ0AAASdAHeZh94AAACmklEQVQ4y41Vi3LiMAzk/3+wpRwHJNCShx2SOH7beyMlUOhx13pmxw+UlSytzMpahxgT+n6AkBKy6yBlh67r0MqWQXshJIPWdVNBCHGzpZl+G5XCKsQIGsMwIKWEnDNyTkAGdNQwUSOnjBADYoxIMULW5aMtAOccc6xCCHwwjiMb0MiYZ5ssVFRMTgRMkhKaZo/ZcLaj4b3HMIyfhLS5EbLneT2G8UZGCNFDtuVfdjPh8A1hnglpHZfUqF5g6tufEA5PI1RBwUTDV6Vx6c6Yxu57wvsc3ufRJ4/e93Mec0J1XD/k7jqIh3M4XyWzTK4e78HO3ACVDERbQh4PSJkiigghLcjQ2rL0VhSqMQbn85klcF+AW2WRMUwXnF5eYLWH8xHOBTg3z94nKKVxIUJrLZRSOJ8rFngI8QsSrHaQmwJeOzB9Tg+gGzq3RBhJCt6jrpvF4yNCAvp9Cdv3oE9Z3Dk/3iBnFnb/v6JgKUoyBvb8wTsi+1eefywbJwQcFYzIFy0+G+TsR51i3t+RQuCr0UdaawYV8n5NN+QcPiVcSJnwdLrlyViLrjpj/PhAKyTKssTr6yvW6zUOhwO/PM8fh2WOxsDVNReDzvSkMZgRBpbt6Qk7Ho/YbDYzYdc9z+G1E3zXMa7DGM16iwG4XC6oqgpvb28c4W634/f0gXAcFaZpYl1OxmBoGkbX92jblnE6nbgJaKboKLKiKBgPsqFuoKTHFOeZ9HbNnTGQUrJTsv8qmc9+jli5kBC57AmUrMSvCvXDtWsCSPzOewY5orMr/AI6p7+TlTyWELsdmkFgI37hJBpstxfsiw5KW2hjMS3zM0zawIeI/aHAdvsbq6GuMFQ1mlHg0Bdo+x5FOaBuFLT1sO57OB8wqonxB79OspURFZyyAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"image5\" title=\"image5\" src=\"/static/32f976ecbf0ef95c2e8741a0edfade38/ce9b1/image5.png\" srcset=\"/static/32f976ecbf0ef95c2e8741a0edfade38/e9ff0/image5.png 180w,\n/static/32f976ecbf0ef95c2e8741a0edfade38/ce9b1/image5.png 326w\" sizes=\"(max-width: 326px) 100vw, 326px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n<p>저기 파란색 점박이 선이 하이퍼볼릭 탄젠트 함수</p>\n<p>그림처럼 얘는 x의 값이 무엇이든 -1 에서 1 사이의 값만 나온다.<br>\n얘는 0 을 중심으로 하고 있다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> os\nimg_path <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>getenv<span class=\"token punctuation\">(</span><span class=\"token string\">'HOME'</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span><span class=\"token string\">'/aiffel/Study/26/activation/me.jpg'</span>\n\n<span class=\"token comment\"># 하이퍼볼릭 탄젠트 함수</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">tanh</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">return</span> <span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>exp<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token operator\">-</span>np<span class=\"token punctuation\">.</span>exp<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token operator\">/</span><span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>exp<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token operator\">+</span>np<span class=\"token punctuation\">.</span>exp<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">dev_tanh</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">return</span> <span class=\"token number\">1</span><span class=\"token operator\">-</span>tanh<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token operator\">**</span><span class=\"token number\">2</span>\n\n<span class=\"token comment\"># 시각화</span>\nax <span class=\"token operator\">=</span> plot_and_visulize<span class=\"token punctuation\">(</span>img_path<span class=\"token punctuation\">,</span> tanh<span class=\"token punctuation\">,</span> dev_tanh<span class=\"token punctuation\">)</span>\nax<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 97.22222222222223%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAATCAYAAACQjC21AAAACXBIWXMAAAsTAAALEwEAmpwYAAAFQklEQVQ4y23SfUwTZxwH8KdDxW2amOiWJcY5IY4YM5BRw8xCmNOZmMk0hO0f3eY0KgaZ0fBSgzYRgVKEs4CilFJoK0WxtCgV5FUQKYpWQeRVNpEWodjS9gp3vdffcoDJluyXXO655/k+n9zvnkMIoWWTk5NJJEnqCYIoxXFcM/F28oZ9eqZ80uVVTbq8NxzOmZMAgOx2+2GSJG8SBKHy4bhmdMx20+ma0ZEkWUoQhM7tdssQQmipz+d7AADA87xwAz/DA8MK44VniqKaBdDj8ejf54QVD8EANx9b3Of3TwjgSo/Hc28xSAEAQ1AMy3E8I2QWwZpFUAULQb+w7pr1szzPs8Dz9CI4IIAf4jhetxikWI5nBRAAhPD/gsI8x/Osl6BZmuFYgAWQJMkFcG5ubr5loViOB5Lm4N9F03SLAOI4rn8/x3A8EDT7nyxFUW8F8OOR0b/T7Q7XPduU0zg++a7G5fbU4Dhu8nq91TiON0xNTZ0TwOFXf520O5zNtiln9fiUs8bj8da8fTdjsjmcRrvDVTtmm7iK9sTEIIvFEtzT2xth7e0L6+6yiFXK4p1dlk7x8PBI6ODg4NednZZgATSbazc87+kVW3t6wzRabXRJiWq7Wq3e/uSpNXz01ciW7kddm4U3XOZ2e9qFE50lKXDP+oHw0zDnp4FhGGBYVmilUQAd09OV863RDDhxcv4vYFkWOI4FP82Ay+MbF8AlTre3fmaOBoeXpNuGp7n7Q9Oc3U1wFMNR4zMEjE175w+ld9Re5iYYeGHzUNY3MxxJs5yPZISPyIw4fDBgcw0iEUKB7X1jDeWWMUiq6mHSa/v5E3orr+sa45Xto/S5mj5o7Ju4LYAtz19pSh++hrOmF7S8fpCX1Q3wWstr/v6Qg73YMARXmgeGEABCRU3992KLLBB05i63TdYCkZnN85f4QhP3jawFFI0DtZ+VEKjy4bB6v+oxROe0srvzH8DOvDbYU9ABP11+CEFn6uDMrWfDCE6jJecNj+uDJGZYl3Tbvz7lDrVBYvZ/kVpLBaXe8YekmUFufmFCZkCZtyzl27KaICj1Dvll2l1qfUqtP0hipoQ9q/80gtRg7UeGCCQ6XWze8OmvmHjFz7Kw5btTty6Njo/66MfUyJUHCr9ae6hQnK6/v35ZNyBpae26oCOXty7dd2GLaMepyMDvE74N/OHUtk/2Xwxfc+jaluP51ZtQ2xSIlMZm1FxZvKmloe5Buaq4W1lU+FyRm/Mk4ejhtt92hH1+RJKB4s8XBuSWGVCNdP+qpnpzq+ralWdFBZesudmZ1qOHfu/eFy0W/3I8BaHep48+eDPYg3LyLu1qbmmBYqUS0tLOglarg2Px8bBx0+bIVcs/QInHDgfcrVSjA38cCWlsbAKVqhSSklOgtFQNCSdOQPDGkLjVKwIRstlsor6+PpSfn7/95cuXdF5eHpeWlsZgGMYlJCRQYrE4PDQ0FEkkkoCKigoUFxcX3N/fP1tQUADJycmMXC5nEhMTISIiIkbIoc7OTlFHRweSy+XfmUwmWqfTsWq1mr5+/TpXVlZGZWRkhMtkMqRUKgOMRiOKj48Prqqq8mk0Gr6oqIjWaDR0SUkJZGVlxWRlZSFkMBhEV69eRQcPHtxVXFwMra2tYDKZwGKxgMFgAIlEIpZKpQjDsIDk5GQUFRUVgmEYNDQ0QHV1NbS3t4PRaASpVBqbnp6OkIDJ5XIUGxsbrFAoMisqKrL1er1Mq9VmKxSKbAzD1mIYhnJyckR79+5FISEha7Kzs9M1Go1cp9MJOVnuQm0WnH8A6AsThD/1Bc4AAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/14faa2b1cd9d7fa0e7371fb4bf0b0b28/37523/output_30_0.png\"\n        srcset=\"/static/14faa2b1cd9d7fa0e7371fb4bf0b0b28/e9ff0/output_30_0.png 180w,\n/static/14faa2b1cd9d7fa0e7371fb4bf0b0b28/f21e7/output_30_0.png 360w,\n/static/14faa2b1cd9d7fa0e7371fb4bf0b0b28/37523/output_30_0.png 720w,\n/static/14faa2b1cd9d7fa0e7371fb4bf0b0b28/01dae/output_30_0.png 721w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<h4 id=\"단점\" style=\"position:relative;\"><a href=\"#%EB%8B%A8%EC%A0%90\" aria-label=\"단점 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>단점</h4>\n<p>-1 과 1에서 포화된다.</p>\n<ol start=\"3\">\n<li>ReLU 함수</li>\n</ol>\n<p>얘가 요즘 핫하다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> os\nimg_path <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>getenv<span class=\"token punctuation\">(</span><span class=\"token string\">'HOME'</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span><span class=\"token string\">'/aiffel/Study/26/activation/me.jpg'</span>\n\n<span class=\"token comment\"># relu 함수</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">relu</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">return</span> <span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span>x<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 시각화</span>\nax <span class=\"token operator\">=</span> plot_and_visulize<span class=\"token punctuation\">(</span>img_path<span class=\"token punctuation\">,</span> relu<span class=\"token punctuation\">)</span>\nax<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 97.22222222222223%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAATCAYAAACQjC21AAAACXBIWXMAAAsTAAALEwEAmpwYAAAE3ElEQVQ4y32SfUyTdxDHj9Q3BgiKyeZKsSzZgsMC8rKIbmJcYnSLupkxp6JZss39YQZpBjp1QRwGI1KZRjOYlNKW0qKtvAiOquvmHMMyK0rVTYZQnNLaljr68Lz26XNLa9mc2XbJN5df7ptP7nd3UFxcHDM+Pn6MpmkNRVFKn8/X9NDlMpAkqWJoqv7RhN845vauRUTwer0VNE3rpnxOp7PF7/erKYqqpyjK4PV6P4DGxsY4hmEoRERBEPDJCAoCEjSHFEVXhIAkSQ7/m2/qTZKkHjQaTSzDMGORAicIAh8SIgYmmQAd4HlkGHpPBNgf8bFTPkEQAoIgMBFgPeh0uliapv8BRESeZAM8xwdpIRhEiqL+CxiI5L+BRqMxlmVZ+skvMIFgWFPfYRjmQAhI0/Qw/k+E5ghfHauJHr53X3vf7Tt7z+lpvefytj1wj7cRfn+r3+83+ny+75xO57shoMvlOkqSZCdJkqcJgjhDkqQplAmCOE2SZLfT6SyCtW++Me1yT0+6/eatxSNDv2U0nzItrT/59eu3bt/OtN+6nT5w40buNdvV5wAg6nJPb6rDMZoxODiYrlKpVmi12vyWlpbX7t69K3M4HIutVmsyfLT943kMQxN8MIg0yyFBsUjQLPJ8aJQCTtIM+iaI/aEOnR7fEBfgw7WnFQwGkSAIHWzevOlZmmHGhtyT2HRlNDDinQwOPiTC4niB6R3y4A+/jO0NA70TN4KPL4QLXVVoeZHMRmaohIEWRWLrzyOuz0wDuLHuJ76szS4cvXhHKDl1Xajq/pXd327Hrv7RMPCB59EAHxQwst0ng4tsWQno7k4o1vW5U3afw/RyM+ZVXsTlVRZ8ae85zK64EFh15Hs0D/z+ebjD8Qn71C0/teBQp0jTVAPwl2oTtyt/HEssPoMLdrZzktIOdsHOs0xyaQf3/KdtVPb+b7C7f2TPMCI4nN7+CYpBgmJYkuGYiFg/ydB+ikGv7496OPXF9mlbq41pszdWZccVVGbOWiVfMnPljldnv1WWE7f1uEz2SV1uh/XOvFFEMHScf9n0rXVxU9elzMO16mU1Sv3S2ibTEoO5J0N/wZrV3NolBTdilNZ8BSxnjW+f62jtV52s7as9ftSmOFRpe3/Le0a4inBMfRo2fbhDVPXlcUh98YW83Jxs64zp02wAENI1ALgIALE75KUANweui7gJD2iadLvN589jtUKBFRUHsLFRje8UFDyCGQmxAAArVywXLXklF/Ly8grXrFmDYrEYY2JicO7cuRgbF4czZs6Shnzg8XhEHMdBZ2envK+vD/ft28eWl5cHampqsLCw0JGQkBAtkUigpKREtGvXLli/fn1BdXU1ymQyXiKRBKRSKc6fP58AgKQw0Gaziex2OyiVSrnJZEKVSsU2NDRwBoMB6+rqHHK5PLqsrAxWr14tysjIgJSUlIKFCxdicnJyICkpiUtLSxPmzJnj/wvY1dUlMpvNUFpauluj0aDFYsH29nbs7e1FtVrty8/Pf2bDhg0hkAgex5bExERct24dZmVl4bZt2zAzMxMBIDlc1ev1URaLBYqKipadOHHiiF6vr2xubj6oUqkOKxSKPTqdbrpWq4WcnJyo6OhoEIlEMrFYfGjRokUHZTLZwdTU1EPx8fEHpFJpvFgshj8BU+0REQTkMaoAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/7f730f3ef7149dfb5985cbc05cf7273b/37523/output_34_0.png\"\n        srcset=\"/static/7f730f3ef7149dfb5985cbc05cf7273b/e9ff0/output_34_0.png 180w,\n/static/7f730f3ef7149dfb5985cbc05cf7273b/f21e7/output_34_0.png 360w,\n/static/7f730f3ef7149dfb5985cbc05cf7273b/37523/output_34_0.png 720w,\n/static/7f730f3ef7149dfb5985cbc05cf7273b/01dae/output_34_0.png 721w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>얘는 y값이 0 이상으로 쭉 나올 수 있다. 얘는 tanh 보다 훨씬 빠르게<br>\n훈련이 되는데,<br>\n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 593px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 87.77777777777777%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAASCAYAAABb0P4QAAAACXBIWXMAABJ0AAASdAHeZh94AAABdklEQVQ4y6WUUY+CQAyE+f+/zUcTnkiMikhQUVQQRXr5aobseeYCd5vUXbazs+20a2Rm1rat3W43ez6f/7K+7y3iB8IkSWy9XrujaRq/YKxxvqoqnyMIGKvVypbLpa9121hj1HXt5FHXdb4B2WKx8DV7U1JlXK/XF6FuyLLM5vP5QDg2OhEOEeZ57rmnaWqz2cz1A/R4POx+v48yAjifzy/CzWbjN10uF4vj2E6nkwsMUGNSyqSqylJptVBZlk7MfphaOD6mTISEDBHpk7rAREkqx+PRjeg5qGjCCAdC2oVDEAHcbre23+8HHZkhZo0fUl2y2+0cSyZI5oR8AAbA5m9to44I0/2hoQBsiHDqk/tGGGqA/XXouQ6EaFEUhZMS6buhG/bJxxnOQzq8FMQOAWgrEsnBGpx6Fd1VIL6xKHzgEluz1vQk/crh0PfpGUYqApVWdd+rTHRqcvnfsfqTcUJuVj8RDaZG1gwGPzgs7MPD4eA+CL8AyzV9zL5UUJMAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"image6\" title=\"image6\" src=\"/static/669fd9aa60bb1f85cdd2310dddc7eb33/0b5b1/image6.png\" srcset=\"/static/669fd9aa60bb1f85cdd2310dddc7eb33/e9ff0/image6.png 180w,\n/static/669fd9aa60bb1f85cdd2310dddc7eb33/f21e7/image6.png 360w,\n/static/669fd9aa60bb1f85cdd2310dddc7eb33/0b5b1/image6.png 593w\" sizes=\"(max-width: 593px) 100vw, 593px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span></p>\n<p>실선이 ReLU 썼을 때 에러 비율이고,<br>\n점선이 tanh 썼을 때 에러 비율이다</p>\n<p>ReLU의 에러 감소비율이 훨씬 빠르다.</p>\n<h4 id=\"미분할때는-0의-경우에만-0또는-1을-무작위로-배출한다\" style=\"position:relative;\"><a href=\"#%EB%AF%B8%EB%B6%84%ED%95%A0%EB%95%8C%EB%8A%94-0%EC%9D%98-%EA%B2%BD%EC%9A%B0%EC%97%90%EB%A7%8C-0%EB%98%90%EB%8A%94-1%EC%9D%84-%EB%AC%B4%EC%9E%91%EC%9C%84%EB%A1%9C-%EB%B0%B0%EC%B6%9C%ED%95%9C%EB%8B%A4\" aria-label=\"미분할때는 0의 경우에만 0또는 1을 무작위로 배출한다 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>미분할때는 0의 경우에만 0,또는 1을 무작위로 배출한다.</h4>\n<p>근데 여기서 신기한거\n얘는 곡선같은 비선형이 아닌데 어떻게 비선형데이터의 특징을 잡아내지?</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">q_X <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">10</span><span class=\"token operator\">+</span>x<span class=\"token operator\">/</span><span class=\"token number\">100</span> <span class=\"token keyword\">for</span> x <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">2001</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nq_y <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token operator\">**</span><span class=\"token number\">2</span> <span class=\"token operator\">+</span> np<span class=\"token punctuation\">.</span>random<span class=\"token punctuation\">.</span>randn<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token operator\">*</span><span class=\"token number\">10</span> <span class=\"token keyword\">for</span> x <span class=\"token keyword\">in</span> q_X<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>scatter<span class=\"token punctuation\">(</span>q_X<span class=\"token punctuation\">,</span> q_y<span class=\"token punctuation\">,</span> s<span class=\"token operator\">=</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">&lt;matplotlib.collections.PathCollection at 0x7fd529d83610></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 377px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 65.55555555555556%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsTAAALEwEAmpwYAAACA0lEQVQ4y61TbYvTQBBePQTBvyH4E/xyhy//y2/+Bc0Hc1JU9Cinh6Ifit6FChZ62isV7rCXclrbNM3bbtKXJM1uZmS3aWkPT1BceJhJZuaZZ3dniR8ExDCMG9PptBUnSSOO43/BYZKkpwPbvk8IIVc1TbuL/2ExFpYl4ZXd5083B2EMTpQIRBQ5gIC/w6zjTtByvCeS8PJO6dFtiyW4fzLETOQguwGAwsI/bxe+XGfumDe6DEPGnhFEJI+3t7dkYP9kCJ+/B8BFviz6HVbJ6XSGr5t9boUJxuNoTvjgoXZLBqM4w1eNHhxb0drZnCcsNoFhnOG71gBbPcbnZ1go1HV9a9HYHaXwpmnh1x7DlItl8aoqpWwyU2TVtouTlCtCSgtCTZsrzOcF0LZHuFPv4ifTQydKcJpyRS7joyRD0xnji3oXjW8OyuNBxHWFpVJps+gOUDg//AnuNXpYPvypLutj28Vax8O9o75qdtSlS/U5wDphuVy+mefzTgCgIMcnijPR7FLx/ngo3rYs8fJLj9c6njjzxpyLXI1YMTZpQajGZkPX9Tt/GthRwnGccnVpmYAL88Iw3CX9fp9UKpXrtm3XKKUHrutWGWMHnudVA0oNaSkNDN/zqiFjKi7zVDwIjMJ+8H2/YZrmPbXler0ulV6TPiHkUmE3Lvgmq/8XkC9O5vwCivOFkSNrOqIAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/8a40c0cdd720fa5a8189a23c2394b8c9/6146e/output_36_1.png\"\n        srcset=\"/static/8a40c0cdd720fa5a8189a23c2394b8c9/e9ff0/output_36_1.png 180w,\n/static/8a40c0cdd720fa5a8189a23c2394b8c9/f21e7/output_36_1.png 360w,\n/static/8a40c0cdd720fa5a8189a23c2394b8c9/6146e/output_36_1.png 377w\"\n        sizes=\"(max-width: 377px) 100vw, 377px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>뭐 이렇게 잡아낼 수 있덴다; 어렵네참</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">approx_relu_model_p <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Input<span class=\"token punctuation\">(</span>shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">6</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 6 nodes 병렬 연결</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\napprox_relu_model_p<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>loss<span class=\"token operator\">=</span><span class=\"token string\">'mse'</span><span class=\"token punctuation\">,</span> optimizer<span class=\"token operator\">=</span>tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>optimizers<span class=\"token punctuation\">.</span>Adam<span class=\"token punctuation\">(</span>learning_rate<span class=\"token operator\">=</span><span class=\"token number\">0.005</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\napprox_relu_model_p<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>q_X<span class=\"token punctuation\">,</span> q_y<span class=\"token punctuation\">,</span> batch_size<span class=\"token operator\">=</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">100</span><span class=\"token punctuation\">,</span> verbose<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n\napprox_relu_model_s <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Input<span class=\"token punctuation\">(</span>shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token comment\"># 2 nodes 직렬로 3번 연결</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\napprox_relu_model_s<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>loss<span class=\"token operator\">=</span><span class=\"token string\">'mse'</span><span class=\"token punctuation\">,</span> optimizer<span class=\"token operator\">=</span>tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>optimizers<span class=\"token punctuation\">.</span>Adam<span class=\"token punctuation\">(</span>learning_rate<span class=\"token operator\">=</span><span class=\"token number\">0.005</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\napprox_relu_model_s<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>q_X<span class=\"token punctuation\">,</span> q_y<span class=\"token punctuation\">,</span> batch_size<span class=\"token operator\">=</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">100</span><span class=\"token punctuation\">,</span> verbose<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n\napprox_relu_model_p<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\napprox_relu_model_s<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Model: \"sequential_4\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_5 (Dense)              (None, 6)                 12        \n_________________________________________________________________\ndense_6 (Dense)              (None, 1)                 7         \n=================================================================\nTotal params: 19\nTrainable params: 19\nNon-trainable params: 0\n_________________________________________________________________\nModel: \"sequential_5\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_7 (Dense)              (None, 2)                 4         \n_________________________________________________________________\ndense_8 (Dense)              (None, 2)                 6         \n_________________________________________________________________\ndense_9 (Dense)              (None, 2)                 6         \n_________________________________________________________________\ndense_10 (Dense)             (None, 1)                 3         \n=================================================================\nTotal params: 19\nTrainable params: 19\nNon-trainable params: 0\n_________________________________________________________________</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">q_test_X <span class=\"token operator\">=</span> q_X<span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token operator\">*</span>q_X<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nax1 <span class=\"token operator\">=</span> plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\nax1<span class=\"token punctuation\">.</span>set_title<span class=\"token punctuation\">(</span><span class=\"token string\">'parallel'</span><span class=\"token punctuation\">)</span>\npred_y_p <span class=\"token operator\">=</span> approx_relu_model_p<span class=\"token punctuation\">(</span>q_test_X<span class=\"token punctuation\">)</span>\nax1<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>q_X<span class=\"token punctuation\">,</span> pred_y_p<span class=\"token punctuation\">)</span>\n\nax2 <span class=\"token operator\">=</span> plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\nax2<span class=\"token punctuation\">.</span>set_title<span class=\"token punctuation\">(</span><span class=\"token string\">'serial'</span><span class=\"token punctuation\">)</span>\npred_y_s <span class=\"token operator\">=</span> approx_relu_model_s<span class=\"token punctuation\">(</span>q_test_X<span class=\"token punctuation\">)</span>\nax2<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>q_X<span class=\"token punctuation\">,</span> pred_y_s<span class=\"token punctuation\">)</span>\n\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 598px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 53.333333333333336%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAACWUlEQVQoz12RTU8TURSGG+MPoPwBl8ak0WLCWq2AERe6culv4Q8Q45qErZuGxEUTOxTaBAK0NBWlDB+RQKidfk3b+eh83HvOvcfcW1rQm9ycmTvPvPO+7yR+HR/Pt9rtt51OZ8E0zXfZbPZTtVp9b9v2gmVZb5p/GpntzfzDunk202g0li3LWur3+wvlcvmDYRgfe73uYrPZXGy328u/L84fJ9r2cAtQkJSChFBT6q2uiSQFYRSWDw6SzVbnpTuK9Nn/nNooJFmd3pdEq9svMJRERKDpu60YGvrRsFgwZn8cHS05o3jCiQknx5OHXFCra68mXM/PjxhqUN5b6qUYBHlB5Jz9rCYHve4LL4yJo0AtdMepAQFDGgwGqwnPdQshR0KhwWkUJejHQIxxZ9MwZk/Nk8WIcQoYTgQnHDEQoDQ811lNjHx/UzmJAaeCanEUQn0VAJztYil5c3PzCgDIjwFvnU3ZUQyg+nGGQy1oqK78iP8jGDAQHCUhgPM9byTPLy5eC0QKGSIDIe+n8SOueqWhEvQ8z1A3XsRBiGkn0ou40E45d3Z3d5KXl5cZBCCOEgMG05/HUUjlULG6Q9/3jduI6EcwiasdjgXBLRZLyaurqwyifq64cYxxEsXfOXRdt6CtCyGDmJMXMnJDRhx09xTHsV+pVGaur68zjDF1JkYR18xkIqJQGrZtf06sr68/qdVqz0qlUvrMrKeyOSO9U/mR2tvdSZunp6mNjY3n+/v7D1ZWVmZyudz8Sb2e2touzhX2qqmv3/LpSu0oVSkfPD08rM6tra09+guFCwxWxTqbwQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/e4cb0b48df2ca3d89370cdbd450804b8/0c69d/output_39_0.png\"\n        srcset=\"/static/e4cb0b48df2ca3d89370cdbd450804b8/e9ff0/output_39_0.png 180w,\n/static/e4cb0b48df2ca3d89370cdbd450804b8/f21e7/output_39_0.png 360w,\n/static/e4cb0b48df2ca3d89370cdbd450804b8/0c69d/output_39_0.png 598w\"\n        sizes=\"(max-width: 598px) 100vw, 598px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>parallel 병렬<br>\nserial 직렬</p>\n<p>병렬로 쌓는게 더 부드러워 보이지?</p>\n<p>x** 2 의 그래프를 근사해낼 수 있다는 말이다.</p>\n<h4 id=\"단점--dying-relu\" style=\"position:relative;\"><a href=\"#%EB%8B%A8%EC%A0%90--dying-relu\" aria-label=\"단점  dying relu permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>단점 : Dying ReLU</h4>\n<p>모델에서 ReLU를 사용한 노드가 비활성화되며 출력을 00으로만 하게 되는 것</p>\n<p>가중치 w값에 의해 입력값 x에 상관없이 0이하로 나오게 되었다면,<br>\n이 이후의 업데이트에서는 그래디언트가 항상 0이 되어<br>\n가중치 업데이트가 일어나지 않는다.</p>\n<p>즉, 이 노드의 출력값과 그래디언트가 0이 되어 노드가 죽어버리는 것이다.</p>\n<p>이러한 현상을 줄여주기 위해서는 학습률을 낮춰주어야 한다.</p>\n<p>학습률 뿐만 아니라 dying ReLU 를 없애기 위해 시도한 여러 경우가 있다.</p>\n<ol>\n<li>Leaky ReLU</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> os\nimg_path <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>getenv<span class=\"token punctuation\">(</span><span class=\"token string\">'HOME'</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span><span class=\"token string\">'/aiffel/Study/26/activation/me.jpg'</span>\n\n<span class=\"token comment\"># leaky relu 함수</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">leaky_relu</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">return</span> <span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span><span class=\"token number\">0.01</span><span class=\"token operator\">*</span>x<span class=\"token punctuation\">,</span>x<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 시각화</span>\nax <span class=\"token operator\">=</span> plot_and_visulize<span class=\"token punctuation\">(</span>img_path<span class=\"token punctuation\">,</span> leaky_relu<span class=\"token punctuation\">)</span>\nax<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 97.22222222222223%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAATCAYAAACQjC21AAAACXBIWXMAAAsTAAALEwEAmpwYAAAE2klEQVQ4y32Se0xTdxTHD6tsih0yt8IfaCVClm0Einbii40t7JElXTaIGDPZA7fsrwkjCyx2m7LgVKYVcLKIUlpaSyG0IApuoNb5RBgVBsrQDFaVUKQPbC/33XvPcrE49zzJyckv55tPzvmeHxQWFi70+XwHaJo2URSl9/v9R+9OTjaSJGlgaKp2OhC0TUx530RE8Hq9ZTRNW+Z0bre7KRgM1lMUVUtRVKPX6/0QjEbj4wzDUIiIoijiwyGIIhI0hxRFl0lAkiTH/k039yZJ0gomk0nOMMxEuMGJohiSEhH5GYan+VAIGYbWhoH9YR07pxNFkRdFkQkDa8Fischpmv4LEBFDJMOHuJBAi4KAFEX9F5AP1z+BNptNzrIs/fAKDC8gywsP1mYYZqcEpGl6DP8nJB/hu4q9UWO3x83jU/4Ttyc9rbfdnmMTU75jRDDYGgwGbdPT02fdbvdGCXh3crKKJMl2kiSbCYJoIUnSLlWCIJpJkvzR7XYXQP7778kuXrqcOjw8vGJk5IbK3tK6rvbI4ayha9fThq4Pp/b0XV3V19cXBwCycxcvPeu6dUt18+bNVIPB8JLZbM5samp6YXR0NMXlcq3o6elRQv6WLQqapgnJfI7nEUUBeT40W1mOR1+QQo6hv5YmdHumf+P4EIZC/0xBEJAgCAu8k5sdf4+g3JIHwxMB3jvDSuYJXoIVZtgQ459hcNwb+GIW6Av8Itz/IZykkY4XrmzYQz20VWkV1u7Rye5RL1aeuhEyXvpdvDLqFXVdI6Lj17vsiYFxHLzlmQVOeO8NhgQRw9d9OLjwlfWAA9YnCi29U69Xnse3qy9ilu4nfKPyPL66/xxqDlzgM/acwa7BO1+GJxya+8t/O7A0KdI0VQd37HtiP9ZfcCs+bcWEkuNc0rYOdknxcSbh8xPckwV2amXpSewccGnHEGFswtMfIBkMkAw7w3AMxfIMQbNsgKRpgmLR579XC6cri+a9u8+eLN9YrpZv2JU2L6twTdQrn2QsfOur5xX536eoCg6var08/NS3IwjGlh+eaz7VvaKm5UzaNwcN66vqGtbt0zetOXrygqrl7M8rrcc6EmCMwghz5xU4227LPnm8td9w5FDvoYNVTl35LucHmzfZoB+hqr4ZNn20Vban4iAkP/P02rWrV/dELZjvfCQCnABwFQBOA4B862clANcGB2RcwAOmo5ZtnV1duE+nw7KynWg01uOG3NxpeDRGDgDwWtbLshcz1sH6jIw8jUaDSqUSo6OjMTY2FqMXLcLH5s9PkHTg8XhkHMdBe3t7UW9vL+7YsYMtLS3lKyoqMC8vzxUTE7Ng6dKlUFJSItNqtZCTk5Or0+lQpVKFEhIS+MTERIyPjycAYMks0Ol0yoaGhkCv1xfZ7XY0GAxsXV0d19jYiDU1Na6ioqIF27dvB41GI1Or1ZCUlJSbkpKCy5cv55ctW8alpqaKCoUi+ADY0dEh6+zshOLi4m0mkwkdDge2tbVhd3c31tfX+zMzM6NycnIkkAzux+a4uDjMzs7G9PR0zM/PR7VajQCgnO1ardYIh8MBBQUF66urq/dbrdZdDQ0Nuw0Gw16dTqe1WCyRZrMZ0tPTI+RyOURGRqYolcpylUq1Oy0tbXdycnL54sWLdyYmJi5SKpXwB1PzFwcfG+ggAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/7da76d02e7f1e5ad1bb29a147069dbd5/37523/output_41_0.png\"\n        srcset=\"/static/7da76d02e7f1e5ad1bb29a147069dbd5/e9ff0/output_41_0.png 180w,\n/static/7da76d02e7f1e5ad1bb29a147069dbd5/f21e7/output_41_0.png 360w,\n/static/7da76d02e7f1e5ad1bb29a147069dbd5/37523/output_41_0.png 720w,\n/static/7da76d02e7f1e5ad1bb29a147069dbd5/01dae/output_41_0.png 721w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>보면 음수가 0이 아니라 0에 가까운 음수이다. 이렇게 0이 나오는 걸 막아주었다.</p>\n<ol start=\"2\">\n<li>PReLU</li>\n</ol>\n<p>return 값을 보면 alpha 값으로 기울기를 직접 설정할 수 있다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># PReLU 함수</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">prelu</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> alpha<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">return</span> <span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span>alpha<span class=\"token operator\">*</span>x<span class=\"token punctuation\">,</span>x<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 시각화</span>\nax <span class=\"token operator\">=</span> plot_and_visulize<span class=\"token punctuation\">(</span>img_path<span class=\"token punctuation\">,</span> <span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> prelu<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> <span class=\"token number\">0.1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># parameter alpha=0.1일 때</span>\n\nax<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 711px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 98.33333333333334%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAAsTAAALEwEAmpwYAAAFP0lEQVQ4y3VSe0xTVxw+wpziTLYRw8OZkghOI/hILVCeWoyPTDK3DBAciyyb24J2NpSHUTQwo2IduBDjLI+xP5Cy8vDBKC0UmDwUUYdbAZEZ8IFQSsELfd3ec+79LbcUsi3Zl3w5uff3ne/8vt85aGBgIHh2dvYQRVEH5+bmDvb09Ej7+/u/tlqtKbOz1Kcm8/Rnj4efrt6wLnDp5ORkEkVRqXxtcHDwq87OTtnY2FiaxWJJpigqzWw270Tj4+MnWJaFBfLgeLIsYEJgzk6D2WzeFyoSrbDb7YTjuEWdS+v+5len09mNpqam5O6aEwD4Dbya5TggFhpjwrJAUa/3hIkjvGiaptxaPK9xaYl7L2CMW5DJZJLz7hzHMfMCziW0OBiWsBzhOzVPT++VSCTLaZqedXfF/ocM/59hGD0ym6cy3aeShRhWGgMmHMwnZ2FmZmZvVFQU36FlISn8G8TdYSsyGo2ZdpoBi8NJLA4nb8Y6MWG5+ZlyGGN+hntFItEKm81uYVnXzHhDdiE2IYTwB9M03YqU5RV+lSp15I0Gzbb6m7+KykpLY+p+qYps0uqELS16YUPDrTClUvmOl5fX8t6u25u7OzuE3d13tlRUVESpVCqxSqWK6Orq2tLR0bFNr9evQ6PPX344PWfTEMyoOYJrR1680o2OTWg4ltRghqm12uw3X89Mb30vYK3X4DPjNRvtrKcdjrqJiQnd5OSk1mQyNTEMo2YYRmOz2fLQg4G/8oaMFpi2OmHUbIXnMw4YNlmBsjMwQTnASNnBZrXE9xR++ZaybQhevnbA/wFj3Iv6hkayMmsewaWWJ3Tl3WdY1z9B9INGor7/Av/QMszo+sfBabfuhlr5yuzq+7PDkxZ+fgxhWf6JLZB233Iz6ng0nLW76DaIz+mdOy62k7Sf7pH0yocktawHH1Dexfm3DGCcmtkNg4UrTtY8pJ6arK5meCP37RIAzuk2bEE1HYZc8flW8M24BWuyGiDohAbeP6mBtccbYeNpLRxQ3oE/Rib2gfnHlZnVD6D32YwrHo0JODELNEMAExb4V4YxvoPUv/WlhOc39nkfrdGtzrih9ZHVN/vIrutWy29q35XW6eOL9PcGRl6FAjQsk/7c2SKt7O043/S46fvmJzqF9onunGZId75pqKlI2/+w/c/RYgQALqpLLm04c1wWnp6WEvdF8kc7vklNCE+I3RzQ5K4j5L1kfkWr3vYLCEMI7UQISdzcihBa5q678IZWq/tdrVZDaWkZoywpofPy8+FAcvK1j/dIUN53ZzxO557wzM3OQJ+nHZKmpCTDNqGQCQ7eyGxYv54NEAgsawVrgl1Obtflen2roba2DqRSKXvhgoIUFRVBdHS0+lDqQZSZmeWRk53tefFCAfokISFDJpOBKDSUCwoK4jUgEAicCKFN6B9YZjAYHtXX10NBQQEuLCxkFAoFHD58uFoul6Ps7GyPqqoqz8bGRiSXy2VXr16FmJgYHBsbSyIjIyEkJMTh4+MT4uvru2j4Znl5eV91dTWUlZUxVVVVTt78ypUrqra2NtTa2uqxa9cuz9jYWBQcHHwsNDQU4uLiGLFYjJOSkriwsDC7v79/sJ+f36Khl0KhGNZoNNDc3Ax6vR7a29uhpKTkusFgQAaDwUMkEnn4+/sjb2/vrO3bt/OjgcTERMjJyYH9+/dDYGDgpsDAwEXDpadOnUosLi4+dvny5XSlUpl+9uxZeW5u7gd85IyMjCUSiWRJfHw8EggEm4RC4bcRERHp0dHRR8LDw48KBIIjUVFRq8RiMfobMZkvEjbG2dEAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/b4e78c3aceed27d2a6bd4990154e4e3a/a8e5b/output_44_0.png\"\n        srcset=\"/static/b4e78c3aceed27d2a6bd4990154e4e3a/e9ff0/output_44_0.png 180w,\n/static/b4e78c3aceed27d2a6bd4990154e4e3a/f21e7/output_44_0.png 360w,\n/static/b4e78c3aceed27d2a6bd4990154e4e3a/a8e5b/output_44_0.png 711w\"\n        sizes=\"(max-width: 711px) 100vw, 711px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<ol start=\"3\">\n<li>ELU</li>\n</ol>\n<p>미분 불가능했던 0의 부분을 자연로그로 꺾어주어 미분 가능하도록 했다.<br>\n(그만큼 계산이 오래걸린다)</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># elu 함수</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">elu</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> alpha<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">return</span> x <span class=\"token keyword\">if</span> x <span class=\"token operator\">></span> <span class=\"token number\">0</span> <span class=\"token keyword\">else</span> alpha<span class=\"token operator\">*</span><span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>exp<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">dev_elu</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> alpha<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">return</span> <span class=\"token number\">1</span> <span class=\"token keyword\">if</span> x <span class=\"token operator\">></span> <span class=\"token number\">0</span> <span class=\"token keyword\">else</span> elu<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> alpha<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> alpha\n\n<span class=\"token comment\"># 시각화</span>\nax <span class=\"token operator\">=</span> plot_and_visulize<span class=\"token punctuation\">(</span>img_path<span class=\"token punctuation\">,</span> <span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> elu<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> dev_elu<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># alpha가 1일 때</span>\nax<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 713px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 97.77777777777777%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAAsTAAALEwEAmpwYAAAFc0lEQVQ4y02Se0xTVxzHz0jmP0tY4nSbcWiWLc7ndMIigsNXsiUT53QxCLhYnMAGrCABNh4FgVmwBayVt7ykYWApAqWltCAwlYfWBRxMh1TlXUGEvnsf597fcisEf8kv9+Sc7/n8vvd7L1Kr1Wvn5+eDzWZzsNVqDRweHg7X6/WRiyYTtxe4uGg6OzFt9AQANDk5ddBsNvMsFkvg9PQUT6O7df62/uG50amXgf+Nv/jRMGH8Hg0ODnqTJAksywLDMLBc3JprG0GBxWYv4IAWi6WT02GMXXoHxQCNGaBo7HoSBPkSjY6OetI0zZEw1yzLMlxzaxtBEzTDAkWSeRzQZrOpuWEsALl0vqyluX2M6ecuIEVRLKd7A8bYSZohKMxdBKfTeZkDWq3W10CWpTDDMg4SM/D6DmcGaJoeQwaDwQtjGt4sJ4VdvTyZIAjJkkPNkgRTmFnWcI7ZJeAEGhkZ8XI4CSBpDARFs3aCdk1mGYbLiuJydDgcLoeLJnMrRTPgJClsJWiGee2MWSogSXIc5V+VviMpvb6nQNbgeaXyhldhWeXe65XlX2m1Wk+tTrdbpVJ519TUbOSABSVlm6WVdd4F1fWeZWXl+0pKSvyqqqp8m5UtXp2dnZ6NDYpdqK+vd5PNbm8gSbIB03T94sKC6un4lJYgCAVBkDdIktQtmkwhHHBsZi7Z7iRaWUzJZ2fnNEajUfdidrbN6XDcpCiq6ZXJUoIeD+r9Zk0OmDY5wU5iIDEL0ybClc0rGwkEzcAri6OYAyr1hp7+ZwuwYHd9K6CW/jIrQbtCfGGym9DQ3/f21vQ9ox+MLdDF3Qa6bdiIJe0juGlgir52+6lzdNYKL0223HEAlHzjXquobQSE6keEYdaK24Zm8OMZM779ZI56OmeDyXnrM2R88o/3mbJeHF//EPtkddA/FPbg4Gv9OKTyPj4o7nIKmoagZ8SYexkAZdx80Op/9S7sy75F/lR1H8fJB3Gm6l8cXz9I5epGoN8w9xwtjj3y9b/yF6yLa4GPf1eDR3wLfH5BCzvTtbA+Tglef3SA/N7zwuhpQCLVYPemlDb4NEkNW1PbYN+lTtidoYNtqRrYlKKBi6rheTQxrN/un6vrcY+Qd647f1O7LrZR+0FMo/b9mEbt2vNNrTsFLUPyvtGoFAegjLo7kk9+a9av/lWh2ZjQ0rYhvlm3JrpRuz5e1bqGr+g5e+2OAiGE3uICV1xNX19wKf3LSF7g/rOnjh+O4gV4n/zadyt33jeD0c7Dx904cdoq9HaxOMMz+MQRv6Dj3x468c3+A98d2rvnwIdodepdO0IA4AIqW1SXm5VKKCsrJ4uLS2ip9CoEnz49fvJMqLvXjs9Q7fUKN4lIiJJTL2ytVygoqVSKs7Oz6YsXhQQvJAT89h8I+2L75hVgQ0NDfkdHByQlJTEJCQmsTCaDI0f8jQihdzlnyUmJbnV/1qCAU6d2aDQaEIvFEBQcDCKRiAkPDwcPjw2/bPD4aAXY1dUl7e/vB6FQSOXl5WGJRAKRkZFT/v7+7gEBAUgmk7m1t7ejsLCw7QMDA4xYLGYFAgGTlpZGxcbGwrFjx8KPHj26AiwoKLhSW1sL1dXVZEVFBd3U1ATl5eWTERER7rGxsai0tNRNJpOh0NDQbRKJBBcVFTHZ2dm4oqKCLCwshMTExPD09PQVYHJycrFcLofu7m5Qq9XQ29sLMplsgcfjuYeFhSGJROIWExODfHx8dmVmZoJSqQTOAPf6dXV1IBAIonJyclxAV/P5fN+8vLyY/Pz8iKKiosicnBx+SkrKudra2lXV1dUoMzMTBQUFoS1btryXkJDws1AojMrKyooQiUQR0dHRcXFxcTv4fD76H0UYZL0Yn+qRAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/b93170df5ed664fb844f977875b814fb/01267/output_47_0.png\"\n        srcset=\"/static/b93170df5ed664fb844f977875b814fb/e9ff0/output_47_0.png 180w,\n/static/b93170df5ed664fb844f977875b814fb/f21e7/output_47_0.png 360w,\n/static/b93170df5ed664fb844f977875b814fb/01267/output_47_0.png 713w\"\n        sizes=\"(max-width: 713px) 100vw, 713px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<div class=\"table-of-contents\">\n<ul>\n<li>\n<p><a href=\"#%ED%99%9C%EC%84%B1%ED%99%94-%ED%95%A8%EC%88%98-%EC%8B%9C%EA%B7%B8%EB%AA%A8%EC%9D%B4%EB%93%9C-%EC%9D%98-%EC%98%88\">활성화 함수 시그모이드 의 예</a></p>\n<ul>\n<li>\n<ul>\n<li><a href=\"#%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%97%90%EC%84%9C-%ED%99%9C%EC%84%B1%ED%99%94-%ED%95%A8%EC%88%98%EB%A5%BC-%EC%93%B0%EB%8A%94-%ED%81%B0-%EC%9D%B4%EC%9C%A0%EB%8A%94\">딥러닝에서 활성화 함수를 쓰는 큰 이유는</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#%ED%99%9C%EC%84%B1%ED%99%94-%ED%95%A8%EC%88%98%EC%9D%98-%EC%A2%85%EB%A5%98\">활성화 함수의 종류</a></p>\n</li>\n</ul>\n</li>\n<li>\n<p><a href=\"#binary-step-function\">binary step function</a></p>\n<ul>\n<li>\n<ul>\n<li><a href=\"#%EC%84%A0%ED%98%95%ED%99%9C%EC%84%B1%ED%99%94-%ED%95%A8%EC%88%98%EB%8A%94-%EC%95%84%EA%B9%8C-%EB%A7%90%ED%96%87%EB%93%AF%EC%9D%B4-%EC%96%BC%EB%A7%88%EB%82%98-%EB%84%A3%EB%93%A0-%ED%95%98%EB%82%98%EC%9D%98-%ED%99%9C%EC%84%B1%ED%99%94-%ED%95%A8%EC%88%98%EB%9E%91-%EB%98%91%EA%B0%99%EA%B3%A0-%EB%B3%84%EB%A1%9C%EB%8B%88%EA%B9%8C-%EB%84%98%EC%96%B4%EA%B0%84%EB%8B%A4\">선형활성화 함수는 아까 말햇듯이 얼마나 넣든 하나의 활성화 함수랑 똑같고 별로니까 넘어간다</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#%EC%A2%85%EB%A5%98\">종류</a></p>\n</li>\n<li>\n<p><a href=\"#%EC%8B%9C%EA%B7%B8%EB%AA%A8%EC%9D%B4%EB%93%9C%EB%8A%94\">시그모이드는</a></p>\n<ul>\n<li><a href=\"#%EB%8B%A8%EC%A0%90\">단점</a></li>\n<li><a href=\"#%EB%AF%B8%EB%B6%84%ED%95%A0%EB%95%8C%EB%8A%94-0%EC%9D%98-%EA%B2%BD%EC%9A%B0%EC%97%90%EB%A7%8C-0%EB%98%90%EB%8A%94-1%EC%9D%84-%EB%AC%B4%EC%9E%91%EC%9C%84%EB%A1%9C-%EB%B0%B0%EC%B6%9C%ED%95%9C%EB%8B%A4\">미분할때는 0의 경우에만 0,또는 1을 무작위로 배출한다.</a></li>\n<li><a href=\"#%EB%8B%A8%EC%A0%90--dying-relu\">단점 : Dying ReLU</a></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</div>","frontmatter":{"date":"May 20, 2022","title":"활성화 함수란?","categories":"DeepML","author":"하성민","emoji":"😁"},"fields":{"slug":"/DML_AI5/"}},"site":{"siteMetadata":{"siteUrl":"https://xman227.github.io","comments":{"utterances":{"repo":""}}}}},"pageContext":{"slug":"/DML_norm/","nextSlug":"/DML_AI4/","prevSlug":"/DML_AI5/"}},
    "staticQueryHashes": ["1073350324","1956554647","2938748437"]}