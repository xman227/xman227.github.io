{
    "componentChunkName": "component---src-templates-category-template-js",
    "path": "/posts/NLP",
    "result": {"pageContext":{"currentCategory":"NLP","categories":["All","Python","DeepML","beginner","NLP","회고"],"edges":[{"node":{"id":"6f2cd6e3-4d52-59b8-8a55-7fe83eb9f0c7","excerpt":"임베딩이란..? 단어를 표현하기 위해서는 적어도 1차원에서는 안된다 (의미가 담기기엔 작다) 그래서 벡터의 특정 차원을 직접 만들어 의미를 직접 mapping 해야 하고, 이를 희소 표현 (Sparse Representation) 이라고 한다. 반면에 그냥 차원은 일정하게 256차원 이렇게 정해놓고 유사한 맥락에서 자주 나오는 단어들은 의미가 비슷하다고 판단하는 방식을\n분포 가설 (distribution hypothesis) 이라고 한다. 그리고 이 가설을 통해 분산표현 (distribution Representation) 이라고 한다. 맥락이라 함은 단어 좌우에 함께 위치하는 단어를 의미한다. 분산표현 은 희소표현 과 달리 단어 간 유사도를 구할 수 있다. embedding 레이어라는 것은 이 단어의 분산표현을 구현하기 위한 레이어!!!!!!!!!!!!!!!!!!!!!! 우리가 단어를 n 개 쓸거야~ k차원으로 구현해조~ 하면 컴퓨터가 n x k 형태의 분산표현 사전을 만든다. …","fields":{"slug":"/NLP_4/"},"frontmatter":{"categories":"NLP","title":"임베딩이란","date":"April 21, 2022"}},"next":{"fields":{"slug":"/DML_EDA/EDA/"}},"previous":{"fields":{"slug":"/DML_AI1/"}}},{"node":{"id":"c1177e06-2486-565d-ab1e-fc6ef4f75243","excerpt":"Vectorize contexts BoW DTM 코사인 유사도 TF-IDF 가중치 LSA 특잇값 분해 LDA soynlp 응집확률 브랜칭 엔트로피 자연어 처리에서 꼭 필요한 텍스트 데이터의 Veoctorization 중에서도 통계와 머신러닝 사용하는 방법의 변천사에 대한 설명이다. 토큰화하는 방식은\nWord2vec 임베딩 모델이 생기기 전 정통적인 Vectorize 방식이었다. 현재는 Word2vec 기술을 사용하지만 단어를 학습시키기 위한 Vectorize 기술의 초기 개념을 이해하여 NLP 의 이해를 심화하도록 한다. 컴퓨터는 단어를 이해하지 못한다. 때문에 단어를 숫자 데이터로 표현하여야 한다. 하지만 단순히 단어를 1, 2, 3, 4.. 로 표현한다면 단어간의 차이를 정확하게 나타내지 못할 것이다 그러기 위해 vectorize 라는 기술이 생겨났다. 단어를 적절한 숫자 데이터로 변경하는 기술을 의미한다. 다음은 이 vectorize 의 문제점과 그 해결책을\n발전 순서대로 나…","fields":{"slug":"/NLP_3/"},"frontmatter":{"categories":"NLP","title":"NLP 전처리 필수 Vecorize","date":"March 25, 2022"}},"next":{"fields":{"slug":"/NLP_2/"}},"previous":{"fields":{"slug":"/DML_AI3/"}}},{"node":{"id":"a5f56b6d-f700-59e0-8291-651faebf1202","excerpt":"🙄 네이버 영화리뷰 감성분석에 SentencePiece 적용해보기 <NLP기초> Contexts 1. READY 2. GAME 3. POTG (best Play Of The Game 1. Ready 1-1. 오늘의 Exp와 Rubric SentencePiece 는 Google 에서 제공하고 있는 Tokenizer / Detokenizer 이다. Tokenize 란 NLP 에서 중요한 부분인 ‘단어사전 제작’ 을 의미한다. 직관적으로 생각했을 때, 단어사전은 단어별, 형태소별, 혹은 그 사이 어떤 경계를 나누어 만들 수 있다. Sentencepiece 는\nBPE 와 unigram 이라는 두 가지의 분리 방법을 통해 subword tokenizing model 을 제공하고 있다. 최근 pretrained model 은 대부분 SentencePiece 를 Tokenizer 로 설정하는 추세이기에 NLP 분야 tokenizer 의 표준이라고 표현해도 과언이 아니다. 오늘은 이러한 Sent…","fields":{"slug":"/NLP_2/"},"frontmatter":{"categories":"NLP","title":"SentencePiece Tokenizer 사용 방법","date":"March 23, 2022"}},"next":{"fields":{"slug":"/NLP_1/"}},"previous":{"fields":{"slug":"/NLP_3/"}}},{"node":{"id":"6d79397e-6ce5-58cd-bb09-adcf492b30f0","excerpt":"우리는 많은 문장들 속에서 살아간다. 한국어, 영어, 일본어, 중국어,, 영어 배워라 배워라 스트레스 받는것도 다 언어가 존재하기 때문이다. 이렇게 일상에서 사용하는 언어를 자연어(Natural Language) 라고 부른다. 반면에 우리가 쓰는 프로그래밍 언어는 기계어 또는 인공어(Artificial Language) 라고 부른다. (엄연히 따지면 자연어 안에 인공어가 속한다) 프로그래밍 언어는 자연어보다 훨씬 명료하고 처리하기에 용이하여야 하므로 자연어와 다르게 문맥과 상관없이 항상 동일한 의미를 가진다. 우리는 자연어를 처리해야 하기 때문에 사람이 하는 방식대로는 즉, 문맥을 이해하는 방식으로는 기계를 학습시키기가 어렵다. 때문에, 단어들을 숫자로 매핑해 표현하는 머신러닝 기법 을 사용한다. 그렇다면 각 단어들의 의미를 기계들도 이해하고 연산할 수 있을 것이다. 해당 블로그에서는 그렇게 수치화된 단어들간의 계산을 시도해 볼 수 있다. 이와 함께 단어를 어떻게 구분할 것인지(형…","fields":{"slug":"/NLP_1/"},"frontmatter":{"categories":"NLP","title":"NLP 에서 데이터 전처리 및 토큰화란","date":"March 15, 2022"}},"next":{"fields":{"slug":"/python_tasking/"}},"previous":{"fields":{"slug":"/NLP_2/"}}}]}},
    "staticQueryHashes": ["1073350324","1956554647","2938748437"]}